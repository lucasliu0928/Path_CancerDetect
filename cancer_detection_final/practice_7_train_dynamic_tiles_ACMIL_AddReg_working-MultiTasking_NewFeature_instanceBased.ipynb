{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from Eval import get_performance\n",
    "from train_utils import pull_tiles, FocalLoss, ModelReadyData_Instance_based, modify_to_instance_based\n",
    "from train_utils import convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from Model import Mutation_MIL_MT_sepAtt #, Mutation_MIL_MT\n",
    "from ACMIL import ACMIL_GA_MultiTask\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.utils import MetricLogger, SmoothedValue, adjust_learning_rate\n",
    "from timm.utils import accuracy\n",
    "import torchmetrics\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fe6b4f-a374-4a86-8276-e5a1bced8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABELS = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0.9 \n",
    "feature_extraction_method = 'uni2' #retccl, uni1\n",
    "focal_gamma = 2\n",
    "focal_alpha = 0.1\n",
    "loss_method = '' #ATTLOSS\n",
    "\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "SELECTED_FOLD = 0\n",
    "\n",
    "if feature_extraction_method == 'retccl':\n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,2048)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 2048\n",
    "elif feature_extraction_method == 'uni1': \n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,1024)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 1024\n",
    "elif feature_extraction_method == 'uni2':\n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,1536)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 1536\n",
    "\n",
    "################################\n",
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "\n",
    "conf.train_epoch = 100\n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.n_task = 7\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name_overlap = \"IMSIZE250_OL100\"\n",
    "folder_name_nonoverlap = \"IMSIZE250_OL0\"\n",
    "feature_path_opx_train =  os.path.join(proj_dir + 'intermediate_data/Old_5_model_ready_data', \"OPX\", folder_name_overlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_opx_test =  os.path.join(proj_dir + 'intermediate_data/Old_5_model_ready_data', \"OPX\", folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_tma = os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"TAN_TMA_Cores\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "folder_name_ids = 'uni1/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "train_val_test_id_path =  os.path.join(proj_dir + 'intermediate_data/6_Train_TEST_IDS', folder_name_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02262025——Instance_based/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02262025——Instance_based/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02262025——Instance_based/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02262025——Instance_based/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02262025——Instance_based/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02262025——Instance_based/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#Create output-dir\n",
    "################################################\n",
    "folder_name1 = feature_extraction_method + '/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out02262025——Instance_based\" + \"/\" + folder_name1 + 'FOLD' + str(SELECTED_FOLD) + '/' + SELECTED_MUTATION + \"/\" \n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "opx_data_ol100 = torch.load(feature_path_opx_train + '/OPX_data.pth')\n",
    "opx_ids_ol100 = torch.load(feature_path_opx_train + '/OPX_ids.pth')\n",
    "opx_info_ol100  = torch.load(feature_path_opx_train + '/OPX_info.pth')\n",
    "\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')\n",
    "opx_ids_ol0 = torch.load(feature_path_opx_test + '/OPX_ids.pth')\n",
    "opx_info_ol0  = torch.load(feature_path_opx_test + '/OPX_info.pth')\n",
    "\n",
    "tma_data = torch.load(feature_path_tma + '/tma_data.pth')\n",
    "tma_ids = torch.load(feature_path_tma + '/tma_ids.pth')\n",
    "tma_info  = torch.load(feature_path_tma + '/tma_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1f8a8-cf34-43b9-80f8-94339c4c5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#Update tma\n",
    "########################################################\n",
    "haslabel_indexes = []\n",
    "for i in range(len(tma_data)):\n",
    "    if torch.isnan(tma_data[i][1]).all() == False:\n",
    "        #print(f\"Item {i} has the second element all NaNs.\")\n",
    "        haslabel_indexes.append(i)\n",
    "\n",
    "\n",
    "tma_data = Subset(tma_data, haslabel_indexes)\n",
    "tma_ids = list(Subset(tma_ids, haslabel_indexes))\n",
    "tma_info = list(Subset(tma_info, haslabel_indexes))\n",
    "len(tma_info) #355 if TF0.9, a lot of cores does not have enough cancer tiles > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a40cb-f7ca-4128-9fee-7d8f045af85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get train, test IDs\n",
    "#NOTE: this was in the old train: ['OPX_207','OPX_209','OPX_213','OPX_214','OPX_215']\n",
    "################################################\n",
    "train_test_val_id_df = pd.read_csv(train_val_test_id_path + \"train_test_split.csv\")\n",
    "train_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TRAIN', 'SAMPLE_ID'])\n",
    "test_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TEST', 'SAMPLE_ID'])\n",
    "val_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'VALID', 'SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6998013-f398-4d47-a884-3751784365a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get Train, test, val data\n",
    "################################################\n",
    "#Train:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in train_ids_all]\n",
    "train_data = Subset(opx_data_ol100, inc_idx)\n",
    "train_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "train_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "\n",
    "#Val:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in val_ids_all]\n",
    "val_data = Subset(opx_data_ol100, inc_idx)\n",
    "val_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "val_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "\n",
    "#Test:\n",
    "inc_idx = [opx_ids_ol0.index(x) for x in test_ids_all]\n",
    "test_data = Subset(opx_data_ol0, inc_idx)\n",
    "test_ids =  list(Subset(opx_ids_ol0, inc_idx))\n",
    "test_info = list(Subset(opx_info_ol0, inc_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count labels in train\n",
    "train_label_counts = [dt[1] for dt in train_data]\n",
    "train_label_counts = torch.concat(train_label_counts)\n",
    "count_ones = (train_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/train_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)\n",
    "\n",
    "#count labels in test\n",
    "test_label_counts = [dt[1] for dt in test_data]\n",
    "test_label_counts = torch.concat(test_label_counts)\n",
    "count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)\n",
    "\n",
    "#count labels in tma\n",
    "tma_label_counts = [dt[1] for dt in tma_data] \n",
    "tma_label_counts = torch.concat(tma_label_counts)\n",
    "count_ones = (tma_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/tma_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366126c0-daa8-4bbb-a487-b51a2e07d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06414d41-e0df-4ae7-9922-238647f45b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify data\n",
    "train_data = modify_to_instance_based(train_data)\n",
    "#test_data = modify_to_instance_based(test_data)\n",
    "#val_data = modify_to_instance_based(val_data)\n",
    "#tma_data = modify_to_instance_based(tma_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d453f5-0919-4380-8908-e3cf002e2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "BATCH_SIZE = 32\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=1, shuffle=False)\n",
    "tma_loader = DataLoader(dataset=tma_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a784e6-2884-46af-b39d-6d68059121fc",
   "metadata": {},
   "source": [
    "## TDOD\n",
    "## For TEST, one batch one patient, prediction if there is one tile predicted postive, then postive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9779ad-390b-4126-b38c-a603496fe3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instance_Based(nn.Module):\n",
    "    def __init__(self, in_features = 2048, act_func = 'tanh', drop_out = 0, n_outcomes = 7, dim_out = 128):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features  \n",
    "        self.n_outs = n_outcomes     # number of outcomes\n",
    "        self.d_out = dim_out          # dim of output layers\n",
    "        self.drop_out = drop_out\n",
    "\n",
    "        if act_func == 'leakyrelu':\n",
    "            self.act_func = nn.LeakyReLU()\n",
    "        if act_func == 'tanh':\n",
    "            self.act_func = nn.Tanh()\n",
    "        elif act_func == 'relu':\n",
    "            self.act_func = nn.ReLU()\n",
    " \n",
    "        self.embedding_layer = nn.Sequential(\n",
    "            nn.Linear(self.in_features, 1024), #linear layer\n",
    "            self.act_func,\n",
    "            nn.Linear(1024, 512), #linear layer\n",
    "            self.act_func,\n",
    "            nn.Linear(512, 256), #linear layer\n",
    "            self.act_func,\n",
    "            nn.Linear(256, self.d_out), #linear layer\n",
    "        )\n",
    "\n",
    "        #Outcome layers\n",
    "        self.hidden_layers =  nn.ModuleList([nn.Linear(self.d_out, 1) for _ in range(self.n_outs)])        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r'''\n",
    "        x size: [1, N_TILE ,N_FEATURE]\n",
    "        '''\n",
    "        #out = x\n",
    "        \n",
    "        #Linear\n",
    "        x = self.embedding_layer(x) #[1, N_TILE ,d_out]\n",
    "\n",
    "        out = []\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            cur_out = self.hidden_layers[i](x) #[BS, 1]\n",
    "            out.append(cur_out)\n",
    "\n",
    "        #Drop out\n",
    "        if self.drop_out > 0:\n",
    "            for i in range(len(self.hidden_layers)):\n",
    "                out[i] = self.dropout(out[i])\n",
    "        \n",
    "        # # predict \n",
    "        # for i in range(len(self.hidden_layers)):\n",
    "        #     out[i] = torch.sigmoid(out[i])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cee9a-95b9-4a80-b9c4-1c02a3060f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "model = Instance_Based(in_features = N_FEATURE, act_func = 'tanh', drop_out = 0, n_outcomes = 7, dim_out = DIM_OUT)\n",
    "model.to(device)\n",
    "\n",
    "# Example usage:\n",
    "criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "#criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2638697-b798-4c88-a996-068f7c84cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_instance_based(model, criterion, data_loader, optimizer0, device, epoch, conf, loss_method = 'none'):\n",
    "    \"\"\"\n",
    "    Trains the given network for one epoch according to given criterions (loss functions)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the network to training mode\n",
    "    model.train()\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 5000\n",
    "\n",
    "\n",
    "    for data_it, data in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "        # for data_it, data in enumerate(data_loader, start=epoch * len(data_loader)):\n",
    "        # Move input batch onto GPU if eager execution is enabled (default), else leave it on CPU\n",
    "        # Data is a dict with keys `input` (patches) and `{task_name}` (labels for given task)\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        label_lists = data[1]\n",
    "\n",
    "        # # Calculate and set new learning rate\n",
    "        adjust_learning_rate(optimizer0, epoch + data_it/len(data_loader), conf)\n",
    "\n",
    "        # Compute loss        \n",
    "        out = model(image_patches) #torch.Size([BS, 1])\n",
    "        \n",
    "        #Compute loss for each task, then sum\n",
    "        loss = 0\n",
    "        for k in range(conf.n_task):\n",
    "            slide_preds = out[k]\n",
    "            labels = label_lists[:,k].to(device, dtype = torch.float32).to(device)\n",
    "            loss += criterion(slide_preds, labels.unsqueeze(1))\n",
    "            pred = torch.sigmoid(slide_preds)\n",
    "            \n",
    "        optimizer0.zero_grad()\n",
    "        # Backpropagate error and update parameters\n",
    "        loss.backward()\n",
    "        optimizer0.step()\n",
    "\n",
    "\n",
    "        metric_logger.update(lr=optimizer0.param_groups[0]['lr'])\n",
    "        metric_logger.update(total_loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33e1fc-d404-4cbc-b218-ce86a650aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient calculation during evaluation\n",
    "@torch.no_grad()\n",
    "def evaluate_instance_based(net, criterion, data_loader, device, conf, header):\n",
    "\n",
    "    # Set the network to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "    for data in metric_logger.log_every(data_loader, 100, header):\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        label_lists = data[1]\n",
    "\n",
    "        out = model(image_patches) #torch.Size([BS, 1])\n",
    "        \n",
    "        #Compute loss for each task, then sum\n",
    "        loss = 0\n",
    "        pred_list = []\n",
    "        acc1_list = []\n",
    "        for k in range(conf.n_task):\n",
    "            slide_preds = out[k]\n",
    "            labels = label_lists[:,k].to(device, dtype = torch.int64).to(device)\n",
    "            loss += criterion(slide_preds, labels)\n",
    "            pred = torch.sigmoid(slide_preds)\n",
    "            acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "            pred_list.append(pred)\n",
    "            acc1_list.append(acc1)\n",
    "            \n",
    "        avg_acc = sum(acc1_list)/conf.n_task\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters['acc1'].update(avg_acc.item(), n=labels.shape[0])\n",
    "\n",
    "        y_pred.append(pred_list)\n",
    "        y_true.append(label_lists)\n",
    "\n",
    "    #Get prediction for each task\n",
    "    y_pred_tasks = []\n",
    "    y_true_tasks = []\n",
    "    for k in range(conf.n_task):\n",
    "        y_pred_tasks.append([p[k] for p in y_pred])\n",
    "        y_true_tasks.append([t[:,k].to(device, dtype = torch.int64) for t in y_true])\n",
    "    \n",
    "    #get performance for each calss\n",
    "    auroc_each = 0\n",
    "    f1_score_each = 0\n",
    "    for k in range(conf.n_task):\n",
    "        y_pred_each = torch.cat(y_pred_tasks[k], dim=0)\n",
    "        y_true_each = torch.cat(y_true_tasks[k], dim=0)\n",
    "    \n",
    "        AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "        AUROC_metric(y_pred_each, y_true_each)\n",
    "        auroc_each += AUROC_metric.compute().item()\n",
    "    \n",
    "        F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "        F1_metric(y_pred_each, y_true_each)\n",
    "        f1_score_each += F1_metric.compute().item()\n",
    "        print(\"AUROC\",str(k),\":\",AUROC_metric.compute().item())\n",
    "    auroc = auroc_each/conf.n_task\n",
    "    f1_score = f1_score_each/conf.n_task\n",
    "\n",
    "    # print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f} auroc {AUROC:.3f} f1_score {F1:.3f}'\n",
    "    #       .format(top1=metric_logger.acc1, losses=metric_logger.loss, AUROC=auroc, F1=f1_score))\n",
    "\n",
    "    # return auroc, metric_logger.acc1.global_avg, f1_score, metric_logger.loss.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56d090-d7ed-463a-9b60-ea19dc430921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slide_preds.shape)\n",
    "print(labels.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95b55d-feb2-4429-84bf-b0534c416276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the network to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "for data in metric_logger.log_every(test_loader, 100000, \"\"):\n",
    "    image_patches = data[0].to(device, dtype=torch.float32)\n",
    "    label_lists = data[1]\n",
    "\n",
    "    out = model(image_patches) #torch.Size([BS, 1])\n",
    "    \n",
    "    #Compute loss for each task, then sum\n",
    "    loss = 0\n",
    "    pred_list = []\n",
    "    acc1_list = []\n",
    "    for k in range(conf.n_task):\n",
    "        slide_preds = out[k]\n",
    "        labels = label_lists[:,k].to(device, dtype = torch.float32).to(device)\n",
    "        loss += criterion(slide_preds, labels.unsqueeze(0))\n",
    "        pred = torch.sigmoid(slide_preds)\n",
    "        acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "        pred_list.append(pred)\n",
    "        acc1_list.append(acc1)\n",
    "        \n",
    "    avg_acc = sum(acc1_list)/conf.n_task\n",
    "\n",
    "    metric_logger.update(loss=loss.item())\n",
    "    metric_logger.meters['acc1'].update(avg_acc.item(), n=labels.shape[0])\n",
    "    \n",
    "    y_pred.append(pred_list)\n",
    "    y_true.append(label_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6ac4e-c654-4518-a317-07119fa25efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lists[:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e72a50-665b-4361-8477-479df3601af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction for each task\n",
    "y_pred_tasks = []\n",
    "y_true_tasks = []\n",
    "for k in range(conf.n_task):\n",
    "    y_pred_tasks.append([p[k] for p in y_pred])\n",
    "    y_true_tasks.append([t[:,k].to(device, dtype = torch.int64) for t in y_true])\n",
    "\n",
    "#get performance for each calss\n",
    "auroc_each = 0\n",
    "f1_score_each = 0\n",
    "for k in range(conf.n_task):\n",
    "    y_pred_each = torch.cat(y_pred_tasks[k], dim=0)\n",
    "    y_true_each = torch.cat(y_true_tasks[k], dim=0)\n",
    "\n",
    "    AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "    AUROC_metric(y_pred_each, y_true_each)\n",
    "    auroc_each += AUROC_metric.compute().item()\n",
    "\n",
    "    F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "    F1_metric(y_pred_each, y_true_each)\n",
    "    f1_score_each += F1_metric.compute().item()\n",
    "    print(\"AUROC\",str(k),\":\",AUROC_metric.compute().item())\n",
    "auroc = auroc_each/conf.n_task\n",
    "f1_score = f1_score_each/conf.n_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616b54e-8daa-417e-a1b3-ad4bb8a64b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_instance_based(model, criterion, val_loader, device, conf, 'Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = outdir1 + SELECTED_MUTATION + \"/\"\n",
    "create_dir_if_not_exists(ckpt_dir)\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "\n",
    "\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "train_epoch = conf.train_epoch\n",
    "for epoch in range(train_epoch):\n",
    "    train_one_epoch_instance_based(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "\n",
    "    #val_auc, val_acc, val_f1, val_loss = evaluate_instance_based(model, criterion, val_loader, device, conf, 'Val')\n",
    "    #test_auc, test_acc, test_f1, test_loss = evaluate_instance_based(model, criterion, test_loader, device, conf, 'Test')\n",
    "    #tma_auc, tma_acc, tma_f1, tma_loss = evaluate_multitask(model, criterion, tma_loader, device, conf, 'TMA')\n",
    "\n",
    "    save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "        save_path=os.path.join(ckpt_dir + 'checkpoint_' + 'epoch' + str(epoch) + '.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07377042-2f38-4f48-9c86-b37329f2e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "model2 = Instance_Based(in_features = N_FEATURE, act_func = 'tanh', drop_out = 0, n_outcomes = 7, dim_out = DIM_OUT)\n",
    "model2.to(device)\n",
    "\n",
    "# Load the checkpoint\n",
    "#checkpoint = torch.load(ckpt_dir + 'checkpoint-best.pth')\n",
    "checkpoint = torch.load(ckpt_dir + 'checkpoint_epoch99.pth')\n",
    "\n",
    "# Load the state_dict into the model\n",
    "model2.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model2, criterion, test_loader, device, conf, 'Test')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], test_ids, ALL_LABELS[i],THRES = round(np.quantile(y_predprob_task_test[i],0.8),2))\n",
    "    pred_df_list.append(pred_df)\n",
    "    perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd25184-b2da-41cd-8f7e-af52b487fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
