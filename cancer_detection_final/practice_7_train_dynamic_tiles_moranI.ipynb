{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg9 env\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles\n",
    "from train_utils import ModelReadyData_diffdim, add_tile_xy, convert_to_dict, prediction_m, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels\n",
    "from Model import Mutation_MIL_MoransI\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out011325/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out011325/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out011325/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out011325/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out011325/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out011325/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "TUMOR_FRAC_THRES = 0.9\n",
    "feature_extraction_method = 'retccl'\n",
    "INCLUDE_TF = False\n",
    "INCLUDE_CLUSTER = False\n",
    "N_CLUSTERS = 4\n",
    "focal_gamma = 2\n",
    "\n",
    "\n",
    "####\n",
    "#model Para\n",
    "LEARNING_RATE = 0.00001 \n",
    "BATCH_SIZE  = 1\n",
    "ACCUM_SIZE = 16  # Number of steps to accumulate gradients\n",
    "EPOCHS = 500\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 5\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2048\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2049\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2049\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2050\n",
    "            \n",
    "\n",
    "LOSS_FUNC_NAME = \"BCE_Weighted_Reg_focal\" #\"BCE_Weighted_Reg\", \"BCE_Weighted_Reg_focal\"\n",
    "REG_COEEF = 0.0000001\n",
    "REG_TYPE = 'L1'\n",
    "OPTMIZER = \"ADAM\"\n",
    "ATT_REG_FLAG = False\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "\n",
    "if SELECTED_MUTATION == \"MT\":\n",
    "    N_LABELS = len(SELECTED_LABEL)\n",
    "    LOSS_WEIGHTS_LIST = [[1, 50], [1, 100], [1, 50], [1, 100], [1, 100], [1, 50], [1, 50]]  #NEG, POS\n",
    "else:\n",
    "    N_LABELS = 1\n",
    "    LOSS_WEIGHTS_LIST = [[1, 10], [1, 10], [1, 50], [1, 100], [1, 100], [1, 100], [1, 20]]  #NEG, POS\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name = feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "in_data_path = proj_dir + 'intermediate_data/model_ready_data/feature_' + folder_name + \"model_input/\"\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    feature_type = \"emb_only\"\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    feature_type = \"emb_and_tf\"\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    feature_type = \"emb_and_cluster\" + str(N_CLUSTERS)\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    feature_type = \"emb_and_tf_and_cluster\" + str(N_CLUSTERS) \n",
    "\n",
    "model_data_path =  in_data_path + feature_type + \"/\"\n",
    "    \n",
    "################################################\n",
    "#Create output-dir\n",
    "################################################\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out011325/\" + folder_name + \"/DL_\" + feature_type + \"/\" + SELECTED_MUTATION + \"/\"\n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data = torch.load(model_data_path + 'train_data.pth')\n",
    "test_data_old = torch.load(model_data_path + 'test_data.pth')\n",
    "test_data_add = torch.load(model_data_path + 'newMSI_test_data.pth')\n",
    "val_data = torch.load(model_data_path + 'val_data.pth')\n",
    "\n",
    "test_ids_old = torch.load(model_data_path + 'test_ids.pth')\n",
    "test_ids_add = torch.load(model_data_path + 'newMSI_test_ids.pth')\n",
    "test_info_old  = torch.load(model_data_path + 'test_info.pth')\n",
    "test_info_add  = torch.load(model_data_path + 'newMSI_test_info.pth')\n",
    "\n",
    "train_info = torch.load(model_data_path + 'train_info.pth')\n",
    "val_info = torch.load(model_data_path + 'val_info.pth')\n",
    "\n",
    "#Add train info to train_data\n",
    "train_data = add_tile_xy(train_data, train_info)\n",
    "val_data = add_tile_xy(val_data, val_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90776496-5604-4e00-a385-588b09eef589",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Exclude OPX_085, Prostate cancer find in colorectal site, patterns are for CRC, not for prostate\n",
    "################################################\n",
    "exc_idx = test_ids_old.index('OPX_085')\n",
    "inc_idx = [i for i in range(len(test_data_old)) if i not in [exc_idx]]\n",
    "\n",
    "#Update old testset\n",
    "test_data_old = Subset(test_data_old, inc_idx)\n",
    "removed_id =   test_ids_old.pop(exc_idx)  \n",
    "removed_info = test_info_old.pop(exc_idx)  \n",
    "\n",
    "################################################\n",
    "#Combine old and new test data\n",
    "################################################\n",
    "test_data  = ConcatDataset([test_data_old, test_data_add])\n",
    "test_ids = test_ids_old +  test_ids_add\n",
    "test_info = test_info_old +  test_info_add\n",
    "\n",
    "test_data = add_tile_xy(test_data, test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ec9bf6-2e4f-4fd0-80c5-11dd1c125926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  6, 14,  5, 19, 12, 12])\n",
      "tensor([10.2041, 12.2449, 28.5714, 10.2041, 38.7755, 24.4898, 24.4898])\n"
     ]
    }
   ],
   "source": [
    "#count labels in test\n",
    "test_label_counts = [dt[1] for dt in test_data]\n",
    "test_label_counts = torch.concat(test_label_counts)\n",
    "count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "print(perc_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 956587\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "#Construct model\n",
    "model = Mutation_MIL_MoransI(in_features = N_FEATURE, \n",
    "                        act_func = 'tanh', \n",
    "                        drop_out = DROPOUT,\n",
    "                        n_outcomes = N_LABELS,\n",
    "                        dim_out = DIM_OUT)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#Optimizer\n",
    "if OPTMIZER == \"ADAM\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTMIZER == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Loss\n",
    "if LOSS_FUNC_NAME == \"BCE_Weighted_Reg\":\n",
    "    loss_func = BCE_Weighted_Reg(REG_COEEF, REG_TYPE, model, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "elif LOSS_FUNC_NAME == \"BCE_Weighted_Reg_focal\":\n",
    "    loss_func = BCE_Weighted_Reg_focal(REG_COEEF, REG_TYPE, model, gamma = focal_gamma, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "elif LOSS_FUNC_NAME == \"BCELoss\":\n",
    "    loss_func = torch.nn.BCELoss()\n",
    "    \n",
    "\n",
    "#Model para\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "#print(model)\n",
    "\n",
    "\n",
    "#OUTPUT MODEL hyper-para\n",
    "hyper_df = pd.DataFrame({\"Target_Mutation\": SELECTED_MUTATION,\n",
    "                         \"TRAIN_OVERLAP\": TRAIN_OVERLAP,\n",
    "                         \"TEST_OVERLAP\": TEST_OVERLAP,\n",
    "                         \"TRAIN_SAMPLE_SIZE\": TRAIN_SAMPLE_SIZE,\n",
    "                         \"TUMOR_FRAC_THRES\": TUMOR_FRAC_THRES,\n",
    "                         \"N_FEATURE\": N_FEATURE,\n",
    "                         \"N_LABELS\": N_LABELS,\n",
    "                         \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                         \"ACCUM_SIZE\": ACCUM_SIZE,\n",
    "                         \"N_EPOCH\": EPOCHS,\n",
    "                         \"OPTMIZER\": OPTMIZER,\n",
    "                         \"LEARNING_RATE\": LEARNING_RATE,\n",
    "                         \"DROPOUT\": DROPOUT,\n",
    "                         \"DIM_OUT\": DIM_OUT,\n",
    "                         \"REG_TYPE\": REG_TYPE,\n",
    "                         \"REG_COEEF\": REG_COEEF,\n",
    "                         \"LOSS_FUNC_NAME\": LOSS_FUNC_NAME,\n",
    "                         \"LOSS_WEIGHTS_LIST\": str(LOSS_WEIGHTS_LIST),\n",
    "                         \"ATT_REG_FLAG\": ATT_REG_FLAG,\n",
    "                         \"NUM_MODEL_PARA\": total_params}, index = [0])\n",
    "hyper_df.to_csv(outdir2 + \"hyperpara_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f1cc8-6b2a-45f4-96e7-09a5d9e604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_message(\"Start Training\", outdir3 + \"training_log.txt\")\n",
    "####################################################################################\n",
    "#Training\n",
    "####################################################################################\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    ct = 0\n",
    "    optmizer_loss = 0\n",
    "    for x,y,tf, coor in train_loader:\n",
    "        ct += 1\n",
    "        #optimizer.zero_grad() #zero the grad\n",
    "        yhat_list, train_att_list = model(x.to(device), coor.to(device)) #Forward\n",
    "\n",
    "        #compute loss\n",
    "        loss = compute_loss_for_all_labels(yhat_list, y, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf , train_att_list, SELECTED_MUTATION, SELECTED_LABEL)\n",
    "\n",
    "        running_loss += loss.detach().item() #acuumalated batch loss\n",
    "        optmizer_loss += loss #accumalted loss for optimizer\n",
    "       \n",
    "        #Optimize\n",
    "        if ct % ACCUM_SIZE == 0:\n",
    "            optmizer_loss = optmizer_loss/ACCUM_SIZE\n",
    "            optmizer_loss.backward() \n",
    "            optimizer.step()  # Optimize\n",
    "            optmizer_loss = 0\n",
    "            optimizer.zero_grad() #gradient reset\n",
    "\n",
    "    #Training loss \n",
    "    epoch_loss = running_loss/len(train_loader) #accumulated loss/total # batches (averaged loss over batches)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_running_loss = 0\n",
    "        for x_val,y_val,tf_val,coor_val in val_loader:\n",
    "            val_yhat_list, val_att_list = model(x_val.to(device),coor_val.to(device))\n",
    "            val_loss = compute_loss_for_all_labels(val_yhat_list, y_val, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf_val, val_att_list, SELECTED_MUTATION, SELECTED_LABEL)\n",
    "            val_running_loss += val_loss.detach().item() \n",
    "        val_epoch_loss = val_running_loss/len(val_loader) \n",
    "        valid_loss.append(val_epoch_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch\"+ str(epoch) + \":\",\n",
    "              \"Train-LOSS:\" + \"{:.5f}\".format(train_loss[epoch]) + \", \" +\n",
    "              \"Valid-LOSS:\" +  \"{:.5f}\".format(valid_loss[epoch]))\n",
    "    \n",
    "    #Save model parameters\n",
    "    torch.save(model.state_dict(), outdir1 + \"model\" + str(epoch))\n",
    "\n",
    "\n",
    "#Plot LOSS\n",
    "plot_LOSS(train_loss,valid_loss, outdir1)\n",
    "log_message(\"End Training\", outdir3 + \"training_log.txt\")\n",
    "\n",
    "#SAVE VALIDATION LOSS\n",
    "valid_loss_df  = pd.DataFrame({\"VALID_LOSS\": valid_loss})\n",
    "valid_loss_df.to_csv(outdir1 + \"Valid_LOSS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47bf67b-a36c-4336-89dd-bee6b77e66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Loss TOTAL: 5.02730\n",
      "               AUC  Recall  Precision  Specificity    PR_AUC  \\\n",
      "SAMPLE_LEVEL  0.43     0.0       0.00         1.00  0.103153   \n",
      "SAMPLE_LEVEL  0.27     0.5       0.09         0.28  0.103815   \n",
      "SAMPLE_LEVEL  0.45     1.0       0.29         0.00  0.296823   \n",
      "SAMPLE_LEVEL  0.39     1.0       0.10         0.00  0.104458   \n",
      "SAMPLE_LEVEL  0.43     0.0       0.00         1.00  0.341050   \n",
      "SAMPLE_LEVEL  0.50     0.0       0.00         1.00  0.247230   \n",
      "SAMPLE_LEVEL  0.47     1.0       0.24         0.00  0.242837   \n",
      "\n",
      "                                                       OUTCOME  \n",
      "SAMPLE_LEVEL                                                AR  \n",
      "SAMPLE_LEVEL  MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2  \n",
      "SAMPLE_LEVEL                                              PTEN  \n",
      "SAMPLE_LEVEL                                               RB1  \n",
      "SAMPLE_LEVEL                                              TP53  \n",
      "SAMPLE_LEVEL                           TMB_HIGHorINTERMEDITATE  \n",
      "SAMPLE_LEVEL                                           MSI_POS  \n",
      "AVG AUC: 0.42\n",
      "AVG PRAUC: 0.21\n"
     ]
    }
   ],
   "source": [
    "## #Testing\n",
    "####################################################################################\n",
    "#Load model\n",
    "#valid_loss_df = pd.read_csv(outdir1 + \"Valid_LOSS.csv\")\n",
    "#min_index = valid_loss_df['VALID_LOSS'].idxmin()\n",
    "#print(min_index)\n",
    "min_index = 272\n",
    "model = Mutation_MIL_MoransI(in_features = N_FEATURE, \n",
    "                        act_func = 'tanh', \n",
    "                        drop_out = DROPOUT,\n",
    "                        n_outcomes = N_LABELS,\n",
    "                        dim_out = DIM_OUT)\n",
    "state_dict = torch.load(outdir1 + \"model\" + str(min_index))\n",
    "\n",
    "#model2 = Mutation_MIL_MT(in_features = 2048, act_func = 'tanh', drop_out = DROPOUT)\n",
    "#model_dir = \"/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/z_old_mutation_prediction_results/mutation_pred_out_11272024/MAX_SS0_NFEATURES2048/MT/saved_model/MIL/\"\n",
    "#state_dict = torch.load(model_dir + \"model\" + str(499))\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#Loss function\n",
    "loss_func = torch.nn.BCELoss()\n",
    "THRES = 0.5\n",
    "\n",
    "#predicts\n",
    "test_pred_prob, test_true_label, test_att, test_loss = prediction_m(test_loader, model, N_LABELS, loss_func, device, SELECTED_MUTATION, SELECTED_LABEL, attention = True)\n",
    "print(\"Test-Loss TOTAL: \" + \"{:.5f}\".format(test_loss))\n",
    "\n",
    "\n",
    "#Prediction df\n",
    "pred_df_list = []\n",
    "for i in range(0,N_LABELS):\n",
    "    if N_LABELS > 1:\n",
    "        cur_pred_df = pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                                              \"Y_True\": [l[i] for l in test_true_label], \n",
    "                                              \"Pred_Prob\" :  [l[i] for l in test_pred_prob],\n",
    "                                              #\"Pred_Prob\" :  test_pred_prob,\n",
    "                                              \"OUTCOME\": SELECTED_LABEL[i]})\n",
    "    else:\n",
    "        cur_pred_df = pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                                    \"Y_True\": [l[i] for l in test_true_label], \n",
    "                                    \"Pred_Prob\" :  test_pred_prob,\n",
    "                                    \"OUTCOME\": SELECTED_MUTATION})\n",
    "        \n",
    "    pred_df_list.append(cur_pred_df)\n",
    "pred_df = pd.concat(pred_df_list)\n",
    "\n",
    "#Add Predict class\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(outdir4 + \"/pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "#Compute performance\n",
    "if SELECTED_MUTATION == \"MT\":\n",
    "    perf_df = compute_performance_each_label(SELECTED_LABEL, pred_df, \"SAMPLE_LEVEL\")\n",
    "else:\n",
    "    perf_df = compute_performance_each_label([SELECTED_MUTATION], pred_df, \"SAMPLE_LEVEL\")\n",
    "perf_df.to_csv(outdir5 + \"/perf.csv\",index = True)\n",
    "\n",
    "print(perf_df.iloc[:,[0,5,6,7,8,9]])\n",
    "print(\"AVG AUC:\", round(perf_df['AUC'].mean(),2))\n",
    "print(\"AVG PRAUC:\", round(perf_df['PR_AUC'].mean(),2))\n",
    "#Use regularization no dropout now has the best performance at avg AUC = 0.61"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
