{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg9 env\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction, BCE_Weighted_Reg, compute_loss_for_all_labels\n",
    "from Model import Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out/MAX_SSALL_TUMOR_TILES_NFEATURES2048_withTFandCLUSTER_TrainOL100_TestOL0/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out/MAX_SSALL_TUMOR_TILES_NFEATURES2048_withTFandCLUSTER_TrainOL100_TestOL0/MT/saved_model/MIL/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out/MAX_SSALL_TUMOR_TILES_NFEATURES2048_withTFandCLUSTER_TrainOL100_TestOL0/MT/model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out/MAX_SSALL_TUMOR_TILES_NFEATURES2048_withTFandCLUSTER_TrainOL100_TestOL0/MT/logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out/MAX_SSALL_TUMOR_TILES_NFEATURES2048_withTFandCLUSTER_TrainOL100_TestOL0/MT/predictions/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "model_name = \"MIL\" #Chose from Linear, LinearMT\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "SELECTED_FEATURE = [str(i) for i in range(0,2048)] \n",
    "TUMOR_FRAC_THRES = 0\n",
    "TRAIN_SAMPLE_SIZE = \"ALL_TUMOR_TILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "WITH_CLUSTER = True\n",
    "WITH_TF = True\n",
    "\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "label_path = proj_dir + 'data/MutationCalls/'\n",
    "model_path = proj_dir + 'models/feature_extraction_models/'\n",
    "ft_ids_path =  proj_dir + 'intermediate_data/cd_finetune/cancer_detection_training/' #the ID used for fine-tuning cancer detection model, needs to be excluded from mutation study\n",
    "train_tile_path = proj_dir + 'intermediate_data/cancer_prediction_results110224/IMSIZE250_OL' + str(TRAIN_OVERLAP) + '/'\n",
    "test_tile_path =  proj_dir + 'intermediate_data/cancer_prediction_results110224/IMSIZE250_OL' + str(TEST_OVERLAP) + '/'\n",
    "feature_name = 'features_alltiles_retccl'\n",
    "\n",
    "# if WITH_CLUSTER == False:\n",
    "#     model_data_path =  proj_dir + 'intermediate_data/model_ready_data/' + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_NFEATURES' + str(len(SELECTED_FEATURE)) + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '/'\n",
    "# else:\n",
    "#     model_data_path =  proj_dir + 'intermediate_data/model_ready_data/' + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_NFEATURES' + str(len(SELECTED_FEATURE)) + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + 'withCluster' + '/'\n",
    "model_data_path = proj_dir + '/intermediate_data/model_ready_data/MAX_SSALL_TUMOR_TILES_NFEATURES2048_withTFandCLUSTER_TrainOL100_TestOL0/split_fold0/'\n",
    "\n",
    "################################################\n",
    "#Create output-dir\n",
    "################################################\n",
    "if WITH_CLUSTER == False:\n",
    "    outdir0 =  proj_dir + \"intermediate_data/pred_out/\" + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_NFEATURES' + str(len(SELECTED_FEATURE)) + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '/'\n",
    "else:\n",
    "    outdir0 =  proj_dir + \"intermediate_data/pred_out/\" + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_NFEATURES2048_withTFandCLUSTER' + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '/'\n",
    "\n",
    "\n",
    "outdir1 =  outdir0  + SELECTED_MUTATION + \"/saved_model/\" + model_name + \"/\"\n",
    "outdir2 =  outdir0 + SELECTED_MUTATION + \"/model_para/\"\n",
    "outdir3 =  outdir0 + SELECTED_MUTATION + \"/logs/\"\n",
    "outdir4 =  outdir0 + SELECTED_MUTATION + \"/predictions/\"\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data = torch.load(model_data_path + 'train_data.pth')\n",
    "test_data = torch.load(model_data_path + 'test_data.pth')\n",
    "val_data = torch.load(model_data_path + 'val_data.pth')\n",
    "\n",
    "train_ids = torch.load(model_data_path + 'train_ids.pth')\n",
    "test_ids = torch.load(model_data_path + 'test_ids.pth')\n",
    "test_info  = torch.load(model_data_path + 'test_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE  = 1\n",
    "ACCUM_SIZE = 16  # Number of steps to accumulate gradients\n",
    "EPOCHS = 1000\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "if WITH_CLUSTER == False and WITH_TF == False:\n",
    "    N_FEATURE = len(SELECTED_FEATURE)\n",
    "else:\n",
    "    N_FEATURE = len(SELECTED_FEATURE) + 2\n",
    "N_LABELS = len(SELECTED_LABEL)\n",
    "LOSS_FUNC_NAME = \"BCE_Weighted_Reg\"\n",
    "LOSS_WEIGHTS_LIST = [[1, 100], [1, 100], [1, 50], [1, 100], [1, 100], [1, 10], [1, 20]]  #NEG, POS\n",
    "REG_COEEF = 0.001\n",
    "REG_TYPE = 'L1'\n",
    "OPTMIZER = \"ADAM\"\n",
    "ATT_REG_FLAG = True\n",
    "\n",
    "\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f1cc8-6b2a-45f4-96e7-09a5d9e604ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3052808\n",
      "Epoch0: Train-LOSS:335.72899, Valid-LOSS:299.27116\n",
      "Epoch10: Train-LOSS:314.22763, Valid-LOSS:282.18399\n",
      "Epoch20: Train-LOSS:285.29984, Valid-LOSS:265.43702\n",
      "Epoch30: Train-LOSS:254.65317, Valid-LOSS:246.99268\n",
      "Epoch40: Train-LOSS:233.78302, Valid-LOSS:231.24034\n",
      "Epoch50: Train-LOSS:217.63654, Valid-LOSS:217.10259\n",
      "Epoch60: Train-LOSS:203.13761, Valid-LOSS:203.38859\n",
      "Epoch70: Train-LOSS:189.52140, Valid-LOSS:190.10292\n",
      "Epoch80: Train-LOSS:176.60449, Valid-LOSS:177.34076\n",
      "Epoch90: Train-LOSS:164.33185, Valid-LOSS:165.15153\n",
      "Epoch100: Train-LOSS:152.68739, Valid-LOSS:153.55875\n",
      "Epoch110: Train-LOSS:141.66546, Valid-LOSS:142.57231\n",
      "Epoch120: Train-LOSS:131.26281, Valid-LOSS:132.19676\n",
      "Epoch130: Train-LOSS:121.48349, Valid-LOSS:122.44035\n",
      "Epoch140: Train-LOSS:112.33187, Valid-LOSS:113.31009\n",
      "Epoch150: Train-LOSS:103.81160, Valid-LOSS:104.81074\n",
      "Epoch160: Train-LOSS:95.92883, Valid-LOSS:96.94903\n",
      "Epoch170: Train-LOSS:88.68419, Valid-LOSS:89.72656\n",
      "Epoch180: Train-LOSS:82.07997, Valid-LOSS:83.14560\n",
      "Epoch190: Train-LOSS:76.12139, Valid-LOSS:77.21197\n",
      "Epoch200: Train-LOSS:70.81041, Valid-LOSS:71.92832\n",
      "Epoch210: Train-LOSS:66.15134, Valid-LOSS:67.29823\n",
      "Epoch220: Train-LOSS:62.14498, Valid-LOSS:63.32288\n",
      "Epoch230: Train-LOSS:58.79384, Valid-LOSS:60.00438\n",
      "Epoch240: Train-LOSS:56.07987, Valid-LOSS:57.31937\n",
      "Epoch250: Train-LOSS:53.90085, Valid-LOSS:55.15060\n",
      "Epoch260: Train-LOSS:52.00745, Valid-LOSS:53.25080\n",
      "Epoch270: Train-LOSS:50.29074, Valid-LOSS:51.52397\n",
      "Epoch280: Train-LOSS:48.71485, Valid-LOSS:49.93736\n",
      "Epoch290: Train-LOSS:47.26063, Valid-LOSS:48.47196\n",
      "Epoch300: Train-LOSS:45.91766, Valid-LOSS:47.11872\n",
      "Epoch310: Train-LOSS:44.67935, Valid-LOSS:45.87039\n",
      "Epoch320: Train-LOSS:43.54226, Valid-LOSS:44.72389\n",
      "Epoch330: Train-LOSS:42.50369, Valid-LOSS:43.67811\n",
      "Epoch340: Train-LOSS:41.56092, Valid-LOSS:42.72916\n",
      "Epoch350: Train-LOSS:40.70545, Valid-LOSS:41.86746\n",
      "Epoch360: Train-LOSS:39.92514, Valid-LOSS:41.08132\n",
      "Epoch370: Train-LOSS:39.20909, Valid-LOSS:40.36070\n",
      "Epoch380: Train-LOSS:38.54934, Valid-LOSS:39.69658\n",
      "Epoch390: Train-LOSS:37.93849, Valid-LOSS:39.08177\n",
      "Epoch400: Train-LOSS:37.37064, Valid-LOSS:38.51117\n",
      "Epoch410: Train-LOSS:36.84067, Valid-LOSS:37.97984\n",
      "Epoch420: Train-LOSS:36.34454, Valid-LOSS:37.48235\n",
      "Epoch430: Train-LOSS:35.87858, Valid-LOSS:37.01652\n",
      "Epoch440: Train-LOSS:35.43919, Valid-LOSS:36.57903\n",
      "Epoch450: Train-LOSS:35.02323, Valid-LOSS:36.16664\n",
      "Epoch460: Train-LOSS:34.62828, Valid-LOSS:35.77631\n",
      "Epoch470: Train-LOSS:34.25297, Valid-LOSS:35.40648\n",
      "Epoch480: Train-LOSS:33.89595, Valid-LOSS:35.05615\n",
      "Epoch490: Train-LOSS:33.55585, Valid-LOSS:34.72334\n",
      "Epoch500: Train-LOSS:33.23197, Valid-LOSS:34.40694\n",
      "Epoch510: Train-LOSS:32.92244, Valid-LOSS:34.10556\n",
      "Epoch520: Train-LOSS:32.62669, Valid-LOSS:33.81772\n",
      "Epoch530: Train-LOSS:32.34424, Valid-LOSS:33.54330\n",
      "Epoch540: Train-LOSS:32.07458, Valid-LOSS:33.28151\n",
      "Epoch550: Train-LOSS:31.81688, Valid-LOSS:33.03138\n",
      "Epoch560: Train-LOSS:31.57058, Valid-LOSS:32.79215\n",
      "Epoch570: Train-LOSS:31.33531, Valid-LOSS:32.56389\n",
      "Epoch580: Train-LOSS:31.11053, Valid-LOSS:32.34589\n"
     ]
    }
   ],
   "source": [
    "#Construct model\n",
    "model = Mutation_MIL_MT(in_features = N_FEATURE, \n",
    "                        act_func = 'tanh', \n",
    "                        drop_out = DROPOUT,\n",
    "                        n_outcomes = N_LABELS,\n",
    "                        dim_out = DIM_OUT)\n",
    "model.to(device)\n",
    "\n",
    "#Optimizer\n",
    "if OPTMIZER == \"ADAM\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTMIZER == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Loss\n",
    "if LOSS_FUNC_NAME == \"BCE_Weighted_Reg\":\n",
    "    loss_func = BCE_Weighted_Reg(REG_COEEF, REG_TYPE, model, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "elif LOSS_FUNC_NAME == \"BCELoss\":\n",
    "    loss_func = torch.nn.BCELoss()\n",
    "    \n",
    "\n",
    "#Model para\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "#print(model)\n",
    "\n",
    "\n",
    "#OUTPUT MODEL hyper-para\n",
    "hyper_df = pd.DataFrame({\"Target_Mutation\": SELECTED_MUTATION,\n",
    "                         \"TRAIN_OVERLAP\": TRAIN_OVERLAP,\n",
    "                         \"TEST_OVERLAP\": TEST_OVERLAP,\n",
    "                         \"TRAIN_SAMPLE_SIZE\": TRAIN_SAMPLE_SIZE,\n",
    "                         \"TUMOR_FRAC_THRES\": TUMOR_FRAC_THRES,\n",
    "                         \"N_FEATURE\": N_FEATURE,\n",
    "                         \"N_LABELS\": N_LABELS,\n",
    "                         \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                         \"ACCUM_SIZE\": ACCUM_SIZE,\n",
    "                         \"N_EPOCH\": EPOCHS,\n",
    "                         \"OPTMIZER\": OPTMIZER,\n",
    "                         \"LEARNING_RATE\": LEARNING_RATE,\n",
    "                         \"DROPOUT\": DROPOUT,\n",
    "                         \"DIM_OUT\": DIM_OUT,\n",
    "                         \"REG_TYPE\": REG_TYPE,\n",
    "                         \"REG_COEEF\": REG_COEEF,\n",
    "                         \"LOSS_FUNC_NAME\": LOSS_FUNC_NAME,\n",
    "                         \"LOSS_WEIGHTS_LIST\": str(LOSS_WEIGHTS_LIST),\n",
    "                         \"ATT_REG_FLAG\": ATT_REG_FLAG,\n",
    "                         \"NUM_MODEL_PARA\": total_params}, index = [0])\n",
    "hyper_df.to_csv(outdir2 + \"hyperpara_df.csv\")\n",
    "\n",
    "\n",
    "log_message(\"Start Training\", outdir3 + \"training_log.txt\")\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "#Training\n",
    "####################################################################################\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    ct = 0\n",
    "    optmizer_loss = 0\n",
    "    for x,y,tf in train_loader:\n",
    "        ct += 1\n",
    "        optimizer.zero_grad() #zero the grad\n",
    "        yhat_list, train_att_list = model(x.to(device)) #Forward\n",
    "\n",
    "        #compute loss\n",
    "        loss = compute_loss_for_all_labels(yhat_list, y, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf , train_att_list)\n",
    "\n",
    "        running_loss += loss.detach().item() #acuumalated batch loss\n",
    "        optmizer_loss += loss #accumalted loss for optimizer\n",
    "       \n",
    "        #Optimize\n",
    "        if ct % ACCUM_SIZE == 0:\n",
    "            optmizer_loss = optmizer_loss/ACCUM_SIZE\n",
    "            optmizer_loss.backward() \n",
    "            optimizer.step()  # Optimize\n",
    "            optmizer_loss = 0\n",
    "            #optimizer.zero_grad() #gradient reset\n",
    "\n",
    "    #Training loss \n",
    "    epoch_loss = running_loss/len(train_loader) #accumulated loss/total # batches (averaged loss over batches)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_running_loss = 0\n",
    "        for x_val,y_val,tf_val in val_loader:\n",
    "            val_yhat_list, val_att_list = model(x_val.to(device))\n",
    "            val_loss = compute_loss_for_all_labels(val_yhat_list, y_val, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf_val, val_att_list)\n",
    "            val_running_loss += val_loss.detach().item() \n",
    "        val_epoch_loss = val_running_loss/len(val_loader) \n",
    "        valid_loss.append(val_epoch_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch\"+ str(epoch) + \":\",\n",
    "              \"Train-LOSS:\" + \"{:.5f}\".format(train_loss[epoch]) + \", \" +\n",
    "              \"Valid-LOSS:\" +  \"{:.5f}\".format(valid_loss[epoch]))\n",
    "    \n",
    "    #Save model parameters\n",
    "    torch.save(model.state_dict(), outdir1 + \"model\" + str(epoch))\n",
    "\n",
    "\n",
    "#Plot LOSS\n",
    "plot_LOSS(train_loss,valid_loss, outdir1)\n",
    "log_message(\"End Training\", outdir3 + \"training_log.txt\")\n",
    "\n",
    "#SAVE VALIDATION LOSS\n",
    "valid_loss_df  = pd.DataFrame({\"VALID_LOSS\": valid_loss})\n",
    "valid_loss_df.to_csv(outdir1 + \"Valid_LOSS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47bf67b-a36c-4336-89dd-bee6b77e66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Loss TOTAL: 12.02473\n",
      "               AUC  Recall  Precision  Specificity    PR_AUC  \\\n",
      "SAMPLE_LEVEL  0.70    1.00       0.12         0.00  0.286667   \n",
      "SAMPLE_LEVEL  0.66    1.00       0.15         0.00  0.311891   \n",
      "SAMPLE_LEVEL  0.41    1.00       0.22         0.00  0.207246   \n",
      "SAMPLE_LEVEL  0.55    1.00       0.10         0.00  0.208575   \n",
      "SAMPLE_LEVEL  0.72    1.00       0.40         0.00  0.619543   \n",
      "SAMPLE_LEVEL  0.67    0.33       0.17         0.86  0.248333   \n",
      "SAMPLE_LEVEL  0.67    1.00       0.08         0.00  0.248333   \n",
      "\n",
      "                                                       OUTCOME  \n",
      "SAMPLE_LEVEL                                                AR  \n",
      "SAMPLE_LEVEL  MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2  \n",
      "SAMPLE_LEVEL                                              PTEN  \n",
      "SAMPLE_LEVEL                                               RB1  \n",
      "SAMPLE_LEVEL                                              TP53  \n",
      "SAMPLE_LEVEL                           TMB_HIGHorINTERMEDITATE  \n",
      "SAMPLE_LEVEL                                           MSI_POS  \n",
      "AVG AUC: 0.63\n",
      "AVG PRAUC: 0.3\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#Testing\n",
    "####################################################################################\n",
    "#Load model\n",
    "#valid_loss_df = pd.read_csv(outdir1 + \"Valid_LOSS.csv\")\n",
    "#min_index = valid_loss_df['VALID_LOSS'].idxmin()\n",
    "#print(min_index)\n",
    "min_index = 900\n",
    "model2 = Mutation_MIL_MT(in_features = N_FEATURE, act_func = 'tanh', drop_out = DROPOUT)\n",
    "state_dict = torch.load(outdir1 + \"model\" + str(min_index))\n",
    "\n",
    "#model_dir = \"/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/z_old_mutation_prediction_results/mutation_pred_out_11272024/MAX_SS0_NFEATURES2048/MT/saved_model/MIL/\"\n",
    "#state_dict = torch.load(model_dir + \"model\" + str(min_index))\n",
    "model2.load_state_dict(state_dict)\n",
    "model2.to(device)\n",
    "\n",
    "\n",
    "#Loss function\n",
    "loss_func = torch.nn.BCELoss()\n",
    "THRES = 0.3\n",
    "\n",
    "#predicts\n",
    "test_pred_prob, test_true_label, test_att, test_loss = prediction(test_loader, model2, N_LABELS, loss_func, device, attention = True)\n",
    "print(\"Test-Loss TOTAL: \" + \"{:.5f}\".format(test_loss))\n",
    "\n",
    "\n",
    "#Prediction df\n",
    "pred_df_list = []\n",
    "for i in range(0,N_LABELS):\n",
    "   pred_df_list.append(pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                                          \"Y_True\": [l[i] for l in test_true_label], \n",
    "                                          \"Pred_Prob\" :  [l[i] for l in test_pred_prob],\n",
    "                                          \"OUTCOME\": SELECTED_LABEL[i]}))\n",
    "pred_df = pd.concat(pred_df_list)\n",
    "\n",
    "#Add Predict class\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(outdir0 + SELECTED_MUTATION + \"/pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "#Compute performance\n",
    "perf_df = compute_performance_each_label(SELECTED_LABEL, pred_df, \"SAMPLE_LEVEL\")\n",
    "perf_df.to_csv(outdir0 + SELECTED_MUTATION + \"/perf.csv\",index = True)\n",
    "\n",
    "print(perf_df.iloc[:,[0,5,6,7,8,9]])\n",
    "print(\"AVG AUC:\", round(perf_df['AUC'].mean(),2))\n",
    "print(\"AVG PRAUC:\", round(perf_df['PR_AUC'].mean(),2))\n",
    "#Use regularization no dropout now has the best performance at avg AUC = 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e775e0-d175-4e9a-bb11-49e38f56539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Atention scores\n",
    "####################################################################################\n",
    "save_image_size = 250\n",
    "pixel_overlap = 100\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "pretrain_model_name = \"retccl\"\n",
    "mag_target_prob = 2.5\n",
    "smooth = False\n",
    "mag_target_tiss = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0367-e302-4b0e-963a-f57fc4624eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "pt = test_ids[i]\n",
    "print(pt)\n",
    "\n",
    "save_location =  outdir4  + pt + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "_file = wsi_path + pt + \".tif\"\n",
    "oslide = openslide.OpenSlide(_file)\n",
    "save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_pt_att = test_att[i]\n",
    "cur_pt_info = test_info[i]\n",
    "cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7f4b2-7b9b-4861-a7e6-454620bddd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_pt_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8695db6-68cf-40ae-bff4-a8ca81a1942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate tiles\n",
    "tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "\n",
    "#get level 0 size in px\n",
    "l0_w = oslide.level_dimensions[0][0]\n",
    "l0_h = oslide.level_dimensions[0][1]\n",
    "\n",
    "#1.25x tissue detection for mask\n",
    "from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "import cv2\n",
    "if 'OPX' in pt:\n",
    "    rad_tissue = 5\n",
    "elif '(2017-0133)' in pt:\n",
    "    rad_tissue = 2\n",
    "lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c5920-1ce0-4e18-a44a-85f99aad234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5x for probability maps\n",
    "lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "\n",
    "cur_att_df['pred_map_location'] = pd.NA\n",
    "for index, row in cur_att_df.iterrows():\n",
    "    cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "    x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "    \n",
    "    #Extract tile for prediction\n",
    "    lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "    tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "    map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    cur_att_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "\n",
    "    #Store predicted probabily in map and count\n",
    "    try: \n",
    "        x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "        x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93070951-982d-40f6-81ca-82dc3a6ab437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('post-processing')\n",
    "x_count = np.where(x_count < 1, 1, x_count)\n",
    "x_map = x_map / x_count\n",
    "x_map[x_map>1]=1\n",
    "\n",
    "if smooth == True:\n",
    "    x_sm = filters.gaussian(x_map, sigma=2)\n",
    "if smooth == False:\n",
    "    x_sm = x_map\n",
    "\n",
    "he_mask = cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])) #resize to output image size\n",
    "#TODO:\n",
    "#get cancer_mask:\n",
    "# cancer_mask == \n",
    "# x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "x_sm[he_mask < 1] = 0.001 \n",
    "\n",
    "plt.imshow(x_sm, cmap='Spectral_r')\n",
    "plt.colorbar()\n",
    "#plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb313585-3a55-44d6-9345-3aa100563dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top attented tiles\n",
    "save_location2 = save_location + \"top_tiles/\"\n",
    "create_dir_if_not_exists(save_location2)\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "\n",
    "for i in range(TOP_K):\n",
    "    cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "    cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "    cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "    coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "    tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "    cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "\n",
    "#Bot attented tiles\n",
    "save_location2 = save_location + \"bot_tiles/\"\n",
    "create_dir_if_not_exists(save_location2)\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "\n",
    "for i in range(TOP_K):\n",
    "    cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "    cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "    cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "    coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "    tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "    cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de144a01-7f41-4451-8785-40b5204032d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO LIST\n",
    "#1.Attention score\n",
    "#2. zero gradiant place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45db48-6f0e-4bab-b968-6d409a3fca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "embed_dim = 128  # Embedding dimension\n",
    "num_heads = 1   # Number of attention heads\n",
    "\n",
    "# Create an instance of the MultiheadAttention module\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e979dd-2353-4c0f-8097-304103e07049",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Sequential(\n",
    "    nn.Linear(2048, 1024), #linear layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512), #linear layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 256), #linear layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(256, 128), #linear layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77606c28-24bc-4691-865d-2904fde41aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 2048)\n",
    "r = embedding_layer(x)\n",
    "r.shape\n",
    "\n",
    "attn_output, attn_output_weights = multihead_attn(r, r, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9a3bc-f6da-49f5-8c34-b8860cb6a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
