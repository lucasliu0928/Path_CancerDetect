{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo, get_performance, plot_roc_curve\n",
    "from train_utils import pull_tiles, FocalLossv2\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from Model import Mutation_MIL_MT_sepAtt #, Mutation_MIL_MT\n",
    "from ACMIL import ACMIL_GA_MultiTask, predict_v2, train_one_epoch_multitask, evaluate_multitask\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fe6b4f-a374-4a86-8276-e5a1bced8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch: 100\n",
      "warmup_epoch: 0\n",
      "wd: 1e-05\n",
      "lr: 0.0001\n",
      "min_lr: 0\n",
      "dataset: bracs\n",
      "B: 1\n",
      "n_class: 1\n",
      "n_worker: 8\n",
      "pin_memory: False\n",
      "n_shot: -1\n",
      "D_feat: 1536\n",
      "D_inner: 128\n",
      "n_token: 3\n",
      "mask_drop: 0.6\n",
      "n_masked_patch: 0\n",
      "wandb_mode: disabled\n",
      "n_task: 7\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABELS = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0.9 \n",
    "feature_extraction_method = 'uni2' #retccl, uni1\n",
    "learning_method = \"acmil\"\n",
    "# focal_gamma = 5 #10 seems good too\n",
    "# focal_alpha = 0.80\n",
    "\n",
    "#Best before\n",
    "focal_gamma = 2\n",
    "focal_alpha = 0.1\n",
    "loss_method = '' #ATTLOSS\n",
    "\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "SELECTED_FOLD = 0\n",
    "arch = 'ga_mt' #ga_mt or ga\n",
    "\n",
    "if feature_extraction_method == 'retccl':\n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,2048)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 2048\n",
    "elif feature_extraction_method == 'uni1': \n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,1024)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 1024\n",
    "elif feature_extraction_method == 'uni2':\n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,1536)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 1536\n",
    "    \n",
    "################################\n",
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "\n",
    "conf.train_epoch = 100\n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "\n",
    "if learning_method == 'abmil':\n",
    "    conf.n_token = 1\n",
    "    conf.mask_drop = 0\n",
    "    conf.n_masked_patch = 0\n",
    "elif learning_method == 'acmil':\n",
    "    conf.n_token = 3\n",
    "    conf.mask_drop = 0.6\n",
    "    conf.n_masked_patch = 0\n",
    "    \n",
    "conf.n_class = 1\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.n_task = 7\n",
    "#conf.lr = 0.000001 #change this for HR only\n",
    "\n",
    "# Print all key-value pairs in the conf object\n",
    "for key, value in conf.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name_overlap = \"IMSIZE250_OL100\"\n",
    "folder_name_nonoverlap = \"IMSIZE250_OL0\"\n",
    "feature_path_opx_train =  os.path.join(proj_dir + 'intermediate_data/Old_5_model_ready_data', \"OPX\", folder_name_overlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_opx_test =  os.path.join(proj_dir + 'intermediate_data/Old_5_model_ready_data', \"OPX\", folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_tma = os.path.join(proj_dir + 'intermediate_data/Old_5_model_ready_data', \"TAN_TMA_Cores\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_tcga = os.path.join(proj_dir + 'intermediate_data/Old_5_model_ready_data', \"TCGA_PRAD\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "\n",
    "folder_name_ids = 'uni1/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "train_val_test_id_path =  os.path.join(proj_dir + 'intermediate_data/Old_6_Train_TEST_IDS', folder_name_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#Create output-dir\n",
    "################################################\n",
    "folder_name1 = feature_extraction_method + '/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out03152025_ACMIL\" + \"/\" + folder_name1 + 'FOLD' + str(SELECTED_FOLD) + '/' + SELECTED_MUTATION + \"/\" \n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "opx_data_ol100 = torch.load(feature_path_opx_train + '/OPX_data.pth')\n",
    "opx_ids_ol100 = torch.load(feature_path_opx_train + '/OPX_ids.pth')\n",
    "opx_info_ol100  = torch.load(feature_path_opx_train + '/OPX_info.pth')\n",
    "\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')\n",
    "opx_ids_ol0 = torch.load(feature_path_opx_test + '/OPX_ids.pth')\n",
    "opx_info_ol0  = torch.load(feature_path_opx_test + '/OPX_info.pth')\n",
    "\n",
    "tma_data = torch.load(feature_path_tma + '/tma_data.pth')\n",
    "tma_ids = torch.load(feature_path_tma + '/tma_ids.pth')\n",
    "tma_info  = torch.load(feature_path_tma + '/tma_info.pth')\n",
    "\n",
    "\n",
    "tcga_data = torch.load(feature_path_tcga + '/TCGA_data.pth')\n",
    "tcga_ids = torch.load(feature_path_tcga + '/TCGA_ids.pth')\n",
    "tcga_info  = torch.load(feature_path_tcga + '/TCGA_info.pth')\n",
    "\n",
    "\n",
    "########################################################\n",
    "#Update tma\n",
    "########################################################\n",
    "haslabel_indexes = []\n",
    "for i in range(len(tma_data)):\n",
    "    if torch.isnan(tma_data[i][1]).all() == False:\n",
    "        #print(f\"Item {i} has the second element all NaNs.\")\n",
    "        haslabel_indexes.append(i)\n",
    "\n",
    "\n",
    "tma_data = Subset(tma_data, haslabel_indexes)\n",
    "tma_ids = list(Subset(tma_ids, haslabel_indexes))\n",
    "tma_info = list(Subset(tma_info, haslabel_indexes))\n",
    "len(tma_info) #355 if TF0.9, a lot of cores does not have enough cancer tiles > 0.9\n",
    "\n",
    "\n",
    "################################################\n",
    "#Get train, test IDs\n",
    "#NOTE: this was in the old train: ['OPX_207','OPX_209','OPX_213','OPX_214','OPX_215']\n",
    "################################################\n",
    "train_test_val_id_df = pd.read_csv(train_val_test_id_path + \"train_test_split.csv\")\n",
    "train_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TRAIN', 'SAMPLE_ID'])\n",
    "test_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TEST', 'SAMPLE_ID'])\n",
    "val_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'VALID', 'SAMPLE_ID'])\n",
    "\n",
    "\n",
    "################################################\n",
    "#Get Train, test, val data\n",
    "################################################\n",
    "#Train:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in train_ids_all]\n",
    "train_data = Subset(opx_data_ol100, inc_idx)\n",
    "train_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "train_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "\n",
    "#Val:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in val_ids_all]\n",
    "val_data = Subset(opx_data_ol100, inc_idx)\n",
    "val_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "val_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "\n",
    "#Test:\n",
    "inc_idx = [opx_ids_ol0.index(x) for x in test_ids_all]\n",
    "test_data = Subset(opx_data_ol0, inc_idx)\n",
    "test_ids =  list(Subset(opx_ids_ol0, inc_idx))\n",
    "test_info = list(Subset(opx_info_ol0, inc_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 25, 32, 18, 55, 10,  9])\n",
      "['10.0', '16.7', '21.3', '12.0', '36.7', '6.7', '6.0']\n",
      "tensor([ 5,  7,  8,  4, 18,  7,  7])\n",
      "['11.1', '15.6', '17.8', '8.9', '40.0', '15.6', '15.6']\n",
      "tensor([216,   0, 119, 107, 178,   0,   0])\n",
      "['60.8', '0.0', '33.5', '30.1', '50.1', '0.0', '0.0']\n",
      "tensor([ 2, 34, 13,  3, 53,  0,  4])\n",
      "['0.4', '7.6', '2.9', '0.7', '11.9', '0.0', '0.9']\n",
      "150\n",
      "8\n",
      "45\n",
      "355\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "#count labels in train\n",
    "train_label_counts = [dt[1] for dt in train_data]\n",
    "train_label_counts = torch.concat(train_label_counts)\n",
    "count_ones = (train_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/train_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)\n",
    "\n",
    "#count labels in test\n",
    "test_label_counts = [dt[1] for dt in test_data]\n",
    "test_label_counts = torch.concat(test_label_counts)\n",
    "count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)\n",
    "\n",
    "#count labels in tma\n",
    "tma_label_counts = [dt[1] for dt in tma_data] \n",
    "tma_label_counts = torch.concat(tma_label_counts)\n",
    "count_ones = (tma_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/tma_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\"\n",
    "\n",
    "\n",
    "#count labels in tcga\n",
    "tcga_label_counts = [dt[1] for dt in tcga_data] \n",
    "tcga_label_counts = torch.concat(tcga_label_counts)\n",
    "count_ones = (tcga_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/tcga_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\"\n",
    "\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "print(len(tma_data))\n",
    "print(len(tcga_data))\n",
    "\n",
    "####################################################\n",
    "#Dataloader for training\n",
    "####################################################\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "tma_loader = DataLoader(dataset=tma_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "tcga_loader = DataLoader(dataset=tcga_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287cee9a-95b9-4a80-b9c4-1c02a3060f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out03152025_ACMIL/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/MT/' already exists.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# define network\n",
    "####################################################\n",
    "if arch == 'ga':\n",
    "    model = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "elif arch == 'ga_mt':\n",
    "    model = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "else:\n",
    "    model = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "model.to(device)\n",
    "\n",
    "            \n",
    "# Example usage:\n",
    "criterion = FocalLossv2(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "\n",
    "ckpt_dir = outdir1 + SELECTED_MUTATION + \"/\"\n",
    "create_dir_if_not_exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/150]  eta: 0:04:10  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.9999 (0.9999)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8078 (0.8078)  total_loss: 6.9989 (6.9989)  time: 1.6733  data: 0.0006  max mem: 26\n",
      "Epoch: [0]  [100/150]  eta: 0:00:05  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.8665 (0.9469)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9724 (0.9542)  total_loss: 5.6747 (6.5579)  time: 0.0875  data: 0.0017  max mem: 900\n",
      "Epoch: [0]  [149/150]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.3733 (0.8313)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9815 (0.9581)  total_loss: 3.1565 (5.7246)  time: 0.0884  data: 0.0027  max mem: 900\n",
      "Epoch: [0] Total time: 0:00:14 (0.0992 s / it)\n",
      "Test  [ 0/45]  eta: 0:00:00  loss: 0.0000 (0.0000)  div_loss: -35.7931 (-35.7931)  acc1: 71.4286 (71.4286)  time: 0.0204  data: 0.0005  max mem: 900\n",
      "Test  [44/45]  eta: 0:00:00  loss: 0.0000 (0.0000)  div_loss: -34.8735 (-41.1582)  acc1: 85.7143 (82.2222)  time: 0.0204  data: 0.0016  max mem: 900\n",
      "Test Total time: 0:00:00 (0.0216 s / it)\n",
      "AUROC 0 : 0.36000001430511475\n",
      "AUROC 1 : 0.5375939607620239\n",
      "AUROC 2 : 0.6993243098258972\n",
      "AUROC 3 : 0.5365853905677795\n",
      "AUROC 4 : 0.24485597014427185\n",
      "AUROC 5 : 0.5977444052696228\n",
      "AUROC 6 : 0.6503759622573853\n",
      "* Acc@1 82.222 loss 0.000 auroc 0.518 f1_score 0.243\n",
      "Epoch: [1]  [  0/150]  eta: 0:00:13  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.6955 (0.6955)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8078 (0.8078)  total_loss: 5.1259 (5.1259)  time: 0.0929  data: 0.0006  max mem: 900\n",
      "Epoch: [1]  [100/150]  eta: 0:00:04  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0830 (0.1916)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9724 (0.9544)  total_loss: 0.5656 (1.3360)  time: 0.0875  data: 0.0018  max mem: 900\n",
      "Epoch: [1]  [149/150]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0473 (0.1809)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9815 (0.9582)  total_loss: 0.3719 (1.2551)  time: 0.0909  data: 0.0032  max mem: 900\n",
      "Epoch: [1] Total time: 0:00:13 (0.0915 s / it)\n",
      "Test  [ 0/45]  eta: 0:00:01  loss: 0.0000 (0.0000)  div_loss: -28.3113 (-28.3113)  acc1: 71.4286 (71.4286)  time: 0.0236  data: 0.0013  max mem: 900\n",
      "Test  [44/45]  eta: 0:00:00  loss: 0.0000 (0.0000)  div_loss: -29.0119 (-35.4375)  acc1: 85.7143 (82.2222)  time: 0.0250  data: 0.0026  max mem: 900\n",
      "Test Total time: 0:00:01 (0.0229 s / it)\n",
      "AUROC 0 : 0.35499998927116394\n",
      "AUROC 1 : 0.5338345766067505\n",
      "AUROC 2 : 0.7195945978164673\n",
      "AUROC 3 : 0.5487805008888245\n",
      "AUROC 4 : 0.22427982091903687\n",
      "AUROC 5 : 0.5526316165924072\n",
      "AUROC 6 : 0.6428571939468384\n",
      "* Acc@1 82.222 loss 0.000 auroc 0.511 f1_score 0.191\n",
      "Epoch: [2]  [  0/150]  eta: 0:00:13  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.2854 (0.2854)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8083 (0.8083)  total_loss: 2.1824 (2.1824)  time: 0.0922  data: 0.0003  max mem: 900\n",
      "Epoch: [2]  [100/150]  eta: 0:00:04  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0201 (0.0700)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9725 (0.9547)  total_loss: 0.1522 (0.4686)  time: 0.0839  data: 0.0024  max mem: 900\n",
      "Epoch: [2]  [149/150]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0156 (0.0736)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9815 (0.9584)  total_loss: 0.1305 (0.5008)  time: 0.0887  data: 0.0030  max mem: 900\n",
      "Epoch: [2] Total time: 0:00:13 (0.0898 s / it)\n",
      "Test  [ 0/45]  eta: 0:00:00  loss: 0.0000 (0.0000)  div_loss: -26.7236 (-26.7236)  acc1: 71.4286 (71.4286)  time: 0.0070  data: 0.0004  max mem: 900\n",
      "Test  [44/45]  eta: 0:00:00  loss: 0.0000 (0.0000)  div_loss: -27.6473 (-33.7695)  acc1: 85.7143 (82.2222)  time: 0.0248  data: 0.0020  max mem: 900\n",
      "Test Total time: 0:00:01 (0.0237 s / it)\n",
      "AUROC 0 : 0.35500001907348633\n",
      "AUROC 1 : 0.5263158082962036\n",
      "AUROC 2 : 0.7398648262023926\n",
      "AUROC 3 : 0.5243902206420898\n",
      "AUROC 4 : 0.23868310451507568\n",
      "AUROC 5 : 0.530075192451477\n",
      "AUROC 6 : 0.635338306427002\n",
      "* Acc@1 82.222 loss 0.000 auroc 0.507 f1_score 0.187\n",
      "Epoch: [3]  [  0/150]  eta: 0:00:14  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.1137 (0.1137)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8089 (0.8089)  total_loss: 0.9743 (0.9743)  time: 0.0974  data: 0.0003  max mem: 900\n",
      "Epoch: [3]  [100/150]  eta: 0:00:04  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0089 (0.0413)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9725 (0.9548)  total_loss: 0.0674 (0.2751)  time: 0.0914  data: 0.0028  max mem: 900\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "loss_method = ''\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "train_epoch = conf.train_epoch\n",
    "for epoch in range(train_epoch):\n",
    "    train_one_epoch_multitask(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "    #val_auc, val_acc, val_f1, val_loss = evaluate_multitask(model, criterion, val_loader, device, conf, 'Val')\n",
    "    test_auc, test_acc, test_f1, test_loss = evaluate_multitask(model, criterion, test_loader, device, conf, 'Test')\n",
    "    #tma_auc, tma_acc, tma_f1, tma_loss = evaluate_multitask(model, criterion, tma_loader, device, conf, 'TMA')\n",
    "\n",
    "    save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "        save_path=os.path.join(ckpt_dir + 'checkpoint_' + 'epoch' + str(epoch) + '.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07377042-2f38-4f48-9c86-b37329f2e77e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ###################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# #           Test \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ###################################################\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# # Load the state_dict into the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model2.load_state_dict(checkpoint['model'])\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mACMIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[0;32m---> 21\u001b[0m y_pred_tasks_test, y_predprob_task_test, y_true_task_test \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pred_df_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m perf_df_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/code_s/cancer_detection_final/../Utils/ACMIL.py:187\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(net, data_loader, device, conf, header)\u001b[0m\n\u001b[1;32m    185\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(slide_preds)\n\u001b[1;32m    186\u001b[0m     pred_list\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[0;32m--> 187\u001b[0m     pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslide_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    188\u001b[0m     pred_prob_list\u001b[38;5;241m.\u001b[39mappend(pred_prob)\n\u001b[1;32m    190\u001b[0m y_pred\u001b[38;5;241m.\u001b[39mappend(pred_list)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "# ###################################################\n",
    "# #           Test \n",
    "# ###################################################\n",
    "# # define network\n",
    "# if arch == 'ga':\n",
    "#     model2 = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "# elif arch == 'ga_mt':\n",
    "#     model2 = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "# else:\n",
    "#     model2 = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "# model2.to(device)\n",
    "\n",
    "# # Load the checkpoint\n",
    "# #checkpoint = torch.load(ckpt_dir + 'checkpoint-best.pth')\n",
    "# checkpoint = torch.load(ckpt_dir + 'checkpoint_epoch99.pth')\n",
    "\n",
    "# # Load the state_dict into the model\n",
    "# model2.load_state_dict(checkpoint['model'])\n",
    "\n",
    "from ACMIL import predict\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, test_loader, device, conf, 'Test')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], test_ids, ALL_LABELS[i], THRES = 0.5)\n",
    "    pred_df_list.append(pred_df)\n",
    "    perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a236391-ba85-46bb-80c8-62fa3773f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_msi = all_perd_df.loc[all_perd_df['OUTCOME'] == 'MSI_POS']\n",
    "pred_msi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e5db7-8c0e-43c3-af13-3c3e5285c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(list(pred_msi['Pred_Prob']),list(pred_msi['Y_True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8621554-50ec-4655-a49c-3c280e3cdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PLOT:\n",
    "# pred_df = all_perd_df\n",
    "# SELECTED_LABEL = ['MSI_POS']\n",
    "# #Get True Postives\n",
    "# true_postive_ids = {}\n",
    "# for label in SELECTED_LABEL:\n",
    "#     cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 1) & (pred_df['OUTCOME'] == label)\n",
    "#     cur_pred_df = pred_df.loc[cond]\n",
    "#     cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "#     true_postive_ids[label] = cur_ids\n",
    "\n",
    "# #Get true nagative\n",
    "# true_negative_ids = {}\n",
    "# for label in SELECTED_LABEL:\n",
    "#     cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 0) & (pred_df['OUTCOME'] == label)\n",
    "#     cur_pred_df = pred_df.loc[cond]\n",
    "#     cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "#     true_negative_ids[label] = cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fde41-231c-4a9d-ba4e-b3dbd8d119ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################################################\n",
    "# #Atention scores\n",
    "# ####################################################################################\n",
    "# save_image_size = 250\n",
    "# pixel_overlap = 0\n",
    "# mag_extract = 20\n",
    "# limit_bounds = True\n",
    "# TOP_K = 5\n",
    "# pretrain_model_name = \"retccl\"\n",
    "# mag_target_prob = 2.5\n",
    "# smooth = True\n",
    "# mag_target_tiss = 1.25\n",
    "\n",
    "# def get_attention_and_tileinfo(pt_label_df, patient_att_score):    \n",
    "#     #Get label\n",
    "#     pt_label_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     #Get attention\n",
    "#     cur_att  = pd.DataFrame({'ATT':list(minmax_normalize(patient_att_score))})\n",
    "#     cur_att.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     #Comb\n",
    "#     cur_att_df = pd.concat([pt_label_df,cur_att], axis = 1)\n",
    "#     cur_att_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     return cur_att_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1e366-7bc8-4ab9-a6db-44b2647d8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn[label_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e7e43-8f39-4748-9855-8c1434037b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_ids = true_postive_ids[SELECTED_LABEL[0]]\n",
    "# wsi_path = proj_dir + '/data/OPX/'\n",
    "# branches = 1\n",
    "\n",
    "# for pt in selected_ids:\n",
    "#     i = test_ids.index(pt)\n",
    "#     pt = test_ids[i]\n",
    "#     print(pt)\n",
    "\n",
    "#     save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "#     save_location =  save_location  + pt + \"/\"\n",
    "#     create_dir_if_not_exists(save_location)\n",
    "    \n",
    "#     _file = wsi_path + pt + \".tif\"\n",
    "#     oslide = openslide.OpenSlide(_file)\n",
    "#     save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "    \n",
    "#     first_batch = list(test_loader)[i]\n",
    "#     feat = first_batch[0].to(device)\n",
    "#     sub_preds, slide_preds, attn = model(feat)\n",
    "#     #cur_pt_att =  attn[0,:,:].mean(0).cpu().detach().numpy() #Take the mean across branches without softmax\n",
    "#     label_index = ALL_LABELS.index(SELECTED_LABEL[0])\n",
    "#     cur_pt_att = attn[label_index][branches].mean(0).cpu().detach().numpy()\n",
    "#     #branches = 0\n",
    "#     #cur_pt_att = torch.softmax(attn, dim=-1)[0][branches].cpu().detach().numpy() \n",
    "    \n",
    "#     #Get all tile info include noncancer tile\n",
    "#     alltileinfo_dir = proj_dir + 'intermediate_data/TODELETE_cancer_prediction_results110224/' + \"IMSIZE250_OL0\" + \"/\"\n",
    "#     tile_info_df = pd.read_csv(alltileinfo_dir + pt + \"/\"  + save_name + \"_tiles.csv\")\n",
    "#     cur_pt_info = test_info[i]\n",
    "#     #Combine current pt_info an all tile info\n",
    "#     #cur_pt_info = tile_info_df.merge(cur_pt_info, on = list(tile_info_df.columns), how = \"left\")\n",
    "    \n",
    "#     cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "#     #cur_att_df.loc[pd.isna(cur_att_df['ATT']),'ATT'] = 0.0001\n",
    "    \n",
    "#     #Generate tiles\n",
    "#     tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "#     #get level 0 size in px\n",
    "#     l0_w = oslide.level_dimensions[0][0]\n",
    "#     l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "#     #1.25x tissue detection for mask\n",
    "#     from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "#     from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "#     import cv2\n",
    "#     if 'OPX' in pt:\n",
    "#         rad_tissue = 5\n",
    "#     elif '(2017-0133)' in pt:\n",
    "#         rad_tissue = 2\n",
    "#     lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "#     lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "#     tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "#     #2.5x for probability maps\n",
    "#     lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "#     x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "#     x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    \n",
    "#     for index, row in cur_att_df.iterrows():\n",
    "#         cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "#         x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "#         #Extract tile for prediction\n",
    "#         lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "#         tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "#         map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    \n",
    "#         #Store predicted probabily in map and count\n",
    "#         try: \n",
    "#             x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "#             x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#     print('post-processing')\n",
    "#     x_count = np.where(x_count < 1, 1, x_count)\n",
    "#     x_map = x_map / x_count\n",
    "#     x_map[x_map>1]=1\n",
    "    \n",
    "#     #Get the following before smooth\n",
    "#     he_mask = cv2.resize(np.uint8(he_mask),(x_map.shape[1],x_map.shape[0])) #resize to output image size\n",
    "#     cond1 = he_mask < 1 #Background\n",
    "#     cond2 = (he_mask == 1) & (x_map == 0) #is tissue, but not selected\n",
    "#     smooth = True\n",
    "    \n",
    "#     if smooth == True:\n",
    "#         #x_sm = filters.gaussian(x_map, sigma=0)\n",
    "#         x_sm = np.where(x_map != 0, filters.gaussian(x_map, sigma=10), x_map)\n",
    "#     if smooth == False:\n",
    "#         x_sm = x_map\n",
    "    \n",
    "#     #TODO:\n",
    "#     #get cancer_mask:\n",
    "#     # cancer_mask == \n",
    "#     # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "#     x_sm[cond1] = 0 #Background\n",
    "#     x_sm[cond2] = 0.1 #Is tissue, but not selected \n",
    "    \n",
    "#     # Define the colors for the sequential colormap (black to fluorescent green)\n",
    "#     colors = [\"#4B0082\", \"#39FF14\"]  # Black to Fluorescent Green\n",
    "#     # Create the sequential colormap\n",
    "#     cmap_name = \"black_to_fluorescent_green\"\n",
    "#     from matplotlib.colors import LinearSegmentedColormap\n",
    "#     from matplotlib.colors import ListedColormap\n",
    "#     sequential_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "#     cmap =  plt.cm.Spectral_r #sequential_cmap # plt.cm.YlGn_r\n",
    "#     cmap_colors = cmap(np.arange(cmap.N))\n",
    "#     cmap_colors[0] = np.array([0.95, 0.95, 0.95, 1]) #np.array([1, 1, 1, 1])  # Set the first color (corresponding to 0) to white\n",
    "#     cmap_colors[1] = np.array([0, 0, 0.545, 1])  # RGB for dark blue\n",
    "#     custom_cmap = ListedColormap(cmap_colors)\n",
    "    \n",
    "#     plt.imshow(x_sm, cmap=custom_cmap) #Spectral_r\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "#     #Top attented tiles\n",
    "#     save_location2 = save_location + \"top_tiles/\"\n",
    "#     create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "#     #Get a Attention, and corresponding tiles\n",
    "#     cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "#     cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "            \n",
    "#     for i in range(TOP_K):\n",
    "#         cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#         cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#         cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#         coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#         tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#         cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "    \n",
    "#     #Bot attented tiles\n",
    "#     save_location2 = save_location + \"bot_tiles/\"\n",
    "#     create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "#     #Get a Attention, and corresponding tiles\n",
    "#     cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "#     cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "    \n",
    "#     for i in range(TOP_K):\n",
    "#         cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#         cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#         cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#         coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#         tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#         cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e138338-01e8-4cb0-91a7-76a7b44cb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "# TMA\n",
    "##############################################################################################################################\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict_v2(model, tma_loader, device, conf, 'TMA')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task): \n",
    "    if i not in [1,5,6]:\n",
    "        pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tma_ids, ALL_LABELS[i],THRES = 0.5)\n",
    "        pred_df_list.append(pred_df)\n",
    "        perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TMA_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TMA_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b54552-96ad-42ac-a8f6-abaa438a9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "# TCGA\n",
    "##############################################################################################################################\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict_v2(model, tcga_loader, device, conf, 'TCGA')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    if i != 5 :\n",
    "        pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tcga_ids, ALL_LABELS[i], THRES = 0.5)\n",
    "        pred_df_list.append(pred_df)\n",
    "        perf_df_list.append(perf_df)\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TCGA_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TCGA_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94820a81-e39e-415e-a4d6-db77afb615b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PLOT:\n",
    "# pred_df = all_perd_df\n",
    "# SELECTED_LABEL = ['MSI_POS']\n",
    "# #Get True Postives\n",
    "# true_postive_ids = {}\n",
    "# for label in SELECTED_LABEL:\n",
    "#     cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 1) & (pred_df['OUTCOME'] == label)\n",
    "#     cur_pred_df = pred_df.loc[cond]\n",
    "#     cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "#     true_postive_ids[label] = cur_ids\n",
    "\n",
    "# #Get true nagative\n",
    "# true_negative_ids = {}\n",
    "# for label in SELECTED_LABEL:\n",
    "#     cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 0) & (pred_df['OUTCOME'] == label)\n",
    "#     cur_pred_df = pred_df.loc[cond]\n",
    "#     cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "#     true_negative_ids[label] = cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbd1de-30b6-49c3-a773-63c100f236e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################################################\n",
    "# #Atention scores\n",
    "# ####################################################################################\n",
    "# save_image_size = 250\n",
    "# pixel_overlap = 0\n",
    "# mag_extract = 20\n",
    "# limit_bounds = True\n",
    "# TOP_K = 5\n",
    "# pretrain_model_name = \"retccl\"\n",
    "# mag_target_prob = 2.5\n",
    "# smooth = True\n",
    "# mag_target_tiss = 1.25\n",
    "\n",
    "# def get_attention_and_tileinfo(pt_label_df, patient_att_score):    \n",
    "#     #Get label\n",
    "#     pt_label_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     #Get attention\n",
    "#     cur_att  = pd.DataFrame({'ATT':list(minmax_normalize(patient_att_score))})\n",
    "#     cur_att.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     #Comb\n",
    "#     cur_att_df = pd.concat([pt_label_df,cur_att], axis = 1)\n",
    "#     cur_att_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     return cur_att_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea6977-e834-4509-85ba-2df6e185f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(attn[label_index].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a3968-1897-4f3e-9fd6-f805a8c5395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_ids = true_postive_ids[SELECTED_LABEL[0]]\n",
    "# wsi_path = proj_dir + '/data/TCGA_PRAD/'\n",
    "# branches = 0\n",
    "\n",
    "# for pt in selected_ids:\n",
    "#     i = tcga_ids.index(pt)\n",
    "#     pt = tcga_ids[i]\n",
    "#     print(pt)\n",
    "\n",
    "#     save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "#     save_location =  save_location  + pt + \"/\"\n",
    "#     create_dir_if_not_exists(save_location)\n",
    "\n",
    "#     slides_name = [f for f in os.listdir(wsi_path + pt + '/') if '.svs' in f][0].replace('.svs','')\n",
    "#     _file = wsi_path + pt + '/' + slides_name + '.svs'\n",
    "#     oslide = openslide.OpenSlide(_file)\n",
    "#     save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "    \n",
    "#     first_batch = list(tcga_loader)[i]\n",
    "#     feat = first_batch[0].to(device)\n",
    "#     sub_preds, slide_preds, attn = model(feat)\n",
    "#     label_index = ALL_LABELS.index(SELECTED_LABEL[0])\n",
    "#     #cur_pt_att = attn[label_index][:,:,:].mean(1).cpu().detach().numpy() #mean across all branchs\n",
    "#     cur_pt_att = attn[label_index][:,branches,:].mean(0).cpu().detach().numpy()\n",
    "#     #branches = 0\n",
    "#     #cur_pt_att = torch.softmax(attn[label_index], dim=1).cpu().detach().numpy() \n",
    "    \n",
    "#     #Get all tile info include noncancer tile    \n",
    "#     alltileinfo_dir = proj_dir + 'intermediate_data/1_tile_pulling/TCGA_PRAD/' + \"IMSIZE250_OL0\" + \"/\"\n",
    "#     tile_info_df = pd.read_csv(alltileinfo_dir + pt + \"/\"  + save_name + \"_tiles.csv\")\n",
    "#     cur_pt_info = tcga_info[i]\n",
    "#     #Combine current pt_info an all tile info\n",
    "#     #cur_pt_info = tile_info_df.merge(cur_pt_info, on = list(tile_info_df.columns), how = \"left\")\n",
    "    \n",
    "#     cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "#     #cur_att_df.loc[pd.isna(cur_att_df['ATT']),'ATT'] = 0.0001\n",
    "    \n",
    "#     #Generate tiles\n",
    "#     tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "#     #get level 0 size in px\n",
    "#     l0_w = oslide.level_dimensions[0][0]\n",
    "#     l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "#     #1.25x tissue detection for mask\n",
    "#     from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "#     from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "#     import cv2\n",
    "#     if 'OPX' in pt:\n",
    "#         rad_tissue = 5\n",
    "#     elif '(2017-0133)' in pt:\n",
    "#         rad_tissue = 2\n",
    "#     else:\n",
    "#         rad_tissue = 2\n",
    "#     lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "#     lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "#     tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "#     #2.5x for probability maps\n",
    "#     lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "#     x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "#     x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    \n",
    "#     for index, row in cur_att_df.iterrows():\n",
    "#         cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "#         x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "#         #Extract tile for prediction\n",
    "#         lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "#         tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "#         map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    \n",
    "#         #Store predicted probabily in map and count\n",
    "#         try: \n",
    "#             x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "#             x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#     print('post-processing')\n",
    "#     x_count = np.where(x_count < 1, 1, x_count)\n",
    "#     x_map = x_map / x_count\n",
    "#     x_map[x_map>1]=1\n",
    "    \n",
    "#     #Get the following before smooth\n",
    "#     he_mask = cv2.resize(np.uint8(he_mask),(x_map.shape[1],x_map.shape[0])) #resize to output image size\n",
    "#     cond1 = he_mask < 1 #Background\n",
    "#     cond2 = (he_mask == 1) & (x_map == 0) #is tissue, but not selected\n",
    "#     smooth = True\n",
    "    \n",
    "#     if smooth == True:\n",
    "#         #x_sm = filters.gaussian(x_map, sigma=0)\n",
    "#         x_sm = np.where(x_map != 0, filters.gaussian(x_map, sigma=10), x_map)\n",
    "#     if smooth == False:\n",
    "#         x_sm = x_map\n",
    "    \n",
    "#     #TODO:\n",
    "#     #get cancer_mask:\n",
    "#     # cancer_mask == \n",
    "#     # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "#     x_sm[cond1] = 0 #Background\n",
    "#     x_sm[cond2] = 0.1 #Is tissue, but not selected \n",
    "    \n",
    "#     # Define the colors for the sequential colormap (black to fluorescent green)\n",
    "#     colors = [\"#4B0082\", \"#39FF14\"]  # Black to Fluorescent Green\n",
    "#     # Create the sequential colormap\n",
    "#     cmap_name = \"black_to_fluorescent_green\"\n",
    "#     from matplotlib.colors import LinearSegmentedColormap\n",
    "#     from matplotlib.colors import ListedColormap\n",
    "#     sequential_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "#     cmap =  plt.cm.Spectral_r #sequential_cmap # plt.cm.YlGn_r\n",
    "#     cmap_colors = cmap(np.arange(cmap.N))\n",
    "#     cmap_colors[0] = np.array([0.95, 0.95, 0.95, 1]) #np.array([1, 1, 1, 1])  # Set the first color (corresponding to 0) to white\n",
    "#     cmap_colors[1] = np.array([0, 0, 0.545, 1])  # RGB for dark blue\n",
    "#     custom_cmap = ListedColormap(cmap_colors)\n",
    "    \n",
    "#     plt.imshow(x_sm, cmap=custom_cmap) #Spectral_r\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "#     #Top attented tiles\n",
    "#     save_location2 = save_location + \"top_tiles/\"\n",
    "#     create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "#     #Get a Attention, and corresponding tiles\n",
    "#     cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "#     cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "            \n",
    "#     for i in range(TOP_K):\n",
    "#         cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#         cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#         cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#         coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#         tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#         cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "    \n",
    "#     #Bot attented tiles\n",
    "#     save_location2 = save_location + \"bot_tiles/\"\n",
    "#     create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "#     #Get a Attention, and corresponding tiles\n",
    "#     cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "#     cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "    \n",
    "#     for i in range(TOP_K):\n",
    "#         cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#         cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#         cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#         coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#         tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#         cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
