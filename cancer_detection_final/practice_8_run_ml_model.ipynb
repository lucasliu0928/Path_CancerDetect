{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d91cc3-2142-4a01-baec-ae90fa93508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg1 env, the retccl one has package issue with torchvision\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, count_label\n",
    "from Utils import log_message, set_seed\n",
    "from Utils import simple_line_plot\n",
    "from cluster_utils import get_cluster_data, get_cluster_label, get_updated_feature, get_pca_components\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles, get_feature_label_array_dynamic\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction\n",
    "from Model import Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b28f440-1549-48ac-80a7-e5e0c3f54c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "CLUSTER_ALG = 'KMEAN'\n",
    "N_CLUSTERS = 4\n",
    "CLUSTER_DIST = 'L2'\n",
    "feature_extraction_method = 'retccl'\n",
    "SELECTED_FEATURE  = list(['C_' + str(x) for x in range(0,N_CLUSTERS)])\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "data_dir = proj_dir + 'intermediate_data/model_ready_data/feature_' + feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\"\n",
    "feature_path =  os.path.join(data_dir, \"clusters\", CLUSTER_ALG, \"ML_Updated_Features_OnlyClusterPerc\")\n",
    "label_path = os.path.join(data_dir, \"clusters\", CLUSTER_ALG, \"ClusterInfo\")\n",
    "save_name = \"_NCLUSTER_\" + str(N_CLUSTERS) +  \"_DISTMETRIC_\" + CLUSTER_DIST\n",
    "\n",
    "################################################\n",
    "#Create output dir\n",
    "################################################\n",
    "#outdir3 =   os.path.join(data_dir, \"clusters\", CLUSTER_ALG, \"ML_Updated_Features_OnlyClusterPerc\")\n",
    "#create_dir_if_not_exists(outdir3)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163d07e8-f00b-41fa-b992-fdcd8ee657f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "#Get features and labels\n",
    "############################################################################################################\n",
    "train_ml_df = torch.load(feature_path + '/updated_train_feature' + save_name + 'cluster_perc.pth')\n",
    "train_ml_df.rename(columns = {'ID': 'SAMPLE_ID'}, inplace = True)\n",
    "test_ml_df = torch.load(feature_path + '/updated_test_feature' + save_name + 'cluster_perc.pth')\n",
    "test_ml_df.rename(columns = {'ID': 'SAMPLE_ID'}, inplace = True)\n",
    "val_ml_df = torch.load(feature_path + '/updated_val_feature' + save_name + 'cluster_perc.pth')\n",
    "val_ml_df.rename(columns = {'ID': 'SAMPLE_ID'}, inplace = True)\n",
    "\n",
    "\n",
    "train_info_df = pd.read_csv(label_path + '/train_cluster_info' + save_name + '.csv')\n",
    "train_info_df.drop_duplicates(subset = ['SAMPLE_ID'], inplace = True)\n",
    "test_info_df = pd.read_csv(label_path + '/test_cluster_info' + save_name + '.csv')\n",
    "test_info_df.drop_duplicates(subset = ['SAMPLE_ID'], inplace = True)\n",
    "val_info_df = pd.read_csv(label_path + '/valid_cluster_info' + save_name + '.csv')\n",
    "val_info_df.drop_duplicates(subset = ['SAMPLE_ID'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b567c4a-b269-44b1-b5f0-4d76e182b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_ml_df.merge(train_info_df[['SAMPLE_ID'] + SELECTED_LABEL], on = ['SAMPLE_ID'])\n",
    "test_df = test_ml_df.merge(test_info_df[['SAMPLE_ID'] + SELECTED_LABEL], on = ['SAMPLE_ID'])\n",
    "val_df = val_ml_df.merge(val_info_df[['SAMPLE_ID'] + SELECTED_LABEL], on = ['SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aee469-9f90-4fca-92cb-a82fe1817b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4add3b-3d3a-4945-bc89-271261b2caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation test\n",
    "#train_df[SELECTED_LABEL].corr()\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98bb938-9880-4567-98c2-c9c03d4ac3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        AUC       ACC        F1        F2        F3    Recall  Precision  \\\n",
      "7  0.678571  0.605714  0.327143  0.454286  0.540000  0.700000   0.244286   \n",
      "7  0.587143  0.794286  0.172857  0.161429  0.158571  0.155714   0.201429   \n",
      "7  0.560000  0.774286  0.177143  0.181429  0.185714  0.194286   0.198571   \n",
      "7  0.610000  0.678571  0.297143  0.357143  0.388571  0.432857   0.242857   \n",
      "\n",
      "   Specificity    PR_AUC Label       Method  \n",
      "7     0.612857  0.316512   NaN       LR_AVG  \n",
      "7     0.891429  0.261478   NaN       RF_AVG  \n",
      "7     0.877143  0.252612   NaN  XGBoost_AVG  \n",
      "7     0.717143  0.297809   NaN      SVM_AVG  \n"
     ]
    }
   ],
   "source": [
    "selected_methods = ['LR','RF','XGBoost','SVM']\n",
    "THRES = 0.5\n",
    "all_perf_list = []\n",
    "for method in selected_methods:\n",
    "    perf_list = []\n",
    "    for label in SELECTED_LABEL:    \n",
    "        X_train , y_train = train_df[SELECTED_FEATURE], train_df[label]\n",
    "        X_test , y_test = test_df[SELECTED_FEATURE], test_df[label]\n",
    "        X_val , y_val = val_df[SELECTED_FEATURE], val_df[label]\n",
    "\n",
    "        # Separate the majority and minority classes\n",
    "        X_train_majority = X_train[y_train == 0]\n",
    "        y_train_majority = y_train[y_train == 0]\n",
    "        X_train_minority = X_train[y_train == 1]\n",
    "        y_train_minority = y_train[y_train == 1]\n",
    "        \n",
    "        # Upsample the minority class\n",
    "        X_train_minority_upsampled, y_train_minority_upsampled = resample(\n",
    "            X_train_minority, y_train_minority,\n",
    "            replace=True,  # Sample with replacement\n",
    "            n_samples=len(X_train_majority),  # Match number of majority class samples\n",
    "            random_state=42  # Reproducible results\n",
    "        )\n",
    "        \n",
    "        # Combine the majority class with the upsampled minority class\n",
    "        X_train_upsampled = np.vstack((X_train_majority, X_train_minority_upsampled))\n",
    "        y_train_upsampled = np.hstack((y_train_majority, y_train_minority_upsampled))\n",
    "\n",
    "        if method == 'LR':\n",
    "            model = LogisticRegression()\n",
    "        elif method == 'RF':\n",
    "            model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "        elif method == 'XGBoost':\n",
    "            model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "        elif method == 'SVM':\n",
    "            model = SVC(probability=True)\n",
    "        # Train the model\n",
    "        model.fit(X_train_upsampled, y_train_upsampled)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict_proba(X_test)[:,1]        \n",
    "        y_pred_c = ([float(t > THRES) for t in y_pred])\n",
    "        \n",
    "        # # Evaluate the model\n",
    "        cur_perf_df = compute_performance(y_test,y_pred,y_pred_c,\"\")\n",
    "        cur_perf_df['Label'] =  label\n",
    "        perf_list.append(cur_perf_df)\n",
    "    perf_df = pd.concat(perf_list)\n",
    "    mean_values = perf_df[['AUC', 'ACC', 'F1', 'F2', 'F3', 'Recall', 'Precision', 'Specificity', 'PR_AUC']].mean()\n",
    "    perf_df.loc['mean'] = mean_values\n",
    "    perf_df['Method'] = method\n",
    "    perf_df.loc['mean','Method'] = method + '_AVG'\n",
    "    perf_df.reset_index(drop = True, inplace = True)\n",
    "    all_perf_list.append(perf_df)\n",
    "\n",
    "all_perf_df = pd.concat(all_perf_list)\n",
    "print(all_perf_df.loc[all_perf_df['Method'].str.contains('AVG')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e932827-5854-44a8-bdc0-1941e0a17a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Label</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.176533</td>\n",
       "      <td>AR</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.299074</td>\n",
       "      <td>MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.247396</td>\n",
       "      <td>PTEN</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>RB1</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.671258</td>\n",
       "      <td>TP53</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.275490</td>\n",
       "      <td>TMB_HIGHorINTERMEDITATE</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.240278</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.605714</td>\n",
       "      <td>0.327143</td>\n",
       "      <td>0.454286</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.244286</td>\n",
       "      <td>0.612857</td>\n",
       "      <td>0.316512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LR_AVG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC       ACC        F1        F2    F3  Recall  Precision  \\\n",
       "0  0.610000  0.620000  0.210000  0.290000  0.34    0.40   0.140000   \n",
       "1  0.500000  0.450000  0.210000  0.330000  0.39    0.50   0.140000   \n",
       "2  0.470000  0.680000  0.380000  0.420000  0.43    0.44   0.330000   \n",
       "3  0.800000  0.700000  0.400000  0.620000  0.77    1.00   0.250000   \n",
       "4  0.740000  0.620000  0.550000  0.560000  0.56    0.56   0.530000   \n",
       "5  0.820000  0.650000  0.300000  0.520000  0.68    1.00   0.180000   \n",
       "6  0.810000  0.520000  0.240000  0.440000  0.61    1.00   0.140000   \n",
       "7  0.678571  0.605714  0.327143  0.454286  0.54    0.70   0.244286   \n",
       "\n",
       "   Specificity    PR_AUC                                             Label  \\\n",
       "0     0.660000  0.176533                                                AR   \n",
       "1     0.440000  0.299074  MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2   \n",
       "2     0.740000  0.247396                                              PTEN   \n",
       "3     0.670000  0.305556                                               RB1   \n",
       "4     0.670000  0.671258                                              TP53   \n",
       "5     0.620000  0.275490                           TMB_HIGHorINTERMEDITATE   \n",
       "6     0.490000  0.240278                                           MSI_POS   \n",
       "7     0.612857  0.316512                                               NaN   \n",
       "\n",
       "   Method  \n",
       "0      LR  \n",
       "1      LR  \n",
       "2      LR  \n",
       "3      LR  \n",
       "4      LR  \n",
       "5      LR  \n",
       "6      LR  \n",
       "7  LR_AVG  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_perf_df.loc[all_perf_df['Method'].str.contains('LR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b93ec0b5-d388-4906-bb81-261ff480e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "# Example data\n",
    "X_train , y_train = train_df[SELECTED_FEATURE], train_df[label]\n",
    "X_test , y_test = test_df[SELECTED_FEATURE], test_df[label]\n",
    "X_val , y_val = val_df[SELECTED_FEATURE], val_df[label]\n",
    "\n",
    "# Separate the majority and minority classes\n",
    "X_train_majority = X_train[y_train == 0]\n",
    "y_train_majority = y_train[y_train == 0]\n",
    "X_train_minority = X_train[y_train == 1]\n",
    "y_train_minority = y_train[y_train == 1]\n",
    "\n",
    "# Upsample the minority class\n",
    "X_train_minority_upsampled, y_train_minority_upsampled = resample(\n",
    "    X_train_minority, y_train_minority,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=len(X_train_majority),  # Match number of majority class samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the majority class with the upsampled minority class\n",
    "X_train_upsampled = np.vstack((X_train_majority, X_train_minority_upsampled))\n",
    "y_train_upsampled = np.hstack((y_train_majority, y_train_minority_upsampled))\n",
    "\n",
    "\n",
    "class ModelReadyData_MT_V2(Dataset):\n",
    "    def __init__(self,\n",
    "                 feature_df,\n",
    "                 label_df,\n",
    "                ):\n",
    "        \n",
    "        self.x = torch.FloatTensor(feature_df)\n",
    "        \n",
    "        # Get the Y labels\n",
    "        self.y = torch.FloatTensor(label_df)\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # Given an index, return a tuple of an X with it's associated Y\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "train_data = ModelReadyData_MT_V2(X_train_upsampled, y_train_upsampled)\n",
    "test_data = ModelReadyData_MT_V2(X_test.to_numpy(), y_test.to_numpy())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class LogisticModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticModel, self).__init__()\n",
    "        self.linear = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "# Create the model\n",
    "model = LogisticModel()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f42a97d1-d889-4eb9-aed0-bc1156a78b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs.squeeze(), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#Validation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat  = model(test_data.x)\n",
    "# Print the learned parameters\n",
    "#print(f'Learned parameters: {model.linear.weight.item()}, {model.linear.bias.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05823856-6911-4c1a-b05d-bc60e38b07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
