{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d91cc3-2142-4a01-baec-ae90fa93508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg1 env, the retccl one has package issue with torchvision\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, count_label\n",
    "from Utils import log_message, set_seed\n",
    "from Utils import simple_line_plot\n",
    "from cluster_utils import get_cluster_data, get_cluster_label, get_updated_feature, get_pca_components\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles, get_feature_label_array_dynamic\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction\n",
    "from Model import Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6e76430f-8106-40c7-ba75-f8f80e7250ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cluster_feature(df_list, selected_labels):\n",
    "    merged_df = df_list[0].copy()\n",
    "    for f in list(['C_' + str(x) for x in range(0,2)]):\n",
    "        merged_df.rename(columns = {f: 'N2_' + f}, inplace = True)\n",
    "    for i in range(1,7):\n",
    "        df = df_list[i].copy()\n",
    "        for f in list(['C_' + str(x) for x in range(0,i+2)]):\n",
    "            df.rename(columns = {f: 'N' + str(i+2) + '_' + f}, inplace = True)\n",
    "        merged_df = pd.merge(merged_df, df, on= ['SAMPLE_ID'] + selected_labels, how='left')\n",
    "    \n",
    "    #Columns order\n",
    "    new_order = [col for col in merged_df.columns if col not in selected_labels] + selected_labels\n",
    "    merged_df = merged_df.reindex(columns=new_order)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b28f440-1549-48ac-80a7-e5e0c3f54c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1210/MAX_SSALLTUMORTILES_TrainOL100_TestOL0/ML_cluster_features/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1210/MAX_SSALLTUMORTILES_TrainOL100_TestOL0/ML_cluster_features//perf/' created.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "CLUSTER_ALG = 'KMEAN'\n",
    "CLUSTER_DIST = 'L2'\n",
    "feature_extraction_method = 'retccl'\n",
    "\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "data_dir = proj_dir + 'intermediate_data/model_ready_data/feature_' + feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\"\n",
    "feature_path =  os.path.join(data_dir, \"clusters\", CLUSTER_ALG, \"ML_Updated_Features_OnlyClusterPerc\")\n",
    "label_path = os.path.join(data_dir, \"clusters\", CLUSTER_ALG, \"ClusterInfo\")\n",
    "\n",
    "################################################\n",
    "#Create output dir\n",
    "################################################\n",
    "outdir =  proj_dir + \"intermediate_data/pred_out1210/\" + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) +'/'\n",
    "outdir0 =  outdir   + \"ML_cluster_features/\" \n",
    "outdir1 =  outdir0  + \"/perf/\"\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "163d07e8-f00b-41fa-b992-fdcd8ee657f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "#Get features and labels\n",
    "############################################################################################################\n",
    "selected_clusters = list(range(0,9))\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "val_df_list = []\n",
    "for N_CLUSTERS in range(2,9):\n",
    "    save_name = \"_NCLUSTER_\" + str(N_CLUSTERS) +  \"_DISTMETRIC_\" + CLUSTER_DIST\n",
    "    \n",
    "    train_ml_df = torch.load(feature_path + '/updated_train_feature' + save_name + 'cluster_perc.pth')\n",
    "    train_ml_df.rename(columns = {'ID': 'SAMPLE_ID'}, inplace = True)\n",
    "    test_ml_df = torch.load(feature_path + '/updated_test_feature' + save_name + 'cluster_perc.pth')\n",
    "    test_ml_df.rename(columns = {'ID': 'SAMPLE_ID'}, inplace = True)\n",
    "    val_ml_df = torch.load(feature_path + '/updated_val_feature' + save_name + 'cluster_perc.pth')\n",
    "    val_ml_df.rename(columns = {'ID': 'SAMPLE_ID'}, inplace = True)\n",
    "    \n",
    "    \n",
    "    train_info_df = pd.read_csv(label_path + '/train_cluster_info' + save_name + '.csv')\n",
    "    train_info_df.drop_duplicates(subset = ['SAMPLE_ID'], inplace = True)\n",
    "    test_info_df = pd.read_csv(label_path + '/test_cluster_info' + save_name + '.csv')\n",
    "    test_info_df.drop_duplicates(subset = ['SAMPLE_ID'], inplace = True)\n",
    "    val_info_df = pd.read_csv(label_path + '/valid_cluster_info' + save_name + '.csv')\n",
    "    val_info_df.drop_duplicates(subset = ['SAMPLE_ID'], inplace = True)\n",
    "\n",
    "    cur_train_df = train_ml_df.merge(train_info_df[['SAMPLE_ID'] + SELECTED_LABEL], on = ['SAMPLE_ID'])\n",
    "    cur_test_df = test_ml_df.merge(test_info_df[['SAMPLE_ID'] + SELECTED_LABEL], on = ['SAMPLE_ID'])\n",
    "    cur_val_df = val_ml_df.merge(val_info_df[['SAMPLE_ID'] + SELECTED_LABEL], on = ['SAMPLE_ID'])\n",
    "    train_df_list.append(cur_train_df)\n",
    "    test_df_list.append(cur_test_df)\n",
    "    val_df_list.append(cur_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dce66a-8854-4708-a2d6-dbdce76d4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comb_df = get_all_cluster_feature(train_df_list, SELECTED_LABEL)\n",
    "test_comb_df = get_all_cluster_feature(test_df_list, SELECTED_LABEL)\n",
    "val_comb_df = get_all_cluster_feature(val_df_list, SELECTED_LABEL)\n",
    "train_df_list.append(train_comb_df)\n",
    "test_df_list.append(test_comb_df)\n",
    "val_df_list.append(val_comb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a4add3b-3d3a-4945-bc89-271261b2caa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation test\n",
    "#train_df[SELECTED_LABEL].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b88aca5a-20ec-47de-a9e9-4dc32c105c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SAMPLE_ID', 'N2_C_0', 'N2_C_1', 'N3_C_0', 'N3_C_1', 'N3_C_2', 'N4_C_0',\n",
       "       'N4_C_1', 'N4_C_2', 'N4_C_3', 'N5_C_0', 'N5_C_1', 'N5_C_2', 'N5_C_3',\n",
       "       'N5_C_4', 'N6_C_0', 'N6_C_1', 'N6_C_2', 'N6_C_3', 'N6_C_4', 'N6_C_5',\n",
       "       'N7_C_0', 'N7_C_1', 'N7_C_2', 'N7_C_3', 'N7_C_4', 'N7_C_5', 'N7_C_6',\n",
       "       'N8_C_0', 'N8_C_1', 'N8_C_2', 'N8_C_3', 'N8_C_4', 'N8_C_5', 'N8_C_6',\n",
       "       'N8_C_7', 'AR', 'MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2',\n",
       "       'PTEN', 'RB1', 'TP53', 'TMB_HIGHorINTERMEDITATE', 'MSI_POS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c98bb938-9880-4567-98c2-c9c03d4ac3f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m final_perf_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     train_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_df \u001b[38;5;241m=\u001b[39m test_df_list[i]\n\u001b[1;32m      9\u001b[0m     val_df \u001b[38;5;241m=\u001b[39m val_df_list[i]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "selected_methods = ['LR','RF','XGBoost','SVM']\n",
    "THRES = 0.5\n",
    "\n",
    "final_perf_list = []\n",
    "for i in range(0,8):\n",
    "\n",
    "    train_df = train_df_list[i]\n",
    "    test_df = test_df_list[i]\n",
    "    val_df = val_df_list[i]\n",
    "\n",
    "    if i != 7:\n",
    "        N_CLUSTERS = i + 2\n",
    "        SELECTED_FEATURE  = list(['C_' + str(x) for x in range(0,N_CLUSTERS)])\n",
    "    else:\n",
    "        N_CLUSTERS = \"Combined\"\n",
    "        SELECTED_FEATURE  = ['N2_C_0', 'N2_C_1', 'N3_C_0', 'N3_C_1', 'N3_C_2', 'N4_C_0',\n",
    "                             'N4_C_1', 'N4_C_2', 'N4_C_3', 'N5_C_0', 'N5_C_1', 'N5_C_2', 'N5_C_3',\n",
    "       'N5_C_4', 'N6_C_0', 'N6_C_1', 'N6_C_2', 'N6_C_3', 'N6_C_4', 'N6_C_5',\n",
    "       'N7_C_0', 'N7_C_1', 'N7_C_2', 'N7_C_3', 'N7_C_4', 'N7_C_5', 'N7_C_6',\n",
    "       'N8_C_0', 'N8_C_1', 'N8_C_2', 'N8_C_3', 'N8_C_4', 'N8_C_5', 'N8_C_6',\n",
    "       'N8_C_7']\n",
    "\n",
    "\n",
    "    \n",
    "    all_perf_list = []\n",
    "    for method in selected_methods:\n",
    "        perf_list = []\n",
    "        for label in SELECTED_LABEL:    \n",
    "            X_train , y_train = train_df[SELECTED_FEATURE], train_df[label]\n",
    "            X_test , y_test = test_df[SELECTED_FEATURE], test_df[label]\n",
    "            X_val , y_val = val_df[SELECTED_FEATURE], val_df[label]\n",
    "    \n",
    "            # Separate the majority and minority classes\n",
    "            X_train_majority = X_train[y_train == 0]\n",
    "            y_train_majority = y_train[y_train == 0]\n",
    "            X_train_minority = X_train[y_train == 1]\n",
    "            y_train_minority = y_train[y_train == 1]\n",
    "            \n",
    "            # Upsample the minority class\n",
    "            X_train_minority_upsampled, y_train_minority_upsampled = resample(\n",
    "                X_train_minority, y_train_minority,\n",
    "                replace=True,  # Sample with replacement\n",
    "                n_samples=len(X_train_majority),  # Match number of majority class samples\n",
    "                random_state=42  # Reproducible results\n",
    "            )\n",
    "            \n",
    "            # Combine the majority class with the upsampled minority class\n",
    "            X_train_upsampled = np.vstack((X_train_majority, X_train_minority_upsampled))\n",
    "            y_train_upsampled = np.hstack((y_train_majority, y_train_minority_upsampled))\n",
    "    \n",
    "            if method == 'LR':\n",
    "                model = LogisticRegression()\n",
    "            elif method == 'RF':\n",
    "                model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "            elif method == 'XGBoost':\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "            elif method == 'SVM':\n",
    "                model = SVC(probability=True)\n",
    "            # Train the model\n",
    "            model.fit(X_train_upsampled, y_train_upsampled)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict_proba(X_test)[:,1]        \n",
    "            y_pred_c = ([float(t > THRES) for t in y_pred])\n",
    "            \n",
    "            # # Evaluate the model\n",
    "            cur_perf_df = compute_performance(y_test,y_pred,y_pred_c,\"\")\n",
    "            cur_perf_df['Label'] =  label\n",
    "            perf_list.append(cur_perf_df)\n",
    "        perf_df = pd.concat(perf_list)\n",
    "        mean_values = perf_df[['AUC', 'ACC', 'F1', 'F2', 'F3', 'Recall', 'Precision', 'Specificity', 'PR_AUC']].mean()\n",
    "        perf_df.loc['mean'] = mean_values\n",
    "        perf_df['Method'] = method\n",
    "        perf_df.loc['mean','Method'] = method + '_AVG'\n",
    "        perf_df.reset_index(drop = True, inplace = True)\n",
    "        all_perf_list.append(perf_df)\n",
    "    \n",
    "    all_perf_df = pd.concat(all_perf_list)\n",
    "    all_perf_df['N_CLUSTER'] = N_CLUSTERS\n",
    "    final_perf_list.append(all_perf_df)\n",
    "\n",
    "final_perf_df = pd.concat(final_perf_list)\n",
    "\n",
    "# print(all_perf_df.loc[all_perf_df['Method'].str.contains('AVG')])\n",
    "final_perf_df.to_csv(outdir1 + \"perf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "028d0edb-cff0-47c7-9b3d-1fbe2acf331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_perf_df = pd.concat(final_perf_list)\n",
    "\n",
    "# print(all_perf_df.loc[all_perf_df['Method'].str.contains('AVG')])\n",
    "final_perf_df.to_csv(outdir1 + \"perf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf67827d-65b8-4abe-9331-076f56aeeb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b93ec0b5-d388-4906-bb81-261ff480e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# BATCH_SIZE = 8\n",
    "# # Example data\n",
    "# X_train , y_train = train_df[SELECTED_FEATURE], train_df[label]\n",
    "# X_test , y_test = test_df[SELECTED_FEATURE], test_df[label]\n",
    "# X_val , y_val = val_df[SELECTED_FEATURE], val_df[label]\n",
    "\n",
    "# # Separate the majority and minority classes\n",
    "# X_train_majority = X_train[y_train == 0]\n",
    "# y_train_majority = y_train[y_train == 0]\n",
    "# X_train_minority = X_train[y_train == 1]\n",
    "# y_train_minority = y_train[y_train == 1]\n",
    "\n",
    "# # Upsample the minority class\n",
    "# X_train_minority_upsampled, y_train_minority_upsampled = resample(\n",
    "#     X_train_minority, y_train_minority,\n",
    "#     replace=True,  # Sample with replacement\n",
    "#     n_samples=len(X_train_majority),  # Match number of majority class samples\n",
    "#     random_state=42  # Reproducible results\n",
    "# )\n",
    "\n",
    "# # Combine the majority class with the upsampled minority class\n",
    "# X_train_upsampled = np.vstack((X_train_majority, X_train_minority_upsampled))\n",
    "# y_train_upsampled = np.hstack((y_train_majority, y_train_minority_upsampled))\n",
    "\n",
    "\n",
    "# class ModelReadyData_MT_V2(Dataset):\n",
    "#     def __init__(self,\n",
    "#                  feature_df,\n",
    "#                  label_df,\n",
    "#                 ):\n",
    "        \n",
    "#         self.x = torch.FloatTensor(feature_df)\n",
    "        \n",
    "#         # Get the Y labels\n",
    "#         self.y = torch.FloatTensor(label_df)\n",
    "        \n",
    "#     def __len__(self): \n",
    "#         return len(self.x)\n",
    "    \n",
    "#     def __getitem__(self,index):\n",
    "#         # Given an index, return a tuple of an X with it's associated Y\n",
    "#         x = self.x[index]\n",
    "#         y = self.y[index]\n",
    "        \n",
    "#         return x, y\n",
    "\n",
    "# train_data = ModelReadyData_MT_V2(X_train_upsampled, y_train_upsampled)\n",
    "# test_data = ModelReadyData_MT_V2(X_test.to_numpy(), y_test.to_numpy())\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # Define the model\n",
    "# class LogisticModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LogisticModel, self).__init__()\n",
    "#         self.linear = nn.Linear(4, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.sigmoid(self.linear(x))\n",
    "\n",
    "# # Create the model\n",
    "# model = LogisticModel()\n",
    "\n",
    "# # Define the loss function and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f42a97d1-d889-4eb9-aed0-bc1156a78b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# for epoch in range(100):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     for x, y in train_loader:\n",
    "#         outputs = model(x)\n",
    "#         loss = criterion(outputs.squeeze(), y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# #Validation\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_hat  = model(test_data.x)\n",
    "# # Print the learned parameters\n",
    "# #print(f'Learned parameters: {model.linear.weight.item()}, {model.linear.bias.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
