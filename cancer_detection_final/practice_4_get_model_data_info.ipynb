{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg1 env, the retccl one has package issue with torchvision\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize\n",
    "from Utils import log_message, set_seed\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles, get_feature_label_array_dynamic\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction\n",
    "from Model import Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52806641-55cf-4476-8d95-38f9cfa23cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Get clustering data\n",
    "def get_cluster_data(feature_list, label_list, id_list, selected_labels):\n",
    "    feature_list = [pd.DataFrame(x) for x in feature_list]\n",
    "    label_list = [y.squeeze() for y in label_list]\n",
    "    \n",
    "    for i,x in enumerate(feature_list):\n",
    "        x['ID'] = id_list[i]\n",
    "        for j,l in enumerate(selected_labels):\n",
    "            x[l] = int(label_list[i][j])\n",
    "    feature_df = pd.concat(feature_list)\n",
    "\n",
    "    #Change feature tumor frac name\n",
    "    feature_df.rename(columns = {2048: 'TUMOR_PIXEL_PERC'}, inplace = True)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def get_cluster_label(feature_df, cluster_centers, cluster_features):\n",
    "    r'''\n",
    "    Get Cluster label by compute dist between test/valid pcs to the center of kmeans\n",
    "    '''\n",
    "    pcs = pca.fit_transform(feature_df[cluster_features])\n",
    "    distances = np.linalg.norm(cluster_centers[:, np.newaxis] - pcs, axis=2)\n",
    "    closest_indices = np.argmin(distances, axis=0)\n",
    "    cluster_labels  = closest_indices\n",
    "\n",
    "    return cluster_labels\n",
    "    \n",
    "def get_updated_feature(input_df, selected_ids, selected_feature):\n",
    "    feature_list = []\n",
    "    ct = 0 \n",
    "    for pt in selected_ids:\n",
    "        if ct % 10 == 0 : print(ct)\n",
    "\n",
    "        cur_df = input_df.loc[input_df['ID'] == pt]\n",
    "\n",
    "        #Extract feature, label and tumor info\n",
    "        cur_feature = cur_df[selected_feature].values\n",
    "\n",
    "        feature_list.append(cur_feature)\n",
    "        ct += 1\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cd3a4d-3ad9-4657-ae9b-efb15592477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/model_ready_data/MAX_SSALLTUMORTILES_TrainOL100_TestOL0/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/model_ready_data/MAX_SSALLTUMORTILES_TrainOL100_TestOL0//clusters/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/model_ready_data/MAX_SSALLTUMORTILES_TrainOL100_TestOL0//split_fold0/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "SELECTED_FEATURE = [str(i) for i in range(0,2048)] + ['TUMOR_PIXEL_PERC']\n",
    "TUMOR_FRAC_THRES = 0\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "label_path = proj_dir + 'data/MutationCalls/'\n",
    "ft_ids_path =  proj_dir + 'intermediate_data/cd_finetune/cancer_detection_training/' #the ID used for fine-tuning cancer detection model, needs to be excluded from mutation study\n",
    "train_tile_path = proj_dir + 'intermediate_data/cancer_prediction_results110224/IMSIZE250_OL' + str(TRAIN_OVERLAP) + '/'\n",
    "test_tile_path =  proj_dir + 'intermediate_data/cancer_prediction_results110224/IMSIZE250_OL' + str(TEST_OVERLAP) + '/'\n",
    "feature_name = 'features_alltiles_retccl'\n",
    "\n",
    "################################################\n",
    "#Create output dir\n",
    "################################################\n",
    "outdir =   proj_dir + 'intermediate_data/model_ready_data/' +'MAX_SS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '/'\n",
    "create_dir_if_not_exists(outdir)\n",
    "outdir1 =  outdir + \"/clusters/\" \n",
    "create_dir_if_not_exists(outdir1)\n",
    "outdir2 =  outdir + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "create_dir_if_not_exists(outdir2)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec92db7-5880-409d-aaab-aaa7aabcdebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "#Select IDS\n",
    "############################################################################################################\n",
    "#All available IDs\n",
    "opx_ids = [x.replace('.tif','') for x in os.listdir(wsi_path)] #207\n",
    "opx_ids.sort()\n",
    "\n",
    "#Get IDs that are in FT train or already processed to exclude \n",
    "ft_ids_df = pd.read_csv(ft_ids_path + 'all_tumor_fraction_info.csv')\n",
    "ft_train_ids = list(ft_ids_df.loc[ft_ids_df['Train_OR_Test'] == 'Train','sample_id'])\n",
    "\n",
    "#OPX_182 â€“Exclude Possible Colon AdenoCa \u000b",
    "\n",
    "toexclude_ids = ft_train_ids + ['OPX_182']  #25\n",
    "\n",
    "\n",
    "#Exclude ids in ft_train or processed\n",
    "selected_ids = [x for x in opx_ids if x not in toexclude_ids] #199\n",
    "print(len(selected_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2c6fc9-cf95-41c4-9ccf-b25226526572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "8\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "#Get Train and test IDs, 80% - 20%\n",
    "############################################################################################################\n",
    "# Number of folds\n",
    "n_splits = 5\n",
    "\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Generate the folds\n",
    "train_ids_folds = []\n",
    "test_ids_folds = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(selected_ids)):\n",
    "    train_ids_folds.append([selected_ids[i] for i in train_index])\n",
    "    test_ids_folds.append([selected_ids[i] for i in test_index])\n",
    "\n",
    "full_train_ids = train_ids_folds[SELECTED_FOLD]\n",
    "test_ids = test_ids_folds[SELECTED_FOLD]\n",
    "\n",
    "# Randomly select 5% of the train_ids for validation\n",
    "train_ids, val_ids = train_test_split(full_train_ids, test_size=0.05, random_state=42)\n",
    "print(len(train_ids))\n",
    "print(len(val_ids))\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e92ff13-08eb-453b-995a-ed890abec534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "0\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "#Get features and labels\n",
    "#NOTE: OPX_005 has no tumor tiles, so excluded in this step\n",
    "############################################################################################################\n",
    "train_feature, train_label, train_info, train_tf_info, selected_train_ids = get_feature_label_array_dynamic(train_tile_path,feature_name, train_ids, SELECTED_LABEL,SELECTED_FEATURE,\"Train\" ,tumor_fraction_thres = TUMOR_FRAC_THRES,train_sample_size = TRAIN_SAMPLE_SIZE)\n",
    "val_feature, val_label, val_info, val_tf_info, select_val_ids = get_feature_label_array_dynamic(train_tile_path,feature_name, val_ids, SELECTED_LABEL,SELECTED_FEATURE, \"Train\" ,tumor_fraction_thres = TUMOR_FRAC_THRES,train_sample_size = TRAIN_SAMPLE_SIZE)\n",
    "test_feature, test_label, test_info, test_tf_info, select_test_ids = get_feature_label_array_dynamic(test_tile_path, feature_name, test_ids, SELECTED_LABEL, SELECTED_FEATURE, \"Test\", tumor_fraction_thres = TUMOR_FRAC_THRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e53ca-16c8-429b-b30c-705022a19f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_feature, outdir2 + 'train_feature.pth')\n",
    "torch.save(test_feature,  outdir2 + 'test_feature.pth')\n",
    "torch.save(val_feature,   outdir2 + 'val_feature.pth')\n",
    "\n",
    "torch.save(train_label, outdir2 + 'train_label.pth')\n",
    "torch.save(test_label,  outdir2 + 'test_label.pth')\n",
    "torch.save(val_label,   outdir2 + 'val_label.pth')\n",
    "\n",
    "\n",
    "torch.save(train_info,   outdir2 + 'train_info.pth')\n",
    "torch.save(test_info,   outdir2 + 'test_info.pth')\n",
    "torch.save(val_info,   outdir2 + 'val_info.pth')\n",
    "\n",
    "torch.save(train_tf_info,   outdir2 + 'train_tf_info.pth')\n",
    "torch.save(test_tf_info,   outdir2 + 'test_tf_info.pth')\n",
    "torch.save(val_tf_info,   outdir2 + 'val_tf_info.pth')\n",
    "\n",
    "\n",
    "torch.save(selected_train_ids,   outdir2 + 'train_ids.pth')\n",
    "torch.save(select_test_ids,   outdir2 + 'test_ids.pth')\n",
    "torch.save(select_val_ids,   outdir2 + 'val_ids.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cbd1a-4751-4935-803f-66ac1fd022c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 1s in each column\n",
    "train_label_np = np.concatenate(train_label)\n",
    "count_ones = np.sum(train_label_np == 1, axis=0)\n",
    "\n",
    "print(\"Number of 1s in each column:\", count_ones)\n",
    "percentage_ones = np.round((count_ones / train_label_np.shape[0]) * 100,1)\n",
    "print(\"% of 1s in each column:\", percentage_ones)\n",
    "print([\"Mutation labels  :\",\"AR\",\"HR\",\"PTEN\",\"RB1\",\"TP53\",\"TMB\",\"MSI_POS\"])\n",
    "\n",
    "# Count the number of 1s in each column\n",
    "test_label_np = np.concatenate(test_label)\n",
    "count_ones = np.sum(test_label_np == 1, axis=0)\n",
    "\n",
    "print(\"--------TEST------\")\n",
    "print(\"Number of 1s in each column:\", count_ones)\n",
    "percentage_ones = np.round((count_ones / test_label_np.shape[0]) * 100,1)\n",
    "print(\"% of 1s in each column:\", percentage_ones)\n",
    "print([\"Mutation labels  :\",\"AR\",\"HR\",\"PTEN\",\"RB1\",\"TP53\",\"TMB\",\"MSI_POS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a9d93-11c1-4f2b-80a7-7321c163d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Clustering\n",
    "################################################\n",
    "feature_for_cluster = range(0,2048)\n",
    "train_feature_df = get_cluster_data(train_feature, train_label, selected_train_ids, SELECTED_LABEL)\n",
    "test_feature_df = get_cluster_data(test_feature, test_label, select_test_ids, SELECTED_LABEL)\n",
    "valid_feature_df = get_cluster_data(val_feature, val_label, select_val_ids, SELECTED_LABEL)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(train_feature_df[feature_for_cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd333d-8078-4b10-a515-6306d2e8ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WCSS for different values of k\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    print(i)\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(principal_components)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow graph\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e54d45-333e-4114-ab9d-a9a988974f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(principal_components)\n",
    "\n",
    "# Get cluster centers and labels\n",
    "centers = kmeans.cluster_centers_\n",
    "cluster_labels_train = kmeans.labels_\n",
    "\n",
    "# Plot the data points and cluster centers with cluster labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=cluster_labels_train, cmap='viridis',alpha=0.6)\n",
    "for i, center in enumerate(centers):\n",
    "    plt.scatter(center[0], center[1], c='red', marker=f'${i}$', s=200)  # Use cluster label as marker\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('K-Means Clustering for Tile Embeddings on PCs')\n",
    "plt.grid(True)\n",
    "plt.savefig(outdir1  + 'original_cluster_scatter.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ddc6c9-5e39-4faa-a0ed-23d17594f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Cluster labels\n",
    "cluster_labels_test = get_cluster_label(test_feature_df, centers, feature_for_cluster)\n",
    "cluster_labels_val = get_cluster_label(valid_feature_df, centers, feature_for_cluster)\n",
    "\n",
    "#add cluster label to df\n",
    "train_feature_df['Cluster'] = cluster_labels_train\n",
    "test_feature_df['Cluster'] = cluster_labels_test\n",
    "valid_feature_df['Cluster'] = cluster_labels_val\n",
    "\n",
    "\n",
    "updated_feature_list = list(range(0,2048)) + ['TUMOR_PIXEL_PERC','Cluster']\n",
    "updated_train_feature = get_updated_feature(train_feature_df, selected_train_ids, updated_feature_list)\n",
    "updated_test_feature = get_updated_feature(test_feature_df, select_test_ids, updated_feature_list)\n",
    "updated_val_feature = get_updated_feature(valid_feature_df, select_val_ids, updated_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data = ModelReadyData_diffdim(updated_train_feature,train_label,train_tf_info)\n",
    "test_data = ModelReadyData_diffdim(updated_test_feature,test_label,test_tf_info)\n",
    "val_data = ModelReadyData_diffdim(updated_val_feature,val_label,val_tf_info)\n",
    "\n",
    "#Output\n",
    "torch.save(train_data, outdir2 + 'train_data.pth')\n",
    "torch.save(test_data,  outdir2 + 'test_data.pth')\n",
    "torch.save(val_data,   outdir2 + 'val_data.pth')\n",
    "\n",
    "torch.save(train_info,   outdir2 + 'train_info.pth')\n",
    "torch.save(test_info,   outdir2 + 'test_info.pth')\n",
    "torch.save(val_info,   outdir2 + 'val_info.pth')\n",
    "\n",
    "torch.save(train_tf_info,   outdir2 + 'train_tf_info.pth')\n",
    "torch.save(test_tf_info,   outdir2 + 'test_tf_info.pth')\n",
    "torch.save(val_tf_info,   outdir2 + 'val_tf_info.pth')\n",
    "\n",
    "\n",
    "torch.save(selected_train_ids,   outdir2 + 'train_ids.pth')\n",
    "torch.save(select_test_ids,   outdir2 + 'test_ids.pth')\n",
    "torch.save(select_val_ids,   outdir2 + 'val_ids.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f4bed-ef96-4bfb-9aa7-a8ded6a7b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster anlaysis\n",
    "#Assign cluster\n",
    "train_feature_df['PC1'] = principal_components[:, 0]\n",
    "train_feature_df['PC2'] = principal_components[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58654b7-d9c1-46ea-890b-b418e9fb9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot scatter cluster plot for each outcome,\n",
    "for plot_outcome in SELECTED_LABEL:\n",
    "    plot_data = train_feature_df[['PC1','PC2', 'Cluster'] + [plot_outcome]]\n",
    "        \n",
    "    # Create scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Separate dots by Cluster but color by Outcome\n",
    "    for cluster in plot_data['Cluster'].unique():\n",
    "        subset = plot_data[plot_data['Cluster'] == cluster]\n",
    "        ax.scatter(subset['PC1'], subset['PC2'], \n",
    "                   s=np.where(subset[plot_outcome] == 1, 20, 0.001), \n",
    "                   c=['steelblue' if outcome == 0 else 'darkred' for outcome in subset[plot_outcome]], \n",
    "                   alpha=0.6,\n",
    "                   linewidth=1.5, label=f'Cluster {cluster}',\n",
    "                   zorder=3 if (subset[plot_outcome] == 1).any() else 2)\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title(plot_outcome)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outdir1 +  'cluster_scatter_' + plot_outcome + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f29007-581c-4a3b-a0af-03ef7cc73698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of outcome by cluster (stacked bar plot)   \n",
    "for plot_outcome in SELECTED_LABEL:\n",
    "    plot_data = train_feature_df[['PC1','PC2', 'Cluster'] + [plot_outcome]]\n",
    " \n",
    "    # Create a crosstab to count the occurrences of each outcome per cluster\n",
    "    crosstab = pd.crosstab(plot_data['Cluster'], plot_data[plot_outcome])\n",
    "    \n",
    "    # Calculate the percentage of each outcome per cluster\n",
    "    percentage_crosstab = crosstab.div(crosstab.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Plot the stacked bar chart\n",
    "    percentage_crosstab.plot(kind='bar', stacked=True, color=['steelblue', 'darkred'])\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title('Bar Chart of ' + plot_outcome + ' per Cluster')\n",
    "    plt.legend(title=plot_outcome, loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir1 + \"outcome_distribution_\" + plot_outcome + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c88fc-11d0-438c-af82-2ae5a00009c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined distribution of outcome by cluster \n",
    "for plot_outcome in SELECTED_LABEL:\n",
    "    plot_data = train_feature_df[['PC1','PC2', 'Cluster'] + [plot_outcome]]\n",
    "\n",
    "    # Create a crosstab to count the occurrences of each outcome per cluster\n",
    "    crosstab = pd.crosstab(plot_data[plot_outcome],plot_data['Cluster'])\n",
    "\n",
    "    # Calculate the percentage of each outcome per cluster\n",
    "    percentage_crosstab = crosstab.div(crosstab.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Plot the stacked bar chart\n",
    "    percentage_crosstab.plot(kind='bar', stacked=False, color=['#440154','#3b528b','#5ec962','#fde725'])\n",
    "    plt.xlabel(plot_outcome)\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title('Bar Chart of Clusters Per Outcome')\n",
    "    plt.legend(title='Cluster', loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir1  + 'cluster_distribution_' +  plot_outcome + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477cf63-21dc-4314-8b81-d3def7e18405",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_size = 250\n",
    "pixel_overlap = 100\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "pretrain_model_name = \"retccl\"\n",
    "mag_target_prob = 2.5\n",
    "smooth = False\n",
    "mag_target_tiss = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72968b-0f49-4f58-bd56-4a80a7b8631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e8a93-6e1a-47cc-bc9c-9cfea8c114f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "pt = selected_train_ids[i]\n",
    "cur_df = train_feature_df.loc[train_feature_df['ID'] == pt,['ID','Cluster']]\n",
    "cur_info_df = train_info[i]\n",
    "\n",
    "print([\"Mutation labels  :\",\"AR\",\"HR\",\"PTEN\",\"RB1\",\"TP53\",\"TMB\",\"MSI_POS\"])\n",
    "print(train_label[i])\n",
    "\n",
    "_file = wsi_path + pt + \".tif\"\n",
    "oslide = openslide.OpenSlide(_file)\n",
    "save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "\n",
    "#Generate tiles\n",
    "tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "\n",
    "#get level 0 size in px\n",
    "l0_w = oslide.level_dimensions[0][0]\n",
    "l0_h = oslide.level_dimensions[0][1]\n",
    "\n",
    "#1.25x tissue detection for mask\n",
    "from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "import cv2\n",
    "if 'OPX' in pt:\n",
    "    rad_tissue = 5\n",
    "elif '(2017-0133)' in pt:\n",
    "    rad_tissue = 2\n",
    "lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "\n",
    "cur_comb_df = pd.concat([cur_info_df, cur_df], axis = 1)\n",
    "\n",
    "#2.5x for probability maps\n",
    "lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "\n",
    "for index, row in cur_comb_df.iterrows():\n",
    "    cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "    x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "    \n",
    "    #Extract tile for prediction\n",
    "    lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "    tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "    map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "\n",
    "    #Store predicted probabily in map and count\n",
    "    try: \n",
    "        x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "        x_map[map_xstart:map_xend,map_ystart:map_yend] += row['Cluster']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('post-processing')\n",
    "x_count = np.where(x_count < 1, 1, x_count)\n",
    "x_map = x_map / x_count\n",
    "\n",
    "x_sm = x_map\n",
    "\n",
    "he_mask = cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])) #resize to output image size\n",
    "#TODO:\n",
    "#get cancer_mask:\n",
    "# cancer_mask == \n",
    "# x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "x_sm[he_mask < 1] = -1 \n",
    "\n",
    "plt.imshow(x_sm, cmap='Spectral_r')\n",
    "plt.colorbar()\n",
    "plt.savefig(os.path.join(outdir1, save_name + '_cluster.png'), dpi=500,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
