{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab26db-e9d0-49fe-b28b-d1f2ecd1de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import openslide\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import geojson\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import PIL\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from skimage import draw, measure, morphology, filters\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon, shape\n",
    "from shapely.ops import cascaded_union, unary_union\n",
    "import json\n",
    "import shapely\n",
    "import warnings\n",
    "from scipy import ndimage\n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords\n",
    "from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "from Utils import slide_ROIS\n",
    "from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import get_map_startend\n",
    "from Utils import cancer_mask_fix_res, tile_ROIS, check_any_invalid_poly, make_valid_poly\n",
    "from Utils import convert_img\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42c6cb8-aed1-4043-854a-735162625e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/2_cancer_detection/TAN_TMA_Cores/IMSIZE250_OL0/' already exists.\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "#USER INPUT \n",
    "############################################################################################################\n",
    "mag_extract = 20        # do not change this, model trained at 250x250 at 20x\n",
    "save_image_size = 250   # do not change this, model trained at 250x250 at 20x\n",
    "pixel_overlap = 0       # specify the level of pixel overlap in your saved images\n",
    "limit_bounds = True     # this is weird, dont change it\n",
    "smooth = True           # whether or not to gaussian smooth the output probability map\n",
    "ft_model = True         # whether or not to use fine-tuned model\n",
    "mag_target_prob = 2.5   # 2.5x for probality maps\n",
    "mag_target_tiss = 1.25   #1.25x for tissue detection, this is not used for TMA\n",
    "bi_thres = 0.4           #Binary classification threshold for cancer mask\n",
    "cohort_name = \"TAN_TMA_Cores\"\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "#DIR\n",
    "############################################################################################################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "wsi_location_ccola = proj_dir + '/data/CCola/all_slides/'\n",
    "wsi_location_opx = proj_dir + '/data/OPX/'\n",
    "wsi_location_tan = proj_dir + 'data/TAN_TMA_Cores/'\n",
    "feature_location = proj_dir + 'intermediate_data/1_tile_pulling/'+ cohort_name + \"/\" + \"IMSIZE\" + str(save_image_size) + \"_OL\" + str(pixel_overlap) + \"/\" #cancer_prediction_results110224\n",
    "model_path = proj_dir + 'models/cancer_detection_models/mets/'\n",
    "\n",
    "out_location = proj_dir + 'intermediate_data/2_cancer_detection/'+ cohort_name + \"/\" + \"IMSIZE\" + str(save_image_size) + \"_OL\" + str(pixel_overlap) + \"/\"\n",
    "create_dir_if_not_exists(out_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ee88f3-ee56-4750-a3fb-ffaa3a1ae360",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "#Select IDS\n",
    "############################################################################################################\n",
    "#Get IDs that are in FT train or already processed to exclude \n",
    "fine_tune_ids_df = pd.read_csv(proj_dir + 'intermediate_data/cd_finetune/cancer_detection_training/all_tumor_fraction_info.csv')\n",
    "ft_train_ids = list(fine_tune_ids_df.loc[fine_tune_ids_df['Train_OR_Test'] == 'Train','sample_id'])\n",
    "toexclude_ids = ft_train_ids + ['OPX_182'] #OPX_182 â€“Exclude Possible Colon AdenoCa \n",
    "\n",
    "#All available IDs\n",
    "opx_ids = [x.replace('.tif','') for x in os.listdir(wsi_location_opx)] #207\n",
    "ccola_ids = [x.replace('.svs','') for x in os.listdir(wsi_location_ccola) if '(2017-0133)' in x] #234\n",
    "tan_ids =  [x.replace('.tif','') for x in os.listdir(wsi_location_tan)] #677\n",
    "\n",
    "if cohort_name == \"OPX\":\n",
    "    all_ids = opx_ids\n",
    "elif cohort_name == \"ccola\":\n",
    "    all_ids = ccola_ids\n",
    "elif cohort_name == \"TAN_TMA_Cores\":\n",
    "    all_ids = tan_ids\n",
    "elif cohort_name == \"all\":\n",
    "    all_ids = opx_ids + ccola_ids + tan_ids\n",
    "\n",
    "#Exclude ids in ft_train or processed\n",
    "selected_ids = [x for x in all_ids if x not in toexclude_ids]\n",
    "selected_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9944488-6254-4056-b1da-55cf9967b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = ['TMA97A-1-2']\n",
    "selected_ids = ['OPX_001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6abb49-01bf-4fce-8131-4668891c94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancer_inference(_file, save_image_size, pixel_overlap, limit_bounds, mag_target_prob, mag_extract):\n",
    "    #Load slides\n",
    "    oslide = openslide.OpenSlide(_file)\n",
    "    \n",
    "    #Generate tiles\n",
    "    tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "    print('starting inference')\n",
    "    #get level 0 size in px\n",
    "    l0_w = oslide.level_dimensions[0][0]\n",
    "    l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "    #2.5x for probability maps\n",
    "    lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "    x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    tile_info_df['pred_map_location'] = pd.NA\n",
    "    for index, row in tile_info_df.iterrows():\n",
    "        if (index % 500 == 0): print(index)\n",
    "        cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "        x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "        #Extract tile for prediction\n",
    "        lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "        tile_pull = tiles.get_tile(lvl_in_deepzoom, (x, y))\n",
    "        tile_pull = tile_pull.resize(size=(save_image_size, save_image_size),resample=PIL.Image.LANCZOS) #resize\n",
    "        tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "        map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "        tile_info_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "        \n",
    "        #Cancer segmentation\n",
    "        tile_pull = np.array(tile_pull)\n",
    "        with learn.no_bar():\n",
    "            inp, pred_class, pred_idx, outputs = learn.predict(tile_pull[:, :, 0:3], with_input=True)\n",
    "        \n",
    "        #Get predicted output\n",
    "        #NOTe: updated 11/06/24, use cv2.resize\n",
    "        outputs_np = outputs.numpy() #[N_CLASS, IMAGE_SIZE, IMAGE_SIZE]\n",
    "        output_c1_np = cv2.resize(outputs_np[1], (map_yend - map_ystart,map_xend - map_xstart)) #class1 predicted prob, resize (width (col in np), height(row in np))\n",
    "        output_c1_np = output_c1_np.round(2)\n",
    "        \n",
    "        #Store predicted probabily in map and count\n",
    "        try: \n",
    "            x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "            x_map[map_xstart:map_xend,map_ystart:map_yend] += output_c1_np\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return x_count, x_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7d3c97-f844-41bd-899a-f6e84a65270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/2_cancer_detection/TAN_TMA_Cores/IMSIZE250_OL0/OPX_001/' created.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'semtorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#Load model   \u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ft_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mft_models/dlv3_2ep_2e4_update-07182023_RT_fine_tuned..pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#all use mets model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         save_location \u001b[38;5;241m=\u001b[39m save_location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m         create_dir_if_not_exists(save_location)\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/acmil/lib/python3.11/site-packages/fastai/learner.py:448\u001b[0m, in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu, pickle_module)\u001b[0m\n\u001b[1;32m    446\u001b[0m distrib_barrier()\n\u001b[1;32m    447\u001b[0m map_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cpu \u001b[38;5;28;01melse\u001b[39;00m default_device()\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[1;32m    450\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom classes or functions exported with your `Learner` not available in namespace. Re-declare/import before loading:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/acmil/lib/python3.11/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/acmil/lib/python3.11/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/acmil/lib/python3.11/site-packages/torch/serialization.py:1165\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'semtorch'"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "#START\n",
    "############################################################################################################\n",
    "for cur_id in selected_ids:\n",
    "\n",
    "    save_location = out_location + cur_id + \"/\" \n",
    "    create_dir_if_not_exists(save_location)\n",
    "\n",
    "    if 'OPX' in cur_id:\n",
    "        _file = wsi_location_opx + cur_id + \".tif\"\n",
    "        rad_tissue = 5\n",
    "    elif '(2017-0133)' in cur_id:\n",
    "        _file = wsi_location_ccola + cur_id + '.svs'\n",
    "        rad_tissue = 2\n",
    "    elif 'TMA' in cur_id:\n",
    "        _file = wsi_location_tan + cur_id + '.tif'\n",
    "        rad_tissue = 2\n",
    "\n",
    "    #Check if already processed\n",
    "    if os.path.exists(save_location + \"ft_model\" + \"/\") == False:\n",
    "        #Load model   \n",
    "        if ft_model == True:\n",
    "            learn = load_learner(model_path + 'ft_models/dlv3_2ep_2e4_update-07182023_RT_fine_tuned..pkl',cpu=False) #all use mets model\n",
    "            save_location = save_location + \"ft_model\" + \"/\"\n",
    "            create_dir_if_not_exists(save_location)\n",
    "        else:\n",
    "            learn = load_learner(model_path + 'dlv3_2ep_2e4_update-07182023_RT.pkl',cpu=False) #all use prior mets model\n",
    "            save_location = save_location + \"prior_model\" + \"/\"\n",
    "            create_dir_if_not_exists(save_location)\n",
    "    \n",
    "        #Load tile info \n",
    "        tile_info_df = pd.read_csv(feature_location + cur_id + \"/\"  + cur_id + \"_tiles.csv\")\n",
    "        tile_mag_extract = list(set(tile_info_df['MAG_EXTRACT']))[0]\n",
    "        tile_save_image_size = list(set(tile_info_df['SAVE_IMAGE_SIZE']))[0]\n",
    "        tile_pixel_overlap = list(set(tile_info_df['PIXEL_OVERLAP']))[0]\n",
    "        tile_limit_bounds =   list(set(tile_info_df['LIMIT_BOUNDS']))[0]\n",
    "    \n",
    "        cond1 = (tile_mag_extract == mag_extract)\n",
    "        cond2 = (tile_save_image_size == save_image_size)\n",
    "        cond3 = (tile_pixel_overlap == pixel_overlap)\n",
    "        cond4 = (tile_limit_bounds == limit_bounds)\n",
    "    \n",
    "        if cond1 & cond2 & cond3 & cond4:\n",
    "            can_proceed = True\n",
    "            print(can_proceed)\n",
    "    \n",
    "        print(tile_info_df.shape)\n",
    "    \n",
    "        if can_proceed == True:\n",
    "            #Cancer inference\n",
    "            x_count, x_map = cancer_inference(_file, save_image_size, pixel_overlap, limit_bounds, mag_target_prob, mag_extract)\n",
    "            \n",
    "            print('post-processing')\n",
    "            print('Cancer Prob generation')\n",
    "            x_count = np.where(x_count < 1, 1, x_count)\n",
    "            x_map = x_map / x_count\n",
    "            x_map[x_map>1]=1\n",
    "    \n",
    "            if smooth == True:\n",
    "                x_sm = filters.gaussian(x_map, sigma=2)\n",
    "            if smooth == False:\n",
    "                x_sm = x_map\n",
    "            cmap = plt.get_cmap('jet')\n",
    "            rgba_img = cmap(x_sm)\n",
    "            rgb_img = np.delete(rgba_img, 3, 2)\n",
    "            colimg = PIL.Image.fromarray(np.uint8(rgb_img * 255))\n",
    "            colimg.save(os.path.join(save_location, cur_id + '_cancer_prob.jpeg'))\n",
    "    \n",
    "    \n",
    "            print('Get cancer mask')\n",
    "            print('detecting tissue')\n",
    "            #1.25x tissue detection\n",
    "            lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "            lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "            tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "            #Binary classification\n",
    "            binary_preds = cancer_mask_fix_res(x_sm,cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])), bi_thres)\n",
    "    \n",
    "            #Output annotation\n",
    "            print('saving...')\n",
    "            polygons = tile_ROIS(mask_arr=binary_preds, lvl_resize=lvl_resize)\n",
    "    \n",
    "            #Make valid polygons (ex: OPX_022)\n",
    "            invalid_polygons = check_any_invalid_poly(polygons) #check if there is any invalid polys\n",
    "            if len(invalid_polygons) > 0 :\n",
    "                polygons = make_valid_poly(polygons, buff_value = 4)\n",
    "        \n",
    "            slide_ROIS(polygons=polygons, mpp=float(oslide.properties[openslide.PROPERTY_NAME_MPP_X]),\n",
    "                            savename=os.path.join(save_location,cur_id+'_cancer.json'), labels='AI_tumor', ref=[0,0], roi_color=-16711936)\n",
    "    \n",
    "            #Get binary prediction for each tile\n",
    "            #NOTE: previous do x_map when prediction, is not accurate, because the x_map may change as process to the next tile, so need to do this in post-processing\n",
    "            tile_info_df['TUMOR_PIXEL_PERC'] = pd.NA\n",
    "            for index, row in tile_info_df.iterrows():\n",
    "                cur_map_loc = row['pred_map_location'].strip(\"()\").split(\", \")\n",
    "                map_xstart, map_xend, map_ystart, map_yend = int(cur_map_loc[0]),int(cur_map_loc[1]), int(cur_map_loc[2]), int(cur_map_loc[3])\n",
    "    \n",
    "                #Get current prediction\n",
    "                cur_pred = binary_preds[map_xstart:map_xend,map_ystart:map_yend]\n",
    "                cur_count1 = np.sum(cur_pred == 1) #num pixels that has predicted prob = 1\n",
    "                cur_perc1  = (cur_count1 / cur_pred.size) #fraction of pixels prob = 1\n",
    "                tile_info_df.loc[index,'TUMOR_PIXEL_PERC'] = cur_perc1\n",
    "    \n",
    "            tile_info_df.to_csv(save_location + cur_id + \"_TILE_TUMOR_PERC.csv\", index = False)\n",
    "    \n",
    "    \n",
    "            #Grab tiles and plot\n",
    "            tile_info_df_sorted = tile_info_df.sort_values(by = ['TUMOR_PIXEL_PERC'], ascending = False) \n",
    "            for i in range(0,5): #top5\n",
    "                cur_row = tile_info_df_sorted.iloc[i]\n",
    "                cur_xy = cur_row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "                x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "                tile_pull_ex = tiles.get_tile(tile_lvls.index(mag_extract), (x, y))\n",
    "                tile_pull_ex = tile_pull_ex.resize(size=(save_image_size, save_image_size),resample=PIL.Image.LANCZOS) #resize\n",
    "                tile_pull_ex = convert_img(tile_pull_ex)\n",
    "    \n",
    "                #Save tile\n",
    "                cur_tf = round(cur_row['TUMOR_PIXEL_PERC'],2)\n",
    "                cur_mag = cur_row['MAG_EXTRACT']\n",
    "                tile_save_name = \"TILE_@\" + str(cur_mag) + \"x\" + \"_X\" + str(x) +  \"Y\" + str(y) +   \"_TF\" + str(cur_tf) + \".png\"\n",
    "                tile_pull_ex.save(os.path.join(save_location, tile_save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
