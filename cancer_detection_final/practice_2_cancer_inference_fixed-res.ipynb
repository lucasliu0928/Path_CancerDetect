{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab26db-e9d0-49fe-b28b-d1f2ecd1de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import openslide\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import geojson\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import PIL\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from skimage import draw, measure, morphology, filters\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon, shape\n",
    "from shapely.ops import cascaded_union, unary_union\n",
    "import json\n",
    "import shapely\n",
    "import warnings\n",
    "from scipy import ndimage\n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords\n",
    "from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "from Utils import slide_ROIS\n",
    "from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import get_map_startend\n",
    "from Utils import cancer_mask_fix_res, tile_ROIS, check_any_invalid_poly, make_valid_poly\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0baa7c-c19b-4c6c-b1f3-c9d4c387a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.11\n",
      "1.13.1+cu117\n",
      "0.14.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(fastai.__version__)\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42c6cb8-aed1-4043-854a-735162625e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USER INPUT \n",
    "mag_extract = 20        # do not change this, model trained at 250x250 at 20x\n",
    "save_image_size = 250   # do not change this, model trained at 250x250 at 20x\n",
    "pixel_overlap = 100     # specify the level of pixel overlap in your saved images\n",
    "limit_bounds = True     # this is weird, dont change it\n",
    "smooth = True           # whether or not to gaussian smooth the output probability map\n",
    "ft_model = True        # whether or not to use fine-tuned model\n",
    "mag_target_prob = 2.5   # 2.5x for probality maps\n",
    "mag_target_tiss = 1.25   #1.25x for tissue detection\n",
    "bi_thres = 0.4  #Binary classification threshold for cancer mask\n",
    "\n",
    "#DIR\n",
    "proj_dir = '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/'\n",
    "wsi_location_ccola = '/fh/scratch/delete90/haffner_m/user/scan_archives/Prostate/MDAnderson/CCola/all_slides/'\n",
    "wsi_location_opx = proj_dir + '/data/OPX/'\n",
    "out_location = proj_dir + 'intermediate_data/cancer_prediction_results110224/'+ \"IMSIZE\" + str(save_image_size) + \"_OL\" + str(pixel_overlap) + \"/\"\n",
    "model_path = proj_dir + 'models/cancer_detection_models/mets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ee88f3-ee56-4750-a3fb-ffaa3a1ae360",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "#Select IDS\n",
    "############################################################################################################\n",
    "#Get IDs that are in FT train or already processed to exclude \n",
    "fine_tune_ids_df = pd.read_csv('/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cd_finetune/cancer_detection_training/all_tumor_fraction_info.csv')\n",
    "ft_train_ids = list(fine_tune_ids_df.loc[fine_tune_ids_df['Train_OR_Test'] == 'Train','sample_id'])\n",
    "\n",
    "#OPX_182 â€“Exclude Possible Colon AdenoCa \u000b",
    "\n",
    "toexclude_ids = ft_train_ids + ['OPX_182'] #25\n",
    "\n",
    "#All available IDs\n",
    "opx_ids = [x.replace('.tif','') for x in os.listdir(wsi_location_opx)] #207\n",
    "opx_ids.sort()\n",
    "ccola_ids = [x.replace('.svs','') for x in os.listdir(wsi_location_ccola) if '(2017-0133)' in x] #234\n",
    "ccola_ids.sort()\n",
    "all_test = opx_ids + ccola_ids\n",
    "\n",
    "#Exclude ids in ft_train or processed\n",
    "selected_ids = [x for x in all_test if x not in toexclude_ids] #416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3a62d0-19af-41d8-92ac-eebedd18efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_id= '(2017-0133) 4-2-B_B1-1'\n",
    "cur_id = \"OPX_001\"\n",
    "\n",
    "if 'OPX' in cur_id:\n",
    "    _file = wsi_location_opx + cur_id + \".tif\"\n",
    "    rad_tissue = 5\n",
    "elif '(2017-0133)' in cur_id:\n",
    "    _file = wsi_location_ccola + cur_id + '.svs'\n",
    "    rad_tissue = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6fdbf8-8771-461a-a300-147e9f05896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results110224/IMSIZE250_OL100/OPX_001/' already exists.\n"
     ]
    }
   ],
   "source": [
    "#Load slides\n",
    "oslide = openslide.OpenSlide(_file)\n",
    "save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "save_location = out_location + cur_id + \"/\" \n",
    "create_dir_if_not_exists(save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae37f25-8136-464c-b122-fc32cb0edd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(save_location + \"ft_model\" + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86369bf1-9608-4733-8a6d-3d6c40863941",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Custom classes or functions exported with your `Learner` not available in namespace.\\Re-declare/import before loading:\n\t'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Load model   \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ft_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mft_models/dlv3_2ep_2e4_update-07182023_RT_fine_tuned..pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#all use mets model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     save_location \u001b[38;5;241m=\u001b[39m save_location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     create_dir_if_not_exists(save_location)\n",
      "File \u001b[0;32m~/anaconda3/envs/paimg_new5/lib/python3.8/site-packages/fastai/learner.py:446\u001b[0m, in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu, pickle_module)\u001b[0m\n\u001b[1;32m    444\u001b[0m distrib_barrier()\n\u001b[1;32m    445\u001b[0m map_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cpu \u001b[38;5;28;01melse\u001b[39;00m default_device()\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[1;32m    448\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom classes or functions exported with your `Learner` not available in namespace.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRe-declare/import before loading:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:81\u001b[0m, in \u001b[0;36m_rebuild_from_type_v2\u001b[0;34m(func, new_type, args, state)\u001b[0m\n\u001b[1;32m     78\u001b[0m     dict_state \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m     79\u001b[0m     slots_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdict_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(ret, k, v)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m slots_state:\n",
      "\u001b[0;31mAttributeError\u001b[0m: Custom classes or functions exported with your `Learner` not available in namespace.\\Re-declare/import before loading:\n\t'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#Load model   \n",
    "if ft_model == True:\n",
    "    learn = load_learner(model_path + 'ft_models/dlv3_2ep_2e4_update-07182023_RT_fine_tuned..pkl',cpu=False) #all use mets model\n",
    "    save_location = save_location + \"ft_model\" + \"/\"\n",
    "    create_dir_if_not_exists(save_location)\n",
    "else:\n",
    "    learn = load_learner(model_path + 'dlv3_2ep_2e4_update-07182023_RT.pkl',cpu=False) #all use prior mets model\n",
    "    save_location = save_location + \"prior_model\" + \"/\"\n",
    "    create_dir_if_not_exists(save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a5e0c-89f2-416e-9180-7e21fcb10142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tile info \n",
    "tile_info_df = pd.read_csv(out_location + cur_id + \"/\"  + save_name + \"_tiles.csv\")\n",
    "tile_mag_extract = list(set(tile_info_df['MAG_EXTRACT']))[0]\n",
    "tile_save_image_size = list(set(tile_info_df['SAVE_IMAGE_SIZE']))[0]\n",
    "tile_pixel_overlap = list(set(tile_info_df['PIXEL_OVERLAP']))[0]\n",
    "tile_limit_bounds =   list(set(tile_info_df['LIMIT_BOUNDS']))[0]\n",
    "\n",
    "cond1 = (tile_mag_extract == mag_extract)\n",
    "cond2 = (tile_save_image_size == save_image_size)\n",
    "cond3 = (tile_pixel_overlap == pixel_overlap)\n",
    "cond4 = (tile_limit_bounds == limit_bounds)\n",
    "\n",
    "if cond1 & cond2 & cond3 & cond4:\n",
    "    can_proceed = True\n",
    "    print(can_proceed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6284550-ea4c-4f07-9b41-f7c6efde3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tile_info_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114870c-2257-4ac3-9100-41e0e6a466dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if can_proceed == True:\n",
    "#Generate tiles\n",
    "tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "\n",
    "print('starting inference')\n",
    "#get level 0 size in px\n",
    "l0_w = oslide.level_dimensions[0][0]\n",
    "l0_h = oslide.level_dimensions[0][1]\n",
    "\n",
    "#2.5x for probability maps\n",
    "lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "\n",
    "tile_info_df['pred_map_location'] = pd.NA\n",
    "for index, row in tile_info_df.iterrows():\n",
    "    if (index % 500 == 0): print(index)\n",
    "    cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "    x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "    \n",
    "    #Extract tile for prediction\n",
    "    lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "    tile_pull = tiles.get_tile(lvl_in_deepzoom, (x, y))\n",
    "    tile_pull = tile_pull.resize(size=(save_image_size, save_image_size),resample=PIL.Image.LANCZOS) #resize\n",
    "    tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "    map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    tile_info_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "    \n",
    "    #Cancer segmentation\n",
    "    tile_pull = np.array(tile_pull)\n",
    "    with learn.no_bar():\n",
    "        inp, pred_class, pred_idx, outputs = learn.predict(tile_pull[:, :, 0:3], with_input=True)\n",
    "    \n",
    "    #Get predicted output\n",
    "    #NOTe: updated 11/06, use cv2.resize\n",
    "    outputs_np = outputs.numpy() #[N_CLASS, IMAGE_SIZE, IMAGE_SIZE]\n",
    "    output_c1_np = cv2.resize(outputs_np[1], (map_yend - map_ystart,map_xend - map_xstart)) #class1 predicted prob, resize (width (col in np), height(row in np))\n",
    "    output_c1_np = output_c1_np.round(2)\n",
    "    \n",
    "    #Store predicted probabily in map and count\n",
    "    try: \n",
    "        x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "        x_map[map_xstart:map_xend,map_ystart:map_yend] += output_c1_np\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed4281d-b127-4e4a-b33a-a085676190f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-processing\n",
      "Cancer Prob generation\n"
     ]
    }
   ],
   "source": [
    "print('post-processing')\n",
    "print('Cancer Prob generation')\n",
    "x_count = np.where(x_count < 1, 1, x_count)\n",
    "x_map = x_map / x_count\n",
    "x_map[x_map>1]=1\n",
    "\n",
    "if smooth == True:\n",
    "    x_sm = filters.gaussian(x_map, sigma=2)\n",
    "if smooth == False:\n",
    "    x_sm = x_map\n",
    "cmap = plt.get_cmap('jet')\n",
    "rgba_img = cmap(x_sm)\n",
    "rgb_img = np.delete(rgba_img, 3, 2)\n",
    "colimg = PIL.Image.fromarray(np.uint8(rgb_img * 255))\n",
    "colimg.save(os.path.join(save_location, save_name + '_cancer_prob.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7191b01-80ff-43b8-902e-0a8385b3d8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get cancer mask\n",
      "detecting tissue\n"
     ]
    }
   ],
   "source": [
    "print('Get cancer mask')\n",
    "print('detecting tissue')\n",
    "#1.25x tissue detection\n",
    "lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b62ee205-c2f8-4ca5-8c34-f2916ed5a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n"
     ]
    }
   ],
   "source": [
    "#Binary classification\n",
    "binary_preds = cancer_mask_fix_res(x_sm,cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])), bi_thres)\n",
    "\n",
    "#Output annotation\n",
    "print('saving...')\n",
    "polygons = tile_ROIS(mask_arr=binary_preds, lvl_resize=lvl_resize)\n",
    "\n",
    "\n",
    "#Make valid polygons (ex: OPX_022)\n",
    "invalid_polygons = check_any_invalid_poly(polygons) #check if there is any invalid polys\n",
    "if len(invalid_polygons) > 0 :\n",
    "    polygons = make_valid_poly(polygons, buff_value = 4)\n",
    "\n",
    "\n",
    "slide_ROIS(polygons=polygons, mpp=float(oslide.properties[openslide.PROPERTY_NAME_MPP_X]),\n",
    "                savename=os.path.join(save_location,save_name+'_cancer.json'), labels='AI_tumor', ref=[0,0], roi_color=-16711936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d2ef6c-d843-46fa-a59c-3a354d99c3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(invalid_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bfc7a29-70aa-4066-b98c-f03f18741c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get binary prediction for each tile\n",
    "#NOTE: prevoiuse do x_map when predition, is not accuate, because the x_map may change as process to the next tile, so need to to this in post processing\n",
    "tile_info_df['TUMOR_PIXEL_PERC'] = pd.NA\n",
    "for index, row in tile_info_df.iterrows():\n",
    "    cur_map_loc = row['pred_map_location'].strip(\"()\").split(\", \")\n",
    "    map_xstart, map_xend, map_ystart, map_yend = int(cur_map_loc[0]),int(cur_map_loc[1]), int(cur_map_loc[2]), int(cur_map_loc[3])\n",
    "\n",
    "    #Get current prediction\n",
    "    cur_pred = binary_preds[map_xstart:map_xend,map_ystart:map_yend]\n",
    "    cur_count1 = np.sum(cur_pred == 1) #num pixels that has predicted prob = 1\n",
    "    cur_perc1  = (cur_count1 / cur_pred.size) #fraction of pixels prob = 1\n",
    "    tile_info_df.loc[index,'TUMOR_PIXEL_PERC'] = cur_perc1\n",
    "\n",
    "tile_info_df.to_csv(save_location + save_name + \"_TILE_TUMOR_PERC.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f65d5c1-946b-4117-9454-890c9e7765f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab tiles and plot\n",
    "tile_info_df_sorted = tile_info_df.sort_values(by = ['TUMOR_PIXEL_PERC'], ascending = False) \n",
    "for i in range(0,5): #top5\n",
    "    cur_row = tile_info_df_sorted.iloc[i]\n",
    "    cur_xy = cur_row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "    x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "    tile_pull_ex = tiles.get_tile(tile_lvls.index(mag_extract), (x, y))\n",
    "    tile_pull_ex = tile_pull_ex.resize(size=(save_image_size, save_image_size),resample=PIL.Image.LANCZOS) #resize\n",
    "\n",
    "    #Save tile\n",
    "    cur_tf = round(cur_row['TUMOR_PIXEL_PERC'],2)\n",
    "    cur_mag = cur_row['MAG_EXTRACT']\n",
    "    tile_save_name = \"TILE_@\" + str(cur_mag) + \"x\" + \"_X\" + str(x) +  \"Y\" + str(y) +   \"_TF\" + str(cur_tf) + \".png\"\n",
    "    tile_pull_ex.save(os.path.join(save_location, tile_save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
