{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg9 env\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction, BCE_Weighted_Reg, compute_loss_for_all_labels\n",
    "from Model import Mutation_Multihead\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1212_mutation/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0/split_fold0//DL_emb_only/MSI_POS/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1212_mutation/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0/split_fold0//DL_emb_only/MSI_POS//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1212_mutation/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0/split_fold0//DL_emb_only/MSI_POS//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1212_mutation/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0/split_fold0//DL_emb_only/MSI_POS//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1212_mutation/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0/split_fold0//DL_emb_only/MSI_POS//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out1212_mutation/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0/split_fold0//DL_emb_only/MSI_POS//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "model_name = \"MIL\" #Chose from Linear, LinearMT\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "TUMOR_FRAC_THRES = 0\n",
    "feature_extraction_method = 'retccl'\n",
    "INCLUDE_TF = False\n",
    "INCLUDE_CLUSTER = False\n",
    "N_CLUSTERS = 4\n",
    "\n",
    "\n",
    "####\n",
    "#model Para\n",
    "LEARNING_RATE = 0.001  #0.00001 \n",
    "BATCH_SIZE  = 1\n",
    "ACCUM_SIZE = 16  # Number of steps to accumulate gradients\n",
    "EPOCHS = 100\n",
    "DROPOUT = 0.2\n",
    "DIM_OUT = 128\n",
    "NUM_HEADS = 8\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2048\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2049\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2049\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2050\n",
    "            \n",
    "\n",
    "LOSS_FUNC_NAME = \"BCELoss\" #\"BCE_Weighted_Reg\"\n",
    "REG_COEEF = 0.00001 #0.0000001\n",
    "REG_TYPE = 'L1'\n",
    "OPTMIZER = \"ADAM\"\n",
    "ATT_REG_FLAG = False\n",
    "SELECTED_MUTATION = \"MSI_POS\"\n",
    "\n",
    "if SELECTED_MUTATION == \"MT\":\n",
    "    N_LABELS = len(SELECTED_LABEL)\n",
    "    LOSS_WEIGHTS_LIST = [[1, 10], [1, 100], [1, 50], [1, 100], [1, 100], [1, 100], [1, 100]]  #NEG, POS\n",
    "else:\n",
    "    N_LABELS = 1\n",
    "    LOSS_WEIGHTS_LIST = [[1, 10], [1, 10], [1, 50], [1, 100], [1, 100], [1, 100], [1, 100]]  #NEG, POS\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name = feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "in_data_path = proj_dir + 'intermediate_data/model_ready_data/feature_' + folder_name + \"model_input/\"\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    feature_type = \"emb_only\"\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    feature_type = \"emb_and_tf\"\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    feature_type = \"emb_and_cluster\" + str(N_CLUSTERS)\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    feature_type = \"emb_and_tf_and_cluster\" + str(N_CLUSTERS) \n",
    "\n",
    "model_data_path =  in_data_path + feature_type + \"/\"\n",
    "    \n",
    "################################################\n",
    "#Create output-dir\n",
    "################################################\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out1212_mutation/\" + folder_name + \"/DL_\" + feature_type + \"/\" + SELECTED_MUTATION + \"/\"\n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data = torch.load(model_data_path + 'train_data.pth')\n",
    "test_data = torch.load(model_data_path + 'test_data.pth')\n",
    "val_data = torch.load(model_data_path + 'val_data.pth')\n",
    "\n",
    "train_ids = torch.load(model_data_path + 'train_ids.pth')\n",
    "test_ids = torch.load(model_data_path + 'test_ids.pth')\n",
    "test_info  = torch.load(model_data_path + 'test_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 25186562\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "#Construct model\n",
    "# model = Mutation_MIL_MT(in_features = N_FEATURE, \n",
    "#                         act_func = 'tanh', \n",
    "#                         drop_out = DROPOUT,\n",
    "#                         n_outcomes = N_LABELS,\n",
    "#                         dim_out = DIM_OUT)\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "model = Mutation_Multihead(in_features = N_FEATURE, num_heads = NUM_HEADS, \n",
    "                            embed_dim = 2048, dim_feedforward = 2048, \n",
    "                            act_func = 'tanh', drop_out = DROPOUT, n_outcomes = N_LABELS, dim_out = 128)\n",
    "model.to(device)\n",
    "\n",
    "#Optimizer\n",
    "if OPTMIZER == \"ADAM\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTMIZER == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Loss\n",
    "if LOSS_FUNC_NAME == \"BCE_Weighted_Reg\":\n",
    "    loss_func = BCE_Weighted_Reg(REG_COEEF, REG_TYPE, model, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "elif LOSS_FUNC_NAME == \"BCELoss\":\n",
    "    loss_func = torch.nn.BCELoss()\n",
    "    \n",
    "\n",
    "#Model para\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "#print(model)\n",
    "\n",
    "\n",
    "#OUTPUT MODEL hyper-para\n",
    "hyper_df = pd.DataFrame({\"Target_Mutation\": SELECTED_MUTATION,\n",
    "                         \"TRAIN_OVERLAP\": TRAIN_OVERLAP,\n",
    "                         \"TEST_OVERLAP\": TEST_OVERLAP,\n",
    "                         \"TRAIN_SAMPLE_SIZE\": TRAIN_SAMPLE_SIZE,\n",
    "                         \"TUMOR_FRAC_THRES\": TUMOR_FRAC_THRES,\n",
    "                         \"N_FEATURE\": N_FEATURE,\n",
    "                         \"N_LABELS\": N_LABELS,\n",
    "                         \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                         \"ACCUM_SIZE\": ACCUM_SIZE,\n",
    "                         \"N_EPOCH\": EPOCHS,\n",
    "                         \"OPTMIZER\": OPTMIZER,\n",
    "                         \"LEARNING_RATE\": LEARNING_RATE,\n",
    "                         \"DROPOUT\": DROPOUT,\n",
    "                         \"DIM_OUT\": DIM_OUT,\n",
    "                         \"REG_TYPE\": REG_TYPE,\n",
    "                         \"REG_COEEF\": REG_COEEF,\n",
    "                         \"LOSS_FUNC_NAME\": LOSS_FUNC_NAME,\n",
    "                         \"LOSS_WEIGHTS_LIST\": str(LOSS_WEIGHTS_LIST),\n",
    "                         \"ATT_REG_FLAG\": ATT_REG_FLAG,\n",
    "                         \"NUM_MODEL_PARA\": total_params}, index = [0])\n",
    "hyper_df.to_csv(outdir2 + \"hyperpara_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7f1cc8-6b2a-45f4-96e7-09a5d9e604ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2048 and 128x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, indices, :]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m yhat_list, train_att_list \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Forward\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#yhat_list = model(x.to(device)) #Forward\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#compute loss\u001b[39;00m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_loss_for_all_labels(yhat_list, y, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf , train_att_list, SELECTED_MUTATION, SELECTED_LABEL)\n",
      "File \u001b[0;32m~/anaconda3/envs/paimg9/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paimg9/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/code_s/cancer_detection_final/../Utils/Model.py:384\u001b[0m, in \u001b[0;36mMutation_Multihead.forward\u001b[0;34m(self, x, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    382\u001b[0m out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)):\n\u001b[0;32m--> 384\u001b[0m     cur_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(cur_out)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m#Drop out\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paimg9/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paimg9/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paimg9/lib/python3.8/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2048 and 128x1)"
     ]
    }
   ],
   "source": [
    "log_message(\"Start Training\", outdir3 + \"training_log.txt\")\n",
    "####################################################################################\n",
    "#Training\n",
    "####################################################################################\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    ct = 0\n",
    "    optmizer_loss = 0\n",
    "    for x,y,tf in train_loader:\n",
    "        ct += 1\n",
    "        #optimizer.zero_grad() #zero the grad\n",
    "        if x.size(1) > 2000:\n",
    "            indices = torch.randperm(x.size(1))[:2000]\n",
    "            x = x[:, indices, :]\n",
    "            #print(x.shape)\n",
    "        yhat_list, train_att_list = model(x.to(device)) #Forward\n",
    "        #yhat_list = model(x.to(device)) #Forward\n",
    "\n",
    "        #compute loss\n",
    "        loss = compute_loss_for_all_labels(yhat_list, y, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf , train_att_list, SELECTED_MUTATION, SELECTED_LABEL)\n",
    "        #loss = compute_loss_for_all_labels(yhat_list, y, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf , None, SELECTED_MUTATION, SELECTED_LABEL)\n",
    "\n",
    "        running_loss += loss.detach().item() #acuumalated batch loss\n",
    "        optmizer_loss += loss #accumalted loss for optimizer\n",
    "       \n",
    "        #Optimize\n",
    "        if ct % ACCUM_SIZE == 0:\n",
    "            optmizer_loss = optmizer_loss/ACCUM_SIZE\n",
    "            optmizer_loss.backward() \n",
    "            optimizer.step()  # Optimize\n",
    "            optmizer_loss = 0\n",
    "            optimizer.zero_grad() #gradient reset\n",
    "\n",
    "    #Training loss \n",
    "    epoch_loss = running_loss/len(train_loader) #accumulated loss/total # batches (averaged loss over batches)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_running_loss = 0\n",
    "        for x_val,y_val,tf_val in val_loader:\n",
    "            val_yhat_list, val_att_list = model(x_val.to(device))\n",
    "            #val_yhat_list = model(x_val.to(device))\n",
    "            val_loss = compute_loss_for_all_labels(val_yhat_list, y_val, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf_val, val_att_list, SELECTED_MUTATION, SELECTED_LABEL)\n",
    "            #val_loss = compute_loss_for_all_labels(val_yhat_list, y_val, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf_val, None, SELECTED_MUTATION, SELECTED_LABEL)\n",
    "            val_running_loss += val_loss.detach().item() \n",
    "        val_epoch_loss = val_running_loss/len(val_loader) \n",
    "        valid_loss.append(val_epoch_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch\"+ str(epoch) + \":\",\n",
    "              \"Train-LOSS:\" + \"{:.5f}\".format(train_loss[epoch]) + \", \" +\n",
    "              \"Valid-LOSS:\" +  \"{:.5f}\".format(valid_loss[epoch]))\n",
    "    \n",
    "    #Save model parameters\n",
    "    torch.save(model.state_dict(), outdir1 + \"model\" + str(epoch))\n",
    "\n",
    "\n",
    "#Plot LOSS\n",
    "plot_LOSS(train_loss,valid_loss, outdir1)\n",
    "log_message(\"End Training\", outdir3 + \"training_log.txt\")\n",
    "\n",
    "#SAVE VALIDATION LOSS\n",
    "valid_loss_df  = pd.DataFrame({\"VALID_LOSS\": valid_loss})\n",
    "valid_loss_df.to_csv(outdir1 + \"Valid_LOSS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bf67b-a36c-4336-89dd-bee6b77e66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## #Testing\n",
    "####################################################################################\n",
    "#Load model\n",
    "valid_loss_df = pd.read_csv(outdir1 + \"Valid_LOSS.csv\")\n",
    "min_index = valid_loss_df['VALID_LOSS'].idxmin()\n",
    "print(min_index)\n",
    "#min_index = 99\n",
    "model = Mutation_Multihead(in_features = N_FEATURE, num_heads = 2, \n",
    "                            embed_dim = 128, dim_feedforward = 2048, \n",
    "                            act_func = 'tanh', drop_out = DROPOUT, n_outcomes = N_LABELS, dim_out = 128)\n",
    "state_dict = torch.load(outdir1 + \"model\" + str(min_index))\n",
    "\n",
    "#model2 = Mutation_MIL_MT(in_features = 2048, act_func = 'tanh', drop_out = DROPOUT)\n",
    "#model_dir = \"/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/z_old_mutation_prediction_results/mutation_pred_out_11272024/MAX_SS0_NFEATURES2048/MT/saved_model/MIL/\"\n",
    "#state_dict = torch.load(model_dir + \"model\" + str(499))\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#Loss function\n",
    "loss_func = torch.nn.BCELoss()\n",
    "THRES = 0.5\n",
    "\n",
    "#predicts\n",
    "test_pred_prob, test_true_label, test_att, test_loss = prediction(test_loader, model, N_LABELS, loss_func, device, SELECTED_MUTATION, SELECTED_LABEL, attention = True)\n",
    "print(\"Test-Loss TOTAL: \" + \"{:.5f}\".format(test_loss))\n",
    "\n",
    "\n",
    "#Prediction df\n",
    "pred_df_list = []\n",
    "for i in range(0,N_LABELS):\n",
    "    if N_LABELS > 1:\n",
    "        cur_pred_df = pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                                              \"Y_True\": [l[i] for l in test_true_label], \n",
    "                                              \"Pred_Prob\" :  [l[i] for l in test_pred_prob],\n",
    "                                              #\"Pred_Prob\" :  test_pred_prob,\n",
    "                                              \"OUTCOME\": SELECTED_LABEL[i]})\n",
    "    else:\n",
    "        cur_pred_df = pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                                    \"Y_True\": [l[i] for l in test_true_label], \n",
    "                                    \"Pred_Prob\" :  test_pred_prob,\n",
    "                                    \"OUTCOME\": SELECTED_MUTATION})\n",
    "        \n",
    "    pred_df_list.append(cur_pred_df)\n",
    "pred_df = pd.concat(pred_df_list)\n",
    "\n",
    "#Add Predict class\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(outdir4 + \"/pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "#Compute performance\n",
    "if SELECTED_MUTATION == \"MT\":\n",
    "    perf_df = compute_performance_each_label(SELECTED_LABEL, pred_df, \"SAMPLE_LEVEL\")\n",
    "else:\n",
    "    perf_df = compute_performance_each_label([SELECTED_MUTATION], pred_df, \"SAMPLE_LEVEL\")\n",
    "perf_df.to_csv(outdir5 + \"/perf.csv\",index = True)\n",
    "\n",
    "print(perf_df.iloc[:,[0,5,6,7,8,9]])\n",
    "print(\"AVG AUC:\", round(perf_df['AUC'].mean(),2))\n",
    "print(\"AVG PRAUC:\", round(perf_df['PR_AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed655a2-6e52-4db1-9567-d88003b4cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.loc[pred_df['OUTCOME'] == 'MSI_POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e775e0-d175-4e9a-bb11-49e38f56539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Atention scores\n",
    "####################################################################################\n",
    "save_image_size = 250\n",
    "pixel_overlap = 0\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "pretrain_model_name = \"retccl\"\n",
    "mag_target_prob = 2.5\n",
    "smooth = False\n",
    "mag_target_tiss = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0367-e302-4b0e-963a-f57fc4624eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = test_ids.index('OPX_011')\n",
    "pt = test_ids[i]\n",
    "print(pt)\n",
    "\n",
    "save_location =  outdir4  + pt + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "_file = wsi_path + pt + \".tif\"\n",
    "oslide = openslide.OpenSlide(_file)\n",
    "save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_pt_att = test_att[i]\n",
    "cur_pt_info = test_info[i]\n",
    "cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8695db6-68cf-40ae-bff4-a8ca81a1942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate tiles\n",
    "tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "\n",
    "#get level 0 size in px\n",
    "l0_w = oslide.level_dimensions[0][0]\n",
    "l0_h = oslide.level_dimensions[0][1]\n",
    "\n",
    "#1.25x tissue detection for mask\n",
    "from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "import cv2\n",
    "if 'OPX' in pt:\n",
    "    rad_tissue = 5\n",
    "elif '(2017-0133)' in pt:\n",
    "    rad_tissue = 2\n",
    "lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c5920-1ce0-4e18-a44a-85f99aad234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5x for probability maps\n",
    "lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "\n",
    "cur_att_df['pred_map_location'] = pd.NA\n",
    "for index, row in cur_att_df.iterrows():\n",
    "    cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "    x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "    \n",
    "    #Extract tile for prediction\n",
    "    lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "    tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "    map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    cur_att_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "\n",
    "    #Store predicted probabily in map and count\n",
    "    try: \n",
    "        x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "        x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('post-processing')\n",
    "x_count = np.where(x_count < 1, 1, x_count)\n",
    "x_map = x_map / x_count\n",
    "x_map[x_map>1]=1\n",
    "\n",
    "if smooth == True:\n",
    "    x_sm = filters.gaussian(x_map, sigma=2)\n",
    "if smooth == False:\n",
    "    x_sm = x_map\n",
    "\n",
    "he_mask = cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])) #resize to output image size\n",
    "#TODO:\n",
    "#get cancer_mask:\n",
    "# cancer_mask == \n",
    "# x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "x_sm[he_mask < 1] = 0.001 \n",
    "\n",
    "plt.imshow(x_sm, cmap='Spectral_r')\n",
    "plt.colorbar()\n",
    "plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#Top attented tiles\n",
    "save_location2 = save_location + \"top_tiles/\"\n",
    "create_dir_if_not_exists(save_location2)\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "\n",
    "for i in range(TOP_K):\n",
    "    cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "    cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "    cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "    coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "    tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "    cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "\n",
    "#Bot attented tiles\n",
    "save_location2 = save_location + \"bot_tiles/\"\n",
    "create_dir_if_not_exists(save_location2)\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "\n",
    "for i in range(TOP_K):\n",
    "    cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "    cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "    cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "    coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "    tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "    cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de144a01-7f41-4451-8785-40b5204032d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO LIST\n",
    "#1.Attention score\n",
    "#2. zero gradiant place"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
