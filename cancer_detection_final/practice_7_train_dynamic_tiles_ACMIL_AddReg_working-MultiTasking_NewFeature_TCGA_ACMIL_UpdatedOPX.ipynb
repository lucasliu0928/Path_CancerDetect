{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo, get_performance, plot_roc_curve\n",
    "from train_utils import pull_tiles, FocalLoss, get_feature_idexes\n",
    "from train_utils import convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from ACMIL import ACMIL_GA_MultiTask, predict_v2, train_one_epoch_multitask_V2, evaluate_multitask_V2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def calibrate_probs_isotonic(y_val, y_prob_val, y_test_prob):\n",
    "    \"\"\"\n",
    "    Perform Isotonic Regression to calibrate predicted probabilities.\n",
    "\n",
    "    Args:\n",
    "        y_val: Ground truth labels from the validation set.\n",
    "        y_prob_val: Model-predicted probabilities from the validation set.\n",
    "        y_test_prob: Model-predicted probabilities for the test set.\n",
    "\n",
    "    Returns:\n",
    "        Calibrated probabilities for the test set.\n",
    "    \"\"\"\n",
    "    iso_reg = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso_reg.fit(y_prob_val, y_val)\n",
    "    calibrated_probs = iso_reg.predict(y_test_prob)\n",
    "    return calibrated_probs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix,fbeta_score,average_precision_score\n",
    "from sklearn import metrics\n",
    "def bootstrap_ci_from_df(df, metric_fn, y_true_col='y_true', y_pred_col=None, y_prob_col=None,\n",
    "                         num_bootstrap=1000, ci=95, seed=None):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for a metric using predictions in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with prediction results.\n",
    "        metric_fn: Metric function. Can accept (y_true, y_pred) or (y_true, y_prob).\n",
    "        y_true_col: Column name for ground truth.\n",
    "        y_pred_col: Column name for predicted labels (used for accuracy, etc.).\n",
    "        y_prob_col: Column name for predicted probabilities (used for AUROC, etc.).\n",
    "        num_bootstrap: Number of bootstrap resamples.\n",
    "        ci: Confidence level (e.g., 95 for 95% CI).\n",
    "        seed: Optional random seed.\n",
    "\n",
    "    Returns:\n",
    "        (lower_bound, upper_bound) of CI.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(df)\n",
    "    perf_list = []\n",
    "\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(n=n, replace=True, random_state=rng.integers(0, 1e6))\n",
    "        y_true = sample[y_true_col].values\n",
    "        y_pred_class =  sample[y_pred_col].values\n",
    "        y_pred_prob =   sample[y_prob_col].values\n",
    "\n",
    "        # mean_metric = np.mean(metrics)\n",
    "        # metric = metric_fn(y_true, y_pred_or_prob)\n",
    "        # metrics.append(metric)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel() #CM\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred_prob, pos_label=1)\n",
    "        PR_AUC = average_precision_score(y_true, y_pred_prob)\n",
    "        AUC = round(metrics.auc(fpr, tpr),2)\n",
    "        ACC = round(accuracy_score(y_true, y_pred_class),2)\n",
    "        F1 = round(f1_score(y_true, y_pred_class),2)\n",
    "        F2 = round(fbeta_score(y_true, y_pred_class,beta = 2),2)\n",
    "        F3 = round(fbeta_score(y_true, y_pred_class,beta = 3),2)\n",
    "        Recall = round(recall_score(y_true, y_pred_class),2)\n",
    "        Precision = round(precision_score(y_true, y_pred_class),2)\n",
    "        Specificity = round(tn / (tn + fp),2)\n",
    "        perf_tb = pd.DataFrame({\"AUC\": AUC,\n",
    "                                \"Recall\": Recall,\n",
    "                                \"Specificity\":Specificity,\n",
    "                                \"ACC\": ACC,\n",
    "                                \"Precision\":Precision,\n",
    "                                \"PR_AUC\":PR_AUC,\n",
    "                                \"F1\": F1,\n",
    "                                \"F2\": F2,\n",
    "                                \"F3\": F3},index = [0])\n",
    "        perf_list.append(perf_tb)\n",
    "    perf_df = pd.concat(perf_list)\n",
    "\n",
    "    mean_values = perf_df.mean()\n",
    "    lower_bounds = perf_df.quantile((100 - ci) / 200)\n",
    "    upper_bounds = perf_df.quantile(1 - (100 - ci) / 200)\n",
    "    \n",
    "    formatted_results = {\n",
    "        column: f\"{mean_values[column]:.2f} [{lower_bounds[column]:.2f} - {upper_bounds[column]:.2f}]\"\n",
    "        for column in perf_df.columns\n",
    "    }\n",
    "    ci_df = pd.DataFrame.from_dict(formatted_results, orient=\"index\", columns=[\"Mean [CI Low, CI High]\"])\n",
    "\n",
    "    return ci_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fe6b4f-a374-4a86-8276-e5a1bced8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch: 100\n",
      "warmup_epoch: 0\n",
      "wd: 1e-05\n",
      "lr: 0.0001\n",
      "min_lr: 0\n",
      "dataset: bracs\n",
      "B: 1\n",
      "n_class: 1\n",
      "n_worker: 8\n",
      "pin_memory: False\n",
      "n_shot: -1\n",
      "D_feat: 1536\n",
      "D_inner: 128\n",
      "n_token: 1\n",
      "mask_drop: 0\n",
      "n_masked_patch: 0\n",
      "wandb_mode: disabled\n",
      "n_task: 7\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABEL = [\"AR\",\"HR\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0.9 \n",
    "feature_extraction_method = 'uni2' #retccl, uni1, prov_gigapath\n",
    "learning_method = \"abmil\"\n",
    "SELECTED_FEATURE = get_feature_idexes(feature_extraction_method, include_tumor_fraction = False)\n",
    "N_FEATURE = len(SELECTED_FEATURE)\n",
    "\n",
    "\n",
    "#For RB1: gamma = 2, focal_alpha = 0.1\n",
    "\n",
    "\n",
    "# Define different values for alpha and gamma\n",
    "alpha_values = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.6]  # Example alpha values\n",
    "gamma_values = [2,    3,    2,   2,  2,   2,  10]  # Example gamma values\n",
    "\n",
    "# focal_gamma = 5 #10 seems good too\n",
    "# focal_alpha = 0.80\n",
    "#Best before\n",
    "focal_gamma = 10\n",
    "focal_alpha = 0.6\n",
    "loss_method = 'ATTLOSS' #ATTLOSS\n",
    "\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "SELECTED_FOLD = 0\n",
    "arch = 'ga_mt' #ga_mt or ga\n",
    "\n",
    "    \n",
    "################################\n",
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "\n",
    "conf.train_epoch = 100\n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "\n",
    "if learning_method == 'abmil':\n",
    "    conf.n_token = 1\n",
    "    conf.mask_drop = 0\n",
    "    conf.n_masked_patch = 0\n",
    "elif learning_method == 'acmil':\n",
    "    conf.n_token = 3\n",
    "    conf.mask_drop = 0.6\n",
    "    conf.n_masked_patch = 0\n",
    "    \n",
    "conf.n_class = 1\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.n_task = 7\n",
    "#conf.lr = 0.000001 #change this for HR only\n",
    "\n",
    "# Print all key-value pairs in the conf object\n",
    "for key, value in conf.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name_overlap = \"IMSIZE250_OL100\"\n",
    "folder_name_nonoverlap = \"IMSIZE250_OL0\"\n",
    "feature_path_opx_train =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_overlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_opx_test =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "train_val_test_id_path =  os.path.join(proj_dir + 'intermediate_data/6_Train_TEST_IDS', 'TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//model_para/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//logs/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//perf/' created.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#Create output-dir\n",
    "################################################\n",
    "folder_name1 = feature_extraction_method + '/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out032025_ACMIL2\" + \"/\" + folder_name1 + 'FOLD' + str(SELECTED_FOLD) + '/' + SELECTED_MUTATION + \"/\" \n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25981794-2637-40c2-94df-dbd3b5cfbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "opx_data_ol100 = torch.load(feature_path_opx_train + '/OPX_data.pth')\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a360618-a0c6-4650-8f2d-8e66bbfd7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get train, test IDs\n",
    "################################################\n",
    "train_test_val_id_df = pd.read_csv(os.path.join(train_val_test_id_path, \"train_test_split.csv\"))\n",
    "train_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TRAIN', 'SAMPLE_ID'])\n",
    "test_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TEST', 'SAMPLE_ID'])\n",
    "val_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'VALID', 'SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa31800f-0219-42fa-ab6a-5567a44cdea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "67\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids_all))\n",
    "print(len(test_ids_all))\n",
    "print(len(val_ids_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2512c51e-0cfe-41b8-a766-a0ba19763f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#IDS\n",
    "################################################\n",
    "opx_ids_ol100 = [x[-2] for x in opx_data_ol100]\n",
    "opx_ids_ol0 = [x[-2] for x in opx_data_ol0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b363757-dbfd-4164-a880-c156df177000",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get Train, test, val data\n",
    "################################################\n",
    "#Train:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in train_ids_all]\n",
    "train_data = Subset(opx_data_ol100, inc_idx)\n",
    "train_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "\n",
    "#Val:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in val_ids_all]\n",
    "val_data = Subset(opx_data_ol100, inc_idx)\n",
    "val_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "\n",
    "#Test:\n",
    "inc_idx = [opx_ids_ol0.index(x) for x in test_ids_all]\n",
    "test_data = Subset(opx_data_ol0, inc_idx)\n",
    "test_ids =  list(Subset(opx_ids_ol0, inc_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#Dataloader for training\n",
    "####################################################\n",
    "train_data2 = [item[:-3] for item in train_data] #only keep the needed for training\n",
    "test_data2 = [item[:-3] for item in test_data] #only keep the needed for training\n",
    "val_data2 = [item[:-3] for item in val_data] #only keep the needed for training\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data2, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287cee9a-95b9-4a80-b9c4-1c02a3060f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/MT/' created.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# define network\n",
    "####################################################\n",
    "if arch == 'ga':\n",
    "    model = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "elif arch == 'ga_mt':\n",
    "    model = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "else:\n",
    "    model = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Create a list of FocalLoss criteria with different alpha and gamma\n",
    "criterion = [FocalLoss(alpha=a, gamma=g, reduction='mean') for a, g in zip(alpha_values, gamma_values)]\n",
    "#criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "\n",
    "ckpt_dir = outdir1 + SELECTED_MUTATION + \"/\"\n",
    "create_dir_if_not_exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/161]  eta: 0:01:14  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0002 (0.0002)  att_loss: 0.8079 (0.8079)  total_loss: 6.1950 (6.1950)  time: 0.4605  data: 0.0007  max mem: 26\n",
      "Epoch: [0]  [100/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0007)  att_loss: 0.9806 (0.9656)  total_loss: 6.9655 (7.0597)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [0]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0005)  att_loss: 0.9844 (0.9691)  total_loss: 7.0337 (7.0183)  time: 0.0132  data: 0.0017  max mem: 891\n",
      "Epoch: [0] Total time: 0:00:02 (0.0166 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0839 (0.0839)  div_loss: -64.2894 (-64.2894)  acc1: 85.7143 (85.7143)  time: 0.0140  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0943 (0.1238)  div_loss: -51.7462 (-50.1866)  acc1: 85.7143 (83.5714)  time: 0.0106  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.8571428060531616\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.7275985479354858\n",
      "AUROC 3 : 0.906862735748291\n",
      "AUROC 4 : 0.703125\n",
      "AUROC 5 : 0.42105263471603394\n",
      "AUROC 6 : 0.3513513505458832\n",
      "* Acc@1 83.571 loss 0.124 auroc 0.645 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1003 (0.1003)  div_loss: -37.5173 (-37.5173)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0466 (0.1331)  div_loss: -43.3203 (-44.6822)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7190476059913635\n",
      "AUROC 1 : 0.49788135290145874\n",
      "AUROC 2 : 0.5615384578704834\n",
      "AUROC 3 : 0.7952381372451782\n",
      "AUROC 4 : 0.6188235282897949\n",
      "AUROC 5 : 0.6103896498680115\n",
      "AUROC 6 : 0.6196969747543335\n",
      "* Acc@1 83.582 loss 0.133 auroc 0.632 f1_score 0.000\n",
      "Epoch: [1]  [  0/161]  eta: 0:00:02  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8079 (0.8079)  total_loss: 5.8702 (5.8702)  time: 0.0130  data: 0.0005  max mem: 891\n",
      "Epoch: [1]  [100/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0004)  att_loss: 0.9806 (0.9656)  total_loss: 6.9292 (6.8812)  time: 0.0119  data: 0.0012  max mem: 891\n",
      "Epoch: [1]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0003)  att_loss: 0.9844 (0.9691)  total_loss: 7.0414 (6.9025)  time: 0.0132  data: 0.0017  max mem: 891\n",
      "Epoch: [1] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0787 (0.0787)  div_loss: -64.2623 (-64.2623)  acc1: 85.7143 (85.7143)  time: 0.0095  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0841 (0.1198)  div_loss: -51.7037 (-50.1588)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.8628571033477783\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.906862735748291\n",
      "AUROC 4 : 0.7708333730697632\n",
      "AUROC 5 : 0.43421053886413574\n",
      "AUROC 6 : 0.35135138034820557\n",
      "* Acc@1 83.571 loss 0.120 auroc 0.654 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0851 (0.0851)  div_loss: -37.4565 (-37.4565)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0425 (0.1300)  div_loss: -43.2843 (-44.6509)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7404761910438538\n",
      "AUROC 1 : 0.5190677642822266\n",
      "AUROC 2 : 0.5512820482254028\n",
      "AUROC 3 : 0.8095238208770752\n",
      "AUROC 4 : 0.6388235092163086\n",
      "AUROC 5 : 0.6217532753944397\n",
      "AUROC 6 : 0.6287878751754761\n",
      "* Acc@1 83.582 loss 0.130 auroc 0.644 f1_score 0.000\n",
      "Epoch: [2]  [  0/161]  eta: 0:00:02  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8079 (0.8079)  total_loss: 5.8715 (5.8715)  time: 0.0160  data: 0.0005  max mem: 891\n",
      "Epoch: [2]  [100/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0002)  att_loss: 0.9806 (0.9656)  total_loss: 6.9325 (6.8733)  time: 0.0147  data: 0.0015  max mem: 891\n",
      "Epoch: [2]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0002)  att_loss: 0.9844 (0.9691)  total_loss: 7.0350 (6.8954)  time: 0.0130  data: 0.0015  max mem: 891\n",
      "Epoch: [2] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0774 (0.0774)  div_loss: -64.2481 (-64.2481)  acc1: 85.7143 (85.7143)  time: 0.0095  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0782 (0.1180)  div_loss: -51.6876 (-50.1466)  acc1: 85.7143 (83.5714)  time: 0.0116  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0096 s / it)\n",
      "AUROC 0 : 0.868571400642395\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8970588445663452\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.3243243396282196\n",
      "* Acc@1 83.571 loss 0.118 auroc 0.654 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0781 (0.0781)  div_loss: -37.4371 (-37.4371)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0564 (0.1287)  div_loss: -43.2721 (-44.6362)  acc1: 85.7143 (83.5821)  time: 0.0051  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0058 s / it)\n",
      "AUROC 0 : 0.7690476179122925\n",
      "AUROC 1 : 0.47669491171836853\n",
      "AUROC 2 : 0.5628204941749573\n",
      "AUROC 3 : 0.8214285373687744\n",
      "AUROC 4 : 0.6576470136642456\n",
      "AUROC 5 : 0.6509740352630615\n",
      "AUROC 6 : 0.6409090757369995\n",
      "* Acc@1 83.582 loss 0.129 auroc 0.654 f1_score 0.000\n",
      "Epoch: [3]  [  0/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8079 (0.8079)  total_loss: 5.8657 (5.8657)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [3]  [100/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0002)  att_loss: 0.9806 (0.9656)  total_loss: 6.9371 (6.8668)  time: 0.0119  data: 0.0012  max mem: 891\n",
      "Epoch: [3]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 7.0263 (6.8894)  time: 0.0138  data: 0.0019  max mem: 891\n",
      "Epoch: [3] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0768 (0.0768)  div_loss: -64.2349 (-64.2349)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0036  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0774 (0.1176)  div_loss: -51.6743 (-50.1324)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8857142925262451\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.6666666865348816\n",
      "AUROC 3 : 0.8970588445663452\n",
      "AUROC 4 : 0.8203125\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.3153153359889984\n",
      "* Acc@1 83.571 loss 0.118 auroc 0.655 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0747 (0.0747)  div_loss: -37.4142 (-37.4142)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0537 (0.1279)  div_loss: -43.2616 (-44.6201)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.4576271176338196\n",
      "AUROC 2 : 0.571794867515564\n",
      "AUROC 3 : 0.8309524059295654\n",
      "AUROC 4 : 0.6717646718025208\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6454545855522156\n",
      "* Acc@1 83.582 loss 0.128 auroc 0.663 f1_score 0.000\n",
      "Epoch: [4]  [  0/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8078 (0.8078)  total_loss: 5.8556 (5.8556)  time: 0.0111  data: 0.0004  max mem: 891\n",
      "Epoch: [4]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9398 (6.8607)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [4]  [160/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 7.0175 (6.8838)  time: 0.0142  data: 0.0019  max mem: 891\n",
      "Epoch: [4] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0762 (0.0762)  div_loss: -64.2203 (-64.2203)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0806 (0.1180)  div_loss: -51.6588 (-50.1137)  acc1: 85.7143 (83.5714)  time: 0.0114  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0095 s / it)\n",
      "AUROC 0 : 0.8799999952316284\n",
      "AUROC 1 : 0.514285683631897\n",
      "AUROC 2 : 0.6523298025131226\n",
      "AUROC 3 : 0.8872548937797546\n",
      "AUROC 4 : 0.828125\n",
      "AUROC 5 : 0.44736841320991516\n",
      "AUROC 6 : 0.29729729890823364\n",
      "* Acc@1 83.571 loss 0.118 auroc 0.644 f1_score 0.017\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0719 (0.0719)  div_loss: -37.3857 (-37.3857)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0507 (0.1274)  div_loss: -43.2467 (-44.6000)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0058 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.4512711763381958\n",
      "AUROC 2 : 0.5807692408561707\n",
      "AUROC 3 : 0.8476190567016602\n",
      "AUROC 4 : 0.6811764240264893\n",
      "AUROC 5 : 0.6915584802627563\n",
      "AUROC 6 : 0.6560605764389038\n",
      "* Acc@1 83.582 loss 0.127 auroc 0.671 f1_score 0.000\n",
      "Epoch: [5]  [  0/161]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8078 (0.8078)  total_loss: 5.8403 (5.8403)  time: 0.0108  data: 0.0003  max mem: 891\n",
      "Epoch: [5]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9399 (6.8550)  time: 0.0122  data: 0.0014  max mem: 891\n",
      "Epoch: [5]  [160/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 7.0078 (6.8784)  time: 0.0134  data: 0.0019  max mem: 891\n",
      "Epoch: [5] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0752 (0.0752)  div_loss: -64.2028 (-64.2028)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0792 (0.1189)  div_loss: -51.6387 (-50.0900)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.8857142925262451\n",
      "AUROC 1 : 0.5028571486473083\n",
      "AUROC 2 : 0.663082480430603\n",
      "AUROC 3 : 0.8872548937797546\n",
      "AUROC 4 : 0.8385417461395264\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.27927929162979126\n",
      "* Acc@1 83.571 loss 0.119 auroc 0.645 f1_score 0.017\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0696 (0.0696)  div_loss: -37.3531 (-37.3531)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0541 (0.1272)  div_loss: -43.2246 (-44.5749)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7928571701049805\n",
      "AUROC 1 : 0.4512711763381958\n",
      "AUROC 2 : 0.5935897827148438\n",
      "AUROC 3 : 0.8571428656578064\n",
      "AUROC 4 : 0.684705913066864\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.6651514768600464\n",
      "* Acc@1 83.582 loss 0.127 auroc 0.678 f1_score 0.016\n",
      "Epoch: [6]  [  0/161]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8078 (0.8078)  total_loss: 5.8217 (5.8217)  time: 0.0108  data: 0.0003  max mem: 891\n",
      "Epoch: [6]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9387 (6.8494)  time: 0.0122  data: 0.0014  max mem: 891\n",
      "Epoch: [6]  [160/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9970 (6.8732)  time: 0.0135  data: 0.0019  max mem: 891\n",
      "Epoch: [6] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0738 (0.0738)  div_loss: -64.1818 (-64.1818)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0772 (0.1204)  div_loss: -51.6099 (-50.0606)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.6594982147216797\n",
      "AUROC 3 : 0.8921568393707275\n",
      "AUROC 4 : 0.8385417461395264\n",
      "AUROC 5 : 0.43421050906181335\n",
      "AUROC 6 : 0.27927929162979126\n",
      "* Acc@1 83.571 loss 0.120 auroc 0.647 f1_score 0.016\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0689 (0.0689)  div_loss: -37.3178 (-37.3178)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0568 (0.1273)  div_loss: -43.1931 (-44.5444)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.4555084705352783\n",
      "AUROC 2 : 0.6089743375778198\n",
      "AUROC 3 : 0.8809523582458496\n",
      "AUROC 4 : 0.6870588064193726\n",
      "AUROC 5 : 0.7061688899993896\n",
      "AUROC 6 : 0.6681817770004272\n",
      "* Acc@1 83.582 loss 0.127 auroc 0.685 f1_score 0.016\n",
      "Epoch: [7]  [  0/161]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8078 (0.8078)  total_loss: 5.8026 (5.8026)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [7]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9364 (6.8439)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [7]  [160/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9872 (6.8680)  time: 0.0133  data: 0.0017  max mem: 891\n",
      "Epoch: [7] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0715 (0.0715)  div_loss: -64.1562 (-64.1562)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0753 (0.1224)  div_loss: -51.5693 (-50.0236)  acc1: 85.7143 (83.5714)  time: 0.0114  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.6630824208259583\n",
      "AUROC 3 : 0.8872549533843994\n",
      "AUROC 4 : 0.8463541865348816\n",
      "AUROC 5 : 0.4473683834075928\n",
      "AUROC 6 : 0.27027028799057007\n",
      "* Acc@1 83.571 loss 0.122 auroc 0.650 f1_score 0.016\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0679 (0.0679)  div_loss: -37.2781 (-37.2781)  acc1: 85.7143 (85.7143)  time: 0.0070  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0590 (0.1278)  div_loss: -43.1488 (-44.5062)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7833333611488342\n",
      "AUROC 1 : 0.4661017060279846\n",
      "AUROC 2 : 0.615384578704834\n",
      "AUROC 3 : 0.8999999761581421\n",
      "AUROC 4 : 0.684705913066864\n",
      "AUROC 5 : 0.7175325155258179\n",
      "AUROC 6 : 0.6651514768600464\n",
      "* Acc@1 83.582 loss 0.128 auroc 0.690 f1_score 0.016\n",
      "Epoch: [8]  [  0/161]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8078 (0.8078)  total_loss: 5.7852 (5.7852)  time: 0.0097  data: 0.0003  max mem: 891\n",
      "Epoch: [8]  [100/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9302 (6.8386)  time: 0.0133  data: 0.0016  max mem: 891\n",
      "Epoch: [8]  [160/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9782 (6.8629)  time: 0.0135  data: 0.0018  max mem: 891\n",
      "Epoch: [8] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0699 (0.0699)  div_loss: -64.1225 (-64.1225)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0730 (0.1250)  div_loss: -51.5133 (-49.9749)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0095 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.8823529481887817\n",
      "AUROC 4 : 0.8463541865348816\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.29729729890823364\n",
      "* Acc@1 83.571 loss 0.125 auroc 0.657 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0672 (0.0672)  div_loss: -37.2294 (-37.2294)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0613 (0.1286)  div_loss: -43.0892 (-44.4561)  acc1: 85.7143 (83.5821)  time: 0.0052  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0057 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.4830508232116699\n",
      "AUROC 2 : 0.6243590116500854\n",
      "AUROC 3 : 0.9190475940704346\n",
      "AUROC 4 : 0.6823529601097107\n",
      "AUROC 5 : 0.7224026322364807\n",
      "AUROC 6 : 0.6681817770004272\n",
      "* Acc@1 83.582 loss 0.129 auroc 0.698 f1_score 0.052\n",
      "Epoch: [9]  [  0/161]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8078 (0.8078)  total_loss: 5.7690 (5.7690)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [9]  [100/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9242 (6.8334)  time: 0.0119  data: 0.0012  max mem: 891\n",
      "Epoch: [9]  [160/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9654 (6.8579)  time: 0.0134  data: 0.0018  max mem: 891\n",
      "Epoch: [9] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0691 (0.0691)  div_loss: -64.0767 (-64.0767)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0708 (0.1284)  div_loss: -51.4364 (-49.9085)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.8774509429931641\n",
      "AUROC 4 : 0.84375\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.3333333730697632\n",
      "* Acc@1 83.571 loss 0.128 auroc 0.661 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0673 (0.0673)  div_loss: -37.1662 (-37.1662)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0641 (0.1297)  div_loss: -43.0107 (-44.3878)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.5063559412956238\n",
      "AUROC 2 : 0.634615421295166\n",
      "AUROC 3 : 0.9285714030265808\n",
      "AUROC 4 : 0.6870588064193726\n",
      "AUROC 5 : 0.7240259647369385\n",
      "AUROC 6 : 0.668181836605072\n",
      "* Acc@1 83.582 loss 0.130 auroc 0.705 f1_score 0.052\n",
      "Epoch: [10]  [  0/161]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8077 (0.8077)  total_loss: 5.7543 (5.7543)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [10]  [100/161]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9227 (6.8283)  time: 0.0124  data: 0.0015  max mem: 891\n",
      "Epoch: [10]  [160/161]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9542 (6.8529)  time: 0.0135  data: 0.0019  max mem: 891\n",
      "Epoch: [10] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0682 (0.0682)  div_loss: -64.0160 (-64.0160)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0681 (0.1326)  div_loss: -51.3304 (-49.8175)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9199999570846558\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8774509429931641\n",
      "AUROC 4 : 0.8411458730697632\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.36036038398742676\n",
      "* Acc@1 83.571 loss 0.133 auroc 0.667 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0675 (0.0675)  div_loss: -37.0826 (-37.0826)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0684 (0.1311)  div_loss: -42.9216 (-44.2939)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7857142686843872\n",
      "AUROC 1 : 0.5254237651824951\n",
      "AUROC 2 : 0.6397435665130615\n",
      "AUROC 3 : 0.9357142448425293\n",
      "AUROC 4 : 0.6905882358551025\n",
      "AUROC 5 : 0.7288960814476013\n",
      "AUROC 6 : 0.668181836605072\n",
      "* Acc@1 83.582 loss 0.131 auroc 0.711 f1_score 0.052\n",
      "Epoch: [11]  [  0/161]  eta: 0:00:01  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8077 (0.8077)  total_loss: 5.7408 (5.7408)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [11]  [100/161]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9188 (6.8231)  time: 0.0120  data: 0.0012  max mem: 891\n",
      "Epoch: [11]  [160/161]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9469 (6.8478)  time: 0.0133  data: 0.0016  max mem: 891\n",
      "Epoch: [11] Total time: 0:00:02 (0.0130 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0673 (0.0673)  div_loss: -63.9317 (-63.9317)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0650 (0.1381)  div_loss: -51.1825 (-49.6926)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0021  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9257142543792725\n",
      "AUROC 1 : 0.49714285135269165\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8676470518112183\n",
      "AUROC 4 : 0.8411458134651184\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.37837839126586914\n",
      "* Acc@1 83.571 loss 0.138 auroc 0.667 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0691 (0.0691)  div_loss: -36.9708 (-36.9708)  acc1: 85.7143 (85.7143)  time: 0.0041  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0741 (0.1330)  div_loss: -42.8222 (-44.1644)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.5423728823661804\n",
      "AUROC 2 : 0.6461538672447205\n",
      "AUROC 3 : 0.9404761791229248\n",
      "AUROC 4 : 0.6894117593765259\n",
      "AUROC 5 : 0.7207791805267334\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.133 auroc 0.714 f1_score 0.052\n",
      "Epoch: [12]  [  0/161]  eta: 0:00:01  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8077 (0.8077)  total_loss: 5.7290 (5.7290)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [12]  [100/161]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9166 (6.8179)  time: 0.0120  data: 0.0014  max mem: 891\n",
      "Epoch: [12]  [160/161]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9451 (6.8426)  time: 0.0134  data: 0.0018  max mem: 891\n",
      "Epoch: [12] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0661 (0.0661)  div_loss: -63.8092 (-63.8092)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0650 (0.1450)  div_loss: -50.9786 (-49.5239)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9314285516738892\n",
      "AUROC 1 : 0.49714285135269165\n",
      "AUROC 2 : 0.7025089859962463\n",
      "AUROC 3 : 0.8578431606292725\n",
      "AUROC 4 : 0.8255208730697632\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.36936938762664795\n",
      "* Acc@1 83.571 loss 0.145 auroc 0.663 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0714 (0.0714)  div_loss: -36.8199 (-36.8199)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0811 (0.1353)  div_loss: -42.6849 (-43.9905)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.5487288236618042\n",
      "AUROC 2 : 0.6551282405853271\n",
      "AUROC 3 : 0.9428571462631226\n",
      "AUROC 4 : 0.6917647123336792\n",
      "AUROC 5 : 0.725649356842041\n",
      "AUROC 6 : 0.6803030371665955\n",
      "* Acc@1 83.582 loss 0.135 auroc 0.718 f1_score 0.052\n",
      "Epoch: [13]  [  0/161]  eta: 0:00:01  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8077 (0.8077)  total_loss: 5.7187 (5.7187)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [13]  [100/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9119 (6.8125)  time: 0.0122  data: 0.0015  max mem: 891\n",
      "Epoch: [13]  [160/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9389 (6.8373)  time: 0.0143  data: 0.0019  max mem: 891\n",
      "Epoch: [13] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0650 (0.0650)  div_loss: -63.6373 (-63.6373)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0605 (0.1541)  div_loss: -50.6871 (-49.2942)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9314285516738892\n",
      "AUROC 1 : 0.5028571486473083\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8480392098426819\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.3963963985443115\n",
      "* Acc@1 83.571 loss 0.154 auroc 0.666 f1_score 0.076\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0753 (0.0753)  div_loss: -36.6032 (-36.6032)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0769 (0.1383)  div_loss: -42.5009 (-43.7517)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.5677965879440308\n",
      "AUROC 2 : 0.656410276889801\n",
      "AUROC 3 : 0.9523809552192688\n",
      "AUROC 4 : 0.6882352828979492\n",
      "AUROC 5 : 0.7272727489471436\n",
      "AUROC 6 : 0.6803030967712402\n",
      "* Acc@1 83.582 loss 0.138 auroc 0.722 f1_score 0.079\n",
      "Epoch: [14]  [  0/161]  eta: 0:00:01  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8077 (0.8077)  total_loss: 5.7099 (5.7099)  time: 0.0076  data: 0.0003  max mem: 891\n",
      "Epoch: [14]  [100/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9095 (6.8070)  time: 0.0121  data: 0.0014  max mem: 891\n",
      "Epoch: [14]  [160/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9322 (6.8317)  time: 0.0132  data: 0.0018  max mem: 891\n",
      "Epoch: [14] Total time: 0:00:02 (0.0129 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0633 (0.0633)  div_loss: -63.4116 (-63.4116)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0555 (0.1652)  div_loss: -50.3035 (-48.9997)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9314285516738892\n",
      "AUROC 1 : 0.485714316368103\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.843137264251709\n",
      "AUROC 4 : 0.78125\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.4144144654273987\n",
      "* Acc@1 83.571 loss 0.165 auroc 0.661 f1_score 0.088\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0806 (0.0806)  div_loss: -36.3229 (-36.3229)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0726 (0.1430)  div_loss: -42.2671 (-43.4419)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7666666507720947\n",
      "AUROC 1 : 0.5826271176338196\n",
      "AUROC 2 : 0.6589743494987488\n",
      "AUROC 3 : 0.9547619223594666\n",
      "AUROC 4 : 0.6835294365882874\n",
      "AUROC 5 : 0.7305194735527039\n",
      "AUROC 6 : 0.6712121367454529\n",
      "* Acc@1 83.582 loss 0.143 auroc 0.721 f1_score 0.079\n",
      "Epoch: [15]  [  0/161]  eta: 0:00:01  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8077 (0.8077)  total_loss: 5.7026 (5.7026)  time: 0.0078  data: 0.0004  max mem: 891\n",
      "Epoch: [15]  [100/161]  eta: 0:00:00  lr: 0.000094  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.9081 (6.8016)  time: 0.0119  data: 0.0014  max mem: 891\n",
      "Epoch: [15]  [160/161]  eta: 0:00:00  lr: 0.000094  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9266 (6.8263)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [15] Total time: 0:00:02 (0.0130 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0610 (0.0610)  div_loss: -63.1323 (-63.1323)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0535 (0.1770)  div_loss: -49.8884 (-48.6648)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9257142543792725\n",
      "AUROC 1 : 0.48000001907348633\n",
      "AUROC 2 : 0.7025089859962463\n",
      "AUROC 3 : 0.8480392694473267\n",
      "AUROC 4 : 0.7708333730697632\n",
      "AUROC 5 : 0.4605262875556946\n",
      "AUROC 6 : 0.4144144654273987\n",
      "* Acc@1 83.571 loss 0.177 auroc 0.657 f1_score 0.123\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0879 (0.0879)  div_loss: -36.0204 (-36.0204)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0689 (0.1494)  div_loss: -41.9938 (-43.0945)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7714285850524902\n",
      "AUROC 1 : 0.5974576473236084\n",
      "AUROC 2 : 0.6589744091033936\n",
      "AUROC 3 : 0.961904764175415\n",
      "AUROC 4 : 0.6870588064193726\n",
      "AUROC 5 : 0.7272727489471436\n",
      "AUROC 6 : 0.6696969866752625\n",
      "* Acc@1 83.582 loss 0.149 auroc 0.725 f1_score 0.079\n",
      "Epoch: [16]  [  0/161]  eta: 0:00:01  lr: 0.000094  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8076 (0.8076)  total_loss: 5.6969 (5.6969)  time: 0.0113  data: 0.0003  max mem: 891\n",
      "Epoch: [16]  [100/161]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.9074 (6.7966)  time: 0.0125  data: 0.0015  max mem: 891\n",
      "Epoch: [16]  [160/161]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9217 (6.8213)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [16] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0585 (0.0585)  div_loss: -62.8026 (-62.8026)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0519 (0.1891)  div_loss: -49.4572 (-48.3078)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9199999570846558\n",
      "AUROC 1 : 0.48000001907348633\n",
      "AUROC 2 : 0.7132617235183716\n",
      "AUROC 3 : 0.8480392694473267\n",
      "AUROC 4 : 0.765625\n",
      "AUROC 5 : 0.4736841917037964\n",
      "AUROC 6 : 0.4234234690666199\n",
      "* Acc@1 83.571 loss 0.189 auroc 0.661 f1_score 0.132\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0979 (0.0979)  div_loss: -35.6958 (-35.6958)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0657 (0.1565)  div_loss: -41.7144 (-42.7341)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7547619342803955\n",
      "AUROC 1 : 0.6016949415206909\n",
      "AUROC 2 : 0.6602563858032227\n",
      "AUROC 3 : 0.9666666984558105\n",
      "AUROC 4 : 0.6847058534622192\n",
      "AUROC 5 : 0.7321428656578064\n",
      "AUROC 6 : 0.6712120771408081\n",
      "* Acc@1 83.582 loss 0.157 auroc 0.724 f1_score 0.092\n",
      "Epoch: [17]  [  0/161]  eta: 0:00:01  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8076 (0.8076)  total_loss: 5.6924 (5.6924)  time: 0.0106  data: 0.0003  max mem: 891\n",
      "Epoch: [17]  [100/161]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.9067 (6.7921)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [17]  [160/161]  eta: 0:00:00  lr: 0.000092  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9691)  total_loss: 6.9171 (6.8167)  time: 0.0132  data: 0.0018  max mem: 891\n",
      "Epoch: [17] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0555 (0.0555)  div_loss: -62.4420 (-62.4420)  acc1: 85.7143 (85.7143)  time: 0.0105  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0512 (0.2014)  div_loss: -49.0175 (-47.9474)  acc1: 85.7143 (83.5714)  time: 0.0113  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0096 s / it)\n",
      "AUROC 0 : 0.9199999570846558\n",
      "AUROC 1 : 0.4571428894996643\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8480392694473267\n",
      "AUROC 4 : 0.7604166269302368\n",
      "AUROC 5 : 0.4736841917037964\n",
      "AUROC 6 : 0.44144147634506226\n",
      "* Acc@1 83.571 loss 0.201 auroc 0.659 f1_score 0.151\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1108 (0.1108)  div_loss: -35.3540 (-35.3540)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0628 (0.1635)  div_loss: -41.4581 (-42.3783)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7523809671401978\n",
      "AUROC 1 : 0.6080508828163147\n",
      "AUROC 2 : 0.6615384817123413\n",
      "AUROC 3 : 0.9690476059913635\n",
      "AUROC 4 : 0.6823529601097107\n",
      "AUROC 5 : 0.7353895902633667\n",
      "AUROC 6 : 0.6712120771408081\n",
      "* Acc@1 83.582 loss 0.163 auroc 0.726 f1_score 0.128\n",
      "Epoch: [18]  [  0/161]  eta: 0:00:01  lr: 0.000092  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8076 (0.8076)  total_loss: 5.6893 (5.6893)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [18]  [100/161]  eta: 0:00:00  lr: 0.000092  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.9001 (6.7880)  time: 0.0127  data: 0.0014  max mem: 891\n",
      "Epoch: [18]  [160/161]  eta: 0:00:00  lr: 0.000091  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9691)  total_loss: 6.9128 (6.8125)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [18] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0519 (0.0519)  div_loss: -62.0646 (-62.0646)  acc1: 85.7143 (85.7143)  time: 0.0100  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0521 (0.2142)  div_loss: -48.5742 (-47.5753)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9199999570846558\n",
      "AUROC 1 : 0.4628571569919586\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.7526041269302368\n",
      "AUROC 5 : 0.4868420958518982\n",
      "AUROC 6 : 0.45045047998428345\n",
      "* Acc@1 83.571 loss 0.214 auroc 0.660 f1_score 0.184\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1266 (0.1266)  div_loss: -34.9909 (-34.9909)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0601 (0.1708)  div_loss: -41.2009 (-42.0173)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7452380657196045\n",
      "AUROC 1 : 0.6059322357177734\n",
      "AUROC 2 : 0.6576923131942749\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6870588064193726\n",
      "AUROC 5 : 0.7305195331573486\n",
      "AUROC 6 : 0.6727272868156433\n",
      "* Acc@1 83.582 loss 0.171 auroc 0.725 f1_score 0.139\n",
      "Epoch: [19]  [  0/161]  eta: 0:00:01  lr: 0.000091  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8076 (0.8076)  total_loss: 5.6871 (5.6871)  time: 0.0110  data: 0.0003  max mem: 891\n",
      "Epoch: [19]  [100/161]  eta: 0:00:00  lr: 0.000091  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8908 (6.7842)  time: 0.0120  data: 0.0014  max mem: 891\n",
      "Epoch: [19]  [160/161]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9691)  total_loss: 6.9089 (6.8086)  time: 0.0148  data: 0.0019  max mem: 891\n",
      "Epoch: [19] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0480 (0.0480)  div_loss: -61.6524 (-61.6524)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0553 (0.2274)  div_loss: -48.1144 (-47.1772)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9199999570846558\n",
      "AUROC 1 : 0.4571428596973419\n",
      "AUROC 2 : 0.698924720287323\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.75\n",
      "AUROC 5 : 0.4868420958518982\n",
      "AUROC 6 : 0.45045047998428345\n",
      "* Acc@1 83.571 loss 0.227 auroc 0.657 f1_score 0.184\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1477 (0.1477)  div_loss: -34.5901 (-34.5901)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0571 (0.1787)  div_loss: -40.9389 (-41.6327)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.738095223903656\n",
      "AUROC 1 : 0.6144068241119385\n",
      "AUROC 2 : 0.6499999761581421\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6870588064193726\n",
      "AUROC 5 : 0.7288961410522461\n",
      "AUROC 6 : 0.6712121367454529\n",
      "* Acc@1 83.582 loss 0.179 auroc 0.724 f1_score 0.139\n",
      "Epoch: [20]  [  0/161]  eta: 0:00:01  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8075 (0.8075)  total_loss: 5.6856 (5.6856)  time: 0.0101  data: 0.0003  max mem: 891\n",
      "Epoch: [20]  [100/161]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8852 (6.7808)  time: 0.0118  data: 0.0012  max mem: 891\n",
      "Epoch: [20]  [160/161]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.9060 (6.8051)  time: 0.0129  data: 0.0015  max mem: 891\n",
      "Epoch: [20] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0441 (0.0441)  div_loss: -61.2057 (-61.2057)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0607 (0.2402)  div_loss: -47.6507 (-46.7651)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9142856597900391\n",
      "AUROC 1 : 0.4571428596973419\n",
      "AUROC 2 : 0.6989247798919678\n",
      "AUROC 3 : 0.8333333134651184\n",
      "AUROC 4 : 0.7447916269302368\n",
      "AUROC 5 : 0.4868420958518982\n",
      "AUROC 6 : 0.45945948362350464\n",
      "* Acc@1 83.571 loss 0.240 auroc 0.656 f1_score 0.166\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1724 (0.1724)  div_loss: -34.1731 (-34.1731)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0538 (0.1869)  div_loss: -40.6583 (-41.2369)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.738095223903656\n",
      "AUROC 1 : 0.6207627058029175\n",
      "AUROC 2 : 0.6474359035491943\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6835293769836426\n",
      "AUROC 5 : 0.7288960814476013\n",
      "AUROC 6 : 0.6803030967712402\n",
      "* Acc@1 83.582 loss 0.187 auroc 0.725 f1_score 0.151\n",
      "Epoch: [21]  [  0/161]  eta: 0:00:01  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8075 (0.8075)  total_loss: 5.6841 (5.6841)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [21]  [100/161]  eta: 0:00:00  lr: 0.000089  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8849 (6.7778)  time: 0.0124  data: 0.0012  max mem: 891\n",
      "Epoch: [21]  [160/161]  eta: 0:00:00  lr: 0.000089  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.9035 (6.8020)  time: 0.0136  data: 0.0015  max mem: 891\n",
      "Epoch: [21] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0411 (0.0411)  div_loss: -60.7343 (-60.7343)  acc1: 85.7143 (85.7143)  time: 0.0095  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0613 (0.2522)  div_loss: -47.1923 (-46.3695)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9142856597900391\n",
      "AUROC 1 : 0.4628571569919586\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8333333134651184\n",
      "AUROC 4 : 0.7447916269302368\n",
      "AUROC 5 : 0.5\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.252 auroc 0.660 f1_score 0.194\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1889 (0.1889)  div_loss: -33.8522 (-33.8522)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0507 (0.1950)  div_loss: -40.4275 (-40.8725)  acc1: 85.7143 (83.5821)  time: 0.0051  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7333333492279053\n",
      "AUROC 1 : 0.625\n",
      "AUROC 2 : 0.6410256624221802\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6788235306739807\n",
      "AUROC 5 : 0.7337661981582642\n",
      "AUROC 6 : 0.686363697052002\n",
      "* Acc@1 83.582 loss 0.195 auroc 0.725 f1_score 0.152\n",
      "Epoch: [22]  [  0/161]  eta: 0:00:01  lr: 0.000089  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8075 (0.8075)  total_loss: 5.6825 (5.6825)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [22]  [100/161]  eta: 0:00:00  lr: 0.000088  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8846 (6.7752)  time: 0.0127  data: 0.0012  max mem: 891\n",
      "Epoch: [22]  [160/161]  eta: 0:00:00  lr: 0.000088  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.9015 (6.7993)  time: 0.0134  data: 0.0016  max mem: 891\n",
      "Epoch: [22] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0392 (0.0392)  div_loss: -60.2572 (-60.2572)  acc1: 85.7143 (85.7143)  time: 0.0097  data: 0.0028  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0693 (0.2643)  div_loss: -46.7616 (-45.9726)  acc1: 85.7143 (83.5714)  time: 0.0106  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9142856597900391\n",
      "AUROC 1 : 0.4571428596973419\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7421875\n",
      "AUROC 5 : 0.5131579041481018\n",
      "AUROC 6 : 0.5045045614242554\n",
      "* Acc@1 83.571 loss 0.264 auroc 0.664 f1_score 0.194\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2049 (0.2049)  div_loss: -33.5161 (-33.5161)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0473 (0.2038)  div_loss: -40.2073 (-40.4946)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.723809540271759\n",
      "AUROC 1 : 0.6313559412956238\n",
      "AUROC 2 : 0.6397435665130615\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6741176843643188\n",
      "AUROC 5 : 0.7321428656578064\n",
      "AUROC 6 : 0.6893939971923828\n",
      "* Acc@1 83.582 loss 0.204 auroc 0.724 f1_score 0.173\n",
      "Epoch: [23]  [  0/161]  eta: 0:00:01  lr: 0.000088  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8074 (0.8074)  total_loss: 5.6807 (5.6807)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [23]  [100/161]  eta: 0:00:00  lr: 0.000087  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8844 (6.7730)  time: 0.0122  data: 0.0015  max mem: 891\n",
      "Epoch: [23]  [160/161]  eta: 0:00:00  lr: 0.000086  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8999 (6.7970)  time: 0.0132  data: 0.0017  max mem: 891\n",
      "Epoch: [23] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0379 (0.0379)  div_loss: -59.7638 (-59.7638)  acc1: 85.7143 (85.7143)  time: 0.0097  data: 0.0027  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0713 (0.2764)  div_loss: -46.3569 (-45.5915)  acc1: 85.7143 (83.5714)  time: 0.0104  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9142856597900391\n",
      "AUROC 1 : 0.46857142448425293\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.8235293626785278\n",
      "AUROC 4 : 0.7447916865348816\n",
      "AUROC 5 : 0.5394736528396606\n",
      "AUROC 6 : 0.5225225687026978\n",
      "* Acc@1 83.571 loss 0.276 auroc 0.672 f1_score 0.211\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2147 (0.2147)  div_loss: -33.2311 (-33.2311)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0441 (0.2126)  div_loss: -40.0122 (-40.1330)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.723809540271759\n",
      "AUROC 1 : 0.6355932354927063\n",
      "AUROC 2 : 0.6358973979949951\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6741176843643188\n",
      "AUROC 5 : 0.7272727489471436\n",
      "AUROC 6 : 0.6863636374473572\n",
      "* Acc@1 83.582 loss 0.213 auroc 0.723 f1_score 0.173\n",
      "Epoch: [24]  [  0/161]  eta: 0:00:01  lr: 0.000086  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8074 (0.8074)  total_loss: 5.6787 (5.6787)  time: 0.0096  data: 0.0003  max mem: 891\n",
      "Epoch: [24]  [100/161]  eta: 0:00:00  lr: 0.000086  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8824 (6.7710)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [24]  [160/161]  eta: 0:00:00  lr: 0.000085  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8986 (6.7951)  time: 0.0134  data: 0.0016  max mem: 891\n",
      "Epoch: [24] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0369 (0.0369)  div_loss: -59.2612 (-59.2612)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0711 (0.2882)  div_loss: -45.9739 (-45.2273)  acc1: 85.7143 (83.5714)  time: 0.0106  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.48571428656578064\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8235293626785278\n",
      "AUROC 4 : 0.7578125\n",
      "AUROC 5 : 0.5394736528396606\n",
      "AUROC 6 : 0.5585585832595825\n",
      "* Acc@1 83.571 loss 0.288 auroc 0.681 f1_score 0.234\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2196 (0.2196)  div_loss: -32.9916 (-32.9916)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0407 (0.2212)  div_loss: -39.8308 (-39.7935)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.723809540271759\n",
      "AUROC 1 : 0.6525424122810364\n",
      "AUROC 2 : 0.629487156867981\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6788235306739807\n",
      "AUROC 5 : 0.7175324559211731\n",
      "AUROC 6 : 0.6939393877983093\n",
      "* Acc@1 83.582 loss 0.221 auroc 0.725 f1_score 0.184\n",
      "Epoch: [25]  [  0/161]  eta: 0:00:01  lr: 0.000085  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6765 (5.6765)  time: 0.0113  data: 0.0003  max mem: 891\n",
      "Epoch: [25]  [100/161]  eta: 0:00:00  lr: 0.000085  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8803 (6.7694)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [25]  [160/161]  eta: 0:00:00  lr: 0.000084  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8975 (6.7934)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [25] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0362 (0.0362)  div_loss: -58.7473 (-58.7473)  acc1: 85.7143 (85.7143)  time: 0.0100  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0694 (0.3002)  div_loss: -45.6175 (-44.8827)  acc1: 85.7143 (83.5714)  time: 0.0103  data: 0.0020  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0087 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.47999998927116394\n",
      "AUROC 2 : 0.698924720287323\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7630208134651184\n",
      "AUROC 5 : 0.5394736528396606\n",
      "AUROC 6 : 0.5585585832595825\n",
      "* Acc@1 83.571 loss 0.300 auroc 0.681 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2214 (0.2214)  div_loss: -32.7802 (-32.7802)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0375 (0.2298)  div_loss: -39.6745 (-39.4792)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0051 s / it)\n",
      "AUROC 0 : 0.726190447807312\n",
      "AUROC 1 : 0.6567797064781189\n",
      "AUROC 2 : 0.6269230842590332\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6800000071525574\n",
      "AUROC 5 : 0.7207792401313782\n",
      "AUROC 6 : 0.689393937587738\n",
      "* Acc@1 83.582 loss 0.230 auroc 0.726 f1_score 0.173\n",
      "Epoch: [26]  [  0/161]  eta: 0:00:01  lr: 0.000084  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6745 (5.6745)  time: 0.0083  data: 0.0003  max mem: 891\n",
      "Epoch: [26]  [100/161]  eta: 0:00:00  lr: 0.000084  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8785 (6.7679)  time: 0.0125  data: 0.0014  max mem: 891\n",
      "Epoch: [26]  [160/161]  eta: 0:00:00  lr: 0.000083  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8966 (6.7919)  time: 0.0136  data: 0.0016  max mem: 891\n",
      "Epoch: [26] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0354 (0.0354)  div_loss: -58.2421 (-58.2421)  acc1: 85.7143 (85.7143)  time: 0.0100  data: 0.0029  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0669 (0.3124)  div_loss: -45.2798 (-44.5577)  acc1: 85.7143 (83.5714)  time: 0.0104  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.49142858386039734\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7630208134651184\n",
      "AUROC 5 : 0.5526315569877625\n",
      "AUROC 6 : 0.5855855941772461\n",
      "* Acc@1 83.571 loss 0.312 auroc 0.688 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2198 (0.2198)  div_loss: -32.5967 (-32.5967)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0348 (0.2382)  div_loss: -39.4322 (-39.1871)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0050 s / it)\n",
      "AUROC 0 : 0.726190447807312\n",
      "AUROC 1 : 0.6673728823661804\n",
      "AUROC 2 : 0.6102564334869385\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6788235306739807\n",
      "AUROC 5 : 0.7175325155258179\n",
      "AUROC 6 : 0.684848427772522\n",
      "* Acc@1 83.582 loss 0.238 auroc 0.723 f1_score 0.183\n",
      "Epoch: [27]  [  0/161]  eta: 0:00:01  lr: 0.000083  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6728 (5.6728)  time: 0.0084  data: 0.0003  max mem: 891\n",
      "Epoch: [27]  [100/161]  eta: 0:00:00  lr: 0.000082  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8769 (6.7665)  time: 0.0128  data: 0.0015  max mem: 891\n",
      "Epoch: [27]  [160/161]  eta: 0:00:00  lr: 0.000082  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8957 (6.7906)  time: 0.0136  data: 0.0017  max mem: 891\n",
      "Epoch: [27] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0345 (0.0345)  div_loss: -57.8063 (-57.8063)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0027  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0630 (0.3250)  div_loss: -44.9690 (-44.2748)  acc1: 85.7143 (83.5714)  time: 0.0102  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0086 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.49142858386039734\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7682291865348816\n",
      "AUROC 5 : 0.5526315569877625\n",
      "AUROC 6 : 0.5945945978164673\n",
      "* Acc@1 83.571 loss 0.325 auroc 0.689 f1_score 0.236\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2155 (0.2155)  div_loss: -32.4385 (-32.4385)  acc1: 85.7143 (85.7143)  time: 0.0040  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0339 (0.2467)  div_loss: -39.1313 (-38.9313)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7309523820877075\n",
      "AUROC 1 : 0.6737288236618042\n",
      "AUROC 2 : 0.6051281690597534\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.677647054195404\n",
      "AUROC 5 : 0.7126623392105103\n",
      "AUROC 6 : 0.6863636374473572\n",
      "* Acc@1 83.582 loss 0.247 auroc 0.724 f1_score 0.224\n",
      "Epoch: [28]  [  0/161]  eta: 0:00:01  lr: 0.000082  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6713 (5.6713)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [28]  [100/161]  eta: 0:00:00  lr: 0.000081  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8752 (6.7654)  time: 0.0123  data: 0.0012  max mem: 891\n",
      "Epoch: [28]  [160/161]  eta: 0:00:00  lr: 0.000081  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8951 (6.7895)  time: 0.0142  data: 0.0017  max mem: 891\n",
      "Epoch: [28] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0336 (0.0336)  div_loss: -57.3876 (-57.3876)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0588 (0.3384)  div_loss: -44.7022 (-44.0370)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.49714288115501404\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7708333730697632\n",
      "AUROC 5 : 0.5526315569877625\n",
      "AUROC 6 : 0.6126126050949097\n",
      "* Acc@1 83.571 loss 0.338 auroc 0.693 f1_score 0.213\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2093 (0.2093)  div_loss: -32.3101 (-32.3101)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0330 (0.2554)  div_loss: -38.8700 (-38.7160)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7309523820877075\n",
      "AUROC 1 : 0.6779661178588867\n",
      "AUROC 2 : 0.5987179279327393\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.6788235306739807\n",
      "AUROC 5 : 0.7126623392105103\n",
      "AUROC 6 : 0.6863636374473572\n",
      "* Acc@1 83.582 loss 0.255 auroc 0.724 f1_score 0.245\n",
      "Epoch: [29]  [  0/161]  eta: 0:00:01  lr: 0.000081  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6699 (5.6699)  time: 0.0084  data: 0.0003  max mem: 891\n",
      "Epoch: [29]  [100/161]  eta: 0:00:00  lr: 0.000080  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8737 (6.7644)  time: 0.0125  data: 0.0015  max mem: 891\n",
      "Epoch: [29]  [160/161]  eta: 0:00:00  lr: 0.000079  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8945 (6.7885)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [29] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0327 (0.0327)  div_loss: -56.9749 (-56.9749)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0552 (0.3533)  div_loss: -44.4679 (-43.8352)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.49714288115501404\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7760416865348816\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6396396160125732\n",
      "* Acc@1 83.571 loss 0.353 auroc 0.701 f1_score 0.213\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.2021 (0.2021)  div_loss: -32.2264 (-32.2264)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0323 (0.2643)  div_loss: -38.6194 (-38.5342)  acc1: 85.7143 (83.5821)  time: 0.0050  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0057 s / it)\n",
      "AUROC 0 : 0.738095223903656\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.684705913066864\n",
      "AUROC 5 : 0.7045454978942871\n",
      "AUROC 6 : 0.6833333373069763\n",
      "* Acc@1 83.582 loss 0.264 auroc 0.724 f1_score 0.245\n",
      "Epoch: [30]  [  0/161]  eta: 0:00:01  lr: 0.000079  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6686 (5.6686)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [30]  [100/161]  eta: 0:00:00  lr: 0.000079  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8723 (6.7637)  time: 0.0119  data: 0.0012  max mem: 891\n",
      "Epoch: [30]  [160/161]  eta: 0:00:00  lr: 0.000078  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8940 (6.7878)  time: 0.0142  data: 0.0018  max mem: 891\n",
      "Epoch: [30] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0320 (0.0320)  div_loss: -56.5772 (-56.5772)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0518 (0.3690)  div_loss: -44.2669 (-43.6642)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7786458134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6396396160125732\n",
      "* Acc@1 83.571 loss 0.369 auroc 0.704 f1_score 0.213\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1953 (0.1953)  div_loss: -32.1623 (-32.1623)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0311 (0.2732)  div_loss: -38.3898 (-38.3823)  acc1: 85.7143 (83.5821)  time: 0.0052  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0058 s / it)\n",
      "AUROC 0 : 0.735714316368103\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5871794819831848\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.6870588660240173\n",
      "AUROC 5 : 0.7061688899993896\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.273 auroc 0.724 f1_score 0.243\n",
      "Epoch: [31]  [  0/161]  eta: 0:00:01  lr: 0.000078  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6673 (5.6673)  time: 0.0122  data: 0.0003  max mem: 891\n",
      "Epoch: [31]  [100/161]  eta: 0:00:00  lr: 0.000077  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8711 (6.7630)  time: 0.0115  data: 0.0012  max mem: 891\n",
      "Epoch: [31]  [160/161]  eta: 0:00:00  lr: 0.000077  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8936 (6.7872)  time: 0.0166  data: 0.0018  max mem: 891\n",
      "Epoch: [31] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0316 (0.0316)  div_loss: -56.2361 (-56.2361)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0480 (0.3851)  div_loss: -44.1027 (-43.5318)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.514285683631897\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.78125\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6576576232910156\n",
      "* Acc@1 83.571 loss 0.385 auroc 0.706 f1_score 0.208\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1887 (0.1887)  div_loss: -32.1344 (-32.1344)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0301 (0.2820)  div_loss: -38.1938 (-38.2643)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7428571581840515\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.5833333134651184\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.6905882358551025\n",
      "AUROC 5 : 0.7045454382896423\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.282 auroc 0.725 f1_score 0.238\n",
      "Epoch: [32]  [  0/161]  eta: 0:00:01  lr: 0.000077  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6661 (5.6661)  time: 0.0115  data: 0.0003  max mem: 891\n",
      "Epoch: [32]  [100/161]  eta: 0:00:00  lr: 0.000076  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8701 (6.7625)  time: 0.0117  data: 0.0012  max mem: 891\n",
      "Epoch: [32]  [160/161]  eta: 0:00:00  lr: 0.000075  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8932 (6.7867)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [32] Total time: 0:00:02 (0.0129 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0318 (0.0318)  div_loss: -55.9159 (-55.9159)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0502 (0.4018)  div_loss: -43.9592 (-43.4153)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.514285683631897\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8039215803146362\n",
      "AUROC 4 : 0.7838541865348816\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.402 auroc 0.706 f1_score 0.225\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1825 (0.1825)  div_loss: -32.1130 (-32.1130)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0288 (0.2909)  div_loss: -38.0370 (-38.1627)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7452380657196045\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.5743589997291565\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.6905882358551025\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.674242377281189\n",
      "* Acc@1 83.582 loss 0.291 auroc 0.723 f1_score 0.246\n",
      "Epoch: [33]  [  0/161]  eta: 0:00:01  lr: 0.000075  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6649 (5.6649)  time: 0.0079  data: 0.0004  max mem: 891\n",
      "Epoch: [33]  [100/161]  eta: 0:00:00  lr: 0.000075  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8692 (6.7621)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [33]  [160/161]  eta: 0:00:00  lr: 0.000074  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8929 (6.7863)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [33] Total time: 0:00:02 (0.0133 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0322 (0.0322)  div_loss: -55.6564 (-55.6564)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0532 (0.4186)  div_loss: -43.8380 (-43.3271)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7864583730697632\n",
      "AUROC 5 : 0.6052631735801697\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.419 auroc 0.713 f1_score 0.225\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1766 (0.1766)  div_loss: -32.1028 (-32.1028)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0272 (0.3000)  div_loss: -37.8967 (-38.0851)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.571794867515564\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.6941176652908325\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.300 auroc 0.723 f1_score 0.260\n",
      "Epoch: [34]  [  0/161]  eta: 0:00:01  lr: 0.000074  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6638 (5.6638)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [34]  [100/161]  eta: 0:00:00  lr: 0.000073  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8685 (6.7617)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [34]  [160/161]  eta: 0:00:00  lr: 0.000073  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8927 (6.7859)  time: 0.0130  data: 0.0015  max mem: 891\n",
      "Epoch: [34] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0330 (0.0330)  div_loss: -55.4170 (-55.4170)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0027  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0571 (0.4353)  div_loss: -43.7267 (-43.2585)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.698924720287323\n",
      "AUROC 3 : 0.8039215803146362\n",
      "AUROC 4 : 0.7942708730697632\n",
      "AUROC 5 : 0.6052631735801697\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.435 auroc 0.715 f1_score 0.222\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1699 (0.1699)  div_loss: -32.1122 (-32.1122)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0257 (0.3087)  div_loss: -37.8015 (-38.0292)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5679486989974976\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.6976470947265625\n",
      "AUROC 5 : 0.6964285373687744\n",
      "AUROC 6 : 0.6712120771408081\n",
      "* Acc@1 83.582 loss 0.309 auroc 0.722 f1_score 0.287\n",
      "Epoch: [35]  [  0/161]  eta: 0:00:01  lr: 0.000073  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6627 (5.6627)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [35]  [100/161]  eta: 0:00:00  lr: 0.000072  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8679 (6.7614)  time: 0.0125  data: 0.0015  max mem: 891\n",
      "Epoch: [35]  [160/161]  eta: 0:00:00  lr: 0.000071  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8924 (6.7856)  time: 0.0136  data: 0.0019  max mem: 891\n",
      "Epoch: [35] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0339 (0.0339)  div_loss: -55.2497 (-55.2497)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0599 (0.4514)  div_loss: -43.6556 (-43.2242)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.698924720287323\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7916666865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.451 auroc 0.717 f1_score 0.250\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1632 (0.1632)  div_loss: -32.1511 (-32.1511)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0244 (0.3169)  div_loss: -37.7090 (-38.0044)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.75\n",
      "AUROC 1 : 0.6927966475486755\n",
      "AUROC 2 : 0.5692307949066162\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.7011765241622925\n",
      "AUROC 5 : 0.6964285373687744\n",
      "AUROC 6 : 0.6712120771408081\n",
      "* Acc@1 83.582 loss 0.317 auroc 0.724 f1_score 0.308\n",
      "Epoch: [36]  [  0/161]  eta: 0:00:01  lr: 0.000071  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6616 (5.6616)  time: 0.0098  data: 0.0003  max mem: 891\n",
      "Epoch: [36]  [100/161]  eta: 0:00:00  lr: 0.000070  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8674 (6.7612)  time: 0.0124  data: 0.0015  max mem: 891\n",
      "Epoch: [36]  [160/161]  eta: 0:00:00  lr: 0.000070  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8922 (6.7854)  time: 0.0131  data: 0.0015  max mem: 891\n",
      "Epoch: [36] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0350 (0.0350)  div_loss: -55.0608 (-55.0608)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0644 (0.4666)  div_loss: -43.5824 (-43.1919)  acc1: 85.7143 (83.5714)  time: 0.0107  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.698924720287323\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7916666865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.467 auroc 0.717 f1_score 0.250\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1538 (0.1538)  div_loss: -32.1836 (-32.1836)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0233 (0.3248)  div_loss: -37.6564 (-37.9840)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5692307949066162\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.7023530006408691\n",
      "AUROC 5 : 0.698051929473877\n",
      "AUROC 6 : 0.6696969270706177\n",
      "* Acc@1 83.582 loss 0.325 auroc 0.724 f1_score 0.308\n",
      "Epoch: [37]  [  0/161]  eta: 0:00:01  lr: 0.000070  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6606 (5.6606)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [37]  [100/161]  eta: 0:00:00  lr: 0.000069  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8669 (6.7610)  time: 0.0124  data: 0.0015  max mem: 891\n",
      "Epoch: [37]  [160/161]  eta: 0:00:00  lr: 0.000068  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8921 (6.7852)  time: 0.0135  data: 0.0019  max mem: 891\n",
      "Epoch: [37] Total time: 0:00:02 (0.0133 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0359 (0.0359)  div_loss: -54.9417 (-54.9417)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0672 (0.4813)  div_loss: -43.5372 (-43.1807)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.698924720287323\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7916666865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.481 auroc 0.716 f1_score 0.250\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1449 (0.1449)  div_loss: -32.2459 (-32.2459)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0236 (0.3323)  div_loss: -37.5785 (-37.9792)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5705128908157349\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.707058846950531\n",
      "AUROC 5 : 0.698051929473877\n",
      "AUROC 6 : 0.6681817770004272\n",
      "* Acc@1 83.582 loss 0.332 auroc 0.724 f1_score 0.308\n",
      "Epoch: [38]  [  0/161]  eta: 0:00:01  lr: 0.000068  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6597 (5.6597)  time: 0.0079  data: 0.0003  max mem: 891\n",
      "Epoch: [38]  [100/161]  eta: 0:00:00  lr: 0.000067  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8666 (6.7608)  time: 0.0125  data: 0.0015  max mem: 891\n",
      "Epoch: [38]  [160/161]  eta: 0:00:00  lr: 0.000067  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8919 (6.7850)  time: 0.0134  data: 0.0018  max mem: 891\n",
      "Epoch: [38] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0366 (0.0366)  div_loss: -54.8124 (-54.8124)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0716 (0.4949)  div_loss: -43.4919 (-43.1863)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7916666865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.571 loss 0.495 auroc 0.716 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1365 (0.1365)  div_loss: -32.2937 (-32.2937)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0245 (0.3390)  div_loss: -37.5627 (-37.9960)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.75\n",
      "AUROC 1 : 0.6949152946472168\n",
      "AUROC 2 : 0.5730769634246826\n",
      "AUROC 3 : 0.9904761910438538\n",
      "AUROC 4 : 0.7082353234291077\n",
      "AUROC 5 : 0.6996753215789795\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.582 loss 0.339 auroc 0.726 f1_score 0.317\n",
      "Epoch: [39]  [  0/161]  eta: 0:00:01  lr: 0.000067  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6588 (5.6588)  time: 0.0112  data: 0.0003  max mem: 891\n",
      "Epoch: [39]  [100/161]  eta: 0:00:00  lr: 0.000066  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8663 (6.7606)  time: 0.0119  data: 0.0013  max mem: 891\n",
      "Epoch: [39]  [160/161]  eta: 0:00:00  lr: 0.000065  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8918 (6.7848)  time: 0.0132  data: 0.0018  max mem: 891\n",
      "Epoch: [39] Total time: 0:00:02 (0.0130 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0372 (0.0372)  div_loss: -54.7469 (-54.7469)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0720 (0.5075)  div_loss: -43.4635 (-43.2003)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7942708730697632\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.508 auroc 0.719 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1279 (0.1279)  div_loss: -32.3815 (-32.3815)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0251 (0.3454)  div_loss: -37.5000 (-38.0159)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7523809671401978\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.5743589997291565\n",
      "AUROC 3 : 0.9904761910438538\n",
      "AUROC 4 : 0.7094117999076843\n",
      "AUROC 5 : 0.698051929473877\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.345 auroc 0.728 f1_score 0.317\n",
      "Epoch: [40]  [  0/161]  eta: 0:00:02  lr: 0.000065  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6580 (5.6580)  time: 0.0130  data: 0.0006  max mem: 891\n",
      "Epoch: [40]  [100/161]  eta: 0:00:00  lr: 0.000065  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8660 (6.7605)  time: 0.0126  data: 0.0015  max mem: 891\n",
      "Epoch: [40]  [160/161]  eta: 0:00:00  lr: 0.000064  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8917 (6.7847)  time: 0.0138  data: 0.0019  max mem: 891\n",
      "Epoch: [40] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0375 (0.0375)  div_loss: -54.6449 (-54.6449)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0745 (0.5198)  div_loss: -43.4221 (-43.2235)  acc1: 85.7143 (83.5714)  time: 0.0114  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0096 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7942708730697632\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.520 auroc 0.719 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1209 (0.1209)  div_loss: -32.4213 (-32.4213)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0240 (0.3510)  div_loss: -37.4918 (-38.0477)  acc1: 85.7143 (83.5821)  time: 0.0045  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7547619342803955\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.5730769038200378\n",
      "AUROC 3 : 0.9904761910438538\n",
      "AUROC 4 : 0.7094117999076843\n",
      "AUROC 5 : 0.698051929473877\n",
      "AUROC 6 : 0.6681817770004272\n",
      "* Acc@1 83.582 loss 0.351 auroc 0.728 f1_score 0.317\n",
      "Epoch: [41]  [  0/161]  eta: 0:00:01  lr: 0.000064  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6574 (5.6574)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [41]  [100/161]  eta: 0:00:00  lr: 0.000063  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8658 (6.7603)  time: 0.0117  data: 0.0012  max mem: 891\n",
      "Epoch: [41]  [160/161]  eta: 0:00:00  lr: 0.000062  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8916 (6.7846)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [41] Total time: 0:00:02 (0.0126 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0378 (0.0378)  div_loss: -54.6354 (-54.6354)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0741 (0.5312)  div_loss: -43.4127 (-43.2611)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.531 auroc 0.720 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1124 (0.1124)  div_loss: -32.5241 (-32.5241)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0230 (0.3566)  div_loss: -37.4557 (-38.0896)  acc1: 85.7143 (83.5821)  time: 0.0051  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0056 s / it)\n",
      "AUROC 0 : 0.7571428418159485\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.5743589401245117\n",
      "AUROC 3 : 0.9904761910438538\n",
      "AUROC 4 : 0.710588276386261\n",
      "AUROC 5 : 0.6931818127632141\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.357 auroc 0.729 f1_score 0.317\n",
      "Epoch: [42]  [  0/161]  eta: 0:00:01  lr: 0.000062  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6568 (5.6568)  time: 0.0116  data: 0.0003  max mem: 891\n",
      "Epoch: [42]  [100/161]  eta: 0:00:00  lr: 0.000061  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8656 (6.7602)  time: 0.0145  data: 0.0015  max mem: 891\n",
      "Epoch: [42]  [160/161]  eta: 0:00:00  lr: 0.000061  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8915 (6.7845)  time: 0.0130  data: 0.0018  max mem: 891\n",
      "Epoch: [42] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0379 (0.0379)  div_loss: -54.5365 (-54.5365)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0756 (0.5420)  div_loss: -43.3616 (-43.2850)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.542 auroc 0.720 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1070 (0.1070)  div_loss: -32.5381 (-32.5381)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0221 (0.3616)  div_loss: -37.4217 (-38.1181)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7595238089561462\n",
      "AUROC 1 : 0.6991525292396545\n",
      "AUROC 2 : 0.5730769038200378\n",
      "AUROC 3 : 0.9904761910438538\n",
      "AUROC 4 : 0.7164705991744995\n",
      "AUROC 5 : 0.6915584802627563\n",
      "AUROC 6 : 0.6712120771408081\n",
      "* Acc@1 83.582 loss 0.362 auroc 0.729 f1_score 0.308\n",
      "Epoch: [43]  [  0/161]  eta: 0:00:01  lr: 0.000061  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6563 (5.6563)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [43]  [100/161]  eta: 0:00:00  lr: 0.000060  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8654 (6.7601)  time: 0.0119  data: 0.0014  max mem: 891\n",
      "Epoch: [43]  [160/161]  eta: 0:00:00  lr: 0.000059  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8915 (6.7844)  time: 0.0129  data: 0.0015  max mem: 891\n",
      "Epoch: [43] Total time: 0:00:02 (0.0129 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0375 (0.0375)  div_loss: -54.6093 (-54.6093)  acc1: 85.7143 (85.7143)  time: 0.0094  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0721 (0.5510)  div_loss: -43.4017 (-43.3561)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0022  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5199999809265137\n",
      "AUROC 2 : 0.7025089859962463\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6846847534179688\n",
      "* Acc@1 83.571 loss 0.551 auroc 0.722 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1000 (0.1000)  div_loss: -32.7074 (-32.7074)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0207 (0.3667)  div_loss: -37.4588 (-38.1904)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.764285683631897\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7164705991744995\n",
      "AUROC 5 : 0.6883116960525513\n",
      "AUROC 6 : 0.6712120771408081\n",
      "* Acc@1 83.582 loss 0.367 auroc 0.730 f1_score 0.348\n",
      "Epoch: [44]  [  0/161]  eta: 0:00:01  lr: 0.000059  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6559 (5.6559)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [44]  [100/161]  eta: 0:00:00  lr: 0.000058  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8652 (6.7600)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [44]  [160/161]  eta: 0:00:00  lr: 0.000058  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8914 (6.7843)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [44] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0377 (0.0377)  div_loss: -54.4513 (-54.4513)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0775 (0.5624)  div_loss: -43.3275 (-43.3601)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0020  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.6917563080787659\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.562 auroc 0.726 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0951 (0.0951)  div_loss: -32.5736 (-32.5736)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0206 (0.3708)  div_loss: -37.3626 (-38.1959)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0051 s / it)\n",
      "AUROC 0 : 0.764285683631897\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.5782051086425781\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7176470756530762\n",
      "AUROC 5 : 0.6915584802627563\n",
      "AUROC 6 : 0.6696969270706177\n",
      "* Acc@1 83.582 loss 0.371 auroc 0.730 f1_score 0.367\n",
      "Epoch: [45]  [  0/161]  eta: 0:00:01  lr: 0.000058  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6555 (5.6555)  time: 0.0079  data: 0.0003  max mem: 891\n",
      "Epoch: [45]  [100/161]  eta: 0:00:00  lr: 0.000057  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8653 (6.7600)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [45]  [160/161]  eta: 0:00:00  lr: 0.000056  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8914 (6.7843)  time: 0.0134  data: 0.0018  max mem: 891\n",
      "Epoch: [45] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0353 (0.0353)  div_loss: -54.7074 (-54.7074)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0649 (0.5632)  div_loss: -43.4974 (-43.4927)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5028571486473083\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6846847534179688\n",
      "* Acc@1 83.571 loss 0.563 auroc 0.720 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0898 (0.0898)  div_loss: -33.0612 (-33.0612)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0183 (0.3769)  div_loss: -37.5762 (-38.3208)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7666666507720947\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.5833333730697632\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7129411697387695\n",
      "AUROC 5 : 0.6850649118423462\n",
      "AUROC 6 : 0.6696969270706177\n",
      "* Acc@1 83.582 loss 0.377 auroc 0.731 f1_score 0.366\n",
      "Epoch: [46]  [  0/161]  eta: 0:00:01  lr: 0.000056  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6554 (5.6554)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [46]  [100/161]  eta: 0:00:00  lr: 0.000055  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8650 (6.7600)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [46]  [160/161]  eta: 0:00:00  lr: 0.000055  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8913 (6.7842)  time: 0.0148  data: 0.0018  max mem: 891\n",
      "Epoch: [46] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0363 (0.0363)  div_loss: -54.4966 (-54.4966)  acc1: 85.7143 (85.7143)  time: 0.0105  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0766 (0.5732)  div_loss: -43.4271 (-43.5270)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.6917563080787659\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.573 auroc 0.728 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0927 (0.0927)  div_loss: -32.6133 (-32.6133)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0200 (0.3761)  div_loss: -37.6688 (-38.3545)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7690476179122925\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.5794872045516968\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7235294580459595\n",
      "AUROC 5 : 0.6866883039474487\n",
      "AUROC 6 : 0.6666666269302368\n",
      "* Acc@1 83.582 loss 0.376 auroc 0.731 f1_score 0.340\n",
      "Epoch: [47]  [  0/161]  eta: 0:00:01  lr: 0.000055  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6555 (5.6555)  time: 0.0119  data: 0.0003  max mem: 891\n",
      "Epoch: [47]  [100/161]  eta: 0:00:00  lr: 0.000054  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8650 (6.7600)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [47]  [160/161]  eta: 0:00:00  lr: 0.000053  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8913 (6.7842)  time: 0.0139  data: 0.0018  max mem: 891\n",
      "Epoch: [47] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0347 (0.0347)  div_loss: -54.8094 (-54.8094)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0560 (0.5799)  div_loss: -43.4810 (-43.6213)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.49714288115501404\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6846847534179688\n",
      "* Acc@1 83.571 loss 0.580 auroc 0.719 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0876 (0.0876)  div_loss: -33.2241 (-33.2241)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0178 (0.3808)  div_loss: -37.5717 (-38.4552)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7666666507720947\n",
      "AUROC 1 : 0.7076271176338196\n",
      "AUROC 2 : 0.5846153497695923\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7129411697387695\n",
      "AUROC 5 : 0.6834415793418884\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.381 auroc 0.732 f1_score 0.397\n",
      "Epoch: [48]  [  0/161]  eta: 0:00:01  lr: 0.000053  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6568 (5.6568)  time: 0.0114  data: 0.0003  max mem: 891\n",
      "Epoch: [48]  [100/161]  eta: 0:00:00  lr: 0.000052  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8648 (6.7599)  time: 0.0129  data: 0.0015  max mem: 891\n",
      "Epoch: [48]  [160/161]  eta: 0:00:00  lr: 0.000052  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7841)  time: 0.0139  data: 0.0018  max mem: 891\n",
      "Epoch: [48] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0358 (0.0358)  div_loss: -54.6929 (-54.6929)  acc1: 85.7143 (85.7143)  time: 0.0100  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0665 (0.5913)  div_loss: -43.5569 (-43.7361)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.6917563080787659\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7942708134651184\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.591 auroc 0.727 f1_score 0.279\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1170 (0.1170)  div_loss: -32.7685 (-32.7685)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0190 (0.3799)  div_loss: -37.7508 (-38.5494)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7690476179122925\n",
      "AUROC 1 : 0.7033898830413818\n",
      "AUROC 2 : 0.5807692408561707\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7200000286102295\n",
      "AUROC 5 : 0.6834415197372437\n",
      "AUROC 6 : 0.6696969866752625\n",
      "* Acc@1 83.582 loss 0.380 auroc 0.731 f1_score 0.378\n",
      "Epoch: [49]  [  0/161]  eta: 0:00:01  lr: 0.000052  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6558 (5.6558)  time: 0.0115  data: 0.0003  max mem: 891\n",
      "Epoch: [49]  [100/161]  eta: 0:00:00  lr: 0.000051  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8649 (6.7599)  time: 0.0127  data: 0.0012  max mem: 891\n",
      "Epoch: [49]  [160/161]  eta: 0:00:00  lr: 0.000050  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7841)  time: 0.0141  data: 0.0019  max mem: 891\n",
      "Epoch: [49] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0344 (0.0344)  div_loss: -54.9557 (-54.9557)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0626 (0.5960)  div_loss: -43.6560 (-43.8239)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0021  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8088235259056091\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6846847534179688\n",
      "* Acc@1 83.571 loss 0.596 auroc 0.718 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0703 (0.0703)  div_loss: -33.3834 (-33.3834)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0156 (0.3953)  div_loss: -37.8382 (-38.6567)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7714285850524902\n",
      "AUROC 1 : 0.7076271176338196\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7164705991744995\n",
      "AUROC 5 : 0.6834415793418884\n",
      "AUROC 6 : 0.674242377281189\n",
      "* Acc@1 83.582 loss 0.395 auroc 0.733 f1_score 0.397\n",
      "Epoch: [50]  [  0/161]  eta: 0:00:01  lr: 0.000050  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6565 (5.6565)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [50]  [100/161]  eta: 0:00:00  lr: 0.000049  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8647 (6.7598)  time: 0.0129  data: 0.0014  max mem: 891\n",
      "Epoch: [50]  [160/161]  eta: 0:00:00  lr: 0.000048  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7841)  time: 0.0141  data: 0.0019  max mem: 891\n",
      "Epoch: [50] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0336 (0.0336)  div_loss: -54.9172 (-54.9172)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0036  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0629 (0.6033)  div_loss: -43.6425 (-43.9604)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.6953405141830444\n",
      "AUROC 3 : 0.8333333730697632\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6756756901741028\n",
      "* Acc@1 83.571 loss 0.603 auroc 0.728 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0955 (0.0955)  div_loss: -33.0071 (-33.0071)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0176 (0.3867)  div_loss: -37.9663 (-38.7809)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.7033898830413818\n",
      "AUROC 2 : 0.5846154093742371\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7211764454841614\n",
      "AUROC 5 : 0.6834415793418884\n",
      "AUROC 6 : 0.6727272868156433\n",
      "* Acc@1 83.582 loss 0.387 auroc 0.733 f1_score 0.378\n",
      "Epoch: [51]  [  0/161]  eta: 0:00:01  lr: 0.000048  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6542 (5.6542)  time: 0.0117  data: 0.0003  max mem: 891\n",
      "Epoch: [51]  [100/161]  eta: 0:00:00  lr: 0.000047  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8647 (6.7597)  time: 0.0131  data: 0.0013  max mem: 891\n",
      "Epoch: [51]  [160/161]  eta: 0:00:00  lr: 0.000047  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7840)  time: 0.0137  data: 0.0015  max mem: 891\n",
      "Epoch: [51] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0329 (0.0329)  div_loss: -55.0892 (-55.0892)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0608 (0.6114)  div_loss: -43.7612 (-44.0329)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.7025089859962463\n",
      "AUROC 3 : 0.813725471496582\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6846847534179688\n",
      "* Acc@1 83.571 loss 0.611 auroc 0.720 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0639 (0.0639)  div_loss: -33.4678 (-33.4678)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0149 (0.4019)  div_loss: -37.9313 (-38.8688)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.773809552192688\n",
      "AUROC 1 : 0.7097457647323608\n",
      "AUROC 2 : 0.5846154093742371\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7200000286102295\n",
      "AUROC 5 : 0.6834415793418884\n",
      "AUROC 6 : 0.6772726774215698\n",
      "* Acc@1 83.582 loss 0.402 auroc 0.735 f1_score 0.391\n",
      "Epoch: [52]  [  0/161]  eta: 0:00:01  lr: 0.000047  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6540 (5.6540)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [52]  [100/161]  eta: 0:00:00  lr: 0.000046  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8646 (6.7596)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [52]  [160/161]  eta: 0:00:00  lr: 0.000045  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7839)  time: 0.0142  data: 0.0018  max mem: 891\n",
      "Epoch: [52] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0317 (0.0317)  div_loss: -54.9837 (-54.9837)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0627 (0.6119)  div_loss: -43.8334 (-44.0947)  acc1: 85.7143 (83.5714)  time: 0.0104  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5542857646942139\n",
      "AUROC 2 : 0.6989247798919678\n",
      "AUROC 3 : 0.8235294222831726\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6578947305679321\n",
      "AUROC 6 : 0.6846847534179688\n",
      "* Acc@1 83.571 loss 0.612 auroc 0.731 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0937 (0.0937)  div_loss: -33.1830 (-33.1830)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0154 (0.3953)  div_loss: -38.1211 (-38.9158)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.5897436141967773\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7211765050888062\n",
      "AUROC 5 : 0.6818181872367859\n",
      "AUROC 6 : 0.6727272868156433\n",
      "* Acc@1 83.582 loss 0.395 auroc 0.734 f1_score 0.398\n",
      "Epoch: [53]  [  0/161]  eta: 0:00:01  lr: 0.000045  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6534 (5.6534)  time: 0.0092  data: 0.0003  max mem: 891\n",
      "Epoch: [53]  [100/161]  eta: 0:00:00  lr: 0.000044  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8647 (6.7596)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [53]  [160/161]  eta: 0:00:00  lr: 0.000044  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7839)  time: 0.0135  data: 0.0016  max mem: 891\n",
      "Epoch: [53] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0303 (0.0303)  div_loss: -55.1600 (-55.1600)  acc1: 85.7143 (85.7143)  time: 0.0099  data: 0.0030  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0636 (0.6208)  div_loss: -43.8743 (-44.1472)  acc1: 85.7143 (83.5714)  time: 0.0103  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0087 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.813725471496582\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.621 auroc 0.726 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0553 (0.0553)  div_loss: -33.5967 (-33.5967)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0140 (0.4116)  div_loss: -38.0601 (-38.9732)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.7118643522262573\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7235294580459595\n",
      "AUROC 5 : 0.6801948547363281\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.412 auroc 0.736 f1_score 0.391\n",
      "Epoch: [54]  [  0/161]  eta: 0:00:01  lr: 0.000044  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6536 (5.6536)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [54]  [100/161]  eta: 0:00:00  lr: 0.000043  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8645 (6.7596)  time: 0.0127  data: 0.0014  max mem: 891\n",
      "Epoch: [54]  [160/161]  eta: 0:00:00  lr: 0.000042  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7839)  time: 0.0136  data: 0.0018  max mem: 891\n",
      "Epoch: [54] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0316 (0.0316)  div_loss: -55.0554 (-55.0554)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0648 (0.6233)  div_loss: -43.8552 (-44.1975)  acc1: 85.7143 (83.5714)  time: 0.0113  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5542857646942139\n",
      "AUROC 2 : 0.6989247798919678\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6578947305679321\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.623 auroc 0.733 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0757 (0.0757)  div_loss: -33.2816 (-33.2816)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0145 (0.4042)  div_loss: -38.1476 (-39.0230)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.5884615182876587\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7247059345245361\n",
      "AUROC 5 : 0.6818182468414307\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.404 auroc 0.735 f1_score 0.392\n",
      "Epoch: [55]  [  0/161]  eta: 0:00:01  lr: 0.000042  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6529 (5.6529)  time: 0.0084  data: 0.0003  max mem: 891\n",
      "Epoch: [55]  [100/161]  eta: 0:00:00  lr: 0.000041  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8646 (6.7595)  time: 0.0127  data: 0.0013  max mem: 891\n",
      "Epoch: [55]  [160/161]  eta: 0:00:00  lr: 0.000041  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7838)  time: 0.0135  data: 0.0015  max mem: 891\n",
      "Epoch: [55] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0298 (0.0298)  div_loss: -55.2251 (-55.2251)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0027  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0612 (0.6349)  div_loss: -43.8772 (-44.2378)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.7025089859962463\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.635 auroc 0.727 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0564 (0.0564)  div_loss: -33.6518 (-33.6518)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0129 (0.4189)  div_loss: -38.0465 (-39.0630)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.7076271176338196\n",
      "AUROC 2 : 0.5923076868057251\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7247059345245361\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.419 auroc 0.736 f1_score 0.391\n",
      "Epoch: [56]  [  0/161]  eta: 0:00:01  lr: 0.000041  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6530 (5.6530)  time: 0.0115  data: 0.0003  max mem: 891\n",
      "Epoch: [56]  [100/161]  eta: 0:00:00  lr: 0.000040  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8645 (6.7595)  time: 0.0129  data: 0.0015  max mem: 891\n",
      "Epoch: [56]  [160/161]  eta: 0:00:00  lr: 0.000039  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7838)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [56] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0304 (0.0304)  div_loss: -55.1571 (-55.1571)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0642 (0.6340)  div_loss: -43.9588 (-44.3057)  acc1: 85.7143 (83.5714)  time: 0.0107  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7025089859962463\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.634 auroc 0.732 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0823 (0.0823)  div_loss: -33.3546 (-33.3546)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0136 (0.4113)  div_loss: -38.2285 (-39.1167)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.7076271176338196\n",
      "AUROC 2 : 0.5923076868057251\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.6801948547363281\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.411 auroc 0.736 f1_score 0.392\n",
      "Epoch: [57]  [  0/161]  eta: 0:00:01  lr: 0.000039  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6526 (5.6526)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [57]  [100/161]  eta: 0:00:00  lr: 0.000038  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8645 (6.7595)  time: 0.0128  data: 0.0015  max mem: 891\n",
      "Epoch: [57]  [160/161]  eta: 0:00:00  lr: 0.000038  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [57] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0291 (0.0291)  div_loss: -55.3118 (-55.3118)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0625 (0.6452)  div_loss: -43.9540 (-44.3435)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0021  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.645 auroc 0.728 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0514 (0.0514)  div_loss: -33.7197 (-33.7197)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0124 (0.4276)  div_loss: -38.1129 (-39.1638)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7761905193328857\n",
      "AUROC 1 : 0.7097457647323608\n",
      "AUROC 2 : 0.5935897827148438\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7258824110031128\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6757575869560242\n",
      "* Acc@1 83.582 loss 0.428 auroc 0.736 f1_score 0.391\n",
      "Epoch: [58]  [  0/161]  eta: 0:00:01  lr: 0.000038  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6528 (5.6528)  time: 0.0099  data: 0.0003  max mem: 891\n",
      "Epoch: [58]  [100/161]  eta: 0:00:00  lr: 0.000037  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8644 (6.7594)  time: 0.0117  data: 0.0012  max mem: 891\n",
      "Epoch: [58]  [160/161]  eta: 0:00:00  lr: 0.000036  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0132  data: 0.0018  max mem: 891\n",
      "Epoch: [58] Total time: 0:00:02 (0.0130 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0291 (0.0291)  div_loss: -55.2043 (-55.2043)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0648 (0.6428)  div_loss: -43.9693 (-44.4026)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5657142996788025\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.643 auroc 0.734 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0715 (0.0715)  div_loss: -33.4641 (-33.4641)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0126 (0.4177)  div_loss: -38.2468 (-39.2174)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.5935897827148438\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.418 auroc 0.736 f1_score 0.392\n",
      "Epoch: [59]  [  0/161]  eta: 0:00:01  lr: 0.000036  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6522 (5.6522)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [59]  [100/161]  eta: 0:00:00  lr: 0.000035  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8644 (6.7594)  time: 0.0140  data: 0.0015  max mem: 891\n",
      "Epoch: [59]  [160/161]  eta: 0:00:00  lr: 0.000035  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0139  data: 0.0019  max mem: 891\n",
      "Epoch: [59] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0278 (0.0278)  div_loss: -55.3766 (-55.3766)  acc1: 85.7143 (85.7143)  time: 0.0109  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0626 (0.6570)  div_loss: -43.9609 (-44.4329)  acc1: 85.7143 (83.5714)  time: 0.0106  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8235293626785278\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.657 auroc 0.729 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0499 (0.0499)  div_loss: -33.7809 (-33.7809)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0119 (0.4347)  div_loss: -38.1964 (-39.2435)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7761905193328857\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.5974358916282654\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7247059345245361\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6742424368858337\n",
      "* Acc@1 83.582 loss 0.435 auroc 0.735 f1_score 0.391\n",
      "Epoch: [60]  [  0/161]  eta: 0:00:01  lr: 0.000035  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6524 (5.6524)  time: 0.0112  data: 0.0002  max mem: 891\n",
      "Epoch: [60]  [100/161]  eta: 0:00:00  lr: 0.000034  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8644 (6.7594)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [60]  [160/161]  eta: 0:00:00  lr: 0.000033  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0130  data: 0.0017  max mem: 891\n",
      "Epoch: [60] Total time: 0:00:02 (0.0133 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0283 (0.0283)  div_loss: -55.2966 (-55.2966)  acc1: 85.7143 (85.7143)  time: 0.0100  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0669 (0.6534)  div_loss: -44.0201 (-44.4989)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5657142996788025\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.653 auroc 0.733 f1_score 0.277\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0658 (0.0658)  div_loss: -33.5646 (-33.5646)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0126 (0.4262)  div_loss: -38.3145 (-39.3052)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.7033898234367371\n",
      "AUROC 2 : 0.5935897827148438\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6818181872367859\n",
      "AUROC 6 : 0.6742424368858337\n",
      "* Acc@1 83.582 loss 0.426 auroc 0.736 f1_score 0.392\n",
      "Epoch: [61]  [  0/161]  eta: 0:00:01  lr: 0.000033  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6519 (5.6519)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [61]  [100/161]  eta: 0:00:00  lr: 0.000032  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8644 (6.7593)  time: 0.0119  data: 0.0013  max mem: 891\n",
      "Epoch: [61]  [160/161]  eta: 0:00:00  lr: 0.000032  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7836)  time: 0.0140  data: 0.0018  max mem: 891\n",
      "Epoch: [61] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0266 (0.0266)  div_loss: -55.4203 (-55.4203)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0635 (0.6670)  div_loss: -43.9900 (-44.5098)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0021  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8235293626785278\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.667 auroc 0.728 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0489 (0.0489)  div_loss: -33.8371 (-33.8371)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0125 (0.4417)  div_loss: -38.2265 (-39.3173)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.6000000238418579\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7223529815673828\n",
      "AUROC 5 : 0.6818181872367859\n",
      "AUROC 6 : 0.6742424368858337\n",
      "* Acc@1 83.582 loss 0.442 auroc 0.736 f1_score 0.391\n",
      "Epoch: [62]  [  0/161]  eta: 0:00:01  lr: 0.000032  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6520 (5.6520)  time: 0.0084  data: 0.0003  max mem: 891\n",
      "Epoch: [62]  [100/161]  eta: 0:00:00  lr: 0.000031  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0130  data: 0.0015  max mem: 891\n",
      "Epoch: [62]  [160/161]  eta: 0:00:00  lr: 0.000030  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7836)  time: 0.0142  data: 0.0018  max mem: 891\n",
      "Epoch: [62] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0273 (0.0273)  div_loss: -55.3410 (-55.3410)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0683 (0.6624)  div_loss: -44.0236 (-44.5666)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0095 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5657142996788025\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.662 auroc 0.734 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0597 (0.0597)  div_loss: -33.6390 (-33.6390)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0130 (0.4329)  div_loss: -38.3414 (-39.3705)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.7033898234367371\n",
      "AUROC 2 : 0.5961538553237915\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7258824110031128\n",
      "AUROC 5 : 0.6801947951316833\n",
      "AUROC 6 : 0.6712121367454529\n",
      "* Acc@1 83.582 loss 0.433 auroc 0.736 f1_score 0.392\n",
      "Epoch: [63]  [  0/161]  eta: 0:00:01  lr: 0.000030  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6516 (5.6516)  time: 0.0116  data: 0.0003  max mem: 891\n",
      "Epoch: [63]  [100/161]  eta: 0:00:00  lr: 0.000029  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0128  data: 0.0012  max mem: 891\n",
      "Epoch: [63]  [160/161]  eta: 0:00:00  lr: 0.000029  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0142  data: 0.0019  max mem: 891\n",
      "Epoch: [63] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0262 (0.0262)  div_loss: -55.4678 (-55.4678)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0651 (0.6774)  div_loss: -43.9926 (-44.5709)  acc1: 85.7143 (83.5714)  time: 0.0107  data: 0.0020  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5428571701049805\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7942708134651184\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.677 auroc 0.730 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0456 (0.0456)  div_loss: -33.8670 (-33.8670)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0131 (0.4490)  div_loss: -38.2694 (-39.3705)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.6012821197509766\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7223529815673828\n",
      "AUROC 5 : 0.6801948547363281\n",
      "AUROC 6 : 0.6757575869560242\n",
      "* Acc@1 83.582 loss 0.449 auroc 0.737 f1_score 0.391\n",
      "Epoch: [64]  [  0/161]  eta: 0:00:01  lr: 0.000029  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6518 (5.6518)  time: 0.0118  data: 0.0004  max mem: 891\n",
      "Epoch: [64]  [100/161]  eta: 0:00:00  lr: 0.000028  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0129  data: 0.0014  max mem: 891\n",
      "Epoch: [64]  [160/161]  eta: 0:00:00  lr: 0.000027  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0137  data: 0.0016  max mem: 891\n",
      "Epoch: [64] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0268 (0.0268)  div_loss: -55.4044 (-55.4044)  acc1: 85.7143 (85.7143)  time: 0.0095  data: 0.0025  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0707 (0.6710)  div_loss: -44.0506 (-44.6298)  acc1: 85.7143 (83.5714)  time: 0.0115  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8333333134651184\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.671 auroc 0.734 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0545 (0.0545)  div_loss: -33.7026 (-33.7026)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0136 (0.4400)  div_loss: -38.3780 (-39.4270)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.7033898234367371\n",
      "AUROC 2 : 0.6000000238418579\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7282352447509766\n",
      "AUROC 5 : 0.6785714030265808\n",
      "AUROC 6 : 0.6757575869560242\n",
      "* Acc@1 83.582 loss 0.440 auroc 0.737 f1_score 0.392\n",
      "Epoch: [65]  [  0/161]  eta: 0:00:01  lr: 0.000027  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6514 (5.6514)  time: 0.0086  data: 0.0003  max mem: 891\n",
      "Epoch: [65]  [100/161]  eta: 0:00:00  lr: 0.000026  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0128  data: 0.0015  max mem: 891\n",
      "Epoch: [65]  [160/161]  eta: 0:00:00  lr: 0.000026  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0134  data: 0.0017  max mem: 891\n",
      "Epoch: [65] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0256 (0.0256)  div_loss: -55.5057 (-55.5057)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0671 (0.6864)  div_loss: -44.0041 (-44.6303)  acc1: 85.7143 (83.5714)  time: 0.0115  data: 0.0021  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5428571701049805\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.686 auroc 0.730 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0448 (0.0448)  div_loss: -33.8912 (-33.8912)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0137 (0.4553)  div_loss: -38.3102 (-39.4239)  acc1: 85.7143 (83.5821)  time: 0.0052  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0058 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.7055084705352783\n",
      "AUROC 2 : 0.6025640964508057\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7223529815673828\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6742424368858337\n",
      "* Acc@1 83.582 loss 0.455 auroc 0.737 f1_score 0.391\n",
      "Epoch: [66]  [  0/161]  eta: 0:00:01  lr: 0.000026  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6515 (5.6515)  time: 0.0084  data: 0.0003  max mem: 891\n",
      "Epoch: [66]  [100/161]  eta: 0:00:00  lr: 0.000025  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7592)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [66]  [160/161]  eta: 0:00:00  lr: 0.000025  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0132  data: 0.0018  max mem: 891\n",
      "Epoch: [66] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0259 (0.0259)  div_loss: -55.4557 (-55.4557)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0728 (0.6797)  div_loss: -44.0586 (-44.6857)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.680 auroc 0.734 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0492 (0.0492)  div_loss: -33.7599 (-33.7599)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0142 (0.4470)  div_loss: -38.4028 (-39.4788)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.7033898234367371\n",
      "AUROC 2 : 0.598717987537384\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6801947951316833\n",
      "AUROC 6 : 0.6757575869560242\n",
      "* Acc@1 83.582 loss 0.447 auroc 0.737 f1_score 0.392\n",
      "Epoch: [67]  [  0/161]  eta: 0:00:01  lr: 0.000025  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6512 (5.6512)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [67]  [100/161]  eta: 0:00:00  lr: 0.000024  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7592)  time: 0.0120  data: 0.0014  max mem: 891\n",
      "Epoch: [67]  [160/161]  eta: 0:00:00  lr: 0.000023  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0135  data: 0.0018  max mem: 891\n",
      "Epoch: [67] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0248 (0.0248)  div_loss: -55.5453 (-55.5453)  acc1: 85.7143 (85.7143)  time: 0.0105  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0691 (0.6945)  div_loss: -44.0079 (-44.6813)  acc1: 85.7143 (83.5714)  time: 0.0104  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5485714077949524\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.695 auroc 0.731 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0428 (0.0428)  div_loss: -33.9131 (-33.9131)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0142 (0.4612)  div_loss: -38.3546 (-39.4688)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.7033898234367371\n",
      "AUROC 2 : 0.607692301273346\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7235294580459595\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.461 auroc 0.738 f1_score 0.391\n",
      "Epoch: [68]  [  0/161]  eta: 0:00:01  lr: 0.000023  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6512 (5.6512)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [68]  [100/161]  eta: 0:00:00  lr: 0.000022  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [68]  [160/161]  eta: 0:00:00  lr: 0.000022  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0135  data: 0.0018  max mem: 891\n",
      "Epoch: [68] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0256 (0.0256)  div_loss: -55.5113 (-55.5113)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0746 (0.6879)  div_loss: -44.0641 (-44.7337)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.688 auroc 0.734 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0460 (0.0460)  div_loss: -33.8037 (-33.8037)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0146 (0.4535)  div_loss: -38.4346 (-39.5192)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.7033898234367371\n",
      "AUROC 2 : 0.6025640964508057\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6801947951316833\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.454 auroc 0.738 f1_score 0.392\n",
      "Epoch: [69]  [  0/161]  eta: 0:00:01  lr: 0.000022  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6509 (5.6509)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [69]  [100/161]  eta: 0:00:00  lr: 0.000021  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [69]  [160/161]  eta: 0:00:00  lr: 0.000021  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0139  data: 0.0019  max mem: 891\n",
      "Epoch: [69] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0243 (0.0243)  div_loss: -55.5789 (-55.5789)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0715 (0.7022)  div_loss: -44.0141 (-44.7273)  acc1: 85.7143 (83.5714)  time: 0.0115  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0097 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5485714077949524\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.702 auroc 0.731 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0415 (0.0415)  div_loss: -33.9327 (-33.9327)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0148 (0.4669)  div_loss: -38.3950 (-39.5099)  acc1: 85.7143 (83.5821)  time: 0.0053  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0059 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.6076923608779907\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7247058749198914\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.467 auroc 0.738 f1_score 0.391\n",
      "Epoch: [70]  [  0/161]  eta: 0:00:01  lr: 0.000021  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6510 (5.6510)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [70]  [100/161]  eta: 0:00:00  lr: 0.000020  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [70]  [160/161]  eta: 0:00:00  lr: 0.000019  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0135  data: 0.0019  max mem: 891\n",
      "Epoch: [70] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0247 (0.0247)  div_loss: -55.5564 (-55.5564)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0763 (0.6959)  div_loss: -44.0683 (-44.7743)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.7942707538604736\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.696 auroc 0.734 f1_score 0.283\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0426 (0.0426)  div_loss: -33.8501 (-33.8501)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0152 (0.4596)  div_loss: -38.4575 (-39.5552)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.6064102649688721\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6785714030265808\n",
      "AUROC 6 : 0.6742424368858337\n",
      "* Acc@1 83.582 loss 0.460 auroc 0.739 f1_score 0.392\n",
      "Epoch: [71]  [  0/161]  eta: 0:00:01  lr: 0.000019  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6508 (5.6508)  time: 0.0116  data: 0.0003  max mem: 891\n",
      "Epoch: [71]  [100/161]  eta: 0:00:00  lr: 0.000019  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0121  data: 0.0012  max mem: 891\n",
      "Epoch: [71]  [160/161]  eta: 0:00:00  lr: 0.000018  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0132  data: 0.0015  max mem: 891\n",
      "Epoch: [71] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0238 (0.0238)  div_loss: -55.6093 (-55.6093)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0739 (0.7094)  div_loss: -44.0166 (-44.7649)  acc1: 85.7143 (83.5714)  time: 0.0107  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5485714077949524\n",
      "AUROC 2 : 0.7060931921005249\n",
      "AUROC 3 : 0.8333333134651184\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.709 auroc 0.732 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0400 (0.0400)  div_loss: -33.9451 (-33.9451)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0153 (0.4720)  div_loss: -38.4283 (-39.5432)  acc1: 85.7143 (83.5821)  time: 0.0054  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0056 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.6089743971824646\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7235293984413147\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6803029775619507\n",
      "* Acc@1 83.582 loss 0.472 auroc 0.739 f1_score 0.391\n",
      "Epoch: [72]  [  0/161]  eta: 0:00:01  lr: 0.000018  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6507 (5.6507)  time: 0.0095  data: 0.0003  max mem: 891\n",
      "Epoch: [72]  [100/161]  eta: 0:00:00  lr: 0.000017  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0120  data: 0.0014  max mem: 891\n",
      "Epoch: [72]  [160/161]  eta: 0:00:00  lr: 0.000017  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [72] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0242 (0.0242)  div_loss: -55.5993 (-55.5993)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0779 (0.7037)  div_loss: -44.0644 (-44.8084)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.704 auroc 0.735 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0403 (0.0403)  div_loss: -33.8866 (-33.8866)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0150 (0.4657)  div_loss: -38.4841 (-39.5845)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7904761433601379\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.6089743375778198\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6757575869560242\n",
      "* Acc@1 83.582 loss 0.466 auroc 0.739 f1_score 0.392\n",
      "Epoch: [73]  [  0/161]  eta: 0:00:01  lr: 0.000017  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6506 (5.6506)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [73]  [100/161]  eta: 0:00:00  lr: 0.000016  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [73]  [160/161]  eta: 0:00:00  lr: 0.000016  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0139  data: 0.0019  max mem: 891\n",
      "Epoch: [73] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0235 (0.0235)  div_loss: -55.6430 (-55.6430)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0763 (0.7157)  div_loss: -44.0187 (-44.7983)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5485714077949524\n",
      "AUROC 2 : 0.7096774578094482\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.716 auroc 0.733 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0383 (0.0383)  div_loss: -33.9573 (-33.9573)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0158 (0.4766)  div_loss: -38.4650 (-39.5730)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7904761433601379\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.6115384697914124\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7247058749198914\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6803029775619507\n",
      "* Acc@1 83.582 loss 0.477 auroc 0.740 f1_score 0.391\n",
      "Epoch: [74]  [  0/161]  eta: 0:00:01  lr: 0.000016  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6506 (5.6506)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [74]  [100/161]  eta: 0:00:00  lr: 0.000015  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0122  data: 0.0015  max mem: 891\n",
      "Epoch: [74]  [160/161]  eta: 0:00:00  lr: 0.000015  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0134  data: 0.0019  max mem: 891\n",
      "Epoch: [74] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0237 (0.0237)  div_loss: -55.6423 (-55.6423)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0796 (0.7108)  div_loss: -44.0603 (-44.8375)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5542857050895691\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.7942708134651184\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.711 auroc 0.734 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0380 (0.0380)  div_loss: -33.9180 (-33.9180)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0140 (0.4714)  div_loss: -38.5106 (-39.6098)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7904761433601379\n",
      "AUROC 1 : 0.7012711763381958\n",
      "AUROC 2 : 0.6102564334869385\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6757575869560242\n",
      "* Acc@1 83.582 loss 0.471 auroc 0.739 f1_score 0.392\n",
      "Epoch: [75]  [  0/161]  eta: 0:00:01  lr: 0.000015  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6505 (5.6505)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [75]  [100/161]  eta: 0:00:00  lr: 0.000014  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [75]  [160/161]  eta: 0:00:00  lr: 0.000014  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0137  data: 0.0018  max mem: 891\n",
      "Epoch: [75] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0233 (0.0233)  div_loss: -55.6771 (-55.6771)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0784 (0.7212)  div_loss: -44.0197 (-44.8298)  acc1: 85.7143 (83.5714)  time: 0.0101  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5542857050895691\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.721 auroc 0.735 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0365 (0.0365)  div_loss: -33.9663 (-33.9663)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0162 (0.4805)  div_loss: -38.4954 (-39.6010)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7904761433601379\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.6115384697914124\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7247058749198914\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6787878274917603\n",
      "* Acc@1 83.582 loss 0.480 auroc 0.740 f1_score 0.392\n",
      "Epoch: [76]  [  0/161]  eta: 0:00:01  lr: 0.000014  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6504 (5.6504)  time: 0.0084  data: 0.0003  max mem: 891\n",
      "Epoch: [76]  [100/161]  eta: 0:00:00  lr: 0.000013  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0125  data: 0.0014  max mem: 891\n",
      "Epoch: [76]  [160/161]  eta: 0:00:00  lr: 0.000013  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0148  data: 0.0018  max mem: 891\n",
      "Epoch: [76] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0234 (0.0234)  div_loss: -55.6825 (-55.6825)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0812 (0.7180)  div_loss: -44.0522 (-44.8612)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5542857050895691\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.80078125\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.718 auroc 0.735 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0360 (0.0360)  div_loss: -33.9428 (-33.9428)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0136 (0.4773)  div_loss: -38.5365 (-39.6300)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7904761433601379\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.6128205060958862\n",
      "AUROC 3 : 0.9928570985794067\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.477 auroc 0.740 f1_score 0.392\n",
      "Epoch: [77]  [  0/161]  eta: 0:00:01  lr: 0.000012  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6504 (5.6504)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [77]  [100/161]  eta: 0:00:00  lr: 0.000012  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [77]  [160/161]  eta: 0:00:00  lr: 0.000011  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0131  data: 0.0018  max mem: 891\n",
      "Epoch: [77] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0230 (0.0230)  div_loss: -55.7084 (-55.7084)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0805 (0.7260)  div_loss: -44.0271 (-44.8581)  acc1: 85.7143 (83.5714)  time: 0.0104  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.726 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0351 (0.0351)  div_loss: -33.9762 (-33.9762)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0149 (0.4842)  div_loss: -38.5279 (-39.6256)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.6153846383094788\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6787878274917603\n",
      "* Acc@1 83.582 loss 0.484 auroc 0.741 f1_score 0.392\n",
      "Epoch: [78]  [  0/161]  eta: 0:00:01  lr: 0.000011  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6503 (5.6503)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [78]  [100/161]  eta: 0:00:00  lr: 0.000011  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0121  data: 0.0014  max mem: 891\n",
      "Epoch: [78]  [160/161]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0132  data: 0.0017  max mem: 891\n",
      "Epoch: [78] Total time: 0:00:02 (0.0130 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0230 (0.0230)  div_loss: -55.7174 (-55.7174)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0827 (0.7242)  div_loss: -44.0475 (-44.8824)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.724 auroc 0.736 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0344 (0.0344)  div_loss: -33.9622 (-33.9622)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0130 (0.4824)  div_loss: -38.5648 (-39.6482)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.6192307472229004\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.482 auroc 0.742 f1_score 0.392\n",
      "Epoch: [79]  [  0/161]  eta: 0:00:01  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6503 (5.6503)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [79]  [100/161]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0130  data: 0.0015  max mem: 891\n",
      "Epoch: [79]  [160/161]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0136  data: 0.0018  max mem: 891\n",
      "Epoch: [79] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0228 (0.0228)  div_loss: -55.7407 (-55.7407)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0825 (0.7304)  div_loss: -44.0305 (-44.8829)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0091 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.730 auroc 0.736 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0337 (0.0337)  div_loss: -33.9861 (-33.9861)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0138 (0.4876)  div_loss: -38.5608 (-39.6472)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.6192307472229004\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6787878274917603\n",
      "* Acc@1 83.582 loss 0.488 auroc 0.742 f1_score 0.390\n",
      "Epoch: [80]  [  0/161]  eta: 0:00:01  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6503 (5.6503)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [80]  [100/161]  eta: 0:00:00  lr: 0.000009  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0120  data: 0.0013  max mem: 891\n",
      "Epoch: [80]  [160/161]  eta: 0:00:00  lr: 0.000009  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [80] Total time: 0:00:02 (0.0130 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0228 (0.0228)  div_loss: -55.7502 (-55.7502)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0841 (0.7299)  div_loss: -44.0425 (-44.8998)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.730 auroc 0.736 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0331 (0.0331)  div_loss: -33.9761 (-33.9761)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0127 (0.4872)  div_loss: -38.5892 (-39.6627)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6991525888442993\n",
      "AUROC 2 : 0.620512843132019\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6785714626312256\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.487 auroc 0.742 f1_score 0.390\n",
      "Epoch: [81]  [  0/161]  eta: 0:00:01  lr: 0.000009  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0108  data: 0.0003  max mem: 891\n",
      "Epoch: [81]  [100/161]  eta: 0:00:00  lr: 0.000008  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0126  data: 0.0015  max mem: 891\n",
      "Epoch: [81]  [160/161]  eta: 0:00:00  lr: 0.000008  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0134  data: 0.0018  max mem: 891\n",
      "Epoch: [81] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0227 (0.0227)  div_loss: -55.7701 (-55.7701)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0037  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0843 (0.7341)  div_loss: -44.0346 (-44.9037)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.734 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0326 (0.0326)  div_loss: -33.9904 (-33.9904)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0130 (0.4907)  div_loss: -38.5924 (-39.6650)  acc1: 85.7143 (83.5821)  time: 0.0052  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0058 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.620512843132019\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6787878274917603\n",
      "* Acc@1 83.582 loss 0.491 auroc 0.741 f1_score 0.390\n",
      "Epoch: [82]  [  0/161]  eta: 0:00:01  lr: 0.000008  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [82]  [100/161]  eta: 0:00:00  lr: 0.000007  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7591)  time: 0.0125  data: 0.0013  max mem: 891\n",
      "Epoch: [82]  [160/161]  eta: 0:00:00  lr: 0.000007  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0136  data: 0.0015  max mem: 891\n",
      "Epoch: [82] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0226 (0.0226)  div_loss: -55.7809 (-55.7809)  acc1: 85.7143 (85.7143)  time: 0.0095  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0855 (0.7347)  div_loss: -44.0398 (-44.9155)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.735 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0320 (0.0320)  div_loss: -33.9872 (-33.9872)  acc1: 85.7143 (85.7143)  time: 0.0040  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0124 (0.4913)  div_loss: -38.6136 (-39.6759)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.620512843132019\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6787878274917603\n",
      "* Acc@1 83.582 loss 0.491 auroc 0.741 f1_score 0.390\n",
      "Epoch: [83]  [  0/161]  eta: 0:00:01  lr: 0.000007  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0108  data: 0.0003  max mem: 891\n",
      "Epoch: [83]  [100/161]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0127  data: 0.0015  max mem: 891\n",
      "Epoch: [83]  [160/161]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0139  data: 0.0019  max mem: 891\n",
      "Epoch: [83] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.7971 (-55.7971)  acc1: 85.7143 (85.7143)  time: 0.0095  data: 0.0026  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0859 (0.7374)  div_loss: -44.0374 (-44.9214)  acc1: 85.7143 (83.5714)  time: 0.0105  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.737 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0315 (0.0315)  div_loss: -33.9964 (-33.9964)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0124 (0.4936)  div_loss: -38.6206 (-39.6804)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6787878274917603\n",
      "* Acc@1 83.582 loss 0.494 auroc 0.741 f1_score 0.390\n",
      "Epoch: [84]  [  0/161]  eta: 0:00:01  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [84]  [100/161]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0126  data: 0.0015  max mem: 891\n",
      "Epoch: [84]  [160/161]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0139  data: 0.0016  max mem: 891\n",
      "Epoch: [84] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8084 (-55.8084)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0870 (0.7385)  div_loss: -44.0389 (-44.9290)  acc1: 85.7143 (83.5714)  time: 0.0104  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7132616639137268\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.738 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0311 (0.0311)  div_loss: -33.9959 (-33.9959)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0121 (0.4947)  div_loss: -38.6350 (-39.6870)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6803029775619507\n",
      "* Acc@1 83.582 loss 0.495 auroc 0.741 f1_score 0.390\n",
      "Epoch: [85]  [  0/161]  eta: 0:00:01  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0114  data: 0.0003  max mem: 891\n",
      "Epoch: [85]  [100/161]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0120  data: 0.0013  max mem: 891\n",
      "Epoch: [85]  [160/161]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0142  data: 0.0019  max mem: 891\n",
      "Epoch: [85] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8213 (-55.8213)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0874 (0.7403)  div_loss: -44.0384 (-44.9352)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.740 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0307 (0.0307)  div_loss: -34.0008 (-34.0008)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0119 (0.4962)  div_loss: -38.6447 (-39.6923)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6803029775619507\n",
      "* Acc@1 83.582 loss 0.496 auroc 0.741 f1_score 0.390\n",
      "Epoch: [86]  [  0/161]  eta: 0:00:01  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0101  data: 0.0004  max mem: 891\n",
      "Epoch: [86]  [100/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0121  data: 0.0014  max mem: 891\n",
      "Epoch: [86]  [160/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0130  data: 0.0017  max mem: 891\n",
      "Epoch: [86] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8317 (-55.8317)  acc1: 85.7143 (85.7143)  time: 0.0089  data: 0.0025  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0881 (0.7414)  div_loss: -44.0391 (-44.9410)  acc1: 85.7143 (83.5714)  time: 0.0102  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0085 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0303 (0.0303)  div_loss: -34.0016 (-34.0016)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0118 (0.4973)  div_loss: -38.6547 (-39.6972)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0052 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.497 auroc 0.741 f1_score 0.390\n",
      "Epoch: [87]  [  0/161]  eta: 0:00:01  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0107  data: 0.0003  max mem: 891\n",
      "Epoch: [87]  [100/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0126  data: 0.0014  max mem: 891\n",
      "Epoch: [87]  [160/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0144  data: 0.0018  max mem: 891\n",
      "Epoch: [87] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8414 (-55.8414)  acc1: 85.7143 (85.7143)  time: 0.0105  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0886 (0.7427)  div_loss: -44.0397 (-44.9465)  acc1: 85.7143 (83.5714)  time: 0.0112  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0095 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.743 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0300 (0.0300)  div_loss: -34.0042 (-34.0042)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0117 (0.4984)  div_loss: -38.6642 (-39.7020)  acc1: 85.7143 (83.5821)  time: 0.0052  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0058 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.498 auroc 0.741 f1_score 0.390\n",
      "Epoch: [88]  [  0/161]  eta: 0:00:01  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0114  data: 0.0003  max mem: 891\n",
      "Epoch: [88]  [100/161]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0128  data: 0.0014  max mem: 891\n",
      "Epoch: [88]  [160/161]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0136  data: 0.0015  max mem: 891\n",
      "Epoch: [88] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8503 (-55.8503)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0027  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0892 (0.7436)  div_loss: -44.0399 (-44.9509)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0022  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.744 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0297 (0.0297)  div_loss: -34.0054 (-34.0054)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0115 (0.4994)  div_loss: -38.6721 (-39.7056)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.499 auroc 0.740 f1_score 0.390\n",
      "Epoch: [89]  [  0/161]  eta: 0:00:02  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0129  data: 0.0005  max mem: 891\n",
      "Epoch: [89]  [100/161]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [89]  [160/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0134  data: 0.0018  max mem: 891\n",
      "Epoch: [89] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8580 (-55.8580)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0897 (0.7445)  div_loss: -44.0401 (-44.9548)  acc1: 85.7143 (83.5714)  time: 0.0113  data: 0.0022  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.745 auroc 0.737 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0294 (0.0294)  div_loss: -34.0067 (-34.0067)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0115 (0.5002)  div_loss: -38.6791 (-39.7091)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.500 auroc 0.740 f1_score 0.390\n",
      "Epoch: [90]  [  0/161]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0081  data: 0.0004  max mem: 891\n",
      "Epoch: [90]  [100/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0122  data: 0.0015  max mem: 891\n",
      "Epoch: [90]  [160/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0135  data: 0.0015  max mem: 891\n",
      "Epoch: [90] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8647 (-55.8647)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0901 (0.7453)  div_loss: -44.0406 (-44.9582)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.745 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0292 (0.0292)  div_loss: -34.0078 (-34.0078)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0114 (0.5010)  div_loss: -38.6849 (-39.7121)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.501 auroc 0.740 f1_score 0.390\n",
      "Epoch: [91]  [  0/161]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0089  data: 0.0003  max mem: 891\n",
      "Epoch: [91]  [100/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0129  data: 0.0016  max mem: 891\n",
      "Epoch: [91]  [160/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0143  data: 0.0019  max mem: 891\n",
      "Epoch: [91] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0224 (0.0224)  div_loss: -55.8704 (-55.8704)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0905 (0.7459)  div_loss: -44.0406 (-44.9611)  acc1: 85.7143 (83.5714)  time: 0.0110  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0093 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.746 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0290 (0.0290)  div_loss: -34.0089 (-34.0089)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0113 (0.5016)  div_loss: -38.6898 (-39.7145)  acc1: 85.7143 (83.5821)  time: 0.0049  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0055 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.502 auroc 0.741 f1_score 0.390\n",
      "Epoch: [92]  [  0/161]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0089  data: 0.0003  max mem: 891\n",
      "Epoch: [92]  [100/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0120  data: 0.0013  max mem: 891\n",
      "Epoch: [92]  [160/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0132  data: 0.0018  max mem: 891\n",
      "Epoch: [92] Total time: 0:00:02 (0.0133 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8750 (-55.8750)  acc1: 85.7143 (85.7143)  time: 0.0100  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0908 (0.7464)  div_loss: -44.0408 (-44.9633)  acc1: 85.7143 (83.5714)  time: 0.0103  data: 0.0018  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.746 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0288 (0.0288)  div_loss: -34.0091 (-34.0091)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0113 (0.5021)  div_loss: -38.6937 (-39.7165)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.502 auroc 0.741 f1_score 0.390\n",
      "Epoch: [93]  [  0/161]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0081  data: 0.0003  max mem: 891\n",
      "Epoch: [93]  [100/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0121  data: 0.0015  max mem: 891\n",
      "Epoch: [93]  [160/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0144  data: 0.0019  max mem: 891\n",
      "Epoch: [93] Total time: 0:00:02 (0.0135 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8786 (-55.8786)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0911 (0.7468)  div_loss: -44.0410 (-44.9652)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.747 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0287 (0.0287)  div_loss: -34.0097 (-34.0097)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5025)  div_loss: -38.6969 (-39.7182)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.502 auroc 0.741 f1_score 0.390\n",
      "Epoch: [94]  [  0/161]  eta: 0:00:02  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0130  data: 0.0004  max mem: 891\n",
      "Epoch: [94]  [100/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [94]  [160/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0152  data: 0.0019  max mem: 891\n",
      "Epoch: [94] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8813 (-55.8813)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0913 (0.7471)  div_loss: -44.0411 (-44.9665)  acc1: 85.7143 (83.5714)  time: 0.0111  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0094 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.747 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0286 (0.0286)  div_loss: -34.0100 (-34.0100)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5028)  div_loss: -38.6991 (-39.7195)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.741 f1_score 0.390\n",
      "Epoch: [95]  [  0/161]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0115  data: 0.0003  max mem: 891\n",
      "Epoch: [95]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0123  data: 0.0015  max mem: 891\n",
      "Epoch: [95]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0130  data: 0.0015  max mem: 891\n",
      "Epoch: [95] Total time: 0:00:02 (0.0134 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8831 (-55.8831)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0027  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0914 (0.7473)  div_loss: -44.0411 (-44.9675)  acc1: 85.7143 (83.5714)  time: 0.0108  data: 0.0021  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.747 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0285 (0.0285)  div_loss: -34.0100 (-34.0100)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5030)  div_loss: -38.7006 (-39.7203)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.741 f1_score 0.390\n",
      "Epoch: [96]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0098  data: 0.0003  max mem: 891\n",
      "Epoch: [96]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0125  data: 0.0015  max mem: 891\n",
      "Epoch: [96]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0141  data: 0.0019  max mem: 891\n",
      "Epoch: [96] Total time: 0:00:02 (0.0136 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8843 (-55.8843)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0915 (0.7474)  div_loss: -44.0411 (-44.9681)  acc1: 85.7143 (83.5714)  time: 0.0114  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0097 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.747 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0284 (0.0284)  div_loss: -34.0102 (-34.0102)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5032)  div_loss: -38.7015 (-39.7209)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.741 f1_score 0.390\n",
      "Epoch: [97]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [97]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0123  data: 0.0014  max mem: 891\n",
      "Epoch: [97]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0136  data: 0.0018  max mem: 891\n",
      "Epoch: [97] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8849 (-55.8849)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0916 (0.7475)  div_loss: -44.0410 (-44.9684)  acc1: 85.7143 (83.5714)  time: 0.0102  data: 0.0020  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0090 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.748 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0284 (0.0284)  div_loss: -34.0102 (-34.0102)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5032)  div_loss: -38.7019 (-39.7212)  acc1: 85.7143 (83.5821)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0051 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.741 f1_score 0.390\n",
      "Epoch: [98]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0077  data: 0.0003  max mem: 891\n",
      "Epoch: [98]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0120  data: 0.0014  max mem: 891\n",
      "Epoch: [98]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0133  data: 0.0018  max mem: 891\n",
      "Epoch: [98] Total time: 0:00:02 (0.0131 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8851 (-55.8851)  acc1: 85.7143 (85.7143)  time: 0.0101  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0916 (0.7475)  div_loss: -44.0409 (-44.9685)  acc1: 85.7143 (83.5714)  time: 0.0102  data: 0.0019  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0088 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.748 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0284 (0.0284)  div_loss: -34.0102 (-34.0102)  acc1: 85.7143 (85.7143)  time: 0.0037  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5033)  div_loss: -38.7020 (-39.7214)  acc1: 85.7143 (83.5821)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0054 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.741 f1_score 0.390\n",
      "Epoch: [99]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0118  data: 0.0004  max mem: 891\n",
      "Epoch: [99]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0118  data: 0.0014  max mem: 891\n",
      "Epoch: [99]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0133  data: 0.0019  max mem: 891\n",
      "Epoch: [99] Total time: 0:00:02 (0.0132 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0225 (0.0225)  div_loss: -55.8851 (-55.8851)  acc1: 85.7143 (85.7143)  time: 0.0103  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0916 (0.7476)  div_loss: -44.0408 (-44.9685)  acc1: 85.7143 (83.5714)  time: 0.0109  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0092 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.7168458700180054\n",
      "AUROC 3 : 0.8382352590560913\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6936937570571899\n",
      "* Acc@1 83.571 loss 0.748 auroc 0.738 f1_score 0.341\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0284 (0.0284)  div_loss: -34.0102 (-34.0102)  acc1: 85.7143 (85.7143)  time: 0.0038  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0112 (0.5033)  div_loss: -38.7020 (-39.7214)  acc1: 85.7143 (83.5821)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0053 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.6217948794364929\n",
      "AUROC 3 : 0.9952380657196045\n",
      "AUROC 4 : 0.725882351398468\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6772727370262146\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.741 f1_score 0.390\n",
      "Results on best epoch:\n",
      "{'epoch': -1, 'val_acc': 0, 'val_auc': 0, 'val_f1': 0, 'test_acc': 0, 'test_auc': 0, 'test_f1': 0}\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "train_epoch = conf.train_epoch\n",
    "for epoch in range(train_epoch):\n",
    "    # train_one_epoch_multitask(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "    # val_auc, val_acc, val_f1, val_loss = evaluate_multitask(model, criterion, val_loader, device, conf, 'Val')\n",
    "    # test_auc, test_acc, test_f1, test_loss = evaluate_multitask(model, criterion, test_loader, device, conf, 'Test')\n",
    "    train_one_epoch_multitask_V2(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "    val_auc, val_acc, val_f1, val_loss = evaluate_multitask_V2(model, criterion, val_loader, device, conf, 'Val')\n",
    "    test_auc, test_acc, test_f1, test_loss = evaluate_multitask_V2(model, criterion, test_loader, device, conf, 'Test')\n",
    "\n",
    "    save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "        save_path=os.path.join(ckpt_dir + 'checkpoint_' + 'epoch' + str(epoch) + '.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07377042-2f38-4f48-9c86-b37329f2e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               AUC  Recall  Specificity   ACC  Precision    PR_AUC    F1  \\\n",
      "SAMPLE_LEVEL  0.79    0.43         0.93  0.88       0.43  0.394683  0.43   \n",
      "SAMPLE_LEVEL  0.70    0.38         0.98  0.91       0.75  0.594513  0.50   \n",
      "SAMPLE_LEVEL  0.62    0.13         0.90  0.73       0.29  0.310475  0.18   \n",
      "SAMPLE_LEVEL  1.00    0.86         0.98  0.97       0.86  0.968254  0.86   \n",
      "SAMPLE_LEVEL  0.73    0.41         0.86  0.75       0.50  0.526308  0.45   \n",
      "SAMPLE_LEVEL  0.68    0.09         1.00  0.85       1.00  0.411357  0.17   \n",
      "SAMPLE_LEVEL  0.68    0.08         0.98  0.82       0.50  0.349305  0.14   \n",
      "\n",
      "                F2    F3                  OUTCOME  \n",
      "SAMPLE_LEVEL  0.43  0.43                       AR  \n",
      "SAMPLE_LEVEL  0.42  0.39                       HR  \n",
      "SAMPLE_LEVEL  0.15  0.14                     PTEN  \n",
      "SAMPLE_LEVEL  0.86  0.86                      RB1  \n",
      "SAMPLE_LEVEL  0.43  0.42                     TP53  \n",
      "SAMPLE_LEVEL  0.11  0.10  TMB_HIGHorINTERMEDITATE  \n",
      "SAMPLE_LEVEL  0.10  0.09                  MSI_POS  \n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "# ###################################################\n",
    "# #           Test \n",
    "# ###################################################\n",
    "# # define network\n",
    "# if arch == 'ga':\n",
    "#     model2 = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "# elif arch == 'ga_mt':\n",
    "#     model2 = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "# else:\n",
    "#     model2 = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "# model2.to(device)\n",
    "\n",
    "# # Load the checkpoint\n",
    "# #checkpoint = torch.load(ckpt_dir + 'checkpoint-best.pth')\n",
    "# checkpoint = torch.load(ckpt_dir + 'checkpoint_epoch99.pth')\n",
    "\n",
    "# # Load the state_dict into the model\n",
    "# model2.load_state_dict(checkpoint['model'])\n",
    "\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict_v2(model, test_loader, device, conf, 'Test')\n",
    "y_pred_tasks_val,  y_predprob_task_val, y_true_task_val = predict_v2(model, val_loader, device, conf, 'Test')\n",
    "\n",
    "\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    #Calibration\n",
    "    #prob_calibrated = calibrate_probs_isotonic(y_true_task_val[i], y_predprob_task_val[i], y_predprob_task_test[i])\n",
    "    pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], test_ids, ALL_LABEL[i], THRES = 0.5)\n",
    "    pred_df_list.append(pred_df)\n",
    "    perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923122c6-b454-4f26-8d54-f0d832ecc0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#bootstrap perforance\n",
    "ci_list = []\n",
    "for i in range(conf.n_task):\n",
    "    print(i)\n",
    "    cur_pred_df = all_perd_df.loc[all_perd_df['OUTCOME'] == ALL_LABEL[i]]\n",
    "    cur_ci_df = bootstrap_ci_from_df(cur_pred_df, roc_auc_score, y_true_col='Y_True', y_pred_col='Pred_Class', y_prob_col='Pred_Prob', num_bootstrap=1000, ci=95, seed=42)\n",
    "    cur_ci_df['OUTCOME'] = ALL_LABEL[i]\n",
    "    ci_list.append(cur_ci_df)\n",
    "ci_final_df = pd.concat(ci_list)\n",
    "ci_final_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf_bootstrap.csv\",index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a236391-ba85-46bb-80c8-62fa3773f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_IDs</th>\n",
       "      <th>Y_True</th>\n",
       "      <th>Pred_Prob</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>Pred_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPX_002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225377</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPX_007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265897</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPX_015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237645</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPX_019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174435</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPX_020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238731</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>OPX_319</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247376</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>OPX_325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357763</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>OPX_337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363420</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>OPX_345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176374</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>OPX_351</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176895</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_IDs  Y_True  Pred_Prob  OUTCOME  Pred_Class\n",
       "0     OPX_002       0   0.225377  MSI_POS           0\n",
       "1     OPX_007       1   0.265897  MSI_POS           0\n",
       "2     OPX_015       0   0.237645  MSI_POS           0\n",
       "3     OPX_019       0   0.174435  MSI_POS           0\n",
       "4     OPX_020       0   0.238731  MSI_POS           0\n",
       "..        ...     ...        ...      ...         ...\n",
       "62    OPX_319       0   0.247376  MSI_POS           0\n",
       "63    OPX_325       0   0.357763  MSI_POS           0\n",
       "64    OPX_337       0   0.363420  MSI_POS           0\n",
       "65    OPX_345       0   0.176374  MSI_POS           0\n",
       "66    OPX_351       0   0.176895  MSI_POS           0\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_msi = all_perd_df.loc[all_perd_df['OUTCOME'] == 'MSI_POS']\n",
    "pred_msi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e81a3892-8dbe-4981-aad5-0984cfc2fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate Pred_Prob values based on Y_True values\n",
    "pred_prob_0 = pred_msi[pred_msi[\"Y_True\"] == 0][\"Pred_Prob\"]\n",
    "pred_prob_1 = pred_msi[pred_msi[\"Y_True\"] == 1][\"Pred_Prob\"]\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([pred_prob_0, pred_prob_1], labels=[\"Y_True = 0\", \"Y_True = 1\"])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Y_True\")\n",
    "plt.ylabel(\"Predicted Probability (Pred_Prob)\")\n",
    "plt.title(\"Boxplot of Pred_Prob for Y_True = 0 and 1\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359e5db7-8c0e-43c3-af13-3c3e5285c74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(list(pred_msi['Pred_Prob']),list(pred_msi['Y_True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8621554-50ec-4655-a49c-3c280e3cdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT:\n",
    "pred_df = all_perd_df\n",
    "SELECTED_LABEL = ['MSI_POS']\n",
    "#Get True Postives\n",
    "true_postive_ids = {}\n",
    "for label in SELECTED_LABEL:\n",
    "    cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 1) & (pred_df['OUTCOME'] == label)\n",
    "    cur_pred_df = pred_df.loc[cond]\n",
    "    cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "    true_postive_ids[label] = cur_ids\n",
    "\n",
    "#Get true nagative\n",
    "true_negative_ids = {}\n",
    "for label in SELECTED_LABEL:\n",
    "    cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 0) & (pred_df['OUTCOME'] == label)\n",
    "    cur_pred_df = pred_df.loc[cond]\n",
    "    cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "    true_negative_ids[label] = cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326fde41-231c-4a9d-ba4e-b3dbd8d119ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Atention scores\n",
    "####################################################################################\n",
    "save_image_size = 250\n",
    "pixel_overlap = 0\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "mag_target_prob = 2.5\n",
    "smooth = True\n",
    "mag_target_tiss = 1.25\n",
    "\n",
    "def get_attention_and_tileinfo(pt_label_df, patient_att_score):    \n",
    "    #Get label\n",
    "    pt_label_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Get attention\n",
    "    cur_att  = pd.DataFrame({'ATT':list(minmax_normalize(patient_att_score))})\n",
    "    cur_att.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Comb\n",
    "    cur_att_df = pd.concat([pt_label_df,cur_att], axis = 1)\n",
    "    cur_att_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return cur_att_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d14342-5cd3-461c-9e30-fd6499892438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test data\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')\n",
    "opx_ids_ol0 = [x[-2] for x in opx_data_ol0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684e7e43-8f39-4748-9855-8c1434037b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPX_075\n",
      "OPX_075\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/MSI_POS/OPX_075/' created.\n",
      "post-processing\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/MSI_POS/OPX_075/top_tiles/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/MSI_POS/OPX_075/bot_tiles/' created.\n"
     ]
    }
   ],
   "source": [
    "selected_ids = true_postive_ids[SELECTED_LABEL[0]]\n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "#branches = 2\n",
    "\n",
    "for pt in selected_ids:\n",
    "    i =  opx_ids_ol0.index(pt)\n",
    "    print(pt)\n",
    "    print(opx_ids_ol0[i])\n",
    "\n",
    "    save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "    save_location =  save_location  + pt + \"/\"\n",
    "    create_dir_if_not_exists(save_location)\n",
    "    \n",
    "    _file = wsi_path + pt + \".tif\"\n",
    "    oslide = openslide.OpenSlide(_file)\n",
    "    save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "\n",
    "    first_batch = opx_data_ol0[i]\n",
    "    feat = first_batch[0].unsqueeze(0).to(device)\n",
    "    sub_preds, slide_preds, attn = model(feat)\n",
    "    label_index = ALL_LABEL.index(SELECTED_LABEL[0])\n",
    "\n",
    "    #Get attention\n",
    "    cur_att = attn[label_index] #att no softmax \n",
    "    #cur_att_softmax = torch.softmax(cur_att, dim=-1) #att softmax over tiles\n",
    "\n",
    "    #Mean\n",
    "    cur_pt_att = cur_att.mean(dim = 1).squeeze().cpu().detach().numpy() #Mean aross channels without softmax\n",
    "    #cur_pt_att = cur_att_softmax.mean(dim = 1).squeeze().cpu().detach().numpy()  #Mean aross channels with softmax\n",
    "    \n",
    "    #cur_pt_att = cur_att[0,branches,:].cpu().detach().numpy() #branch\n",
    "    \n",
    "    #Get all tile info include noncancer tile\n",
    "    alltileinfo_dir = proj_dir + 'intermediate_data/2_cancer_detection/OPX/' + \"IMSIZE250_OL0\" + \"/\"\n",
    "    tile_info_df = pd.read_csv(alltileinfo_dir + pt + \"/ft_model/\"  + save_name + \"_TILE_TUMOR_PERC.csv\")\n",
    "    #Combine current pt_info an all tile info\n",
    "    #cur_pt_info = tile_info_df.merge(cur_pt_info, on = list(tile_info_df.columns), how = \"left\")\n",
    "    cur_pt_info = first_batch[3]\n",
    "    cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "    #cur_att_df.loc[pd.isna(cur_att_df['ATT']),'ATT'] = 0.0001\n",
    "    \n",
    "    \n",
    "    #Generate tiles\n",
    "    tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "    #get level 0 size in px\n",
    "    l0_w = oslide.level_dimensions[0][0]\n",
    "    l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "    #1.25x tissue detection for mask\n",
    "    from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "    from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "    import cv2\n",
    "    if 'OPX' in pt:\n",
    "        rad_tissue = 5\n",
    "    elif '(2017-0133)' in pt:\n",
    "        rad_tissue = 2\n",
    "    lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "    lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "    tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "    #2.5x for probability maps\n",
    "    lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "    x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    \n",
    "    for index, row in cur_att_df.iterrows():\n",
    "        cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "        x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "        #Extract tile for prediction\n",
    "        lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "        tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "        map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    \n",
    "        #Store predicted probabily in map and count\n",
    "        try: \n",
    "            x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "            x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print('post-processing')\n",
    "    x_count = np.where(x_count < 1, 1, x_count)\n",
    "    x_map = x_map / x_count\n",
    "    x_map[x_map>1]=1\n",
    "    \n",
    "    #Get the following before smooth\n",
    "    he_mask = cv2.resize(np.uint8(he_mask),(x_map.shape[1],x_map.shape[0])) #resize to output image size\n",
    "    cond1 = he_mask < 1 #Background\n",
    "    cond2 = (he_mask == 1) & (x_map == 0) #is tissue, but not selected\n",
    "    smooth = True\n",
    "    \n",
    "    if smooth == True:\n",
    "        #x_sm = filters.gaussian(x_map, sigma=0)\n",
    "        x_sm = np.where(x_map != 0, filters.gaussian(x_map, sigma=10), x_map)\n",
    "    if smooth == False:\n",
    "        x_sm = x_map\n",
    "    \n",
    "    #TODO:\n",
    "    #get cancer_mask:\n",
    "    # cancer_mask == \n",
    "    # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "    x_sm[cond1] = 0 #Background\n",
    "    x_sm[cond2] = 0.1 #Is tissue, but not selected \n",
    "    \n",
    "    # Define the colors for the sequential colormap (black to fluorescent green)\n",
    "    colors = [\"#4B0082\", \"#39FF14\"]  # Black to Fluorescent Green\n",
    "    # Create the sequential colormap\n",
    "    cmap_name = \"black_to_fluorescent_green\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    sequential_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "    cmap =  plt.cm.Spectral_r #sequential_cmap # plt.cm.YlGn_r\n",
    "    cmap_colors = cmap(np.arange(cmap.N))\n",
    "    cmap_colors[0] = np.array([0.95, 0.95, 0.95, 1]) #np.array([1, 1, 1, 1])  # Set the first color (corresponding to 0) to white\n",
    "    cmap_colors[1] = np.array([0, 0, 0.545, 1])  # RGB for dark blue\n",
    "    custom_cmap = ListedColormap(cmap_colors)\n",
    "    \n",
    "    plt.imshow(x_sm, cmap=custom_cmap) #Spectral_r\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    #Top attented tiles\n",
    "    save_location2 = save_location + \"top_tiles/\"\n",
    "    create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "    #Get a Attention, and corresponding tiles\n",
    "    cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "    cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "            \n",
    "    for i in range(TOP_K):\n",
    "        cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "        cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "        cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "        coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "        tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "        cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "    \n",
    "    #Bot attented tiles\n",
    "    save_location2 = save_location + \"bot_tiles/\"\n",
    "    create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "    #Get a Attention, and corresponding tiles\n",
    "    cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "    cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "    \n",
    "    for i in range(TOP_K):\n",
    "        cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "        cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "        cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "        coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "        tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "        cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
