{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo, get_performance, plot_roc_curve\n",
    "from train_utils import pull_tiles, FocalLoss, get_feature_idexes\n",
    "from train_utils import convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from ACMIL import ACMIL_GA_MultiTask, predict_v2, train_one_epoch_multitask_V2, evaluate_multitask_V2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def calibrate_probs_isotonic(y_val, y_prob_val, y_test_prob):\n",
    "    \"\"\"\n",
    "    Perform Isotonic Regression to calibrate predicted probabilities.\n",
    "\n",
    "    Args:\n",
    "        y_val: Ground truth labels from the validation set.\n",
    "        y_prob_val: Model-predicted probabilities from the validation set.\n",
    "        y_test_prob: Model-predicted probabilities for the test set.\n",
    "\n",
    "    Returns:\n",
    "        Calibrated probabilities for the test set.\n",
    "    \"\"\"\n",
    "    iso_reg = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso_reg.fit(y_prob_val, y_val)\n",
    "    calibrated_probs = iso_reg.predict(y_test_prob)\n",
    "    return calibrated_probs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix,fbeta_score,average_precision_score\n",
    "from sklearn import metrics\n",
    "def bootstrap_ci_from_df(df, metric_fn, y_true_col='y_true', y_pred_col=None, y_prob_col=None,\n",
    "                         num_bootstrap=1000, ci=95, seed=None):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for a metric using predictions in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with prediction results.\n",
    "        metric_fn: Metric function. Can accept (y_true, y_pred) or (y_true, y_prob).\n",
    "        y_true_col: Column name for ground truth.\n",
    "        y_pred_col: Column name for predicted labels (used for accuracy, etc.).\n",
    "        y_prob_col: Column name for predicted probabilities (used for AUROC, etc.).\n",
    "        num_bootstrap: Number of bootstrap resamples.\n",
    "        ci: Confidence level (e.g., 95 for 95% CI).\n",
    "        seed: Optional random seed.\n",
    "\n",
    "    Returns:\n",
    "        (lower_bound, upper_bound) of CI.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(df)\n",
    "    perf_list = []\n",
    "\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(n=n, replace=True, random_state=rng.integers(0, 1e6))\n",
    "        y_true = sample[y_true_col].values\n",
    "        y_pred_class =  sample[y_pred_col].values\n",
    "        y_pred_prob =   sample[y_prob_col].values\n",
    "\n",
    "        # mean_metric = np.mean(metrics)\n",
    "        # metric = metric_fn(y_true, y_pred_or_prob)\n",
    "        # metrics.append(metric)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel() #CM\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred_prob, pos_label=1)\n",
    "        PR_AUC = average_precision_score(y_true, y_pred_prob)\n",
    "        AUC = round(metrics.auc(fpr, tpr),2)\n",
    "        ACC = round(accuracy_score(y_true, y_pred_class),2)\n",
    "        F1 = round(f1_score(y_true, y_pred_class),2)\n",
    "        F2 = round(fbeta_score(y_true, y_pred_class,beta = 2),2)\n",
    "        F3 = round(fbeta_score(y_true, y_pred_class,beta = 3),2)\n",
    "        Recall = round(recall_score(y_true, y_pred_class),2)\n",
    "        Precision = round(precision_score(y_true, y_pred_class),2)\n",
    "        Specificity = round(tn / (tn + fp),2)\n",
    "        perf_tb = pd.DataFrame({\"AUC\": AUC,\n",
    "                                \"Recall\": Recall,\n",
    "                                \"Specificity\":Specificity,\n",
    "                                \"ACC\": ACC,\n",
    "                                \"Precision\":Precision,\n",
    "                                \"PR_AUC\":PR_AUC,\n",
    "                                \"F1\": F1,\n",
    "                                \"F2\": F2,\n",
    "                                \"F3\": F3},index = [0])\n",
    "        perf_list.append(perf_tb)\n",
    "    perf_df = pd.concat(perf_list)\n",
    "\n",
    "    mean_values = perf_df.mean()\n",
    "    lower_bounds = perf_df.quantile((100 - ci) / 200)\n",
    "    upper_bounds = perf_df.quantile(1 - (100 - ci) / 200)\n",
    "    \n",
    "    formatted_results = {\n",
    "        column: f\"{mean_values[column]:.2f} [{lower_bounds[column]:.2f} - {upper_bounds[column]:.2f}]\"\n",
    "        for column in perf_df.columns\n",
    "    }\n",
    "    ci_df = pd.DataFrame.from_dict(formatted_results, orient=\"index\", columns=[\"Mean [CI Low, CI High]\"])\n",
    "\n",
    "    return ci_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fe6b4f-a374-4a86-8276-e5a1bced8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch: 100\n",
      "warmup_epoch: 0\n",
      "wd: 1e-05\n",
      "lr: 0.0001\n",
      "min_lr: 0\n",
      "dataset: bracs\n",
      "B: 1\n",
      "n_class: 1\n",
      "n_worker: 8\n",
      "pin_memory: False\n",
      "n_shot: -1\n",
      "D_feat: 1536\n",
      "D_inner: 128\n",
      "n_token: 1\n",
      "mask_drop: 0\n",
      "n_masked_patch: 0\n",
      "wandb_mode: disabled\n",
      "n_task: 7\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABEL = [\"AR\",\"HR\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0.9 \n",
    "feature_extraction_method = 'uni2' #retccl, uni1, prov_gigapath\n",
    "learning_method = \"abmil\"\n",
    "SELECTED_FEATURE = get_feature_idexes(feature_extraction_method, include_tumor_fraction = False)\n",
    "N_FEATURE = len(SELECTED_FEATURE)\n",
    "\n",
    "\n",
    "#For RB1: gamma = 2, focal_alpha = 0.1\n",
    "\n",
    "\n",
    "# Define different values for alpha and gamma\n",
    "alpha_values = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.6]  # Example alpha values\n",
    "gamma_values = [2,    3,    2,   2,  2,   2,  10]  # Example gamma values\n",
    "\n",
    "# focal_gamma = 5 #10 seems good too\n",
    "# focal_alpha = 0.80\n",
    "#Best before\n",
    "focal_gamma = 10\n",
    "focal_alpha = 0.6\n",
    "loss_method = 'ATTLOSS' #ATTLOSS\n",
    "\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "SELECTED_FOLD = 0\n",
    "arch = 'ga_mt' #ga_mt or ga\n",
    "\n",
    "    \n",
    "################################\n",
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "\n",
    "conf.train_epoch = 100\n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "\n",
    "if learning_method == 'abmil':\n",
    "    conf.n_token = 1\n",
    "    conf.mask_drop = 0\n",
    "    conf.n_masked_patch = 0\n",
    "elif learning_method == 'acmil':\n",
    "    conf.n_token = 3\n",
    "    conf.mask_drop = 0.6\n",
    "    conf.n_masked_patch = 0\n",
    "    \n",
    "conf.n_class = 1\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.n_task = 7\n",
    "#conf.lr = 0.000001 #change this for HR only\n",
    "\n",
    "# Print all key-value pairs in the conf object\n",
    "for key, value in conf.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name_overlap = \"IMSIZE250_OL100\"\n",
    "folder_name_nonoverlap = \"IMSIZE250_OL0\"\n",
    "feature_path_opx_train =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_overlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_opx_test =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "train_val_test_id_path =  os.path.join(proj_dir + 'intermediate_data/6_Train_TEST_IDS', 'TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#Create output-dir\n",
    "################################################\n",
    "folder_name1 = feature_extraction_method + '/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out032025_ACMIL2\" + \"/\" + folder_name1 + 'FOLD' + str(SELECTED_FOLD) + '/' + SELECTED_MUTATION + \"/\" \n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25981794-2637-40c2-94df-dbd3b5cfbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "opx_data_ol100 = torch.load(feature_path_opx_train + '/OPX_data.pth')\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a360618-a0c6-4650-8f2d-8e66bbfd7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get train, test IDs\n",
    "################################################\n",
    "train_test_val_id_df = pd.read_csv(os.path.join(train_val_test_id_path, \"train_test_split.csv\"))\n",
    "train_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TRAIN', 'SAMPLE_ID'])\n",
    "test_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TEST', 'SAMPLE_ID'])\n",
    "val_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'VALID', 'SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa31800f-0219-42fa-ab6a-5567a44cdea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "67\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids_all))\n",
    "print(len(test_ids_all))\n",
    "print(len(val_ids_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2512c51e-0cfe-41b8-a766-a0ba19763f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#IDS\n",
    "################################################\n",
    "opx_ids_ol100 = [x[-2] for x in opx_data_ol100]\n",
    "opx_ids_ol0 = [x[-2] for x in opx_data_ol0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b363757-dbfd-4164-a880-c156df177000",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get Train, test, val data\n",
    "################################################\n",
    "#Train:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in train_ids_all]\n",
    "train_data = Subset(opx_data_ol100, inc_idx)\n",
    "train_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "\n",
    "#Val:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in val_ids_all]\n",
    "val_data = Subset(opx_data_ol100, inc_idx)\n",
    "val_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "\n",
    "#Test:\n",
    "inc_idx = [opx_ids_ol0.index(x) for x in test_ids_all]\n",
    "test_data = Subset(opx_data_ol0, inc_idx)\n",
    "test_ids =  list(Subset(opx_ids_ol0, inc_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#Dataloader for training\n",
    "####################################################\n",
    "train_data2 = [item[:-3] for item in train_data] #only keep the needed for training\n",
    "test_data2 = [item[:-3] for item in test_data] #only keep the needed for training\n",
    "val_data2 = [item[:-3] for item in val_data] #only keep the needed for training\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data2, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287cee9a-95b9-4a80-b9c4-1c02a3060f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/MT/' already exists.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# define network\n",
    "####################################################\n",
    "if arch == 'ga':\n",
    "    model = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "elif arch == 'ga_mt':\n",
    "    model = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "else:\n",
    "    model = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Create a list of FocalLoss criteria with different alpha and gamma\n",
    "criterion = [FocalLoss(alpha=a, gamma=g, reduction='mean') for a, g in zip(alpha_values, gamma_values)]\n",
    "#criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "\n",
    "ckpt_dir = outdir1 + SELECTED_MUTATION + \"/\"\n",
    "create_dir_if_not_exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/161]  eta: 0:01:23  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0003 (0.0003)  att_loss: 0.8078 (0.8078)  total_loss: 6.2018 (6.2018)  time: 0.5156  data: 0.0006  max mem: 26\n",
      "Epoch: [0]  [100/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0002)  att_loss: 0.9806 (0.9656)  total_loss: 6.9813 (7.0506)  time: 0.0158  data: 0.0016  max mem: 891\n",
      "Epoch: [0]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0002)  att_loss: 0.9844 (0.9691)  total_loss: 7.0428 (7.0132)  time: 0.0168  data: 0.0020  max mem: 891\n",
      "Epoch: [0] Total time: 0:00:03 (0.0190 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0807 (0.0807)  div_loss: -64.2919 (-64.2919)  acc1: 85.7143 (85.7143)  time: 0.0211  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0859 (0.1235)  div_loss: -51.7519 (-50.1935)  acc1: 85.7143 (83.5714)  time: 0.0120  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0108 s / it)\n",
      "AUROC 0 : 0.8514285683631897\n",
      "AUROC 1 : 0.5428571701049805\n",
      "AUROC 2 : 0.7060932517051697\n",
      "AUROC 3 : 0.9019607901573181\n",
      "AUROC 4 : 0.7005208730697632\n",
      "AUROC 5 : 0.43421053886413574\n",
      "AUROC 6 : 0.36936938762664795\n",
      "* Acc@1 83.571 loss 0.124 auroc 0.644 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1065 (0.1065)  div_loss: -37.5401 (-37.5401)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0425 (0.1314)  div_loss: -43.3268 (-44.6902)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7309523820877075\n",
      "AUROC 1 : 0.5021186470985413\n",
      "AUROC 2 : 0.5833333730697632\n",
      "AUROC 3 : 0.8214285373687744\n",
      "AUROC 4 : 0.570588231086731\n",
      "AUROC 5 : 0.6201298832893372\n",
      "AUROC 6 : 0.5651515126228333\n",
      "* Acc@1 83.582 loss 0.131 auroc 0.628 f1_score 0.022\n",
      "Epoch: [1]  [  0/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8078 (0.8078)  total_loss: 5.8757 (5.8757)  time: 0.0100  data: 0.0003  max mem: 891\n",
      "Epoch: [1]  [100/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0002)  att_loss: 0.9806 (0.9656)  total_loss: 6.9322 (6.8823)  time: 0.0132  data: 0.0016  max mem: 891\n",
      "Epoch: [1]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0002)  att_loss: 0.9844 (0.9691)  total_loss: 7.0451 (6.9035)  time: 0.0148  data: 0.0018  max mem: 891\n",
      "Epoch: [1] Total time: 0:00:02 (0.0146 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0755 (0.0755)  div_loss: -64.2647 (-64.2647)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0031  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0787 (0.1204)  div_loss: -51.7127 (-50.1665)  acc1: 85.7143 (83.5714)  time: 0.0115  data: 0.0022  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0098 s / it)\n",
      "AUROC 0 : 0.8514285683631897\n",
      "AUROC 1 : 0.49142858386039734\n",
      "AUROC 2 : 0.6917563080787659\n",
      "AUROC 3 : 0.906862735748291\n",
      "AUROC 4 : 0.7734375\n",
      "AUROC 5 : 0.44736841320991516\n",
      "AUROC 6 : 0.3243243396282196\n",
      "* Acc@1 83.571 loss 0.120 auroc 0.641 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0939 (0.0939)  div_loss: -37.4799 (-37.4799)  acc1: 85.7143 (85.7143)  time: 0.0048  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0427 (0.1289)  div_loss: -43.2943 (-44.6609)  acc1: 85.7143 (83.5821)  time: 0.0056  data: 0.0004  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0063 s / it)\n",
      "AUROC 0 : 0.7595238089561462\n",
      "AUROC 1 : 0.5190677642822266\n",
      "AUROC 2 : 0.5730769634246826\n",
      "AUROC 3 : 0.8428571224212646\n",
      "AUROC 4 : 0.6317647099494934\n",
      "AUROC 5 : 0.636363685131073\n",
      "AUROC 6 : 0.5666666030883789\n",
      "* Acc@1 83.582 loss 0.129 auroc 0.647 f1_score 0.022\n",
      "Epoch: [2]  [  0/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8078 (0.8078)  total_loss: 5.8678 (5.8678)  time: 0.0103  data: 0.0003  max mem: 891\n",
      "Epoch: [2]  [100/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9329 (6.8746)  time: 0.0139  data: 0.0016  max mem: 891\n",
      "Epoch: [2]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 7.0278 (6.8963)  time: 0.0164  data: 0.0019  max mem: 891\n",
      "Epoch: [2] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0724 (0.0724)  div_loss: -64.2485 (-64.2485)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0743 (0.1186)  div_loss: -51.6945 (-50.1523)  acc1: 85.7143 (83.5714)  time: 0.0118  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8857142925262451\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6774193644523621\n",
      "AUROC 3 : 0.8872548937797546\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.43421050906181335\n",
      "AUROC 6 : 0.3243243396282196\n",
      "* Acc@1 83.571 loss 0.119 auroc 0.648 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0874 (0.0874)  div_loss: -37.4522 (-37.4522)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0554 (0.1275)  div_loss: -43.2806 (-44.6446)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.47669491171836853\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.8500000238418579\n",
      "AUROC 4 : 0.6647058725357056\n",
      "AUROC 5 : 0.6607142686843872\n",
      "AUROC 6 : 0.5878788232803345\n",
      "* Acc@1 83.582 loss 0.128 auroc 0.656 f1_score 0.022\n",
      "Epoch: [3]  [  0/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8077 (0.8077)  total_loss: 5.8527 (5.8527)  time: 0.0103  data: 0.0003  max mem: 891\n",
      "Epoch: [3]  [100/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9369 (6.8679)  time: 0.0134  data: 0.0015  max mem: 891\n",
      "Epoch: [3]  [160/161]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 7.0123 (6.8900)  time: 0.0147  data: 0.0019  max mem: 891\n",
      "Epoch: [3] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0709 (0.0709)  div_loss: -64.2324 (-64.2324)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0742 (0.1180)  div_loss: -51.6752 (-50.1353)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8857142925262451\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6810036301612854\n",
      "AUROC 3 : 0.8872549533843994\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.40789473056793213\n",
      "AUROC 6 : 0.3243243396282196\n",
      "* Acc@1 83.571 loss 0.118 auroc 0.647 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0825 (0.0825)  div_loss: -37.4215 (-37.4215)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0513 (0.1266)  div_loss: -43.2650 (-44.6256)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.4766949415206909\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.8738095164299011\n",
      "AUROC 4 : 0.6705881953239441\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.6106060743331909\n",
      "* Acc@1 83.582 loss 0.127 auroc 0.667 f1_score 0.022\n",
      "Epoch: [4]  [  0/161]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8077 (0.8077)  total_loss: 5.8368 (5.8368)  time: 0.0113  data: 0.0003  max mem: 891\n",
      "Epoch: [4]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9397 (6.8617)  time: 0.0140  data: 0.0018  max mem: 891\n",
      "Epoch: [4]  [160/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9989 (6.8841)  time: 0.0151  data: 0.0020  max mem: 891\n",
      "Epoch: [4] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0692 (0.0692)  div_loss: -64.2140 (-64.2140)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0754 (0.1182)  div_loss: -51.6522 (-50.1141)  acc1: 85.7143 (83.5714)  time: 0.0126  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5200000405311584\n",
      "AUROC 2 : 0.6881721019744873\n",
      "AUROC 3 : 0.8823529481887817\n",
      "AUROC 4 : 0.8307292461395264\n",
      "AUROC 5 : 0.40789473056793213\n",
      "AUROC 6 : 0.3513513505458832\n",
      "* Acc@1 83.571 loss 0.118 auroc 0.655 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0784 (0.0784)  div_loss: -37.3875 (-37.3875)  acc1: 85.7143 (85.7143)  time: 0.0054  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0476 (0.1261)  div_loss: -43.2441 (-44.6031)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7952381372451782\n",
      "AUROC 1 : 0.48516950011253357\n",
      "AUROC 2 : 0.5871794819831848\n",
      "AUROC 3 : 0.8904762268066406\n",
      "AUROC 4 : 0.6835293769836426\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.6272727251052856\n",
      "* Acc@1 83.582 loss 0.126 auroc 0.681 f1_score 0.022\n",
      "Epoch: [5]  [  0/161]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8077 (0.8077)  total_loss: 5.8198 (5.8198)  time: 0.0117  data: 0.0002  max mem: 891\n",
      "Epoch: [5]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9417 (6.8558)  time: 0.0141  data: 0.0017  max mem: 891\n",
      "Epoch: [5]  [160/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9905 (6.8786)  time: 0.0154  data: 0.0024  max mem: 891\n",
      "Epoch: [5] Total time: 0:00:02 (0.0149 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0674 (0.0674)  div_loss: -64.1925 (-64.1925)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0740 (0.1192)  div_loss: -51.6235 (-50.0879)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9085714817047119\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6917562484741211\n",
      "AUROC 3 : 0.8774510025978088\n",
      "AUROC 4 : 0.8385416269302368\n",
      "AUROC 5 : 0.42105263471603394\n",
      "AUROC 6 : 0.36036035418510437\n",
      "* Acc@1 83.571 loss 0.119 auroc 0.660 f1_score 0.000\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0753 (0.0753)  div_loss: -37.3502 (-37.3502)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0486 (0.1260)  div_loss: -43.2140 (-44.5757)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.8023809790611267\n",
      "AUROC 1 : 0.4894067943096161\n",
      "AUROC 2 : 0.5987179279327393\n",
      "AUROC 3 : 0.8904762268066406\n",
      "AUROC 4 : 0.6870588064193726\n",
      "AUROC 5 : 0.7126623392105103\n",
      "AUROC 6 : 0.6363636255264282\n",
      "* Acc@1 83.582 loss 0.126 auroc 0.688 f1_score 0.038\n",
      "Epoch: [6]  [  0/161]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8077 (0.8077)  total_loss: 5.8012 (5.8012)  time: 0.0110  data: 0.0003  max mem: 891\n",
      "Epoch: [6]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9421 (6.8502)  time: 0.0137  data: 0.0016  max mem: 891\n",
      "Epoch: [6]  [160/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9891 (6.8734)  time: 0.0156  data: 0.0020  max mem: 891\n",
      "Epoch: [6] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0657 (0.0657)  div_loss: -64.1675 (-64.1675)  acc1: 85.7143 (85.7143)  time: 0.0104  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0729 (0.1209)  div_loss: -51.5876 (-50.0556)  acc1: 85.7143 (83.5714)  time: 0.0120  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9085714817047119\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.8774510025978088\n",
      "AUROC 4 : 0.8411458134651184\n",
      "AUROC 5 : 0.43421053886413574\n",
      "AUROC 6 : 0.36936938762664795\n",
      "* Acc@1 83.571 loss 0.121 auroc 0.665 f1_score 0.016\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0725 (0.0725)  div_loss: -37.3090 (-37.3090)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0517 (0.1263)  div_loss: -43.1724 (-44.5421)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.8023809790611267\n",
      "AUROC 1 : 0.49788135290145874\n",
      "AUROC 2 : 0.6051282286643982\n",
      "AUROC 3 : 0.9023809432983398\n",
      "AUROC 4 : 0.6882352828979492\n",
      "AUROC 5 : 0.7142857313156128\n",
      "AUROC 6 : 0.6424242258071899\n",
      "* Acc@1 83.582 loss 0.126 auroc 0.693 f1_score 0.038\n",
      "Epoch: [7]  [  0/161]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8077 (0.8077)  total_loss: 5.7820 (5.7820)  time: 0.0119  data: 0.0002  max mem: 891\n",
      "Epoch: [7]  [100/161]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9407 (6.8447)  time: 0.0145  data: 0.0024  max mem: 891\n",
      "Epoch: [7]  [160/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9826 (6.8682)  time: 0.0157  data: 0.0026  max mem: 891\n",
      "Epoch: [7] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0642 (0.0642)  div_loss: -64.1386 (-64.1386)  acc1: 85.7143 (85.7143)  time: 0.0132  data: 0.0060  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0716 (0.1232)  div_loss: -51.5431 (-50.0155)  acc1: 85.7143 (83.5714)  time: 0.0126  data: 0.0030  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0109 s / it)\n",
      "AUROC 0 : 0.9085714817047119\n",
      "AUROC 1 : 0.5428571701049805\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.8676470518112183\n",
      "AUROC 4 : 0.84375\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.38738739490509033\n",
      "* Acc@1 83.571 loss 0.123 auroc 0.669 f1_score 0.016\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0700 (0.0700)  div_loss: -37.2633 (-37.2633)  acc1: 85.7143 (85.7143)  time: 0.0039  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0546 (0.1270)  div_loss: -43.1174 (-44.5003)  acc1: 85.7143 (83.5821)  time: 0.0067  data: 0.0016  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0071 s / it)\n",
      "AUROC 0 : 0.7952381372451782\n",
      "AUROC 1 : 0.5127118825912476\n",
      "AUROC 2 : 0.6166666746139526\n",
      "AUROC 3 : 0.9142857193946838\n",
      "AUROC 4 : 0.6929411888122559\n",
      "AUROC 5 : 0.7224025726318359\n",
      "AUROC 6 : 0.6424242258071899\n",
      "* Acc@1 83.582 loss 0.127 auroc 0.700 f1_score 0.038\n",
      "Epoch: [8]  [  0/161]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8076 (0.8076)  total_loss: 5.7639 (5.7639)  time: 0.0113  data: 0.0003  max mem: 891\n",
      "Epoch: [8]  [100/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9383 (6.8393)  time: 0.0150  data: 0.0023  max mem: 891\n",
      "Epoch: [8]  [160/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9713 (6.8632)  time: 0.0161  data: 0.0031  max mem: 891\n",
      "Epoch: [8] Total time: 0:00:02 (0.0161 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0631 (0.0631)  div_loss: -64.1044 (-64.1044)  acc1: 85.7143 (85.7143)  time: 0.0117  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0704 (0.1262)  div_loss: -51.4879 (-49.9654)  acc1: 85.7143 (83.5714)  time: 0.0129  data: 0.0031  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0111 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5371428728103638\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.8627450466156006\n",
      "AUROC 4 : 0.8541666269302368\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.4054054021835327\n",
      "* Acc@1 83.571 loss 0.126 auroc 0.670 f1_score 0.030\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0676 (0.0676)  div_loss: -37.2127 (-37.2127)  acc1: 85.7143 (85.7143)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0573 (0.1278)  div_loss: -43.0531 (-44.4473)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7928571701049805\n",
      "AUROC 1 : 0.5190677642822266\n",
      "AUROC 2 : 0.629487156867981\n",
      "AUROC 3 : 0.9190475940704346\n",
      "AUROC 4 : 0.6976470947265625\n",
      "AUROC 5 : 0.725649356842041\n",
      "AUROC 6 : 0.6424242258071899\n",
      "* Acc@1 83.582 loss 0.128 auroc 0.704 f1_score 0.074\n",
      "Epoch: [9]  [  0/161]  eta: 0:00:02  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8076 (0.8076)  total_loss: 5.7481 (5.7481)  time: 0.0139  data: 0.0003  max mem: 891\n",
      "Epoch: [9]  [100/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9335 (6.8340)  time: 0.0146  data: 0.0022  max mem: 891\n",
      "Epoch: [9]  [160/161]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9616 (6.8582)  time: 0.0155  data: 0.0030  max mem: 891\n",
      "Epoch: [9] Total time: 0:00:02 (0.0159 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0621 (0.0621)  div_loss: -64.0627 (-64.0627)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0036  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0692 (0.1297)  div_loss: -51.4185 (-49.9018)  acc1: 85.7143 (83.5714)  time: 0.0130  data: 0.0034  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0112 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5314285755157471\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.8578431010246277\n",
      "AUROC 4 : 0.8541666865348816\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.4324324131011963\n",
      "* Acc@1 83.571 loss 0.130 auroc 0.672 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0657 (0.0657)  div_loss: -37.1547 (-37.1547)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0599 (0.1290)  div_loss: -43.0082 (-44.3789)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.5317796468734741\n",
      "AUROC 2 : 0.6282051205635071\n",
      "AUROC 3 : 0.9285714030265808\n",
      "AUROC 4 : 0.6988235712051392\n",
      "AUROC 5 : 0.725649356842041\n",
      "AUROC 6 : 0.6469696760177612\n",
      "* Acc@1 83.582 loss 0.129 auroc 0.706 f1_score 0.074\n",
      "Epoch: [10]  [  0/161]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8076 (0.8076)  total_loss: 5.7339 (5.7339)  time: 0.0120  data: 0.0003  max mem: 891\n",
      "Epoch: [10]  [100/161]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9249 (6.8289)  time: 0.0152  data: 0.0025  max mem: 891\n",
      "Epoch: [10]  [160/161]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9529 (6.8533)  time: 0.0161  data: 0.0030  max mem: 891\n",
      "Epoch: [10] Total time: 0:00:02 (0.0159 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0611 (0.0611)  div_loss: -64.0077 (-64.0077)  acc1: 85.7143 (85.7143)  time: 0.0154  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0677 (0.1340)  div_loss: -51.3284 (-49.8177)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0028  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5200000405311584\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.843137264251709\n",
      "AUROC 4 : 0.8515625\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.45945948362350464\n",
      "* Acc@1 83.571 loss 0.134 auroc 0.672 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0643 (0.0643)  div_loss: -37.0834 (-37.0834)  acc1: 85.7143 (85.7143)  time: 0.0054  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0630 (0.1305)  div_loss: -42.9487 (-44.2870)  acc1: 85.7143 (83.5821)  time: 0.0065  data: 0.0008  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.555084764957428\n",
      "AUROC 2 : 0.6269230842590332\n",
      "AUROC 3 : 0.938095211982727\n",
      "AUROC 4 : 0.7047058939933777\n",
      "AUROC 5 : 0.7240259647369385\n",
      "AUROC 6 : 0.653030276298523\n",
      "* Acc@1 83.582 loss 0.131 auroc 0.711 f1_score 0.074\n",
      "Epoch: [11]  [  0/161]  eta: 0:00:01  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0001 (0.0001)  att_loss: 0.8076 (0.8076)  total_loss: 5.7216 (5.7216)  time: 0.0120  data: 0.0003  max mem: 891\n",
      "Epoch: [11]  [100/161]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9190 (6.8238)  time: 0.0162  data: 0.0037  max mem: 891\n",
      "Epoch: [11]  [160/161]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9455 (6.8484)  time: 0.0162  data: 0.0026  max mem: 891\n",
      "Epoch: [11] Total time: 0:00:02 (0.0164 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0601 (0.0601)  div_loss: -63.9307 (-63.9307)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0630 (0.1394)  div_loss: -51.2102 (-49.7042)  acc1: 85.7143 (83.5714)  time: 0.0133  data: 0.0036  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0110 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.8284313678741455\n",
      "AUROC 4 : 0.8411458730697632\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.45045047998428345\n",
      "* Acc@1 83.571 loss 0.139 auroc 0.667 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0642 (0.0642)  div_loss: -36.9897 (-36.9897)  acc1: 85.7143 (85.7143)  time: 0.0088  data: 0.0041  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0667 (0.1323)  div_loss: -42.8674 (-44.1616)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0072 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.5720338821411133\n",
      "AUROC 2 : 0.629487156867981\n",
      "AUROC 3 : 0.9428571462631226\n",
      "AUROC 4 : 0.7058823704719543\n",
      "AUROC 5 : 0.7224026322364807\n",
      "AUROC 6 : 0.6606060266494751\n",
      "* Acc@1 83.582 loss 0.132 auroc 0.716 f1_score 0.074\n",
      "Epoch: [12]  [  0/161]  eta: 0:00:02  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8075 (0.8075)  total_loss: 5.7120 (5.7120)  time: 0.0130  data: 0.0004  max mem: 891\n",
      "Epoch: [12]  [100/161]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9182 (6.8186)  time: 0.0148  data: 0.0020  max mem: 891\n",
      "Epoch: [12]  [160/161]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9388 (6.8434)  time: 0.0161  data: 0.0023  max mem: 891\n",
      "Epoch: [12] Total time: 0:00:02 (0.0160 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0589 (0.0589)  div_loss: -63.8197 (-63.8197)  acc1: 85.7143 (85.7143)  time: 0.0111  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0582 (0.1460)  div_loss: -51.0484 (-49.5512)  acc1: 85.7143 (83.5714)  time: 0.0128  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0110 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.8186274766921997\n",
      "AUROC 4 : 0.8385416865348816\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.45045047998428345\n",
      "* Acc@1 83.571 loss 0.146 auroc 0.666 f1_score 0.029\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0651 (0.0651)  div_loss: -36.8606 (-36.8606)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0718 (0.1345)  div_loss: -42.7556 (-43.9909)  acc1: 85.7143 (83.5821)  time: 0.0054  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0071 s / it)\n",
      "AUROC 0 : 0.7785714268684387\n",
      "AUROC 1 : 0.5826271772384644\n",
      "AUROC 2 : 0.6371794939041138\n",
      "AUROC 3 : 0.9452380537986755\n",
      "AUROC 4 : 0.703529417514801\n",
      "AUROC 5 : 0.7175324559211731\n",
      "AUROC 6 : 0.6681817770004272\n",
      "* Acc@1 83.582 loss 0.135 auroc 0.719 f1_score 0.101\n",
      "Epoch: [13]  [  0/161]  eta: 0:00:01  lr: 0.000096  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8075 (0.8075)  total_loss: 5.7041 (5.7041)  time: 0.0093  data: 0.0002  max mem: 891\n",
      "Epoch: [13]  [100/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9173 (6.8135)  time: 0.0141  data: 0.0022  max mem: 891\n",
      "Epoch: [13]  [160/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9329 (6.8384)  time: 0.0156  data: 0.0028  max mem: 891\n",
      "Epoch: [13] Total time: 0:00:02 (0.0158 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0576 (0.0576)  div_loss: -63.6594 (-63.6594)  acc1: 85.7143 (85.7143)  time: 0.0118  data: 0.0040  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0579 (0.1541)  div_loss: -50.8218 (-49.3456)  acc1: 85.7143 (83.5714)  time: 0.0126  data: 0.0028  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0109 s / it)\n",
      "AUROC 0 : 0.9028571248054504\n",
      "AUROC 1 : 0.5257143378257751\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.813725471496582\n",
      "AUROC 4 : 0.8333333730697632\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.45945948362350464\n",
      "* Acc@1 83.571 loss 0.154 auroc 0.665 f1_score 0.076\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0678 (0.0678)  div_loss: -36.6784 (-36.6784)  acc1: 85.7143 (85.7143)  time: 0.0082  data: 0.0037  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0685 (0.1372)  div_loss: -42.6017 (-43.7593)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0070 s / it)\n",
      "AUROC 0 : 0.7738094925880432\n",
      "AUROC 1 : 0.5932203531265259\n",
      "AUROC 2 : 0.6371794939041138\n",
      "AUROC 3 : 0.9452381134033203\n",
      "AUROC 4 : 0.6976470947265625\n",
      "AUROC 5 : 0.7175324559211731\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.137 auroc 0.720 f1_score 0.116\n",
      "Epoch: [14]  [  0/161]  eta: 0:00:01  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8075 (0.8075)  total_loss: 5.6979 (5.6979)  time: 0.0088  data: 0.0003  max mem: 891\n",
      "Epoch: [14]  [100/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9152 (6.8082)  time: 0.0154  data: 0.0025  max mem: 891\n",
      "Epoch: [14]  [160/161]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9275 (6.8333)  time: 0.0177  data: 0.0043  max mem: 891\n",
      "Epoch: [14] Total time: 0:00:02 (0.0164 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0561 (0.0561)  div_loss: -63.4387 (-63.4387)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0576 (0.1641)  div_loss: -50.5098 (-49.0796)  acc1: 85.7143 (83.5714)  time: 0.0128  data: 0.0030  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0114 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6666666865348816\n",
      "AUROC 3 : 0.813725471496582\n",
      "AUROC 4 : 0.8203125\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.164 auroc 0.663 f1_score 0.076\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0719 (0.0719)  div_loss: -36.4281 (-36.4281)  acc1: 85.7143 (85.7143)  time: 0.0087  data: 0.0040  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0645 (0.1404)  div_loss: -42.4000 (-43.4562)  acc1: 85.7143 (83.5821)  time: 0.0068  data: 0.0009  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0072 s / it)\n",
      "AUROC 0 : 0.7690476179122925\n",
      "AUROC 1 : 0.6038135886192322\n",
      "AUROC 2 : 0.6384615302085876\n",
      "AUROC 3 : 0.9452381134033203\n",
      "AUROC 4 : 0.6952941417694092\n",
      "AUROC 5 : 0.7142857313156128\n",
      "AUROC 6 : 0.6727272272109985\n",
      "* Acc@1 83.582 loss 0.140 auroc 0.720 f1_score 0.116\n",
      "Epoch: [15]  [  0/161]  eta: 0:00:01  lr: 0.000095  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8074 (0.8074)  total_loss: 5.6936 (5.6936)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [15]  [100/161]  eta: 0:00:00  lr: 0.000094  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9120 (6.8029)  time: 0.0145  data: 0.0022  max mem: 891\n",
      "Epoch: [15]  [160/161]  eta: 0:00:00  lr: 0.000094  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9226 (6.8281)  time: 0.0163  data: 0.0030  max mem: 891\n",
      "Epoch: [15] Total time: 0:00:02 (0.0160 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0536 (0.0536)  div_loss: -63.1452 (-63.1452)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0542 (0.1754)  div_loss: -50.1465 (-48.7681)  acc1: 85.7143 (83.5714)  time: 0.0126  data: 0.0031  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.663082480430603\n",
      "AUROC 3 : 0.813725471496582\n",
      "AUROC 4 : 0.8151042461395264\n",
      "AUROC 5 : 0.43421053886413574\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.175 auroc 0.658 f1_score 0.100\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0778 (0.0778)  div_loss: -36.0979 (-36.0979)  acc1: 85.7143 (85.7143)  time: 0.0057  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0611 (0.1444)  div_loss: -42.1543 (-43.0988)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7666666507720947\n",
      "AUROC 1 : 0.6144068241119385\n",
      "AUROC 2 : 0.634615421295166\n",
      "AUROC 3 : 0.9476190209388733\n",
      "AUROC 4 : 0.6988235712051392\n",
      "AUROC 5 : 0.7077922224998474\n",
      "AUROC 6 : 0.6727272868156433\n",
      "* Acc@1 83.582 loss 0.144 auroc 0.720 f1_score 0.116\n",
      "Epoch: [16]  [  0/161]  eta: 0:00:02  lr: 0.000094  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8074 (0.8074)  total_loss: 5.6900 (5.6900)  time: 0.0129  data: 0.0002  max mem: 891\n",
      "Epoch: [16]  [100/161]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9071 (6.7979)  time: 0.0145  data: 0.0026  max mem: 891\n",
      "Epoch: [16]  [160/161]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9691)  total_loss: 6.9182 (6.8230)  time: 0.0164  data: 0.0025  max mem: 891\n",
      "Epoch: [16] Total time: 0:00:02 (0.0162 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0514 (0.0514)  div_loss: -62.7916 (-62.7916)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0537 (0.1880)  div_loss: -49.7651 (-48.4287)  acc1: 85.7143 (83.5714)  time: 0.0127  data: 0.0031  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0108 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5028572082519531\n",
      "AUROC 2 : 0.6594982147216797\n",
      "AUROC 3 : 0.8088234663009644\n",
      "AUROC 4 : 0.8125\n",
      "AUROC 5 : 0.44736844301223755\n",
      "AUROC 6 : 0.45945948362350464\n",
      "* Acc@1 83.571 loss 0.188 auroc 0.656 f1_score 0.195\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0846 (0.0846)  div_loss: -35.7141 (-35.7141)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0599 (0.1497)  div_loss: -41.8864 (-42.7157)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0070 s / it)\n",
      "AUROC 0 : 0.761904776096344\n",
      "AUROC 1 : 0.6228814125061035\n",
      "AUROC 2 : 0.6371794939041138\n",
      "AUROC 3 : 0.9476190805435181\n",
      "AUROC 4 : 0.7011765241622925\n",
      "AUROC 5 : 0.7077922224998474\n",
      "AUROC 6 : 0.678787887096405\n",
      "* Acc@1 83.582 loss 0.150 auroc 0.722 f1_score 0.114\n",
      "Epoch: [17]  [  0/161]  eta: 0:00:01  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8074 (0.8074)  total_loss: 5.6868 (5.6868)  time: 0.0091  data: 0.0003  max mem: 891\n",
      "Epoch: [17]  [100/161]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.9018 (6.7933)  time: 0.0137  data: 0.0015  max mem: 891\n",
      "Epoch: [17]  [160/161]  eta: 0:00:00  lr: 0.000092  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9690)  total_loss: 6.9150 (6.8183)  time: 0.0156  data: 0.0019  max mem: 891\n",
      "Epoch: [17] Total time: 0:00:02 (0.0149 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0495 (0.0495)  div_loss: -62.4086 (-62.4086)  acc1: 85.7143 (85.7143)  time: 0.0130  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0494 (0.2015)  div_loss: -49.3782 (-48.0778)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6451613306999207\n",
      "AUROC 3 : 0.8039215803146362\n",
      "AUROC 4 : 0.8098958730697632\n",
      "AUROC 5 : 0.46052634716033936\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.202 auroc 0.658 f1_score 0.187\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0928 (0.0928)  div_loss: -35.3170 (-35.3170)  acc1: 85.7143 (85.7143)  time: 0.0081  data: 0.0034  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0570 (0.1557)  div_loss: -41.6036 (-42.3360)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7523809671401978\n",
      "AUROC 1 : 0.6313559412956238\n",
      "AUROC 2 : 0.6282051205635071\n",
      "AUROC 3 : 0.9476190805435181\n",
      "AUROC 4 : 0.6964706182479858\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.6818181872367859\n",
      "* Acc@1 83.582 loss 0.156 auroc 0.720 f1_score 0.148\n",
      "Epoch: [18]  [  0/161]  eta: 0:00:01  lr: 0.000092  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6841 (5.6841)  time: 0.0095  data: 0.0003  max mem: 891\n",
      "Epoch: [18]  [100/161]  eta: 0:00:00  lr: 0.000092  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.8972 (6.7891)  time: 0.0155  data: 0.0018  max mem: 891\n",
      "Epoch: [18]  [160/161]  eta: 0:00:00  lr: 0.000091  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9690)  total_loss: 6.9117 (6.8139)  time: 0.0167  data: 0.0022  max mem: 891\n",
      "Epoch: [18] Total time: 0:00:02 (0.0161 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0468 (0.0468)  div_loss: -61.9848 (-61.9848)  acc1: 85.7143 (85.7143)  time: 0.0114  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0467 (0.2152)  div_loss: -48.9872 (-47.7149)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6344085931777954\n",
      "AUROC 3 : 0.7941176295280457\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.47368425130844116\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.215 auroc 0.656 f1_score 0.200\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1023 (0.1023)  div_loss: -34.9052 (-34.9052)  acc1: 85.7143 (85.7143)  time: 0.0061  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0532 (0.1617)  div_loss: -41.3244 (-41.9643)  acc1: 85.7143 (83.5821)  time: 0.0056  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.75\n",
      "AUROC 1 : 0.6355932354927063\n",
      "AUROC 2 : 0.6128205060958862\n",
      "AUROC 3 : 0.9523809552192688\n",
      "AUROC 4 : 0.6929411888122559\n",
      "AUROC 5 : 0.698051929473877\n",
      "AUROC 6 : 0.6833333373069763\n",
      "* Acc@1 83.582 loss 0.162 auroc 0.718 f1_score 0.171\n",
      "Epoch: [19]  [  0/161]  eta: 0:00:01  lr: 0.000091  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6820 (5.6820)  time: 0.0114  data: 0.0003  max mem: 891\n",
      "Epoch: [19]  [100/161]  eta: 0:00:00  lr: 0.000091  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9806 (0.9656)  total_loss: 6.8933 (6.7852)  time: 0.0142  data: 0.0017  max mem: 891\n",
      "Epoch: [19]  [160/161]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9690)  total_loss: 6.9088 (6.8098)  time: 0.0161  data: 0.0020  max mem: 891\n",
      "Epoch: [19] Total time: 0:00:02 (0.0158 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0430 (0.0430)  div_loss: -61.5290 (-61.5290)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0445 (0.2298)  div_loss: -48.6139 (-47.3455)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6308243870735168\n",
      "AUROC 3 : 0.7941176295280457\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.4868420958518982\n",
      "AUROC 6 : 0.477477490901947\n",
      "* Acc@1 83.571 loss 0.230 auroc 0.657 f1_score 0.200\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1126 (0.1126)  div_loss: -34.4944 (-34.4944)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0493 (0.1683)  div_loss: -41.0432 (-41.6022)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6398305296897888\n",
      "AUROC 2 : 0.6141026020050049\n",
      "AUROC 3 : 0.9595237970352173\n",
      "AUROC 4 : 0.6988235712051392\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.6878787875175476\n",
      "* Acc@1 83.582 loss 0.168 auroc 0.721 f1_score 0.185\n",
      "Epoch: [20]  [  0/161]  eta: 0:00:01  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6802 (5.6802)  time: 0.0097  data: 0.0003  max mem: 891\n",
      "Epoch: [20]  [100/161]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8899 (6.7817)  time: 0.0142  data: 0.0017  max mem: 891\n",
      "Epoch: [20]  [160/161]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0001)  att_loss: 0.9844 (0.9690)  total_loss: 6.9067 (6.8062)  time: 0.0152  data: 0.0020  max mem: 891\n",
      "Epoch: [20] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0392 (0.0392)  div_loss: -61.0452 (-61.0452)  acc1: 85.7143 (85.7143)  time: 0.0146  data: 0.0062  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0434 (0.2461)  div_loss: -48.2449 (-46.9662)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0108 s / it)\n",
      "AUROC 0 : 0.9142856597900391\n",
      "AUROC 1 : 0.49714288115501404\n",
      "AUROC 2 : 0.6200717091560364\n",
      "AUROC 3 : 0.7941176295280457\n",
      "AUROC 4 : 0.7942708730697632\n",
      "AUROC 5 : 0.4868420958518982\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.246 auroc 0.654 f1_score 0.200\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1211 (0.1211)  div_loss: -34.1283 (-34.1283)  acc1: 85.7143 (85.7143)  time: 0.0052  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0456 (0.1755)  div_loss: -40.7624 (-41.2460)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7404761910438538\n",
      "AUROC 1 : 0.6398305296897888\n",
      "AUROC 2 : 0.6102564334869385\n",
      "AUROC 3 : 0.9595237970352173\n",
      "AUROC 4 : 0.6952941417694092\n",
      "AUROC 5 : 0.6948052048683167\n",
      "AUROC 6 : 0.689393937587738\n",
      "* Acc@1 83.582 loss 0.176 auroc 0.719 f1_score 0.207\n",
      "Epoch: [21]  [  0/161]  eta: 0:00:02  lr: 0.000090  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8073 (0.8073)  total_loss: 5.6783 (5.6783)  time: 0.0144  data: 0.0003  max mem: 891\n",
      "Epoch: [21]  [100/161]  eta: 0:00:00  lr: 0.000089  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8854 (6.7786)  time: 0.0138  data: 0.0017  max mem: 891\n",
      "Epoch: [21]  [160/161]  eta: 0:00:00  lr: 0.000089  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.9025 (6.8029)  time: 0.0155  data: 0.0020  max mem: 891\n",
      "Epoch: [21] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0356 (0.0356)  div_loss: -60.5660 (-60.5660)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0449 (0.2633)  div_loss: -47.8745 (-46.5814)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9142856597900391\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6272401809692383\n",
      "AUROC 3 : 0.7941176295280457\n",
      "AUROC 4 : 0.7890625\n",
      "AUROC 5 : 0.4868420958518982\n",
      "AUROC 6 : 0.46846848726272583\n",
      "* Acc@1 83.571 loss 0.263 auroc 0.656 f1_score 0.205\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1296 (0.1296)  div_loss: -33.7816 (-33.7816)  acc1: 85.7143 (85.7143)  time: 0.0056  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0422 (0.1829)  div_loss: -40.4969 (-40.8919)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.740476131439209\n",
      "AUROC 1 : 0.6483050584793091\n",
      "AUROC 2 : 0.6051281690597534\n",
      "AUROC 3 : 0.9642857313156128\n",
      "AUROC 4 : 0.6964706182479858\n",
      "AUROC 5 : 0.698051929473877\n",
      "AUROC 6 : 0.6909090876579285\n",
      "* Acc@1 83.582 loss 0.183 auroc 0.721 f1_score 0.208\n",
      "Epoch: [22]  [  0/161]  eta: 0:00:01  lr: 0.000089  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6765 (5.6765)  time: 0.0122  data: 0.0002  max mem: 891\n",
      "Epoch: [22]  [100/161]  eta: 0:00:00  lr: 0.000088  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8845 (6.7758)  time: 0.0139  data: 0.0019  max mem: 891\n",
      "Epoch: [22]  [160/161]  eta: 0:00:00  lr: 0.000088  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.9004 (6.8000)  time: 0.0151  data: 0.0023  max mem: 891\n",
      "Epoch: [22] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0323 (0.0323)  div_loss: -60.0838 (-60.0838)  acc1: 85.7143 (85.7143)  time: 0.0115  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0419 (0.2801)  div_loss: -47.5022 (-46.1948)  acc1: 85.7143 (83.5714)  time: 0.0119  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.9142857193946838\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6236559152603149\n",
      "AUROC 3 : 0.7794117331504822\n",
      "AUROC 4 : 0.7864583134651184\n",
      "AUROC 5 : 0.5\n",
      "AUROC 6 : 0.477477490901947\n",
      "* Acc@1 83.571 loss 0.280 auroc 0.656 f1_score 0.205\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1373 (0.1373)  div_loss: -33.4288 (-33.4288)  acc1: 85.7143 (85.7143)  time: 0.0052  data: 0.0009  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0393 (0.1897)  div_loss: -40.2414 (-40.5341)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7428570985794067\n",
      "AUROC 1 : 0.6588982939720154\n",
      "AUROC 2 : 0.6000000238418579\n",
      "AUROC 3 : 0.9666666388511658\n",
      "AUROC 4 : 0.6929411888122559\n",
      "AUROC 5 : 0.701298713684082\n",
      "AUROC 6 : 0.6924242377281189\n",
      "* Acc@1 83.582 loss 0.190 auroc 0.722 f1_score 0.205\n",
      "Epoch: [23]  [  0/161]  eta: 0:00:01  lr: 0.000088  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6749 (5.6749)  time: 0.0090  data: 0.0002  max mem: 891\n",
      "Epoch: [23]  [100/161]  eta: 0:00:00  lr: 0.000087  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8825 (6.7733)  time: 0.0142  data: 0.0019  max mem: 891\n",
      "Epoch: [23]  [160/161]  eta: 0:00:00  lr: 0.000086  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8988 (6.7975)  time: 0.0154  data: 0.0020  max mem: 891\n",
      "Epoch: [23] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0298 (0.0298)  div_loss: -59.5957 (-59.5957)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0435 (0.2963)  div_loss: -47.1664 (-45.8212)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9085714817047119\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6379928588867188\n",
      "AUROC 3 : 0.7794117331504822\n",
      "AUROC 4 : 0.7838541865348816\n",
      "AUROC 5 : 0.5\n",
      "AUROC 6 : 0.477477490901947\n",
      "* Acc@1 83.571 loss 0.296 auroc 0.657 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1423 (0.1423)  div_loss: -33.1168 (-33.1168)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0369 (0.1965)  div_loss: -39.9925 (-40.1883)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.7452380657196045\n",
      "AUROC 1 : 0.6631355881690979\n",
      "AUROC 2 : 0.5948717594146729\n",
      "AUROC 3 : 0.9690476059913635\n",
      "AUROC 4 : 0.6952941417694092\n",
      "AUROC 5 : 0.6948052048683167\n",
      "AUROC 6 : 0.6924242377281189\n",
      "* Acc@1 83.582 loss 0.197 auroc 0.722 f1_score 0.202\n",
      "Epoch: [24]  [  0/161]  eta: 0:00:02  lr: 0.000086  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6735 (5.6735)  time: 0.0134  data: 0.0002  max mem: 891\n",
      "Epoch: [24]  [100/161]  eta: 0:00:00  lr: 0.000086  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8806 (6.7712)  time: 0.0138  data: 0.0015  max mem: 891\n",
      "Epoch: [24]  [160/161]  eta: 0:00:00  lr: 0.000085  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8976 (6.7953)  time: 0.0155  data: 0.0019  max mem: 891\n",
      "Epoch: [24] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0283 (0.0283)  div_loss: -59.0967 (-59.0967)  acc1: 85.7143 (85.7143)  time: 0.0120  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0457 (0.3132)  div_loss: -46.8672 (-45.4592)  acc1: 85.7143 (83.5714)  time: 0.0127  data: 0.0031  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6487455368041992\n",
      "AUROC 3 : 0.7794117331504822\n",
      "AUROC 4 : 0.78125\n",
      "AUROC 5 : 0.5263158082962036\n",
      "AUROC 6 : 0.4864864945411682\n",
      "* Acc@1 83.571 loss 0.313 auroc 0.663 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1455 (0.1455)  div_loss: -32.8223 (-32.8223)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0347 (0.2043)  div_loss: -39.7678 (-39.8631)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.75\n",
      "AUROC 1 : 0.6673728823661804\n",
      "AUROC 2 : 0.5948717594146729\n",
      "AUROC 3 : 0.9690476059913635\n",
      "AUROC 4 : 0.6941176652908325\n",
      "AUROC 5 : 0.7029221057891846\n",
      "AUROC 6 : 0.6909090280532837\n",
      "* Acc@1 83.582 loss 0.204 auroc 0.724 f1_score 0.211\n",
      "Epoch: [25]  [  0/161]  eta: 0:00:01  lr: 0.000085  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6720 (5.6720)  time: 0.0089  data: 0.0003  max mem: 891\n",
      "Epoch: [25]  [100/161]  eta: 0:00:00  lr: 0.000085  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8788 (6.7694)  time: 0.0137  data: 0.0016  max mem: 891\n",
      "Epoch: [25]  [160/161]  eta: 0:00:00  lr: 0.000084  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8966 (6.7934)  time: 0.0148  data: 0.0019  max mem: 891\n",
      "Epoch: [25] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0275 (0.0275)  div_loss: -58.6054 (-58.6054)  acc1: 85.7143 (85.7143)  time: 0.0118  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0481 (0.3305)  div_loss: -46.5978 (-45.1169)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.663082480430603\n",
      "AUROC 3 : 0.7745097875595093\n",
      "AUROC 4 : 0.7864583134651184\n",
      "AUROC 5 : 0.5263158082962036\n",
      "AUROC 6 : 0.4864864945411682\n",
      "* Acc@1 83.571 loss 0.331 auroc 0.666 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1488 (0.1488)  div_loss: -32.5129 (-32.5129)  acc1: 85.7143 (85.7143)  time: 0.0088  data: 0.0041  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0328 (0.2125)  div_loss: -39.5490 (-39.5588)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6716101765632629\n",
      "AUROC 2 : 0.5948717594146729\n",
      "AUROC 3 : 0.9690476059913635\n",
      "AUROC 4 : 0.6917647123336792\n",
      "AUROC 5 : 0.6996753215789795\n",
      "AUROC 6 : 0.6924241781234741\n",
      "* Acc@1 83.582 loss 0.213 auroc 0.724 f1_score 0.211\n",
      "Epoch: [26]  [  0/161]  eta: 0:00:01  lr: 0.000084  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6707 (5.6707)  time: 0.0086  data: 0.0003  max mem: 891\n",
      "Epoch: [26]  [100/161]  eta: 0:00:00  lr: 0.000084  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8771 (6.7678)  time: 0.0140  data: 0.0016  max mem: 891\n",
      "Epoch: [26]  [160/161]  eta: 0:00:00  lr: 0.000083  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8958 (6.7919)  time: 0.0155  data: 0.0028  max mem: 891\n",
      "Epoch: [26] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0272 (0.0272)  div_loss: -58.1216 (-58.1216)  acc1: 85.7143 (85.7143)  time: 0.0181  data: 0.0071  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0504 (0.3475)  div_loss: -46.3692 (-44.8052)  acc1: 85.7143 (83.5714)  time: 0.0116  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0101 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.7794117331504822\n",
      "AUROC 4 : 0.7890625\n",
      "AUROC 5 : 0.5263158082962036\n",
      "AUROC 6 : 0.4864864945411682\n",
      "* Acc@1 83.571 loss 0.348 auroc 0.667 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1502 (0.1502)  div_loss: -32.2530 (-32.2530)  acc1: 85.7143 (85.7143)  time: 0.0045  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0312 (0.2212)  div_loss: -39.3583 (-39.2870)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7476190328598022\n",
      "AUROC 1 : 0.6822034120559692\n",
      "AUROC 2 : 0.5935897827148438\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6917647123336792\n",
      "AUROC 5 : 0.6996753215789795\n",
      "AUROC 6 : 0.6939393281936646\n",
      "* Acc@1 83.582 loss 0.221 auroc 0.726 f1_score 0.220\n",
      "Epoch: [27]  [  0/161]  eta: 0:00:01  lr: 0.000083  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6695 (5.6695)  time: 0.0122  data: 0.0002  max mem: 891\n",
      "Epoch: [27]  [100/161]  eta: 0:00:00  lr: 0.000082  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8755 (6.7665)  time: 0.0137  data: 0.0017  max mem: 891\n",
      "Epoch: [27]  [160/161]  eta: 0:00:00  lr: 0.000082  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8951 (6.7906)  time: 0.0151  data: 0.0020  max mem: 891\n",
      "Epoch: [27] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0272 (0.0272)  div_loss: -57.6216 (-57.6216)  acc1: 85.7143 (85.7143)  time: 0.0114  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0523 (0.3641)  div_loss: -46.1745 (-44.5254)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0109 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.508571445941925\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.779411792755127\n",
      "AUROC 4 : 0.7864583134651184\n",
      "AUROC 5 : 0.5394736528396606\n",
      "AUROC 6 : 0.4954954981803894\n",
      "* Acc@1 83.571 loss 0.364 auroc 0.670 f1_score 0.245\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1505 (0.1505)  div_loss: -32.0164 (-32.0164)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0298 (0.2304)  div_loss: -39.1938 (-39.0515)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7428570985794067\n",
      "AUROC 1 : 0.6822034120559692\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6941176652908325\n",
      "AUROC 5 : 0.6964285373687744\n",
      "AUROC 6 : 0.6969696879386902\n",
      "* Acc@1 83.582 loss 0.230 auroc 0.726 f1_score 0.252\n",
      "Epoch: [28]  [  0/161]  eta: 0:00:02  lr: 0.000082  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6683 (5.6683)  time: 0.0131  data: 0.0002  max mem: 891\n",
      "Epoch: [28]  [100/161]  eta: 0:00:00  lr: 0.000081  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8740 (6.7654)  time: 0.0141  data: 0.0017  max mem: 891\n",
      "Epoch: [28]  [160/161]  eta: 0:00:00  lr: 0.000081  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8945 (6.7895)  time: 0.0159  data: 0.0021  max mem: 891\n",
      "Epoch: [28] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0277 (0.0277)  div_loss: -57.1130 (-57.1130)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0539 (0.3803)  div_loss: -45.9924 (-44.2676)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5028571486473083\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7890625\n",
      "AUROC 5 : 0.5394736528396606\n",
      "AUROC 6 : 0.4954954981803894\n",
      "* Acc@1 83.571 loss 0.380 auroc 0.671 f1_score 0.227\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1511 (0.1511)  div_loss: -31.7932 (-31.7932)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0287 (0.2400)  div_loss: -39.0331 (-38.8315)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7452380657196045\n",
      "AUROC 1 : 0.6822034120559692\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.9738094806671143\n",
      "AUROC 4 : 0.6941176652908325\n",
      "AUROC 5 : 0.6964285373687744\n",
      "AUROC 6 : 0.6924242377281189\n",
      "* Acc@1 83.582 loss 0.240 auroc 0.725 f1_score 0.252\n",
      "Epoch: [29]  [  0/161]  eta: 0:00:01  lr: 0.000081  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6671 (5.6671)  time: 0.0122  data: 0.0003  max mem: 891\n",
      "Epoch: [29]  [100/161]  eta: 0:00:00  lr: 0.000080  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8727 (6.7645)  time: 0.0137  data: 0.0016  max mem: 891\n",
      "Epoch: [29]  [160/161]  eta: 0:00:00  lr: 0.000079  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8940 (6.7886)  time: 0.0155  data: 0.0022  max mem: 891\n",
      "Epoch: [29] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0285 (0.0285)  div_loss: -56.6357 (-56.6357)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0555 (0.3958)  div_loss: -45.8366 (-44.0421)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0101 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5028571486473083\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7890625\n",
      "AUROC 5 : 0.5394736528396606\n",
      "AUROC 6 : 0.4954954981803894\n",
      "* Acc@1 83.571 loss 0.396 auroc 0.671 f1_score 0.245\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1495 (0.1495)  div_loss: -31.6272 (-31.6272)  acc1: 85.7143 (85.7143)  time: 0.0045  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0280 (0.2499)  div_loss: -38.9039 (-38.6403)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0063 s / it)\n",
      "AUROC 0 : 0.7404761910438538\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5846153497695923\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6894117593765259\n",
      "AUROC 5 : 0.6883116960525513\n",
      "AUROC 6 : 0.6893938779830933\n",
      "* Acc@1 83.582 loss 0.250 auroc 0.722 f1_score 0.266\n",
      "Epoch: [30]  [  0/161]  eta: 0:00:01  lr: 0.000079  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6659 (5.6659)  time: 0.0115  data: 0.0003  max mem: 891\n",
      "Epoch: [30]  [100/161]  eta: 0:00:00  lr: 0.000079  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8714 (6.7637)  time: 0.0139  data: 0.0017  max mem: 891\n",
      "Epoch: [30]  [160/161]  eta: 0:00:00  lr: 0.000078  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8936 (6.7878)  time: 0.0155  data: 0.0021  max mem: 891\n",
      "Epoch: [30] Total time: 0:00:02 (0.0149 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0296 (0.0296)  div_loss: -56.2672 (-56.2672)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0572 (0.4109)  div_loss: -45.7117 (-43.8598)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7890625\n",
      "AUROC 5 : 0.5526315569877625\n",
      "AUROC 6 : 0.5045045018196106\n",
      "* Acc@1 83.571 loss 0.411 auroc 0.676 f1_score 0.245\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1467 (0.1467)  div_loss: -31.4949 (-31.4949)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0273 (0.2599)  div_loss: -38.8054 (-38.4828)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7404761910438538\n",
      "AUROC 1 : 0.688559353351593\n",
      "AUROC 2 : 0.576923131942749\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6882352828979492\n",
      "AUROC 5 : 0.6834415793418884\n",
      "AUROC 6 : 0.689393937587738\n",
      "* Acc@1 83.582 loss 0.260 auroc 0.720 f1_score 0.267\n",
      "Epoch: [31]  [  0/161]  eta: 0:00:01  lr: 0.000078  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6649 (5.6649)  time: 0.0088  data: 0.0003  max mem: 891\n",
      "Epoch: [31]  [100/161]  eta: 0:00:00  lr: 0.000077  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8704 (6.7631)  time: 0.0141  data: 0.0020  max mem: 891\n",
      "Epoch: [31]  [160/161]  eta: 0:00:00  lr: 0.000077  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8933 (6.7872)  time: 0.0151  data: 0.0021  max mem: 891\n",
      "Epoch: [31] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0314 (0.0314)  div_loss: -55.9614 (-55.9614)  acc1: 85.7143 (85.7143)  time: 0.0165  data: 0.0036  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0593 (0.4252)  div_loss: -45.6186 (-43.7227)  acc1: 85.7143 (83.5714)  time: 0.0118  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5199999809265137\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7864583134651184\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5135135650634766\n",
      "* Acc@1 83.571 loss 0.425 auroc 0.679 f1_score 0.253\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1427 (0.1427)  div_loss: -31.4390 (-31.4390)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0271 (0.2701)  div_loss: -38.6708 (-38.3667)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0008  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7452381253242493\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5769230723381042\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6882352828979492\n",
      "AUROC 5 : 0.6818181872367859\n",
      "AUROC 6 : 0.6939393877983093\n",
      "* Acc@1 83.582 loss 0.270 auroc 0.722 f1_score 0.265\n",
      "Epoch: [32]  [  0/161]  eta: 0:00:01  lr: 0.000077  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6638 (5.6638)  time: 0.0120  data: 0.0003  max mem: 891\n",
      "Epoch: [32]  [100/161]  eta: 0:00:00  lr: 0.000076  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8694 (6.7626)  time: 0.0138  data: 0.0017  max mem: 891\n",
      "Epoch: [32]  [160/161]  eta: 0:00:00  lr: 0.000075  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8930 (6.7867)  time: 0.0156  data: 0.0023  max mem: 891\n",
      "Epoch: [32] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0334 (0.0334)  div_loss: -55.6893 (-55.6893)  acc1: 85.7143 (85.7143)  time: 0.0117  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0605 (0.4388)  div_loss: -45.5540 (-43.6158)  acc1: 85.7143 (83.5714)  time: 0.0126  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7864583134651184\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5225225687026978\n",
      "* Acc@1 83.571 loss 0.439 auroc 0.681 f1_score 0.273\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1392 (0.1392)  div_loss: -31.3718 (-31.3718)  acc1: 85.7143 (85.7143)  time: 0.0083  data: 0.0032  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0264 (0.2800)  div_loss: -38.5273 (-38.2769)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0071 s / it)\n",
      "AUROC 0 : 0.7428570985794067\n",
      "AUROC 1 : 0.6949152946472168\n",
      "AUROC 2 : 0.5743589401245117\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6917647123336792\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.6939393877983093\n",
      "* Acc@1 83.582 loss 0.280 auroc 0.722 f1_score 0.265\n",
      "Epoch: [33]  [  0/161]  eta: 0:00:01  lr: 0.000075  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6628 (5.6628)  time: 0.0092  data: 0.0002  max mem: 891\n",
      "Epoch: [33]  [100/161]  eta: 0:00:00  lr: 0.000075  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8686 (6.7622)  time: 0.0138  data: 0.0020  max mem: 891\n",
      "Epoch: [33]  [160/161]  eta: 0:00:00  lr: 0.000074  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8927 (6.7863)  time: 0.0153  data: 0.0021  max mem: 891\n",
      "Epoch: [33] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0361 (0.0361)  div_loss: -55.4823 (-55.4823)  acc1: 85.7143 (85.7143)  time: 0.0143  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0620 (0.4516)  div_loss: -45.5274 (-43.5399)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5199999809265137\n",
      "AUROC 2 : 0.663082480430603\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7916666269302368\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5405405759811401\n",
      "* Acc@1 83.571 loss 0.452 auroc 0.682 f1_score 0.251\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1326 (0.1326)  div_loss: -31.4027 (-31.4027)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0261 (0.2902)  div_loss: -38.4212 (-38.2176)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.740476131439209\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5730769038200378\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6929411888122559\n",
      "AUROC 5 : 0.676948070526123\n",
      "AUROC 6 : 0.6924242377281189\n",
      "* Acc@1 83.582 loss 0.290 auroc 0.721 f1_score 0.259\n",
      "Epoch: [34]  [  0/161]  eta: 0:00:01  lr: 0.000074  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6618 (5.6618)  time: 0.0100  data: 0.0002  max mem: 891\n",
      "Epoch: [34]  [100/161]  eta: 0:00:00  lr: 0.000073  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8679 (6.7618)  time: 0.0140  data: 0.0017  max mem: 891\n",
      "Epoch: [34]  [160/161]  eta: 0:00:00  lr: 0.000073  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8925 (6.7860)  time: 0.0151  data: 0.0019  max mem: 891\n",
      "Epoch: [34] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0389 (0.0389)  div_loss: -55.2978 (-55.2978)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0633 (0.4639)  div_loss: -45.5071 (-43.4846)  acc1: 85.7143 (83.5714)  time: 0.0119  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0101 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.663082480430603\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7942708134651184\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5405405759811401\n",
      "* Acc@1 83.571 loss 0.464 auroc 0.683 f1_score 0.270\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1326 (0.1326)  div_loss: -31.3598 (-31.3598)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0279 (0.2985)  div_loss: -38.3188 (-38.1705)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.740476131439209\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.571794867515564\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6917647123336792\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.6924242377281189\n",
      "* Acc@1 83.582 loss 0.299 auroc 0.720 f1_score 0.259\n",
      "Epoch: [35]  [  0/161]  eta: 0:00:01  lr: 0.000073  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6609 (5.6609)  time: 0.0099  data: 0.0005  max mem: 891\n",
      "Epoch: [35]  [100/161]  eta: 0:00:00  lr: 0.000072  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8675 (6.7615)  time: 0.0140  data: 0.0018  max mem: 891\n",
      "Epoch: [35]  [160/161]  eta: 0:00:00  lr: 0.000071  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8924 (6.7857)  time: 0.0154  data: 0.0020  max mem: 891\n",
      "Epoch: [35] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0421 (0.0421)  div_loss: -55.1930 (-55.1930)  acc1: 85.7143 (85.7143)  time: 0.0128  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0643 (0.4762)  div_loss: -45.5194 (-43.4541)  acc1: 85.7143 (83.5714)  time: 0.0125  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5142857432365417\n",
      "AUROC 2 : 0.6666666865348816\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5675675868988037\n",
      "* Acc@1 83.571 loss 0.476 auroc 0.686 f1_score 0.251\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1212 (0.1212)  div_loss: -31.4992 (-31.4992)  acc1: 85.7143 (85.7143)  time: 0.0055  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0307 (0.3099)  div_loss: -38.2598 (-38.1545)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7428571581840515\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.571794867515564\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6894117593765259\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.6924242377281189\n",
      "* Acc@1 83.582 loss 0.310 auroc 0.720 f1_score 0.269\n",
      "Epoch: [36]  [  0/161]  eta: 0:00:01  lr: 0.000071  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6600 (5.6600)  time: 0.0091  data: 0.0003  max mem: 891\n",
      "Epoch: [36]  [100/161]  eta: 0:00:00  lr: 0.000070  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8668 (6.7613)  time: 0.0147  data: 0.0016  max mem: 891\n",
      "Epoch: [36]  [160/161]  eta: 0:00:00  lr: 0.000070  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8922 (6.7855)  time: 0.0152  data: 0.0027  max mem: 891\n",
      "Epoch: [36] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0450 (0.0450)  div_loss: -55.0660 (-55.0660)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0658 (0.4866)  div_loss: -45.5110 (-43.4309)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5257142782211304\n",
      "AUROC 2 : 0.6666666865348816\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.7942708134651184\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5585585832595825\n",
      "* Acc@1 83.571 loss 0.487 auroc 0.687 f1_score 0.270\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1276 (0.1276)  div_loss: -31.3937 (-31.3937)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0327 (0.3145)  div_loss: -38.1801 (-38.1347)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.75\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.5653846263885498\n",
      "AUROC 3 : 0.976190447807312\n",
      "AUROC 4 : 0.6941176652908325\n",
      "AUROC 5 : 0.6753246784210205\n",
      "AUROC 6 : 0.6954545378684998\n",
      "* Acc@1 83.582 loss 0.315 auroc 0.721 f1_score 0.271\n",
      "Epoch: [37]  [  0/161]  eta: 0:00:02  lr: 0.000070  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6592 (5.6592)  time: 0.0127  data: 0.0003  max mem: 891\n",
      "Epoch: [37]  [100/161]  eta: 0:00:00  lr: 0.000069  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8668 (6.7611)  time: 0.0133  data: 0.0016  max mem: 891\n",
      "Epoch: [37]  [160/161]  eta: 0:00:00  lr: 0.000068  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8921 (6.7853)  time: 0.0148  data: 0.0020  max mem: 891\n",
      "Epoch: [37] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0487 (0.0487)  div_loss: -55.0600 (-55.0600)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0638 (0.5001)  div_loss: -45.5881 (-43.4539)  acc1: 85.7143 (83.5714)  time: 0.0120  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5199999809265137\n",
      "AUROC 2 : 0.6702508926391602\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.7942707538604736\n",
      "AUROC 5 : 0.5657894611358643\n",
      "AUROC 6 : 0.5675675868988037\n",
      "* Acc@1 83.571 loss 0.500 auroc 0.688 f1_score 0.251\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1102 (0.1102)  div_loss: -31.7060 (-31.7060)  acc1: 85.7143 (85.7143)  time: 0.0078  data: 0.0028  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0358 (0.3298)  div_loss: -38.1949 (-38.1731)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7523809671401978\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5692307949066162\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6882352828979492\n",
      "AUROC 5 : 0.673701286315918\n",
      "AUROC 6 : 0.6969696879386902\n",
      "* Acc@1 83.582 loss 0.330 auroc 0.721 f1_score 0.267\n",
      "Epoch: [38]  [  0/161]  eta: 0:00:01  lr: 0.000068  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6585 (5.6585)  time: 0.0106  data: 0.0002  max mem: 891\n",
      "Epoch: [38]  [100/161]  eta: 0:00:00  lr: 0.000067  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8661 (6.7609)  time: 0.0159  data: 0.0029  max mem: 891\n",
      "Epoch: [38]  [160/161]  eta: 0:00:00  lr: 0.000067  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8920 (6.7851)  time: 0.0146  data: 0.0019  max mem: 891\n",
      "Epoch: [38] Total time: 0:00:02 (0.0155 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0506 (0.0506)  div_loss: -54.9234 (-54.9234)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0671 (0.5061)  div_loss: -45.5643 (-43.4454)  acc1: 85.7143 (83.5714)  time: 0.0119  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5428571701049805\n",
      "AUROC 2 : 0.6702508926391602\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.8020833134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.5675675868988037\n",
      "* Acc@1 83.571 loss 0.506 auroc 0.694 f1_score 0.261\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1269 (0.1269)  div_loss: -31.4689 (-31.4689)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0362 (0.3258)  div_loss: -38.1200 (-38.1621)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7523809671401978\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5666667222976685\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.6952941417694092\n",
      "AUROC 5 : 0.6688311696052551\n",
      "AUROC 6 : 0.6954545378684998\n",
      "* Acc@1 83.582 loss 0.326 auroc 0.721 f1_score 0.271\n",
      "Epoch: [39]  [  0/161]  eta: 0:00:01  lr: 0.000067  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6577 (5.6577)  time: 0.0093  data: 0.0002  max mem: 891\n",
      "Epoch: [39]  [100/161]  eta: 0:00:00  lr: 0.000066  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8663 (6.7608)  time: 0.0142  data: 0.0016  max mem: 891\n",
      "Epoch: [39]  [160/161]  eta: 0:00:00  lr: 0.000065  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8918 (6.7849)  time: 0.0152  data: 0.0019  max mem: 891\n",
      "Epoch: [39] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0545 (0.0545)  div_loss: -55.0411 (-55.0411)  acc1: 85.7143 (85.7143)  time: 0.0109  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0670 (0.5220)  div_loss: -45.6855 (-43.5207)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0109 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5485714673995972\n",
      "AUROC 2 : 0.6666666865348816\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7942708134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6036036014556885\n",
      "* Acc@1 83.571 loss 0.522 auroc 0.698 f1_score 0.251\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0996 (0.0996)  div_loss: -31.9326 (-31.9326)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0399 (0.3482)  div_loss: -38.1903 (-38.2552)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7523809671401978\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5705127716064453\n",
      "AUROC 3 : 0.9809523820877075\n",
      "AUROC 4 : 0.6929411888122559\n",
      "AUROC 5 : 0.6672077775001526\n",
      "AUROC 6 : 0.6893938779830933\n",
      "* Acc@1 83.582 loss 0.348 auroc 0.720 f1_score 0.267\n",
      "Epoch: [40]  [  0/161]  eta: 0:00:01  lr: 0.000065  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6572 (5.6572)  time: 0.0079  data: 0.0003  max mem: 891\n",
      "Epoch: [40]  [100/161]  eta: 0:00:00  lr: 0.000065  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8656 (6.7606)  time: 0.0140  data: 0.0016  max mem: 891\n",
      "Epoch: [40]  [160/161]  eta: 0:00:00  lr: 0.000064  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8918 (6.7848)  time: 0.0159  data: 0.0024  max mem: 891\n",
      "Epoch: [40] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0550 (0.0550)  div_loss: -54.8953 (-54.8953)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0663 (0.5244)  div_loss: -45.6668 (-43.5239)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9085714221000671\n",
      "AUROC 1 : 0.5542857050895691\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.796875\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.5765765905380249\n",
      "* Acc@1 83.571 loss 0.524 auroc 0.696 f1_score 0.261\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1231 (0.1231)  div_loss: -31.5898 (-31.5898)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0387 (0.3397)  div_loss: -38.1088 (-38.2624)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7571428418159485\n",
      "AUROC 1 : 0.6970338821411133\n",
      "AUROC 2 : 0.5692307949066162\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.703529417514801\n",
      "AUROC 5 : 0.6704545617103577\n",
      "AUROC 6 : 0.6984848976135254\n",
      "* Acc@1 83.582 loss 0.340 auroc 0.725 f1_score 0.267\n",
      "Epoch: [41]  [  0/161]  eta: 0:00:02  lr: 0.000064  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6565 (5.6565)  time: 0.0132  data: 0.0003  max mem: 891\n",
      "Epoch: [41]  [100/161]  eta: 0:00:00  lr: 0.000063  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8658 (6.7605)  time: 0.0143  data: 0.0019  max mem: 891\n",
      "Epoch: [41]  [160/161]  eta: 0:00:00  lr: 0.000062  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8917 (6.7847)  time: 0.0154  data: 0.0022  max mem: 891\n",
      "Epoch: [41] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0582 (0.0582)  div_loss: -55.0689 (-55.0689)  acc1: 85.7143 (85.7143)  time: 0.0099  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0669 (0.5397)  div_loss: -45.7684 (-43.6122)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0030  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5542857050895691\n",
      "AUROC 2 : 0.6702508926391602\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6126126050949097\n",
      "* Acc@1 83.571 loss 0.540 auroc 0.700 f1_score 0.275\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0925 (0.0925)  div_loss: -32.0882 (-32.0882)  acc1: 85.7143 (85.7143)  time: 0.0094  data: 0.0042  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0424 (0.3634)  div_loss: -38.1950 (-38.3610)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7571428418159485\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5679486989974976\n",
      "AUROC 3 : 0.9809523820877075\n",
      "AUROC 4 : 0.6929411888122559\n",
      "AUROC 5 : 0.6607142686843872\n",
      "AUROC 6 : 0.6969696879386902\n",
      "* Acc@1 83.582 loss 0.363 auroc 0.720 f1_score 0.267\n",
      "Epoch: [42]  [  0/161]  eta: 0:00:02  lr: 0.000062  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6562 (5.6562)  time: 0.0152  data: 0.0003  max mem: 891\n",
      "Epoch: [42]  [100/161]  eta: 0:00:00  lr: 0.000061  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8653 (6.7604)  time: 0.0154  data: 0.0018  max mem: 891\n",
      "Epoch: [42]  [160/161]  eta: 0:00:00  lr: 0.000061  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8916 (6.7846)  time: 0.0153  data: 0.0020  max mem: 891\n",
      "Epoch: [42] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0593 (0.0593)  div_loss: -54.9695 (-54.9695)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0674 (0.5421)  div_loss: -45.8158 (-43.6394)  acc1: 85.7143 (83.5714)  time: 0.0129  data: 0.0032  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0108 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5714285373687744\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.8020833134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.5765765905380249\n",
      "* Acc@1 83.571 loss 0.542 auroc 0.699 f1_score 0.261\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1158 (0.1158)  div_loss: -31.7291 (-31.7291)  acc1: 85.7143 (85.7143)  time: 0.0045  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0393 (0.3533)  div_loss: -38.0808 (-38.4029)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7547618746757507\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.5705128312110901\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.7023530006408691\n",
      "AUROC 5 : 0.6655844449996948\n",
      "AUROC 6 : 0.7000000476837158\n",
      "* Acc@1 83.582 loss 0.353 auroc 0.724 f1_score 0.269\n",
      "Epoch: [43]  [  0/161]  eta: 0:00:01  lr: 0.000061  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8072 (0.8072)  total_loss: 5.6556 (5.6556)  time: 0.0088  data: 0.0002  max mem: 891\n",
      "Epoch: [43]  [100/161]  eta: 0:00:00  lr: 0.000060  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8654 (6.7603)  time: 0.0143  data: 0.0018  max mem: 891\n",
      "Epoch: [43]  [160/161]  eta: 0:00:00  lr: 0.000059  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8915 (6.7845)  time: 0.0157  data: 0.0021  max mem: 891\n",
      "Epoch: [43] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0610 (0.0610)  div_loss: -55.1471 (-55.1471)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0672 (0.5559)  div_loss: -45.8905 (-43.7349)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5542857050895691\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.7994791269302368\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6216216683387756\n",
      "* Acc@1 83.571 loss 0.556 auroc 0.702 f1_score 0.275\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0893 (0.0893)  div_loss: -32.2965 (-32.2965)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0424 (0.3762)  div_loss: -38.2054 (-38.4895)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7595238089561462\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5730769634246826\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.6952941417694092\n",
      "AUROC 5 : 0.6639610528945923\n",
      "AUROC 6 : 0.6984848380088806\n",
      "* Acc@1 83.582 loss 0.376 auroc 0.723 f1_score 0.267\n",
      "Epoch: [44]  [  0/161]  eta: 0:00:01  lr: 0.000059  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6553 (5.6553)  time: 0.0105  data: 0.0002  max mem: 891\n",
      "Epoch: [44]  [100/161]  eta: 0:00:00  lr: 0.000058  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8651 (6.7602)  time: 0.0145  data: 0.0019  max mem: 891\n",
      "Epoch: [44]  [160/161]  eta: 0:00:00  lr: 0.000058  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8914 (6.7844)  time: 0.0158  data: 0.0025  max mem: 891\n",
      "Epoch: [44] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0616 (0.0616)  div_loss: -55.0472 (-55.0472)  acc1: 85.7143 (85.7143)  time: 0.0183  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0672 (0.5577)  div_loss: -45.9620 (-43.7733)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5828571319580078\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.8046874403953552\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.5855855941772461\n",
      "* Acc@1 83.571 loss 0.558 auroc 0.702 f1_score 0.261\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1074 (0.1074)  div_loss: -31.9962 (-31.9962)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0401 (0.3661)  div_loss: -38.1647 (-38.5539)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7595237493515015\n",
      "AUROC 1 : 0.6949152946472168\n",
      "AUROC 2 : 0.5730769038200378\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.7047059535980225\n",
      "AUROC 5 : 0.6639610528945923\n",
      "AUROC 6 : 0.695454478263855\n",
      "* Acc@1 83.582 loss 0.366 auroc 0.724 f1_score 0.269\n",
      "Epoch: [45]  [  0/161]  eta: 0:00:01  lr: 0.000058  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6548 (5.6548)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [45]  [100/161]  eta: 0:00:00  lr: 0.000057  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8652 (6.7601)  time: 0.0137  data: 0.0016  max mem: 891\n",
      "Epoch: [45]  [160/161]  eta: 0:00:00  lr: 0.000056  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8914 (6.7843)  time: 0.0153  data: 0.0019  max mem: 891\n",
      "Epoch: [45] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0622 (0.0622)  div_loss: -55.2487 (-55.2487)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0616 (0.5732)  div_loss: -45.9974 (-43.8537)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0109 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.6738351583480835\n",
      "AUROC 3 : 0.7843136787414551\n",
      "AUROC 4 : 0.8020833134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.573 auroc 0.705 f1_score 0.275\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0807 (0.0807)  div_loss: -32.4941 (-32.4941)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0421 (0.3893)  div_loss: -38.2194 (-38.6219)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0008  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.764285683631897\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5743589997291565\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.6988235712051392\n",
      "AUROC 5 : 0.6623376607894897\n",
      "AUROC 6 : 0.6984848976135254\n",
      "* Acc@1 83.582 loss 0.389 auroc 0.725 f1_score 0.267\n",
      "Epoch: [46]  [  0/161]  eta: 0:00:01  lr: 0.000056  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6546 (5.6546)  time: 0.0089  data: 0.0003  max mem: 891\n",
      "Epoch: [46]  [100/161]  eta: 0:00:00  lr: 0.000055  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8649 (6.7601)  time: 0.0141  data: 0.0015  max mem: 891\n",
      "Epoch: [46]  [160/161]  eta: 0:00:00  lr: 0.000055  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8913 (6.7843)  time: 0.0162  data: 0.0026  max mem: 891\n",
      "Epoch: [46] Total time: 0:00:02 (0.0156 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0635 (0.0635)  div_loss: -55.1371 (-55.1371)  acc1: 85.7143 (85.7143)  time: 0.0111  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0657 (0.5722)  div_loss: -46.0579 (-43.8893)  acc1: 85.7143 (83.5714)  time: 0.0119  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0101 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5942857265472412\n",
      "AUROC 2 : 0.6774194240570068\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020832538604736\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6036036610603333\n",
      "* Acc@1 83.571 loss 0.572 auroc 0.707 f1_score 0.261\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1072 (0.1072)  div_loss: -32.1316 (-32.1316)  acc1: 85.7143 (85.7143)  time: 0.0096  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0386 (0.3780)  div_loss: -38.2124 (-38.6763)  acc1: 85.7143 (83.5821)  time: 0.0064  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7619047164916992\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5730769634246826\n",
      "AUROC 3 : 0.9785714149475098\n",
      "AUROC 4 : 0.7070589065551758\n",
      "AUROC 5 : 0.6607142686843872\n",
      "AUROC 6 : 0.7015151381492615\n",
      "* Acc@1 83.582 loss 0.378 auroc 0.724 f1_score 0.281\n",
      "Epoch: [47]  [  0/161]  eta: 0:00:01  lr: 0.000055  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6542 (5.6542)  time: 0.0104  data: 0.0002  max mem: 891\n",
      "Epoch: [47]  [100/161]  eta: 0:00:00  lr: 0.000054  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8650 (6.7600)  time: 0.0138  data: 0.0016  max mem: 891\n",
      "Epoch: [47]  [160/161]  eta: 0:00:00  lr: 0.000053  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8914 (6.7842)  time: 0.0156  data: 0.0020  max mem: 891\n",
      "Epoch: [47] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0619 (0.0619)  div_loss: -55.3452 (-55.3452)  acc1: 85.7143 (85.7143)  time: 0.0117  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0606 (0.5860)  div_loss: -46.0666 (-43.9702)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.6774193644523621\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8098958134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.586 auroc 0.707 f1_score 0.275\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0754 (0.0754)  div_loss: -32.6474 (-32.6474)  acc1: 85.7143 (85.7143)  time: 0.0066  data: 0.0024  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0400 (0.3991)  div_loss: -38.2463 (-38.7419)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7666666507720947\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5730769634246826\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7047059535980225\n",
      "AUROC 5 : 0.6639610528945923\n",
      "AUROC 6 : 0.7000000476837158\n",
      "* Acc@1 83.582 loss 0.399 auroc 0.726 f1_score 0.267\n",
      "Epoch: [48]  [  0/161]  eta: 0:00:01  lr: 0.000053  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6541 (5.6541)  time: 0.0109  data: 0.0002  max mem: 891\n",
      "Epoch: [48]  [100/161]  eta: 0:00:00  lr: 0.000052  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8648 (6.7600)  time: 0.0145  data: 0.0021  max mem: 891\n",
      "Epoch: [48]  [160/161]  eta: 0:00:00  lr: 0.000052  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7842)  time: 0.0158  data: 0.0024  max mem: 891\n",
      "Epoch: [48] Total time: 0:00:02 (0.0155 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0645 (0.0645)  div_loss: -55.2559 (-55.2559)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0614 (0.5858)  div_loss: -46.1888 (-44.0256)  acc1: 85.7143 (83.5714)  time: 0.0119  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5942857265472412\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6216216683387756\n",
      "* Acc@1 83.571 loss 0.586 auroc 0.711 f1_score 0.270\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.1003 (0.1003)  div_loss: -32.3296 (-32.3296)  acc1: 85.7143 (85.7143)  time: 0.0052  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0326 (0.3877)  div_loss: -38.2850 (-38.8250)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.9809523820877075\n",
      "AUROC 4 : 0.7117646932601929\n",
      "AUROC 5 : 0.6607142686843872\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.388 auroc 0.728 f1_score 0.281\n",
      "Epoch: [49]  [  0/161]  eta: 0:00:01  lr: 0.000052  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6537 (5.6537)  time: 0.0122  data: 0.0003  max mem: 891\n",
      "Epoch: [49]  [100/161]  eta: 0:00:00  lr: 0.000051  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8649 (6.7599)  time: 0.0146  data: 0.0017  max mem: 891\n",
      "Epoch: [49]  [160/161]  eta: 0:00:00  lr: 0.000050  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8913 (6.7841)  time: 0.0152  data: 0.0020  max mem: 891\n",
      "Epoch: [49] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0638 (0.0638)  div_loss: -55.4350 (-55.4350)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0581 (0.6003)  div_loss: -46.1861 (-44.0985)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5600000023841858\n",
      "AUROC 2 : 0.6774193644523621\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020833134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.600 auroc 0.706 f1_score 0.282\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0715 (0.0715)  div_loss: -32.8353 (-32.8353)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0404 (0.4114)  div_loss: -38.3645 (-38.8779)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.776190459728241\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5769230723381042\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7058824300765991\n",
      "AUROC 5 : 0.6672078371047974\n",
      "AUROC 6 : 0.6984848380088806\n",
      "* Acc@1 83.582 loss 0.411 auroc 0.728 f1_score 0.265\n",
      "Epoch: [50]  [  0/161]  eta: 0:00:01  lr: 0.000050  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6535 (5.6535)  time: 0.0105  data: 0.0003  max mem: 891\n",
      "Epoch: [50]  [100/161]  eta: 0:00:00  lr: 0.000049  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8646 (6.7598)  time: 0.0133  data: 0.0015  max mem: 891\n",
      "Epoch: [50]  [160/161]  eta: 0:00:00  lr: 0.000048  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7840)  time: 0.0149  data: 0.0018  max mem: 891\n",
      "Epoch: [50] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0635 (0.0635)  div_loss: -55.3496 (-55.3496)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0578 (0.5968)  div_loss: -46.2645 (-44.1408)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8098958134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.597 auroc 0.713 f1_score 0.270\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0947 (0.0947)  div_loss: -32.4998 (-32.4998)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0273 (0.3971)  div_loss: -38.3364 (-38.9401)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.778571367263794\n",
      "AUROC 1 : 0.6927966475486755\n",
      "AUROC 2 : 0.571794867515564\n",
      "AUROC 3 : 0.9809523820877075\n",
      "AUROC 4 : 0.7152941226959229\n",
      "AUROC 5 : 0.6607142686843872\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.397 auroc 0.729 f1_score 0.281\n",
      "Epoch: [51]  [  0/161]  eta: 0:00:01  lr: 0.000048  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6532 (5.6532)  time: 0.0113  data: 0.0002  max mem: 891\n",
      "Epoch: [51]  [100/161]  eta: 0:00:00  lr: 0.000047  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8648 (6.7598)  time: 0.0136  data: 0.0015  max mem: 891\n",
      "Epoch: [51]  [160/161]  eta: 0:00:00  lr: 0.000047  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7840)  time: 0.0164  data: 0.0029  max mem: 891\n",
      "Epoch: [51] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0631 (0.0631)  div_loss: -55.5354 (-55.5354)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0569 (0.6112)  div_loss: -46.2802 (-44.2117)  acc1: 85.7143 (83.5714)  time: 0.0117  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5657142996788025\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.611 auroc 0.708 f1_score 0.282\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0674 (0.0674)  div_loss: -32.9771 (-32.9771)  acc1: 85.7143 (85.7143)  time: 0.0088  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0338 (0.4201)  div_loss: -38.3967 (-38.9886)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.707058846950531\n",
      "AUROC 5 : 0.6672078371047974\n",
      "AUROC 6 : 0.7030303478240967\n",
      "* Acc@1 83.582 loss 0.420 auroc 0.729 f1_score 0.290\n",
      "Epoch: [52]  [  0/161]  eta: 0:00:01  lr: 0.000047  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6531 (5.6531)  time: 0.0105  data: 0.0003  max mem: 891\n",
      "Epoch: [52]  [100/161]  eta: 0:00:00  lr: 0.000046  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8645 (6.7597)  time: 0.0140  data: 0.0015  max mem: 891\n",
      "Epoch: [52]  [160/161]  eta: 0:00:00  lr: 0.000045  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7840)  time: 0.0146  data: 0.0018  max mem: 891\n",
      "Epoch: [52] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0644 (0.0644)  div_loss: -55.4641 (-55.4641)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0581 (0.6090)  div_loss: -46.3792 (-44.2554)  acc1: 85.7143 (83.5714)  time: 0.0117  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.609 auroc 0.713 f1_score 0.270\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0878 (0.0878)  div_loss: -32.6612 (-32.6612)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0222 (0.4054)  div_loss: -38.4208 (-39.0621)  acc1: 85.7143 (83.5821)  time: 0.0055  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.6927966475486755\n",
      "AUROC 2 : 0.5705128312110901\n",
      "AUROC 3 : 0.9809523820877075\n",
      "AUROC 4 : 0.7141176462173462\n",
      "AUROC 5 : 0.6623376607894897\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.405 auroc 0.729 f1_score 0.326\n",
      "Epoch: [53]  [  0/161]  eta: 0:00:01  lr: 0.000045  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6527 (5.6527)  time: 0.0076  data: 0.0003  max mem: 891\n",
      "Epoch: [53]  [100/161]  eta: 0:00:00  lr: 0.000044  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8647 (6.7597)  time: 0.0153  data: 0.0027  max mem: 891\n",
      "Epoch: [53]  [160/161]  eta: 0:00:00  lr: 0.000044  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8912 (6.7839)  time: 0.0157  data: 0.0026  max mem: 891\n",
      "Epoch: [53] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0630 (0.0630)  div_loss: -55.6279 (-55.6279)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0577 (0.6231)  div_loss: -46.3375 (-44.3093)  acc1: 85.7143 (83.5714)  time: 0.0118  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5714285969734192\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8125\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.623 auroc 0.710 f1_score 0.275\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0628 (0.0628)  div_loss: -33.0940 (-33.0940)  acc1: 85.7143 (85.7143)  time: 0.0066  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0305 (0.4265)  div_loss: -38.4735 (-39.0924)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7809523344039917\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5743589997291565\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7094117999076843\n",
      "AUROC 5 : 0.6672078371047974\n",
      "AUROC 6 : 0.7030303478240967\n",
      "* Acc@1 83.582 loss 0.426 auroc 0.730 f1_score 0.290\n",
      "Epoch: [54]  [  0/161]  eta: 0:00:02  lr: 0.000044  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6527 (5.6527)  time: 0.0136  data: 0.0002  max mem: 891\n",
      "Epoch: [54]  [100/161]  eta: 0:00:00  lr: 0.000043  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8645 (6.7596)  time: 0.0142  data: 0.0016  max mem: 891\n",
      "Epoch: [54]  [160/161]  eta: 0:00:00  lr: 0.000042  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7839)  time: 0.0148  data: 0.0019  max mem: 891\n",
      "Epoch: [54] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0644 (0.0644)  div_loss: -55.5438 (-55.5438)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0597 (0.6198)  div_loss: -46.4378 (-44.3553)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.620 auroc 0.714 f1_score 0.270\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0821 (0.0821)  div_loss: -32.8163 (-32.8163)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0210 (0.4151)  div_loss: -38.4768 (-39.1576)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0063 s / it)\n",
      "AUROC 0 : 0.7857142686843872\n",
      "AUROC 1 : 0.6927966475486755\n",
      "AUROC 2 : 0.571794867515564\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7152941226959229\n",
      "AUROC 5 : 0.6623376607894897\n",
      "AUROC 6 : 0.7030303478240967\n",
      "* Acc@1 83.582 loss 0.415 auroc 0.731 f1_score 0.326\n",
      "Epoch: [55]  [  0/161]  eta: 0:00:01  lr: 0.000042  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6523 (5.6523)  time: 0.0093  data: 0.0003  max mem: 891\n",
      "Epoch: [55]  [100/161]  eta: 0:00:00  lr: 0.000041  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8646 (6.7596)  time: 0.0133  data: 0.0016  max mem: 891\n",
      "Epoch: [55]  [160/161]  eta: 0:00:00  lr: 0.000041  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7839)  time: 0.0149  data: 0.0021  max mem: 891\n",
      "Epoch: [55] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0631 (0.0631)  div_loss: -55.7129 (-55.7129)  acc1: 85.7143 (85.7143)  time: 0.0147  data: 0.0037  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0545 (0.6340)  div_loss: -46.4210 (-44.4105)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5657142996788025\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8177083134651184\n",
      "AUROC 5 : 0.5789473652839661\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.634 auroc 0.709 f1_score 0.275\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0604 (0.0604)  div_loss: -33.2001 (-33.2001)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0263 (0.4357)  div_loss: -38.5395 (-39.1904)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7082353234291077\n",
      "AUROC 5 : 0.6623377203941345\n",
      "AUROC 6 : 0.7045454978942871\n",
      "* Acc@1 83.582 loss 0.436 auroc 0.729 f1_score 0.312\n",
      "Epoch: [56]  [  0/161]  eta: 0:00:01  lr: 0.000041  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6523 (5.6523)  time: 0.0110  data: 0.0002  max mem: 891\n",
      "Epoch: [56]  [100/161]  eta: 0:00:00  lr: 0.000040  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8644 (6.7596)  time: 0.0144  data: 0.0016  max mem: 891\n",
      "Epoch: [56]  [160/161]  eta: 0:00:00  lr: 0.000039  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7838)  time: 0.0156  data: 0.0022  max mem: 891\n",
      "Epoch: [56] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0638 (0.0638)  div_loss: -55.6627 (-55.6627)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0036  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0622 (0.6318)  div_loss: -46.5310 (-44.4570)  acc1: 85.7143 (83.5714)  time: 0.0129  data: 0.0036  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6810036301612854\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8098957538604736\n",
      "AUROC 5 : 0.5921052694320679\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.632 auroc 0.715 f1_score 0.278\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0733 (0.0733)  div_loss: -32.9672 (-32.9672)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0218 (0.4223)  div_loss: -38.5567 (-39.2633)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7857142686843872\n",
      "AUROC 1 : 0.6927966475486755\n",
      "AUROC 2 : 0.5743589401245117\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7176470756530762\n",
      "AUROC 5 : 0.6639610528945923\n",
      "AUROC 6 : 0.7015151381492615\n",
      "* Acc@1 83.582 loss 0.422 auroc 0.731 f1_score 0.322\n",
      "Epoch: [57]  [  0/161]  eta: 0:00:01  lr: 0.000039  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6520 (5.6520)  time: 0.0085  data: 0.0003  max mem: 891\n",
      "Epoch: [57]  [100/161]  eta: 0:00:00  lr: 0.000038  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8645 (6.7595)  time: 0.0139  data: 0.0018  max mem: 891\n",
      "Epoch: [57]  [160/161]  eta: 0:00:00  lr: 0.000038  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8911 (6.7838)  time: 0.0157  data: 0.0021  max mem: 891\n",
      "Epoch: [57] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0641 (0.0641)  div_loss: -55.7892 (-55.7892)  acc1: 85.7143 (85.7143)  time: 0.0111  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0505 (0.6466)  div_loss: -46.4654 (-44.4963)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5714285373687744\n",
      "AUROC 2 : 0.6810035705566406\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.5921052694320679\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.647 auroc 0.714 f1_score 0.282\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0556 (0.0556)  div_loss: -33.3123 (-33.3123)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0260 (0.4436)  div_loss: -38.6494 (-39.2759)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7833333015441895\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5794872045516968\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7094117403030396\n",
      "AUROC 5 : 0.6590909361839294\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.444 auroc 0.730 f1_score 0.314\n",
      "Epoch: [58]  [  0/161]  eta: 0:00:01  lr: 0.000038  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6520 (5.6520)  time: 0.0092  data: 0.0002  max mem: 891\n",
      "Epoch: [58]  [100/161]  eta: 0:00:00  lr: 0.000037  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8644 (6.7595)  time: 0.0141  data: 0.0017  max mem: 891\n",
      "Epoch: [58]  [160/161]  eta: 0:00:00  lr: 0.000036  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7838)  time: 0.0155  data: 0.0023  max mem: 891\n",
      "Epoch: [58] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0638 (0.0638)  div_loss: -55.7496 (-55.7496)  acc1: 85.7143 (85.7143)  time: 0.0134  data: 0.0057  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0622 (0.6417)  div_loss: -46.5955 (-44.5542)  acc1: 85.7143 (83.5714)  time: 0.0125  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8098957538604736\n",
      "AUROC 5 : 0.6052631139755249\n",
      "AUROC 6 : 0.6306306719779968\n",
      "* Acc@1 83.571 loss 0.642 auroc 0.718 f1_score 0.281\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0657 (0.0657)  div_loss: -33.1029 (-33.1029)  acc1: 85.7143 (85.7143)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0227 (0.4307)  div_loss: -38.6142 (-39.3539)  acc1: 85.7143 (83.5821)  time: 0.0056  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.788095235824585\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5756410360336304\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7188235521316528\n",
      "AUROC 5 : 0.6639610528945923\n",
      "AUROC 6 : 0.699999988079071\n",
      "* Acc@1 83.582 loss 0.431 auroc 0.732 f1_score 0.322\n",
      "Epoch: [59]  [  0/161]  eta: 0:00:01  lr: 0.000036  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6517 (5.6517)  time: 0.0098  data: 0.0003  max mem: 891\n",
      "Epoch: [59]  [100/161]  eta: 0:00:00  lr: 0.000035  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9656)  total_loss: 6.8645 (6.7595)  time: 0.0142  data: 0.0021  max mem: 891\n",
      "Epoch: [59]  [160/161]  eta: 0:00:00  lr: 0.000035  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0157  data: 0.0019  max mem: 891\n",
      "Epoch: [59] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0644 (0.0644)  div_loss: -55.8681 (-55.8681)  acc1: 85.7143 (85.7143)  time: 0.0105  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0464 (0.6569)  div_loss: -46.5349 (-44.5851)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5828571319580078\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8125\n",
      "AUROC 5 : 0.5921052694320679\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.657 auroc 0.715 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0529 (0.0529)  div_loss: -33.3838 (-33.3838)  acc1: 85.7143 (85.7143)  time: 0.0047  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0238 (0.4518)  div_loss: -38.7182 (-39.3625)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7904762029647827\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.5807692408561707\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7117646932601929\n",
      "AUROC 5 : 0.6623376607894897\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.452 auroc 0.732 f1_score 0.326\n",
      "Epoch: [60]  [  0/161]  eta: 0:00:01  lr: 0.000035  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6518 (5.6518)  time: 0.0121  data: 0.0003  max mem: 891\n",
      "Epoch: [60]  [100/161]  eta: 0:00:00  lr: 0.000034  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7594)  time: 0.0148  data: 0.0024  max mem: 891\n",
      "Epoch: [60]  [160/161]  eta: 0:00:00  lr: 0.000033  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0158  data: 0.0021  max mem: 891\n",
      "Epoch: [60] Total time: 0:00:02 (0.0155 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0639 (0.0639)  div_loss: -55.8383 (-55.8383)  acc1: 85.7143 (85.7143)  time: 0.0126  data: 0.0049  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0596 (0.6526)  div_loss: -46.6468 (-44.6413)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8072916269302368\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.639639675617218\n",
      "* Acc@1 83.571 loss 0.653 auroc 0.721 f1_score 0.288\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0600 (0.0600)  div_loss: -33.2197 (-33.2197)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0237 (0.4373)  div_loss: -38.7007 (-39.4398)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0063 s / it)\n",
      "AUROC 0 : 0.7928571701049805\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5769230723381042\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7223529815673828\n",
      "AUROC 5 : 0.6607142686843872\n",
      "AUROC 6 : 0.7030303478240967\n",
      "* Acc@1 83.582 loss 0.437 auroc 0.733 f1_score 0.322\n",
      "Epoch: [61]  [  0/161]  eta: 0:00:01  lr: 0.000033  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6515 (5.6515)  time: 0.0110  data: 0.0002  max mem: 891\n",
      "Epoch: [61]  [100/161]  eta: 0:00:00  lr: 0.000032  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8644 (6.7594)  time: 0.0144  data: 0.0016  max mem: 891\n",
      "Epoch: [61]  [160/161]  eta: 0:00:00  lr: 0.000032  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0153  data: 0.0019  max mem: 891\n",
      "Epoch: [61] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0648 (0.0648)  div_loss: -55.9359 (-55.9359)  acc1: 85.7143 (85.7143)  time: 0.0115  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0433 (0.6675)  div_loss: -46.5919 (-44.6598)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5885714292526245\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8125\n",
      "AUROC 5 : 0.6052631139755249\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.668 auroc 0.718 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0497 (0.0497)  div_loss: -33.4529 (-33.4529)  acc1: 85.7143 (85.7143)  time: 0.0045  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0234 (0.4588)  div_loss: -38.7923 (-39.4364)  acc1: 85.7143 (83.5821)  time: 0.0064  data: 0.0010  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7928571701049805\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5807692408561707\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7164705991744995\n",
      "AUROC 5 : 0.6574675440788269\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.459 auroc 0.732 f1_score 0.337\n",
      "Epoch: [62]  [  0/161]  eta: 0:00:01  lr: 0.000032  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6516 (5.6516)  time: 0.0094  data: 0.0002  max mem: 891\n",
      "Epoch: [62]  [100/161]  eta: 0:00:00  lr: 0.000031  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7594)  time: 0.0139  data: 0.0016  max mem: 891\n",
      "Epoch: [62]  [160/161]  eta: 0:00:00  lr: 0.000030  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7837)  time: 0.0150  data: 0.0021  max mem: 891\n",
      "Epoch: [62] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0642 (0.0642)  div_loss: -55.9210 (-55.9210)  acc1: 85.7143 (85.7143)  time: 0.0120  data: 0.0037  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0591 (0.6619)  div_loss: -46.7025 (-44.7214)  acc1: 85.7143 (83.5714)  time: 0.0119  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.662 auroc 0.722 f1_score 0.288\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0539 (0.0539)  div_loss: -33.3253 (-33.3253)  acc1: 85.7143 (85.7143)  time: 0.0044  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0246 (0.4453)  div_loss: -38.7627 (-39.5150)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.7952380776405334\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5769230723381042\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6574674844741821\n",
      "AUROC 6 : 0.699999988079071\n",
      "* Acc@1 83.582 loss 0.445 auroc 0.733 f1_score 0.319\n",
      "Epoch: [63]  [  0/161]  eta: 0:00:02  lr: 0.000030  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6513 (5.6513)  time: 0.0128  data: 0.0006  max mem: 891\n",
      "Epoch: [63]  [100/161]  eta: 0:00:00  lr: 0.000029  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8644 (6.7594)  time: 0.0152  data: 0.0019  max mem: 891\n",
      "Epoch: [63]  [160/161]  eta: 0:00:00  lr: 0.000029  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7836)  time: 0.0157  data: 0.0022  max mem: 891\n",
      "Epoch: [63] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0653 (0.0653)  div_loss: -56.0001 (-56.0001)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0407 (0.6766)  div_loss: -46.6345 (-44.7279)  acc1: 85.7143 (83.5714)  time: 0.0120  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.9028571844100952\n",
      "AUROC 1 : 0.5942857265472412\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.677 auroc 0.722 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0470 (0.0470)  div_loss: -33.4997 (-33.4997)  acc1: 85.7143 (85.7143)  time: 0.0055  data: 0.0011  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0244 (0.4648)  div_loss: -38.8547 (-39.5015)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7928571701049805\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5794872045516968\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7199999690055847\n",
      "AUROC 5 : 0.6574675440788269\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.465 auroc 0.733 f1_score 0.334\n",
      "Epoch: [64]  [  0/161]  eta: 0:00:01  lr: 0.000029  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6514 (5.6514)  time: 0.0088  data: 0.0003  max mem: 891\n",
      "Epoch: [64]  [100/161]  eta: 0:00:00  lr: 0.000028  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0138  data: 0.0016  max mem: 891\n",
      "Epoch: [64]  [160/161]  eta: 0:00:00  lr: 0.000027  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7836)  time: 0.0147  data: 0.0019  max mem: 891\n",
      "Epoch: [64] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0653 (0.0653)  div_loss: -55.9948 (-55.9948)  acc1: 85.7143 (85.7143)  time: 0.0111  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0560 (0.6716)  div_loss: -46.7415 (-44.7885)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.672 auroc 0.722 f1_score 0.288\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0499 (0.0499)  div_loss: -33.4035 (-33.4035)  acc1: 85.7143 (85.7143)  time: 0.0044  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0255 (0.4529)  div_loss: -38.8327 (-39.5778)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5782051086425781\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.729411780834198\n",
      "AUROC 5 : 0.6590909361839294\n",
      "AUROC 6 : 0.7015151381492615\n",
      "* Acc@1 83.582 loss 0.453 auroc 0.734 f1_score 0.319\n",
      "Epoch: [65]  [  0/161]  eta: 0:00:01  lr: 0.000027  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6511 (5.6511)  time: 0.0123  data: 0.0005  max mem: 891\n",
      "Epoch: [65]  [100/161]  eta: 0:00:00  lr: 0.000026  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0132  data: 0.0016  max mem: 891\n",
      "Epoch: [65]  [160/161]  eta: 0:00:00  lr: 0.000026  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8910 (6.7836)  time: 0.0151  data: 0.0025  max mem: 891\n",
      "Epoch: [65] Total time: 0:00:02 (0.0148 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0659 (0.0659)  div_loss: -56.0563 (-56.0563)  acc1: 85.7143 (85.7143)  time: 0.0102  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0410 (0.6848)  div_loss: -46.6816 (-44.7890)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.5942857265472412\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8098958134651184\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.685 auroc 0.719 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0452 (0.0452)  div_loss: -33.5319 (-33.5319)  acc1: 85.7143 (85.7143)  time: 0.0056  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0255 (0.4702)  div_loss: -38.9119 (-39.5602)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7928571105003357\n",
      "AUROC 1 : 0.6927965879440308\n",
      "AUROC 2 : 0.5833333730697632\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7223529815673828\n",
      "AUROC 5 : 0.6542208194732666\n",
      "AUROC 6 : 0.699999988079071\n",
      "* Acc@1 83.582 loss 0.470 auroc 0.733 f1_score 0.334\n",
      "Epoch: [66]  [  0/161]  eta: 0:00:02  lr: 0.000026  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6511 (5.6511)  time: 0.0133  data: 0.0003  max mem: 891\n",
      "Epoch: [66]  [100/161]  eta: 0:00:00  lr: 0.000025  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0146  data: 0.0018  max mem: 891\n",
      "Epoch: [66]  [160/161]  eta: 0:00:00  lr: 0.000025  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0153  data: 0.0019  max mem: 891\n",
      "Epoch: [66] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0658 (0.0658)  div_loss: -56.0594 (-56.0594)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0541 (0.6804)  div_loss: -46.7712 (-44.8455)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8151041269302368\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.680 auroc 0.721 f1_score 0.288\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0467 (0.0467)  div_loss: -33.4671 (-33.4671)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0264 (0.4602)  div_loss: -38.8922 (-39.6301)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7976190447807312\n",
      "AUROC 1 : 0.6885592937469482\n",
      "AUROC 2 : 0.5769230723381042\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.729411780834198\n",
      "AUROC 5 : 0.6590909361839294\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.460 auroc 0.734 f1_score 0.319\n",
      "Epoch: [67]  [  0/161]  eta: 0:00:01  lr: 0.000025  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6509 (5.6509)  time: 0.0100  data: 0.0002  max mem: 891\n",
      "Epoch: [67]  [100/161]  eta: 0:00:00  lr: 0.000024  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7593)  time: 0.0144  data: 0.0019  max mem: 891\n",
      "Epoch: [67]  [160/161]  eta: 0:00:00  lr: 0.000023  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0166  data: 0.0021  max mem: 891\n",
      "Epoch: [67] Total time: 0:00:02 (0.0155 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0659 (0.0659)  div_loss: -56.1060 (-56.1060)  acc1: 85.7143 (85.7143)  time: 0.0106  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0426 (0.6923)  div_loss: -46.7134 (-44.8403)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.5942857265472412\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.692 auroc 0.719 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0439 (0.0439)  div_loss: -33.5556 (-33.5556)  acc1: 85.7143 (85.7143)  time: 0.0082  data: 0.0037  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0265 (0.4753)  div_loss: -38.9629 (-39.6091)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7952380776405334\n",
      "AUROC 1 : 0.6949152946472168\n",
      "AUROC 2 : 0.5820512771606445\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7235294580459595\n",
      "AUROC 5 : 0.6542208194732666\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.475 auroc 0.734 f1_score 0.334\n",
      "Epoch: [68]  [  0/161]  eta: 0:00:01  lr: 0.000023  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6509 (5.6509)  time: 0.0099  data: 0.0002  max mem: 891\n",
      "Epoch: [68]  [100/161]  eta: 0:00:00  lr: 0.000022  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0142  data: 0.0017  max mem: 891\n",
      "Epoch: [68]  [160/161]  eta: 0:00:00  lr: 0.000022  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7836)  time: 0.0158  data: 0.0022  max mem: 891\n",
      "Epoch: [68] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0661 (0.0661)  div_loss: -56.1142 (-56.1142)  acc1: 85.7143 (85.7143)  time: 0.0121  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0509 (0.6891)  div_loss: -46.7896 (-44.8899)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8098958730697632\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.689 auroc 0.720 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0444 (0.0444)  div_loss: -33.5140 (-33.5140)  acc1: 85.7143 (85.7143)  time: 0.0056  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0274 (0.4678)  div_loss: -38.9459 (-39.6704)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7976190447807312\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5769230723381042\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6542208194732666\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.468 auroc 0.733 f1_score 0.335\n",
      "Epoch: [69]  [  0/161]  eta: 0:00:01  lr: 0.000022  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6507 (5.6507)  time: 0.0091  data: 0.0004  max mem: 891\n",
      "Epoch: [69]  [100/161]  eta: 0:00:00  lr: 0.000021  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8643 (6.7592)  time: 0.0138  data: 0.0016  max mem: 891\n",
      "Epoch: [69]  [160/161]  eta: 0:00:00  lr: 0.000021  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0153  data: 0.0020  max mem: 891\n",
      "Epoch: [69] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0660 (0.0660)  div_loss: -56.1528 (-56.1528)  acc1: 85.7143 (85.7143)  time: 0.0117  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0447 (0.6982)  div_loss: -46.7441 (-44.8857)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.5885714292526245\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.698 auroc 0.718 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0423 (0.0423)  div_loss: -33.5716 (-33.5716)  acc1: 85.7143 (85.7143)  time: 0.0054  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0276 (0.4790)  div_loss: -39.0069 (-39.6507)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7952380776405334\n",
      "AUROC 1 : 0.6906780004501343\n",
      "AUROC 2 : 0.5820512771606445\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7247059345245361\n",
      "AUROC 5 : 0.6477273106575012\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.479 auroc 0.733 f1_score 0.331\n",
      "Epoch: [70]  [  0/161]  eta: 0:00:01  lr: 0.000021  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6507 (5.6507)  time: 0.0084  data: 0.0002  max mem: 891\n",
      "Epoch: [70]  [100/161]  eta: 0:00:00  lr: 0.000020  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0138  data: 0.0016  max mem: 891\n",
      "Epoch: [70]  [160/161]  eta: 0:00:00  lr: 0.000019  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0149  data: 0.0019  max mem: 891\n",
      "Epoch: [70] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.1629 (-56.1629)  acc1: 85.7143 (85.7143)  time: 0.0119  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0455 (0.6983)  div_loss: -46.7966 (-44.9266)  acc1: 85.7143 (83.5714)  time: 0.0130  data: 0.0034  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0112 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7843137383460999\n",
      "AUROC 4 : 0.8098958730697632\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.648648738861084\n",
      "* Acc@1 83.571 loss 0.698 auroc 0.720 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0427 (0.0427)  div_loss: -33.5564 (-33.5564)  acc1: 85.7143 (85.7143)  time: 0.0055  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0283 (0.4761)  div_loss: -39.0065 (-39.7047)  acc1: 85.7143 (83.5821)  time: 0.0064  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0071 s / it)\n",
      "AUROC 0 : 0.7976190447807312\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5833333134651184\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353639602661\n",
      "AUROC 5 : 0.649350643157959\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.476 auroc 0.733 f1_score 0.332\n",
      "Epoch: [71]  [  0/161]  eta: 0:00:01  lr: 0.000019  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6506 (5.6506)  time: 0.0120  data: 0.0002  max mem: 891\n",
      "Epoch: [71]  [100/161]  eta: 0:00:00  lr: 0.000019  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0140  data: 0.0016  max mem: 891\n",
      "Epoch: [71]  [160/161]  eta: 0:00:00  lr: 0.000018  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0148  data: 0.0019  max mem: 891\n",
      "Epoch: [71] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0659 (0.0659)  div_loss: -56.1920 (-56.1920)  acc1: 85.7143 (85.7143)  time: 0.0118  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0477 (0.7025)  div_loss: -46.7747 (-44.9256)  acc1: 85.7143 (83.5714)  time: 0.0115  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0101 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.779411792755127\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.702 auroc 0.720 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0407 (0.0407)  div_loss: -33.5822 (-33.5822)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0287 (0.4810)  div_loss: -39.0377 (-39.6854)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5782051682472229\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353639602661\n",
      "AUROC 5 : 0.6444805860519409\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.481 auroc 0.732 f1_score 0.332\n",
      "Epoch: [72]  [  0/161]  eta: 0:00:02  lr: 0.000018  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6505 (5.6505)  time: 0.0127  data: 0.0002  max mem: 891\n",
      "Epoch: [72]  [100/161]  eta: 0:00:00  lr: 0.000017  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0140  data: 0.0016  max mem: 891\n",
      "Epoch: [72]  [160/161]  eta: 0:00:00  lr: 0.000017  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0147  data: 0.0019  max mem: 891\n",
      "Epoch: [72] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0667 (0.0667)  div_loss: -56.2035 (-56.2035)  acc1: 85.7143 (85.7143)  time: 0.0124  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0464 (0.7089)  div_loss: -46.7927 (-44.9528)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7941176891326904\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6184210777282715\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.709 auroc 0.722 f1_score 0.285\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0412 (0.0412)  div_loss: -33.5943 (-33.5943)  acc1: 85.7143 (85.7143)  time: 0.0058  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0291 (0.4863)  div_loss: -39.0686 (-39.7291)  acc1: 85.7143 (83.5821)  time: 0.0064  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7952380776405334\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5820512771606445\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588874816895\n",
      "AUROC 5 : 0.6444805860519409\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.486 auroc 0.732 f1_score 0.331\n",
      "Epoch: [73]  [  0/161]  eta: 0:00:01  lr: 0.000017  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6504 (5.6504)  time: 0.0120  data: 0.0002  max mem: 891\n",
      "Epoch: [73]  [100/161]  eta: 0:00:00  lr: 0.000016  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0138  data: 0.0015  max mem: 891\n",
      "Epoch: [73]  [160/161]  eta: 0:00:00  lr: 0.000016  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0169  data: 0.0027  max mem: 891\n",
      "Epoch: [73] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0655 (0.0655)  div_loss: -56.2312 (-56.2312)  acc1: 85.7143 (85.7143)  time: 0.0115  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0519 (0.7066)  div_loss: -46.7982 (-44.9620)  acc1: 85.7143 (83.5714)  time: 0.0128  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.707 auroc 0.723 f1_score 0.295\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0391 (0.0391)  div_loss: -33.5986 (-33.5986)  acc1: 85.7143 (85.7143)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0297 (0.4830)  div_loss: -39.0736 (-39.7185)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.8023809194564819\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5794872045516968\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353639602661\n",
      "AUROC 5 : 0.6444805860519409\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.483 auroc 0.733 f1_score 0.333\n",
      "Epoch: [74]  [  0/161]  eta: 0:00:01  lr: 0.000016  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6504 (5.6504)  time: 0.0115  data: 0.0004  max mem: 891\n",
      "Epoch: [74]  [100/161]  eta: 0:00:00  lr: 0.000015  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7592)  time: 0.0143  data: 0.0017  max mem: 891\n",
      "Epoch: [74]  [160/161]  eta: 0:00:00  lr: 0.000015  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0152  data: 0.0021  max mem: 891\n",
      "Epoch: [74] Total time: 0:00:02 (0.0156 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0662 (0.0662)  div_loss: -56.2423 (-56.2423)  acc1: 85.7143 (85.7143)  time: 0.0117  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0477 (0.7159)  div_loss: -46.7929 (-44.9754)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6315789222717285\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.716 auroc 0.723 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0400 (0.0400)  div_loss: -33.6135 (-33.6135)  acc1: 85.7143 (85.7143)  time: 0.0048  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0300 (0.4927)  div_loss: -39.1132 (-39.7467)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5833333730697632\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7247059345245361\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.493 auroc 0.732 f1_score 0.334\n",
      "Epoch: [75]  [  0/161]  eta: 0:00:01  lr: 0.000015  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6503 (5.6503)  time: 0.0090  data: 0.0002  max mem: 891\n",
      "Epoch: [75]  [100/161]  eta: 0:00:00  lr: 0.000014  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0141  data: 0.0021  max mem: 891\n",
      "Epoch: [75]  [160/161]  eta: 0:00:00  lr: 0.000014  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0151  data: 0.0021  max mem: 891\n",
      "Epoch: [75] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0661 (0.0661)  div_loss: -56.2637 (-56.2637)  acc1: 85.7143 (85.7143)  time: 0.0109  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0513 (0.7119)  div_loss: -46.8209 (-44.9921)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8072916865348816\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.712 auroc 0.725 f1_score 0.295\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0378 (0.0378)  div_loss: -33.6072 (-33.6072)  acc1: 85.7143 (85.7143)  time: 0.0042  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0308 (0.4868)  div_loss: -39.1084 (-39.7495)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5833333134651184\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7294118404388428\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.487 auroc 0.734 f1_score 0.333\n",
      "Epoch: [76]  [  0/161]  eta: 0:00:01  lr: 0.000014  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6503 (5.6503)  time: 0.0102  data: 0.0003  max mem: 891\n",
      "Epoch: [76]  [100/161]  eta: 0:00:00  lr: 0.000013  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0142  data: 0.0015  max mem: 891\n",
      "Epoch: [76]  [160/161]  eta: 0:00:00  lr: 0.000013  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0152  data: 0.0021  max mem: 891\n",
      "Epoch: [76] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0661 (0.0661)  div_loss: -56.2800 (-56.2800)  acc1: 85.7143 (85.7143)  time: 0.0108  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0492 (0.7200)  div_loss: -46.7979 (-44.9976)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.720 auroc 0.725 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0385 (0.0385)  div_loss: -33.6227 (-33.6227)  acc1: 85.7143 (85.7143)  time: 0.0052  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0310 (0.4959)  div_loss: -39.1477 (-39.7614)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7952380776405334\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7235294580459595\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.496 auroc 0.732 f1_score 0.331\n",
      "Epoch: [77]  [  0/161]  eta: 0:00:01  lr: 0.000012  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0103  data: 0.0002  max mem: 891\n",
      "Epoch: [77]  [100/161]  eta: 0:00:00  lr: 0.000012  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0140  data: 0.0015  max mem: 891\n",
      "Epoch: [77]  [160/161]  eta: 0:00:00  lr: 0.000011  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7835)  time: 0.0175  data: 0.0025  max mem: 891\n",
      "Epoch: [77] Total time: 0:00:02 (0.0156 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0665 (0.0665)  div_loss: -56.2943 (-56.2943)  acc1: 85.7143 (85.7143)  time: 0.0119  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0522 (0.7179)  div_loss: -46.8352 (-45.0146)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.684587836265564\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.718 auroc 0.725 f1_score 0.295\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0370 (0.0370)  div_loss: -33.6184 (-33.6184)  acc1: 85.7143 (85.7143)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0317 (0.4925)  div_loss: -39.1414 (-39.7727)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.8023809194564819\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5858974456787109\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353639602661\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.493 auroc 0.734 f1_score 0.332\n",
      "Epoch: [78]  [  0/161]  eta: 0:00:01  lr: 0.000011  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0110  data: 0.0003  max mem: 891\n",
      "Epoch: [78]  [100/161]  eta: 0:00:00  lr: 0.000011  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0140  data: 0.0017  max mem: 891\n",
      "Epoch: [78]  [160/161]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0155  data: 0.0022  max mem: 891\n",
      "Epoch: [78] Total time: 0:00:02 (0.0157 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0660 (0.0660)  div_loss: -56.3119 (-56.3119)  acc1: 85.7143 (85.7143)  time: 0.0160  data: 0.0039  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0516 (0.7231)  div_loss: -46.8057 (-45.0194)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.723 auroc 0.725 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0370 (0.0370)  div_loss: -33.6317 (-33.6317)  acc1: 85.7143 (85.7143)  time: 0.0049  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0319 (0.4978)  div_loss: -39.1744 (-39.7772)  acc1: 85.7143 (83.5821)  time: 0.0059  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6864407062530518\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.498 auroc 0.733 f1_score 0.332\n",
      "Epoch: [79]  [  0/161]  eta: 0:00:01  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6502 (5.6502)  time: 0.0122  data: 0.0002  max mem: 891\n",
      "Epoch: [79]  [100/161]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0136  data: 0.0018  max mem: 891\n",
      "Epoch: [79]  [160/161]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0148  data: 0.0019  max mem: 891\n",
      "Epoch: [79] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0666 (0.0666)  div_loss: -56.3257 (-56.3257)  acc1: 85.7143 (85.7143)  time: 0.0113  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0532 (0.7237)  div_loss: -46.8376 (-45.0332)  acc1: 85.7143 (83.5714)  time: 0.0120  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0101 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.724 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0361 (0.0361)  div_loss: -33.6315 (-33.6315)  acc1: 85.7143 (85.7143)  time: 0.0063  data: 0.0005  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0324 (0.4982)  div_loss: -39.1752 (-39.7911)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588874816895\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.498 auroc 0.733 f1_score 0.332\n",
      "Epoch: [80]  [  0/161]  eta: 0:00:02  lr: 0.000010  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0144  data: 0.0003  max mem: 891\n",
      "Epoch: [80]  [100/161]  eta: 0:00:00  lr: 0.000009  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0137  data: 0.0016  max mem: 891\n",
      "Epoch: [80]  [160/161]  eta: 0:00:00  lr: 0.000009  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0164  data: 0.0026  max mem: 891\n",
      "Epoch: [80] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0661 (0.0661)  div_loss: -56.3416 (-56.3416)  acc1: 85.7143 (85.7143)  time: 0.0111  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0535 (0.7260)  div_loss: -46.8201 (-45.0400)  acc1: 85.7143 (83.5714)  time: 0.0125  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0107 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6000000238418579\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.726 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0357 (0.0357)  div_loss: -33.6413 (-33.6413)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0006  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0328 (0.5000)  div_loss: -39.2009 (-39.7946)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7060605883598328\n",
      "* Acc@1 83.582 loss 0.500 auroc 0.733 f1_score 0.332\n",
      "Epoch: [81]  [  0/161]  eta: 0:00:01  lr: 0.000009  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0110  data: 0.0003  max mem: 891\n",
      "Epoch: [81]  [100/161]  eta: 0:00:00  lr: 0.000008  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0141  data: 0.0015  max mem: 891\n",
      "Epoch: [81]  [160/161]  eta: 0:00:00  lr: 0.000008  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0150  data: 0.0019  max mem: 891\n",
      "Epoch: [81] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.3549 (-56.3549)  acc1: 85.7143 (85.7143)  time: 0.0111  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0533 (0.7283)  div_loss: -46.8372 (-45.0502)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.8914285898208618\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.728 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0351 (0.0351)  div_loss: -33.6449 (-33.6449)  acc1: 85.7143 (85.7143)  time: 0.0054  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0332 (0.5022)  div_loss: -39.2093 (-39.8064)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.502 auroc 0.733 f1_score 0.332\n",
      "Epoch: [82]  [  0/161]  eta: 0:00:01  lr: 0.000008  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0080  data: 0.0003  max mem: 891\n",
      "Epoch: [82]  [100/161]  eta: 0:00:00  lr: 0.000007  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0146  data: 0.0020  max mem: 891\n",
      "Epoch: [82]  [160/161]  eta: 0:00:00  lr: 0.000007  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0161  data: 0.0021  max mem: 891\n",
      "Epoch: [82] Total time: 0:00:02 (0.0158 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0662 (0.0662)  div_loss: -56.3676 (-56.3676)  acc1: 85.7143 (85.7143)  time: 0.0146  data: 0.0076  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0501 (0.7294)  div_loss: -46.8320 (-45.0574)  acc1: 85.7143 (83.5714)  time: 0.0127  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0110 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.729 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0347 (0.0347)  div_loss: -33.6489 (-33.6489)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0336 (0.5027)  div_loss: -39.2250 (-39.8104)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0006  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5871795415878296\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7258824110031128\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.503 auroc 0.733 f1_score 0.332\n",
      "Epoch: [83]  [  0/161]  eta: 0:00:01  lr: 0.000007  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0096  data: 0.0003  max mem: 891\n",
      "Epoch: [83]  [100/161]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0141  data: 0.0016  max mem: 891\n",
      "Epoch: [83]  [160/161]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0150  data: 0.0019  max mem: 891\n",
      "Epoch: [83] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0663 (0.0663)  div_loss: -56.3794 (-56.3794)  acc1: 85.7143 (85.7143)  time: 0.0117  data: 0.0041  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0496 (0.7316)  div_loss: -46.8363 (-45.0641)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.732 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0343 (0.0343)  div_loss: -33.6540 (-33.6540)  acc1: 85.7143 (85.7143)  time: 0.0044  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0339 (0.5050)  div_loss: -39.2360 (-39.8180)  acc1: 85.7143 (83.5821)  time: 0.0064  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7270588278770447\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.505 auroc 0.733 f1_score 0.332\n",
      "Epoch: [84]  [  0/161]  eta: 0:00:01  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0092  data: 0.0003  max mem: 891\n",
      "Epoch: [84]  [100/161]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0143  data: 0.0020  max mem: 891\n",
      "Epoch: [84]  [160/161]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8909 (6.7834)  time: 0.0158  data: 0.0019  max mem: 891\n",
      "Epoch: [84] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0663 (0.0663)  div_loss: -56.3904 (-56.3904)  acc1: 85.7143 (85.7143)  time: 0.0123  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0472 (0.7326)  div_loss: -46.8382 (-45.0712)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.733 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0338 (0.0338)  div_loss: -33.6572 (-33.6572)  acc1: 85.7143 (85.7143)  time: 0.0055  data: 0.0006  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0342 (0.5056)  div_loss: -39.2480 (-39.8234)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.506 auroc 0.733 f1_score 0.332\n",
      "Epoch: [85]  [  0/161]  eta: 0:00:01  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0109  data: 0.0003  max mem: 891\n",
      "Epoch: [85]  [100/161]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8642 (6.7591)  time: 0.0142  data: 0.0019  max mem: 891\n",
      "Epoch: [85]  [160/161]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0155  data: 0.0023  max mem: 891\n",
      "Epoch: [85] Total time: 0:00:02 (0.0155 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0663 (0.0663)  div_loss: -56.4003 (-56.4003)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0462 (0.7343)  div_loss: -46.8386 (-45.0762)  acc1: 85.7143 (83.5714)  time: 0.0122  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.734 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0335 (0.0335)  div_loss: -33.6601 (-33.6601)  acc1: 85.7143 (85.7143)  time: 0.0043  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0346 (0.5072)  div_loss: -39.2584 (-39.8282)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.507 auroc 0.733 f1_score 0.332\n",
      "Epoch: [86]  [  0/161]  eta: 0:00:01  lr: 0.000005  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6501 (5.6501)  time: 0.0105  data: 0.0003  max mem: 891\n",
      "Epoch: [86]  [100/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7591)  time: 0.0137  data: 0.0015  max mem: 891\n",
      "Epoch: [86]  [160/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0156  data: 0.0023  max mem: 891\n",
      "Epoch: [86] Total time: 0:00:02 (0.0150 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0663 (0.0663)  div_loss: -56.4098 (-56.4098)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0448 (0.7353)  div_loss: -46.8407 (-45.0819)  acc1: 85.7143 (83.5714)  time: 0.0120  data: 0.0026  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.735 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0331 (0.0331)  div_loss: -33.6634 (-33.6634)  acc1: 85.7143 (85.7143)  time: 0.0086  data: 0.0036  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0349 (0.5081)  div_loss: -39.2688 (-39.8332)  acc1: 85.7143 (83.5821)  time: 0.0062  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.508 auroc 0.733 f1_score 0.332\n",
      "Epoch: [87]  [  0/161]  eta: 0:00:01  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0078  data: 0.0003  max mem: 891\n",
      "Epoch: [87]  [100/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7591)  time: 0.0141  data: 0.0016  max mem: 891\n",
      "Epoch: [87]  [160/161]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0151  data: 0.0022  max mem: 891\n",
      "Epoch: [87] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0663 (0.0663)  div_loss: -56.4177 (-56.4177)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0437 (0.7365)  div_loss: -46.8412 (-45.0863)  acc1: 85.7143 (83.5714)  time: 0.0113  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0098 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.736 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0328 (0.0328)  div_loss: -33.6661 (-33.6661)  acc1: 85.7143 (85.7143)  time: 0.0084  data: 0.0039  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0351 (0.5091)  div_loss: -39.2770 (-39.8372)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.7999999523162842\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9833333492279053\n",
      "AUROC 4 : 0.7282353043556213\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.509 auroc 0.733 f1_score 0.332\n",
      "Epoch: [88]  [  0/161]  eta: 0:00:01  lr: 0.000004  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0121  data: 0.0003  max mem: 891\n",
      "Epoch: [88]  [100/161]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7591)  time: 0.0145  data: 0.0017  max mem: 891\n",
      "Epoch: [88]  [160/161]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0167  data: 0.0019  max mem: 891\n",
      "Epoch: [88] Total time: 0:00:02 (0.0157 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4248 (-56.4248)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0428 (0.7374)  div_loss: -46.8423 (-45.0903)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.737 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0326 (0.0326)  div_loss: -33.6680 (-33.6680)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0353 (0.5099)  div_loss: -39.2848 (-39.8408)  acc1: 85.7143 (83.5821)  time: 0.0067  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0069 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.729411780834198\n",
      "AUROC 5 : 0.6428571939468384\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.510 auroc 0.734 f1_score 0.332\n",
      "Epoch: [89]  [  0/161]  eta: 0:00:01  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0110  data: 0.0003  max mem: 891\n",
      "Epoch: [89]  [100/161]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7591)  time: 0.0136  data: 0.0016  max mem: 891\n",
      "Epoch: [89]  [160/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0154  data: 0.0020  max mem: 891\n",
      "Epoch: [89] Total time: 0:00:02 (0.0156 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4309 (-56.4309)  acc1: 85.7143 (85.7143)  time: 0.0118  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0421 (0.7382)  div_loss: -46.8431 (-45.0939)  acc1: 85.7143 (83.5714)  time: 0.0127  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0108 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8020833730697632\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.738 auroc 0.726 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0323 (0.0323)  div_loss: -33.6703 (-33.6703)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0355 (0.5107)  div_loss: -39.2920 (-39.8440)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0070 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.7305882573127747\n",
      "AUROC 5 : 0.6412338018417358\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.511 auroc 0.734 f1_score 0.332\n",
      "Epoch: [90]  [  0/161]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0116  data: 0.0002  max mem: 891\n",
      "Epoch: [90]  [100/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7591)  time: 0.0139  data: 0.0015  max mem: 891\n",
      "Epoch: [90]  [160/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0164  data: 0.0026  max mem: 891\n",
      "Epoch: [90] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4364 (-56.4364)  acc1: 85.7143 (85.7143)  time: 0.0107  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0415 (0.7389)  div_loss: -46.8435 (-45.0968)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.739 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0321 (0.0321)  div_loss: -33.6724 (-33.6724)  acc1: 85.7143 (85.7143)  time: 0.0052  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0357 (0.5113)  div_loss: -39.2986 (-39.8469)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.9857142567634583\n",
      "AUROC 4 : 0.7305882573127747\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.511 auroc 0.734 f1_score 0.332\n",
      "Epoch: [91]  [  0/161]  eta: 0:00:02  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0126  data: 0.0004  max mem: 891\n",
      "Epoch: [91]  [100/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0140  data: 0.0017  max mem: 891\n",
      "Epoch: [91]  [160/161]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0150  data: 0.0020  max mem: 891\n",
      "Epoch: [91] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4408 (-56.4408)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0034  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0410 (0.7395)  div_loss: -46.8442 (-45.0993)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.739 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0319 (0.0319)  div_loss: -33.6737 (-33.6737)  acc1: 85.7143 (85.7143)  time: 0.0053  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0359 (0.5119)  div_loss: -39.3031 (-39.8491)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5884615778923035\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.7305882573127747\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.512 auroc 0.734 f1_score 0.332\n",
      "Epoch: [92]  [  0/161]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0105  data: 0.0002  max mem: 891\n",
      "Epoch: [92]  [100/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0131  data: 0.0016  max mem: 891\n",
      "Epoch: [92]  [160/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0153  data: 0.0022  max mem: 891\n",
      "Epoch: [92] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4444 (-56.4444)  acc1: 85.7143 (85.7143)  time: 0.0137  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0406 (0.7399)  div_loss: -46.8444 (-45.1014)  acc1: 85.7143 (83.5714)  time: 0.0125  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0110 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.740 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0318 (0.0318)  div_loss: -33.6752 (-33.6752)  acc1: 85.7143 (85.7143)  time: 0.0045  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0360 (0.5123)  div_loss: -39.3077 (-39.8511)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5897436141967773\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.7305882573127747\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7030302882194519\n",
      "* Acc@1 83.582 loss 0.512 auroc 0.734 f1_score 0.332\n",
      "Epoch: [93]  [  0/161]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0110  data: 0.0003  max mem: 891\n",
      "Epoch: [93]  [100/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0142  data: 0.0016  max mem: 891\n",
      "Epoch: [93]  [160/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0153  data: 0.0021  max mem: 891\n",
      "Epoch: [93] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4471 (-56.4471)  acc1: 85.7143 (85.7143)  time: 0.0116  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0403 (0.7403)  div_loss: -46.8446 (-45.1028)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.740 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0317 (0.0317)  div_loss: -33.6760 (-33.6760)  acc1: 85.7143 (85.7143)  time: 0.0050  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0361 (0.5126)  div_loss: -39.3106 (-39.8525)  acc1: 85.7143 (83.5821)  time: 0.0063  data: 0.0007  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5897436141967773\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.7305882573127747\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Epoch: [94]  [  0/161]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0100  data: 0.0003  max mem: 891\n",
      "Epoch: [94]  [100/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0138  data: 0.0019  max mem: 891\n",
      "Epoch: [94]  [160/161]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0159  data: 0.0021  max mem: 891\n",
      "Epoch: [94] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4492 (-56.4492)  acc1: 85.7143 (85.7143)  time: 0.0110  data: 0.0035  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0401 (0.7406)  div_loss: -46.8448 (-45.1040)  acc1: 85.7143 (83.5714)  time: 0.0121  data: 0.0023  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0316 (0.0316)  div_loss: -33.6769 (-33.6769)  acc1: 85.7143 (85.7143)  time: 0.0058  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0362 (0.5129)  div_loss: -39.3129 (-39.8536)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0067 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5897436141967773\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.7305882573127747\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Epoch: [95]  [  0/161]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0093  data: 0.0003  max mem: 891\n",
      "Epoch: [95]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0150  data: 0.0022  max mem: 891\n",
      "Epoch: [95]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0152  data: 0.0020  max mem: 891\n",
      "Epoch: [95] Total time: 0:00:02 (0.0154 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4506 (-56.4506)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0401 (0.7408)  div_loss: -46.8448 (-45.1047)  acc1: 85.7143 (83.5714)  time: 0.0124  data: 0.0028  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0106 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0315 (0.0315)  div_loss: -33.6774 (-33.6774)  acc1: 85.7143 (85.7143)  time: 0.0046  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0363 (0.5131)  div_loss: -39.3146 (-39.8545)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.7317647337913513\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Epoch: [96]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0103  data: 0.0003  max mem: 891\n",
      "Epoch: [96]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0146  data: 0.0017  max mem: 891\n",
      "Epoch: [96]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0156  data: 0.0020  max mem: 891\n",
      "Epoch: [96] Total time: 0:00:02 (0.0156 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4515 (-56.4515)  acc1: 85.7143 (85.7143)  time: 0.0132  data: 0.0032  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0401 (0.7409)  div_loss: -46.8449 (-45.1052)  acc1: 85.7143 (83.5714)  time: 0.0117  data: 0.0027  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0102 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0315 (0.0315)  div_loss: -33.6778 (-33.6778)  acc1: 85.7143 (85.7143)  time: 0.0054  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0364 (0.5133)  div_loss: -39.3156 (-39.8550)  acc1: 85.7143 (83.5821)  time: 0.0060  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0065 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.732941210269928\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Epoch: [97]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0119  data: 0.0003  max mem: 891\n",
      "Epoch: [97]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0144  data: 0.0016  max mem: 891\n",
      "Epoch: [97]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0148  data: 0.0020  max mem: 891\n",
      "Epoch: [97] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4520 (-56.4520)  acc1: 85.7143 (85.7143)  time: 0.0109  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0400 (0.7410)  div_loss: -46.8448 (-45.1055)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0104 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0314 (0.0314)  div_loss: -33.6781 (-33.6781)  acc1: 85.7143 (85.7143)  time: 0.0054  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0364 (0.5134)  div_loss: -39.3161 (-39.8553)  acc1: 85.7143 (83.5821)  time: 0.0058  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.732941210269928\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Epoch: [98]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0113  data: 0.0002  max mem: 891\n",
      "Epoch: [98]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0148  data: 0.0017  max mem: 891\n",
      "Epoch: [98]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0147  data: 0.0019  max mem: 891\n",
      "Epoch: [98] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4522 (-56.4522)  acc1: 85.7143 (85.7143)  time: 0.0112  data: 0.0033  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0400 (0.7410)  div_loss: -46.8448 (-45.1056)  acc1: 85.7143 (83.5714)  time: 0.0123  data: 0.0025  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0105 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0314 (0.0314)  div_loss: -33.6782 (-33.6782)  acc1: 85.7143 (85.7143)  time: 0.0044  data: 0.0004  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0364 (0.5134)  div_loss: -39.3163 (-39.8554)  acc1: 85.7143 (83.5821)  time: 0.0057  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0064 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.732941210269928\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Epoch: [99]  [  0/161]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.8071 (0.8071)  total_loss: 5.6500 (5.6500)  time: 0.0113  data: 0.0003  max mem: 891\n",
      "Epoch: [99]  [100/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9806 (0.9655)  total_loss: 6.8641 (6.7590)  time: 0.0142  data: 0.0016  max mem: 891\n",
      "Epoch: [99]  [160/161]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0000 (0.0000)  diff_loss: 0.0000 (0.0000)  slide_loss: 0.0000 (0.0000)  att_loss: 0.9844 (0.9690)  total_loss: 6.8908 (6.7834)  time: 0.0159  data: 0.0027  max mem: 891\n",
      "Epoch: [99] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [ 0/40]  eta: 0:00:00  loss: 0.0664 (0.0664)  div_loss: -56.4522 (-56.4522)  acc1: 85.7143 (85.7143)  time: 0.0151  data: 0.0038  max mem: 891\n",
      "Val  [39/40]  eta: 0:00:00  loss: 0.0400 (0.7410)  div_loss: -46.8448 (-45.1056)  acc1: 85.7143 (83.5714)  time: 0.0118  data: 0.0024  max mem: 891\n",
      "Val Total time: 0:00:00 (0.0103 s / it)\n",
      "AUROC 0 : 0.8971428871154785\n",
      "AUROC 1 : 0.6057143211364746\n",
      "AUROC 2 : 0.6881720423698425\n",
      "AUROC 3 : 0.7892156839370728\n",
      "AUROC 4 : 0.8046875\n",
      "AUROC 5 : 0.6447368860244751\n",
      "AUROC 6 : 0.6576577425003052\n",
      "* Acc@1 83.571 loss 0.741 auroc 0.727 f1_score 0.292\n",
      "Test  [ 0/67]  eta: 0:00:00  loss: 0.0314 (0.0314)  div_loss: -33.6782 (-33.6782)  acc1: 85.7143 (85.7143)  time: 0.0051  data: 0.0003  max mem: 891\n",
      "Test  [66/67]  eta: 0:00:00  loss: 0.0364 (0.5134)  div_loss: -39.3164 (-39.8554)  acc1: 85.7143 (83.5821)  time: 0.0061  data: 0.0005  max mem: 891\n",
      "Test Total time: 0:00:00 (0.0068 s / it)\n",
      "AUROC 0 : 0.8047618865966797\n",
      "AUROC 1 : 0.6843220591545105\n",
      "AUROC 2 : 0.5910256505012512\n",
      "AUROC 3 : 0.988095223903656\n",
      "AUROC 4 : 0.732941210269928\n",
      "AUROC 5 : 0.6396104097366333\n",
      "AUROC 6 : 0.7045454382896423\n",
      "* Acc@1 83.582 loss 0.513 auroc 0.735 f1_score 0.332\n",
      "Results on best epoch:\n",
      "{'epoch': -1, 'val_acc': 0, 'val_auc': 0, 'val_f1': 0, 'test_acc': 0, 'test_auc': 0, 'test_f1': 0}\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "train_epoch = conf.train_epoch\n",
    "for epoch in range(train_epoch):\n",
    "    # train_one_epoch_multitask(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "    # val_auc, val_acc, val_f1, val_loss = evaluate_multitask(model, criterion, val_loader, device, conf, 'Val')\n",
    "    # test_auc, test_acc, test_f1, test_loss = evaluate_multitask(model, criterion, test_loader, device, conf, 'Test')\n",
    "    train_one_epoch_multitask_V2(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "    val_auc, val_acc, val_f1, val_loss = evaluate_multitask_V2(model, criterion, val_loader, device, conf, 'Val')\n",
    "    test_auc, test_acc, test_f1, test_loss = evaluate_multitask_V2(model, criterion, test_loader, device, conf, 'Test')\n",
    "\n",
    "    save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "        save_path=os.path.join(ckpt_dir + 'checkpoint_' + 'epoch' + str(epoch) + '.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07377042-2f38-4f48-9c86-b37329f2e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               AUC  Recall  Specificity   ACC  Precision    PR_AUC    F1  \\\n",
      "SAMPLE_LEVEL  0.80    0.29         0.90  0.84       0.25  0.363213  0.27   \n",
      "SAMPLE_LEVEL  0.68    0.25         1.00  0.91       1.00  0.564383  0.40   \n",
      "SAMPLE_LEVEL  0.59    0.07         0.90  0.72       0.17  0.284454  0.10   \n",
      "SAMPLE_LEVEL  0.99    0.86         0.97  0.96       0.75  0.921429  0.80   \n",
      "SAMPLE_LEVEL  0.73    0.41         0.86  0.75       0.50  0.539816  0.45   \n",
      "SAMPLE_LEVEL  0.64    0.09         1.00  0.85       1.00  0.381284  0.17   \n",
      "SAMPLE_LEVEL  0.70    0.08         0.98  0.82       0.50  0.375483  0.14   \n",
      "\n",
      "                F2    F3                  OUTCOME  \n",
      "SAMPLE_LEVEL  0.28  0.28                       AR  \n",
      "SAMPLE_LEVEL  0.29  0.27                       HR  \n",
      "SAMPLE_LEVEL  0.08  0.07                     PTEN  \n",
      "SAMPLE_LEVEL  0.83  0.85                      RB1  \n",
      "SAMPLE_LEVEL  0.43  0.42                     TP53  \n",
      "SAMPLE_LEVEL  0.11  0.10  TMB_HIGHorINTERMEDITATE  \n",
      "SAMPLE_LEVEL  0.10  0.09                  MSI_POS  \n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "# ###################################################\n",
    "# #           Test \n",
    "# ###################################################\n",
    "# # define network\n",
    "# if arch == 'ga':\n",
    "#     model2 = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "# elif arch == 'ga_mt':\n",
    "#     model2 = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "# else:\n",
    "#     model2 = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "# model2.to(device)\n",
    "\n",
    "# # Load the checkpoint\n",
    "# #checkpoint = torch.load(ckpt_dir + 'checkpoint-best.pth')\n",
    "# checkpoint = torch.load(ckpt_dir + 'checkpoint_epoch99.pth')\n",
    "\n",
    "# # Load the state_dict into the model\n",
    "# model2.load_state_dict(checkpoint['model'])\n",
    "\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict_v2(model, test_loader, device, conf, 'Test')\n",
    "y_pred_tasks_val,  y_predprob_task_val, y_true_task_val = predict_v2(model, val_loader, device, conf, 'Test')\n",
    "\n",
    "\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    #Calibration\n",
    "    #prob_calibrated = calibrate_probs_isotonic(y_true_task_val[i], y_predprob_task_val[i], y_predprob_task_test[i])\n",
    "    pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], test_ids, ALL_LABEL[i], THRES = 0.5)\n",
    "    pred_df_list.append(pred_df)\n",
    "    perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923122c6-b454-4f26-8d54-f0d832ecc0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#bootstrap perforance\n",
    "ci_list = []\n",
    "for i in range(conf.n_task):\n",
    "    print(i)\n",
    "    cur_pred_df = all_perd_df.loc[all_perd_df['OUTCOME'] == ALL_LABEL[i]]\n",
    "    cur_ci_df = bootstrap_ci_from_df(cur_pred_df, roc_auc_score, y_true_col='Y_True', y_pred_col='Pred_Class', y_prob_col='Pred_Prob', num_bootstrap=1000, ci=95, seed=42)\n",
    "    cur_ci_df['OUTCOME'] = ALL_LABEL[i]\n",
    "    ci_list.append(cur_ci_df)\n",
    "ci_final_df = pd.concat(ci_list)\n",
    "ci_final_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf_bootstrap.csv\",index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a236391-ba85-46bb-80c8-62fa3773f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_IDs</th>\n",
       "      <th>Y_True</th>\n",
       "      <th>Pred_Prob</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>Pred_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPX_002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184530</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPX_007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333018</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPX_015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250763</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPX_019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144299</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPX_020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222437</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>OPX_319</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300538</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>OPX_325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350142</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>OPX_337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369557</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>OPX_345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183352</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>OPX_351</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202001</td>\n",
       "      <td>MSI_POS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_IDs  Y_True  Pred_Prob  OUTCOME  Pred_Class\n",
       "0     OPX_002       0   0.184530  MSI_POS           0\n",
       "1     OPX_007       1   0.333018  MSI_POS           0\n",
       "2     OPX_015       0   0.250763  MSI_POS           0\n",
       "3     OPX_019       0   0.144299  MSI_POS           0\n",
       "4     OPX_020       0   0.222437  MSI_POS           0\n",
       "..        ...     ...        ...      ...         ...\n",
       "62    OPX_319       0   0.300538  MSI_POS           0\n",
       "63    OPX_325       0   0.350142  MSI_POS           0\n",
       "64    OPX_337       0   0.369557  MSI_POS           0\n",
       "65    OPX_345       0   0.183352  MSI_POS           0\n",
       "66    OPX_351       0   0.202001  MSI_POS           0\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_msi = all_perd_df.loc[all_perd_df['OUTCOME'] == 'MSI_POS']\n",
    "pred_msi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e81a3892-8dbe-4981-aad5-0984cfc2fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate Pred_Prob values based on Y_True values\n",
    "pred_prob_0 = pred_msi[pred_msi[\"Y_True\"] == 0][\"Pred_Prob\"]\n",
    "pred_prob_1 = pred_msi[pred_msi[\"Y_True\"] == 1][\"Pred_Prob\"]\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([pred_prob_0, pred_prob_1], labels=[\"Y_True = 0\", \"Y_True = 1\"])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Y_True\")\n",
    "plt.ylabel(\"Predicted Probability (Pred_Prob)\")\n",
    "plt.title(\"Boxplot of Pred_Prob for Y_True = 0 and 1\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359e5db7-8c0e-43c3-af13-3c3e5285c74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1e0lEQVR4nO3deVhU1f8H8PewDIusoigCiqKCooCiqLjgDrmC5J6ameVWpllpJmamVubSYmHmniWa4L6FSySaGSqaCgqKuyiKbLLP+f3hj/t1ZJFB4ALzfj2PT82Ze++8Z+4M85lzzz1XIYQQICIiItJCOnIHICIiIpILCyEiIiLSWiyEiIiISGuxECIiIiKtxUKIiIiItBYLISIiItJaLISIiIhIa7EQIiIiIq3FQoiIiIi0FgshqnAODg54/fXX5Y6hdbp27YquXbvKHeOFPv30UygUCiQmJsodpdJRKBT49NNPy2Rb8fHxUCgUWLduXZlsDwD++ecfKJVKXL9+vcy2WdaGDRuGIUOGyB2DKhEWQtXMunXroFAopH96enqwtbXF66+/jtu3b8sdr1JLT0/H/Pnz4erqCmNjY5ibm6Nz587YsGEDqsqVaC5evIhPP/0U8fHxckcpIC8vD2vXrkXXrl1Rs2ZNGBgYwMHBAWPHjsW///4rd7wy8euvv2L58uVyx1BTkZlmz56N4cOHo0GDBlJb165d1f4mGRkZwdXVFcuXL4dKpSp0Ow8fPsQHH3wAJycnGBoaombNmvDx8cHu3buLfOyUlBTMmzcPbm5uMDExgZGREVq0aIGPPvoId+7ckZb76KOPsG3bNkRFRZX4eWnDe1erCapW1q5dKwCIzz77TGzcuFGsWrVKjBs3Tujq6gpHR0eRkZEhd0SRmZkpsrOz5Y6h5t69e8LFxUXo6OiIESNGiJUrV4pvvvlGdOnSRQAQQ4cOFbm5uXLHfKGtW7cKAOLIkSMF7svKyhJZWVkVH0oI8eTJE+Hr6ysAiC5duojFixeL1atXizlz5ggnJyehUCjEzZs3hRBCzJ07VwAQDx48kCXry+jbt69o0KBBuW0/IyND5OTkaLROUZlUKpXIyMgos/f1mTNnBABx/PhxtXZvb29hZ2cnNm7cKDZu3CiWLVsm2rZtKwCIjz/+uMB2oqOjha2trVAqleLtt98Wq1atEosXLxbu7u4CgJgxY0aBdeLi4kTDhg2Frq6uGDZsmPj+++/FTz/9JKZMmSKsrKxEkyZN1Jb39PQUo0aNKtHz0uS9S1UTC6FqJr8QOnXqlFr7Rx99JACI4OBgmZLJKyMjQ+Tl5RV5v4+Pj9DR0RE7duwocN+MGTMEAPHFF1+UZ8RCpaWlabR8cYWQnCZPniwAiGXLlhW4Lzc3VyxevLhCCyGVSiWePHlS5tstj0IoLy/vpX7AlHdxlu/dd98V9evXFyqVSq3d29tbuLi4qLVlZGSIBg0aCFNTU7VCLDs7W7Ro0UIYGxuLv//+W22d3NxcMXToUAFAbN68WWrPyckRbm5uwtjYWPz1118FciUnJxcouL7++mtRo0YNkZqa+sLnpcl792W87H6m0mMhVM0UVQjt3r1bABALFy5Ua7906ZIICAgQlpaWwsDAQHh4eBRaDCQlJYn33ntPNGjQQCiVSmFraytGjRql9mWVmZkpAgMDhaOjo1AqlcLOzk588MEHIjMzU21bDRo0EGPGjBFCCHHq1CkBQKxbt67AY+7fv18AELt27ZLabt26JcaOHSusra2FUqkUzZs3F6tXr1Zb78iRIwKA+O2338Ts2bNFvXr1hEKhEElJSYW+ZidOnBAAxBtvvFHo/Tk5OaJJkybC0tJS+vK8du2aACAWL14sli5dKurXry8MDQ1Fly5dxPnz5wtsoySvc/6+O3r0qJg4caKoXbu2sLCwEEIIER8fLyZOnCiaNm0qDA0NRc2aNcWrr74qrl27VmD95//lF0Xe3t7C29u7wOsUHBwsPv/8c2FraysMDAxE9+7dxZUrVwo8h++//140bNhQGBoairZt24rw8PAC2yzMzZs3hZ6enujVq1exy+XLL4SuXLkixowZI8zNzYWZmZl4/fXXRXp6utqya9asEd26dRO1a9cWSqVSNGvWTPzwww8FttmgQQPRt29fsX//fuHh4SEMDAykL7aSbkMIIfbu3Su6dOkiTExMhKmpqWjTpo3YtGmTEOLp6/v8a/9sAVLSzwcAMXnyZPHLL7+I5s2bCz09PREaGirdN3fuXGnZlJQUMXXqVOlzWbt2bdGzZ08RGRn5wkz57+G1a9eqPf6lS5fE4MGDRa1atYShoaFo2rRpoT03z6tfv754/fXXC7QXVggJIcSrr74qAIg7d+5Ibb/99pvUo12Yx48fCwsLC+Hs7Cy1bd68WQAQCxYseGHGfFFRUQKACAkJKXY5Td+7Y8aMKbTozH9PP6uw/bxlyxZhaWlZ6OuYnJwsDAwMxPvvvy+1lfQ9RcXTK/NjbVQp5Y8ZsbS0lNouXLiAjh07wtbWFjNnzkSNGjWwZcsW+Pn5Ydu2bfD39wcApKWloXPnzrh06RLeeOMNtG7dGomJidi5cydu3bqFWrVqQaVSYcCAATh27BjeeustNGvWDOfPn8eyZctw+fJlbN++vdBcbdq0QaNGjbBlyxaMGTNG7b7g4GBYWlrCx8cHAJCQkID27dtDoVBgypQpqF27Nvbt24dx48YhJSUF7733ntr68+fPh1KpxIwZM5CVlQWlUllohl27dgEARo8eXej9enp6GDFiBObNm4eIiAj07NlTum/Dhg1ITU3F5MmTkZmZiW+++Qbdu3fH+fPnUadOHY1e53yTJk1C7dq1ERgYiPT0dADAqVOncPz4cQwbNgx2dnaIj4/Hjz/+iK5du+LixYswNjZGly5d8O677+Lbb7/Fxx9/jGbNmgGA9N+ifPHFF9DR0cGMGTOQnJyMr776CiNHjsTJkyelZX788UdMmTIFnTt3xrRp0xAfHw8/Pz9YWlrCzs6u2O3v27cPubm5GDVqVLHLPW/IkCFo2LAhFi1ahNOnT+Pnn3+GtbU1vvzyS7VcLi4uGDBgAPT09LBr1y5MmjQJKpUKkydPVtteTEwMhg8fjrfffhvjx4+Hk5OTRttYt24d3njjDbi4uGDWrFmwsLDAmTNnsH//fowYMQKzZ89GcnIybt26hWXLlgEATExMAEDjz8fhw4exZcsWTJkyBbVq1YKDg0Ohr9GECRPw+++/Y8qUKWjevDkePnyIY8eO4dKlS2jdunWxmQpz7tw5dO7cGfr6+njrrbfg4OCAuLg47Nq1CwsWLChyvdu3b+PGjRto3bp1kcs8L3+wtoWFhdT2os+iubk5Bg4ciPXr1yM2NhaNGzfGzp07AUCj91fz5s1hZGSEiIiIAp+/Z5X2vVtSz+/nJk2awN/fHyEhIVi5cqXa36zt27cjKysLw4YNA6D5e4qKIXclRmUrv1cgLCxMPHjwQNy8eVP8/vvvonbt2sLAwECtC7dHjx6iZcuWar8eVCqV8PLyUjumHhgYWOSvp/xu8I0bNwodHZ0CXdNBQUECgIiIiJDanu0REkKIWbNmCX19ffHo0SOpLSsrS1hYWKj10owbN07Y2NiIxMREtccYNmyYMDc3l3pr8ns6GjVqVKLDH35+fgJAkT1GQggREhIiAIhvv/1WCPG/X9NGRkbi1q1b0nInT54UAMS0adOktpK+zvn7rlOnTgXGbRT2PPJ7sjZs2CC1FXdorKgeoWbNmqmNHfrmm28EAKlnKysrS1hZWYm2bduqjU9Zt26dAPDCHqFp06YJAOLMmTPFLpcv/9fz8z10/v7+wsrKSq2tsNfFx8dHNGrUSK2tQYMGAoDYv39/geVLso3Hjx8LU1NT0a5duwKHL549FFTUYShNPh8AhI6Ojrhw4UKB7eC5HiFzc3MxefLkAss9q6hMhfUIdenSRZiamorr168X+RwLExYWVqD3Np+3t7dwdnYWDx48EA8ePBDR0dHigw8+EABE37591ZZ1d3cX5ubmxT7W0qVLBQCxc+dOIYQQrVq1euE6hWnatKl45ZVXil1G0/eupj1Che3nAwcOFPpa9unTR+09qcl7iorHs8aqqZ49e6J27dqwt7fHq6++iho1amDnzp3Sr/dHjx7h8OHDGDJkCFJTU5GYmIjExEQ8fPgQPj4+uHLlinSW2bZt2+Dm5lboLyeFQgEA2Lp1K5o1awZnZ2dpW4mJiejevTsA4MiRI0VmHTp0KHJychASEiK1HTx4EI8fP8bQoUMBAEIIbNu2Df3794cQQu0xfHx8kJycjNOnT6ttd8yYMTAyMnrha5WamgoAMDU1LXKZ/PtSUlLU2v38/GBrayvd9vT0RLt27bB3714Amr3O+caPHw9dXV21tmefR05ODh4+fIjGjRvDwsKiwPPW1NixY9V+eXbu3BkAcPXqVQDAv//+i4cPH2L8+PHQ0/tfJ/LIkSPVehiLkv+aFff6FmbChAlqtzt37oyHDx+q7YNnX5fk5GQkJibC29sbV69eRXJystr6DRs2lHoXn1WSbfzxxx9ITU3FzJkzYWhoqLZ+/megOJp+Pry9vdG8efMXbtfCwgInT55UOyuqtB48eIDw8HC88cYbqF+/vtp9L3qODx8+BIAi3w/R0dGoXbs2ateuDWdnZyxevBgDBgwocOp+amrqC98nz38WU1JSNH5v5Wd90RQNpX3vllRh+7l79+6oVasWgoODpbakpCT88ccf0t9D4OX+5pI6HhqrplasWIGmTZsiOTkZa9asQXh4OAwMDKT7Y2NjIYTAnDlzMGfOnEK3cf/+fdja2iIuLg4BAQHFPt6VK1dw6dIl1K5du8htFcXNzQ3Ozs4IDg7GuHHjADw9LFarVi3pQ/3gwQM8fvwYP/30E3766acSPUbDhg2LzZwv/49camqqWjf9s4oqlpo0aVJg2aZNm2LLli0ANHudi8udkZGBRYsWYe3atbh9+7ba6fzPf+Fr6vkvvfwvs6SkJACQ5oRp3Lix2nJ6enpFHrJ5lpmZGYD/vYZlkSt/mxEREZg7dy5OnDiBJ0+eqC2fnJwMc3Nz6XZR74eSbCMuLg4A0KJFC42eQz5NPx8lfe9+9dVXGDNmDOzt7eHh4YE+ffpg9OjRaNSokcYZ8wvf0j5HAEVOM+Hg4IBVq1ZBpVIhLi4OCxYswIMHDwoUlaampi8sTp7/LJqZmUnZNc36ogKvtO/dkipsP+vp6SEgIAC//vorsrKyYGBggJCQEOTk5KgVQi/zN5fUsRCqpjw9PdGmTRsAT3stOnXqhBEjRiAmJgYmJibS/B0zZswo9FcyUPCLrzgqlQotW7bE0qVLC73f3t6+2PWHDh2KBQsWIDExEaampti5cyeGDx8u9UDk533ttdcKjCXK5+rqqna7JL1BwNMxNNu3b8e5c+fQpUuXQpc5d+4cAJToV/qzSvM6F5b7nXfewdq1a/Hee++hQ4cOMDc3h0KhwLBhw4qci6Wknu99ylfUl5qmnJ2dAQDnz5+Hu7t7idd7Ua64uDj06NEDzs7OWLp0Kezt7aFUKrF3714sW7aswOtS2Ouq6TZKS9PPR0nfu0OGDEHnzp0RGhqKgwcPYvHixfjyyy8REhKCV1555aVzl5SVlRWA/xXPz6tRo4ba2LqOHTuidevW+Pjjj/Htt99K7c2aNcPZs2dx48aNAoVwvuc/i87Ozjhz5gxu3rz5wr8zz0pKSir0h8yzNH3vFlVY5eXlFdpe1H4eNmwYVq5ciX379sHPzw9btmyBs7Mz3NzcpGVe9m8u/Q8LIS2gq6uLRYsWoVu3bvj+++8xc+ZM6Rejvr6+2h+owjg6OuK///574TJRUVHo0aNHiQ4VPG/o0KGYN28etm3bhjp16iAlJUUaFAgAtWvXhqmpKfLy8l6YV1P9+vXDokWLsGHDhkILoby8PPz666+wtLREx44d1e67cuVKgeUvX74s9ZRo8joX5/fff8eYMWOwZMkSqS0zMxOPHz9WW640r/2L5E+OFxsbi27dukntubm5iI+PL1CAPu+VV16Brq4ufvnllzIddLpr1y5kZWVh586dal+amhwSKOk2HB0dAQD//fdfsT8Qinr9X/bzURwbGxtMmjQJkyZNwv3799G6dWssWLBAKoRK+nj579UXfdYLk18wXLt2rUTLu7q64rXXXsPKlSsxY8YM6bXv168ffvvtN2zYsAGffPJJgfVSUlKwY8cOODs7S/uhf//++O233/DLL79g1qxZJXr83Nxc3Lx5EwMGDCh2OU3fu5aWlgU+kwA0nmm7S5cusLGxQXBwMDp16oTDhw9j9uzZasuU53tK23CMkJbo2rUrPD09sXz5cmRmZsLa2hpdu3bFypUrcffu3QLLP3jwQPr/gIAAREVFITQ0tMBy+b/OhwwZgtu3b2PVqlUFlsnIyJDOfipKs2bN0LJlSwQHByM4OBg2NjZqRYmuri4CAgKwbdu2Qv9QP5tXU15eXujZsyfWrl1b6My1s2fPxuXLl/Hhhx8W+AW3fft2tTE+//zzD06ePCl9CWnyOhdHV1e3QA/Nd999V+CXZo0aNQCg0D/GpdWmTRtYWVlh1apVyM3Nldo3bdpUZA/As+zt7TF+/HgcPHgQ3333XYH7VSoVlixZglu3bmmUK7/H6PnDhGvXri3zbfTu3RumpqZYtGgRMjMz1e57dt0aNWoUeqjyZT8fhcnLyyvwWNbW1qhXrx6ysrJemOl5tWvXRpcuXbBmzRrcuHFD7b4X9Q7a2trC3t5eo1mWP/zwQ+Tk5Kj1aLz66qto3rw5vvjiiwLbUqlUmDhxIpKSkjB37ly1dVq2bIkFCxbgxIkTBR4nNTW1QBFx8eJFZGZmwsvLq9iMmr53HR0dkZycLPVaAcDdu3cL/dtZHB0dHbz66qvYtWsXNm7ciNzcXLXDYkD5vKe0FXuEtMgHH3yAwYMHY926dZgwYQJWrFiBTp06oWXLlhg/fjwaNWqEhIQEnDhxArdu3ZKmoP/ggw/w+++/Y/DgwXjjjTfg4eGBR48eYefOnQgKCoKbmxtGjRqFLVu2YMKECThy5Ag6duyIvLw8REdHY8uWLThw4IB0qK4oQ4cORWBgIAwNDTFu3Djo6KjX6V988QWOHDmCdu3aYfz48WjevDkePXqE06dPIywsDI8ePSr1a7Nhwwb06NEDAwcOxIgRI9C5c2dkZWUhJCQER48exdChQ/HBBx8UWK9x48bo1KkTJk6ciKysLCxfvhxWVlb48MMPpWVK+joXp1+/fti4cSPMzc3RvHlznDhxAmFhYdIhiXzu7u7Q1dXFl19+ieTkZBgYGKB79+6wtrYu9WujVCrx6aef4p133kH37t0xZMgQxMfHY926dXB0dCzRr9ElS5YgLi4O7777LkJCQtCvXz9YWlrixo0b2Lp1K6Kjo9V6AEuid+/eUCqV6N+/P95++22kpaVh1apVsLa2LrTofJltmJmZYdmyZXjzzTfRtm1bjBgxApaWloiKisKTJ0+wfv16AICHhweCg4Mxffp0tG3bFiYmJujfv3+ZfD6el5qaCjs7O7z66qvSZSXCwsJw6tQptZ7DojIV5ttvv0WnTp3QunVrvPXWW2jYsCHi4+OxZ88enD17ttg8AwcORGhoaInG3gBPD2316dMHP//8M+bMmQMrKysolUr8/vvv6NGjBzp16oSxY8eiTZs2ePz4MX799VecPn0a77//vtp7RV9fHyEhIejZsye6dOmCIUOGoGPHjtDX18eFCxek3txnT///448/YGxsjF69er0wpybv3WHDhuGjjz6Cv78/3n33XTx58gQ//vgjmjZtqvFJDUOHDsV3332HuXPnomXLlgWmwSiP95TWqvgT1ag8FTWhohBPZy51dHQUjo6O0unZcXFxYvTo0aJu3bpCX19f2Nrain79+onff/9dbd2HDx+KKVOmSFPf29nZiTFjxqidyp6dnS2+/PJL4eLiIgwMDISlpaXw8PAQ8+bNE8nJydJyz58+n+/KlSvSpG/Hjh0r9PklJCSIyZMnC3t7e6Gvry/q1q0revToIX766SdpmfzTwrdu3arRa5eamio+/fRT4eLiIoyMjISpqano2LGjWLduXYHTh5+dUHHJkiXC3t5eGBgYiM6dO4uoqKgC2y7J61zcvktKShJjx44VtWrVEiYmJsLHx0dER0cX+lquWrVKNGrUSOjq6pZoQsXnX6eiJtr79ttvRYMGDYSBgYHw9PQUERERwsPDQ/j6+pbg1X06C+/PP/8sOnfuLMzNzYW+vr5o0KCBGDt2rNrpyUXNLJ3/+jw7ieTOnTuFq6urMDQ0FA4ODuLLL78Ua9asKbBc/oSKhSnpNvKX9fLyEkZGRsLMzEx4enqK3377Tbo/LS1NjBgxQlhYWBSYULGknw/8/0R7hcEzp89nZWWJDz74QLi5uQlTU1NRo0YN4ebmVmAyyKIyFbWf//vvP+Hv7y8sLCyEoaGhcHJyEnPmzCk0z7NOnz4tABQ4nbuoCRWFEOLo0aMFpgQQQoj79++L6dOni8aNGwsDAwNhYWEhevbsKZ0yX5ikpCQRGBgoWrZsKYyNjYWhoaFo0aKFmDVrlrh7967asu3atROvvfbaC59TvpK+d4UQ4uDBg6JFixZCqVQKJycn8csvvxQ7oWJRVCqVsLe3FwDE559/XugyJX1PUfEUQlSRq0kSVSLx8fFo2LAhFi9ejBkzZsgdRxYqlQq1a9fGoEGDCu2eJ+3To0cP1KtXDxs3bpQ7SpHOnj2L1q1b4/Tp0xoN3qfqi2OEiOiFMjMzC4wT2bBhAx49eoSuXbvKE4oqnYULFyI4OFjjwcEV6YsvvsCrr77KIogkHCNERC/0999/Y9q0aRg8eDCsrKxw+vRprF69Gi1atMDgwYPljkeVRLt27ZCdnS13jGJt3rxZ7ghUybAQIqIXcnBwgL29Pb799ls8evQINWvWxOjRo/HFF18UeQ03IqKqgGOEiIiISGtxjBARERFpLRZCREREpLW0boyQSqXCnTt3YGpqymnJiYiIqgghBFJTU1GvXr0CE+6+DK0rhO7cucOL0REREVVRN2/ehJ2dXZltT+sKIVNTUwBPX0gzMzOZ0xAREVFJpKSkwN7eXvoeLytaVwjlHw4zMzNjIURERFTFlPWwFg6WJiIiIq3FQoiIiIi0FgshIiIi0loshIiIiEhrsRAiIiIircVCiIiIiLQWCyEiIiLSWiyEiIiISGuxECIiIiKtxUKIiIiItJashVB4eDj69++PevXqQaFQYPv27S9c5+jRo2jdujUMDAzQuHFjrFu3rtxzEhERUfUkayGUnp4ONzc3rFixokTLX7t2DX379kW3bt1w9uxZvPfee3jzzTdx4MCBck5KRERE1ZGsF1195ZVX8Morr5R4+aCgIDRs2BBLliwBADRr1gzHjh3DsmXL4OPjU14xiYiIqJqqUmOETpw4gZ49e6q1+fj44MSJEzIlIiIiovImhMD9+/fLZduy9ghp6t69e6hTp45aW506dZCSkoKMjAwYGRkVWCcrKwtZWVnS7ZSUlHLPSURUGWzdCgQGAqmpcichKj0jo1R4e+9AzZox5bL9KlUIlcaiRYswb948uWMQEVW4wEAgOlruFESl5+QUjQEDdqFGjSfIzMwtl8eoUoVQ3bp1kZCQoNaWkJAAMzOzQnuDAGDWrFmYPn26dDslJQX29vblmpOIqDLI7wnS0QFsbOTNQqQpQ8N0vPpqCPT1cwAAGRkm5fI4VaoQ6tChA/bu3avW9scff6BDhw5FrmNgYAADA4PyjkZEVGnZ2AC3bsmdgkhTNXD6tC927doFZ2dneHt745tvPinzR5G1EEpLS0NsbKx0+9q1azh79ixq1qyJ+vXrY9asWbh9+zY2bNgAAJgwYQK+//57fPjhh3jjjTdw+PBhbNmyBXv27JHrKRAREVEZUKlUUKlU0NP7X2nSqlUrmJmZwdHREanlNNhN1rPG/v33X7Rq1QqtWrUCAEyfPh2tWrVCYGAgAODu3bu4ceOGtHzDhg2xZ88e/PHHH3Bzc8OSJUvw888/89R5IiKiKiw5ORkbN27EwYMH1doVCgUaN24MhUJRbo+tEEKIctt6JZSSkgJzc3MkJyfDzMxM7jhEROXGzg64fRuwteWhMaq8Lly4gN27dyMzMxMAMGLECDRp0qTAcuX1/V2lxggRERFR9ZCVlYV9+/YhKipKajMzM4NSqazQHCyEiIiIqELdvHkToaGhSEpKktpcXFzQt2/fIs8CLy8shIiIiKhCqFQqhIeHIzw8HPkjc5RKJfr06QNXV9dyHQtUFBZCREREVO6ePHmC3377DbeeGbBmb28Pf39/WFpaypaLhRARERGVO0NDQ+joPD1ZXaFQwNvbG507d5ba5FKlLrpKREREVZOOjg78/f1hY2ODN954A97e3rIXQQB7hIiIiKgcxMfHQ19fH7a2tlKbhYUFxo8fL8tYoKKwECIiIqIyk5eXhyNHjiAiIgKWlpZ4++231S51VZmKIICHxoiIiKiMJCYmYvXq1YiIiAAAJCUl4d9//5U5VfHYI0REREQvRQiB06dPY//+/cjNzQXwdExQ9+7d4eXlJXO64rEQIiIiolJLT0/Hrl27EBMTI7VZWVkhICAANjY2MiYrGRZCREREVCqxsbHYsWMH0tLSpDYPDw/4+PhAX19fxmQlx0KIiIiINJaWlobg4GDpUJixsTEGDBgAJycnmZNphoOliYiISGMmJibo0aMHAMDR0RETJ06sckUQwB4hIiIiKgEhBFQqFXR1daW2du3awczMDM2aNat0p8WXFHuEiIiIqFipqanYtGkTDh8+rNauUCjQvHnzKlsEAewRIiIiomJER0dj586dyMjIQFxcHBo3boyGDRvKHavMsBAiIiKiArKzs3Hw4EFERkZKbSYmJjImKh8shIiIiEjNnTt3EBISgocPH0ptTk5OGDBgAIyNjWVMVvZYCBEREREAQKVS4fjx4zhy5AhUKhUAQF9fHz4+PmjdunWVHgtUFBZCREREhCdPnmDr1q2Ij4+X2mxsbBAQEAArKyv5gpUzFkJEREQEAwMDZGdnS7c7deqErl27qp0uXx2xECKiam3rViAwEEhNlTtJxbt7V+4EVJXo6upi0KBB2Lx5M/r27QsHBwe5I1UIhRBCyB2iIqWkpMDc3BzJyckwMzOTOw4RlbNmzYDoaLlTyMvZGbh0Se4UVNncvHkT+vr6qFu3rlq7EKJSjgUqr+9v9ggRUbWW3xOkowNUgQthlzlTU2D+fLlTUGWiUqkQHh6O8PBwWFlZ4a233lK7QGplLILKEwshItIKNjbArVtypyCSV1JSEkJCQnDr/z8MiYmJOHXqFLy8vGROJh8WQkRERNWcEALnzp3D3r17pQHRCoUC3t7eaN++vczp5MVCiIiIqBrLyMjAnj17cOHCBanN0tISgwYNgp2dnYzJKgcWQkRERNVUfHw8QkNDkZKSIrW5u7vD19cXBgYGMiarPFgIERERVUOpqan45ZdfkJeXBwAwNDREv3794OLiInOyykVH7gBERERU9kxNTeHt7Q0AcHBwwMSJE1kEFYI9QkRERNWAEAJCCOjo/K+Po2PHjjAzM4Orq6vWnRZfUuwRIiIiquLS09MRHByM8PBwtXYdHR24ubmxCCoGe4SIiIiqsNjYWOzYsQNpaWm4fPkyHB0dYW9vL3esKoOFEBERURWUm5uLsLAwnDx5UmozMjJSu3AqvRgLISIioiomISEBISEhuH//vtTm6OgIPz8/mJiYyJis6mEhREREVEUIIXDy5EmEhYVJp8Xr6uqiV69e8PT05FigUmAhREREVAU8efIEISEhiIuLk9qsra0REBAAa2trGZNVbSyEiIiIqgClUonU1FTpdvv27dGjRw/o6fGr/GXw9HkiIqIqQE9PD4MGDYKFhQVee+01+Pj4sAgqA3wFiYiIKqE7d+5AqVSiVq1aUludOnXwzjvvqE2aSC+HryQREVElolKpcOzYMaxevRrbtm1Dbm6u2v0sgsoWX00iIqJKIjk5GRs2bMChQ4egUqlw7949nDp1Su5Y1RoPjREREVUCFy5cwO7du5GZmSm1derUCZ6enjKmqv5YCBEREckoKysL+/btQ1RUlNRmZmYGf39/ODg4yBdMS7AQIiIiksnNmzcRGhqKpKQkqc3FxQV9+/aFkZGRjMm0BwshIiIiGaSkpGD9+vXSDNFKpRJ9+vSBq6srZ4iuQBwsTUREJAMzMzN06NABAGBvb48JEybAzc2NRVAFY48QERFRBRBCAIBaodO1a1eYm5ujdevWPC1eJnzViYiIyllGRga2bduGEydOqLXr6uqiTZs2LIJkxB4hIiKichQfH4/Q0FCkpKTg0qVLaNiwIWxsbOSORf+PhRARVVlbtwKBgcAz16Es4O7distD9Ky8vDwcOXIEERERUptSqURaWpqMqeh5LISIqMoKDASio0u2rKlp+WYhelZiYiJCQkJw95lK3MHBAf7+/jAzM5MxGT2PhRARVVn5PUE6OkBxRxpMTYH58ysmE2k3IQQiIyNx4MAB6RphOjo66N69O7y8vHhGWCXEQoiIqjwbG+DWLblTkLbLyMjAjh07EBMTI7VZWVkhICCAY4IqMRZCREREZUBXVxeJiYnS7TZt2qB3797Q19eXMRW9CM/XIyIiKgNKpRKDBg2Cqakphg0bhr59+7IIqgLYI0RERFQKCQkJUCqVsLS0lNrq1auHd999F3p6/HqtKtgjREREpAEhBP7++2+sWrUKISEhUKlUavezCKpaWAgRERGVUGpqKjZt2oQDBw4gLy8Pt27dwqlTp+SORS9B9kJoxYoVcHBwgKGhIdq1a4d//vmn2OWXL18OJycnGBkZwd7eHtOmTUNmZmYFpSUiIm0VHR2NH3/8EXFxcVJb+/bt4eHhIWMqelmy9t8FBwdj+vTpCAoKQrt27bB8+XL4+PggJiYG1tbWBZb/9ddfMXPmTKxZswZeXl64fPkyXn/9dSgUCixdulSGZ0BERNVddnY2Dh48iMjISKnNxMQEfn5+cHR0lDEZlQVZC6GlS5di/PjxGDt2LAAgKCgIe/bswZo1azBz5swCyx8/fhwdO3bEiBEjADydpXP48OE4efJkheYmIiLtcOfOHYSEhODhw4dSm7OzM/r37w9jY2MZk1FZke3QWHZ2NiIjI9GzZ8//hdHRQc+ePQtcnTefl5cXIiMjpcNnV69exd69e9GnT58iHycrKwspKSlq/4iIiF4kOTkZa9askYogfX199O/fH0OGDGERVI3I1iOUmJiIvLw81KlTR629Tp06iC7i4kEjRoxAYmIiOnXqBCEEcnNzMWHCBHz88cdFPs6iRYswb968Ms1ORETVn7m5Odq0aYOTJ0/CxsYGAQEBsLKykjsWlTHZB0tr4ujRo1i4cCF++OEHnD59GiEhIdizZw/mF3MRoVmzZiE5OVn6d/PmzQpMTEREVYkQQu12z5490bt3b4wbN45FUDUlW49QrVq1oKuri4SEBLX2hIQE1K1bt9B15syZg1GjRuHNN98EALRs2RLp6el46623MHv2bOjoFKzrDAwMYGBgUPZPgIiIqo2srCzs27cPtra2aNu2rdSup6eHDh06yJiMyptsPUJKpRIeHh44dOiQ1KZSqXDo0KEi33RPnjwpUOzo6uoCKFjFExERlcTNmzcRFBSEqKgoHDx4EA8ePJA7ElUgWc8amz59OsaMGYM2bdrA09MTy5cvR3p6unQW2ejRo2Fra4tFixYBAPr374+lS5eiVatWaNeuHWJjYzFnzhz0799fKoiIiIhKQqVSITw8HOHh4dKPaR0dHSQlJaF27doyp6OKImshNHToUDx48ACBgYG4d+8e3N3dsX//fmkA9Y0bN9R6gD755BMoFAp88sknuH37NmrXro3+/ftjwYIFcj0FIiKqgpKSkhASEoJbt25Jbfb29vD391e7dhhVfwqhZceUUlJSYG5ujuTkZJiZmckdh4hegp0dcPs2YGsLPPN9RlQkIQSioqKwb98+ZGdnAwAUCgW8vb3RuXPnQseaUuVQXt/fvDIcERFphczMTOzevRsXLlyQ2iwtLTFo0CDY2dnJmIzkxEKIiIi0xrOHwtzd3eHr68szi7Uc+wCJiEgrGBoawt/fH8bGxnj11VcxcOBAFkHEHiEiIqqeEhMToVQq1caTNGjQAFOnToVSqZQxGVUm7BEiIqJqRQiBf//9FytXrkRoaGiBeeZYBNGzWAgREVG1kZ6ejuDgYOzZswe5ubmIj49HZGSk3LGoEuOhMSIiqhZiY2OxY8cOpKWlSW0eHh5wc3OTMRVVdiyEiIioSsvNzUVYWBhOnjwptRkbG2PAgAFwcnKSMRlVBSyEiIioykpISEBISAju378vtTk6OsLPzw8mJiYyJqOqgoUQERFVSY8fP8aqVauQl5cH4OlFuHv16gVPT08oFAqZ01FVwUKIiEps61YgMBBITZU7yVN378qdgORkYWEBNzc3nD59GtbW1ggICIC1tbXcsaiKYSFERCUWGAhER8udoiBTU7kTkFx8fHxgbm4OLy8v6OnxK400x3cNEZVYfk+Qjg5gYyNvlnympsD8+XKnoPKWnZ2NgwcPws7ODu7u7lK7UqlEly5d5AtGVR4LISLSmI0Nr/ZOFefOnTsICQnBw4cPcf78edSvXx81a9aUOxZVEyyEiIioUlKpVDh+/DiOHDkClUoF4Oms0ffv32chRGWGhRAREVU6ycnJCA0NxfXr16U2GxsbBAQEwMrKSsZkVN2wECIiokrlwoUL2L17NzIzM6W2Tp06oWvXrtDV1ZUxGVVHLISIiKhSyMrKwr59+xAVFSW1mZmZwd/fHw4ODvIFo2qNhRAREVUKeXl5iIuLk267uLigb9++MDIykjEVVXe8+jwREVUKxsbG8PPzg4GBAfz8/BAQEMAiiMode4SIiEgWSUlJ0NfXV7smmKOjI9577z0YGhrKmIy0CXuEiIioQgkhcPbsWQQFBWHnzp0QQqjdzyKIKhJ7hIiIqMJkZGRgz549uHDhAgDgypUrOHv2LFq1aiVzMtJWLISIiKhCxMfHIzQ0FCkpKVKbu7s7mjdvLmMq0nYshIiIqFzl5eXhyJEjiIiIkNoMDQ3Rr18/uLi4yJiMiIUQERGVo8TERISEhODu3btSm4ODA/z9/WFmZiZjMqKnWAgREVG5SEpKwsqVK5GbmwsA0NHRQffu3eHl5QWFQiFzOqKnWAgREVG5sLS0RLNmzXD+/HlYWVkhICAANjY2csciUsNCiIiIyk2fPn1gbm6OLl26QF9fX+44RAW81DxCz14Qj4iItFdubi72798vnRafz9DQED169GARRJWWxoWQSqXC/PnzYWtrCxMTE1y9ehUAMGfOHKxevbrMAxIRUeWWkJCAVatW4eTJk9i9ezeSk5PljkRUYhoXQp9//jnWrVuHr776CkqlUmpv0aIFfv755zINR0RElZcQAn///TdWrVqF+/fvAwBycnJw584dmZMRlZzGY4Q2bNiAn376CT169MCECROkdjc3N0RHR5dpOCIiqpxSU1OxY8cOtavFW1tbIyAgANbW1jImI9KMxoXQ7du30bhx4wLtKpUKOTk5ZRKKiIgqr+joaOzatQtPnjyR2tq3b48ePXpAT4/n4FDVovE7tnnz5vjrr7/QoEEDtfbff/+d14ohIqrGsrOzcfDgQURGRkptJiYm8PPzg6Ojo4zJiEpP40IoMDAQY8aMwe3bt6FSqRASEoKYmBhs2LABu3fvLo+MRERUCWRlZeHSpUvSbWdnZ/Tv3x/GxsYypiJ6ORoPlh44cCB27dqFsLAw1KhRA4GBgbh06RJ27dqFXr16lUdGIiKqBExNTdG/f3/o6+ujf//+GDJkCIsgqvIUQgghd4iKlJKSAnNzcyQnJ/M6N0QasrMDbt8GbG2BW7fkTkPlLTk5GUqlEkZGRmrt6enpqFGjhkypSFuV1/e3xj1CjRo1wsOHDwu0P378GI0aNSqTUEREJK8LFy4gKCgIu3fvxvO/l1kEUXWi8Rih+Ph45OXlFWjPysrC7du3yyQUERHJIysrC/v27UNUVBQA4OLFizh//jxcXV1lTkZUPkpcCO3cuVP6/wMHDsDc3Fy6nZeXh0OHDsHBwaFMwxERUcW5efMmQkJC8PjxY6nNxcUFTZo0kS8UUTkrcSHk5+cHAFAoFBgzZozaffr6+nBwcMCSJUvKNBwREZU/lUqF8PBwhIeHS4fBlEol+vTpA1dXVygUCpkTEpWfEhdCKpUKANCwYUOcOnUKtWrVKrdQRERUMZKSkhASEoJbz4x+t7e3h7+/PywtLWVMRlQxNB4jdO3atfLIQUREFezRo0dYuXIlsrOzATzt8ff29kbnzp2ho6PxuTREVVKp5kJPT0/Hn3/+iRs3bkgfoHzvvvtumQQjIqLyZWlpiUaNGiE6OhqWlpYYNGgQ7Ozs5I5FVKE0LoTOnDmDPn364MmTJ0hPT0fNmjWRmJgIY2NjWFtbsxAiIqoiFAoF+vfvD3Nzc3Tr1g0GBgZyRyKqcBr3fU6bNg39+/dHUlISjIyM8Pfff+P69evw8PDA119/XR4ZiYjoJeXl5SEsLAyXL19Wazc2Noavry+LINJaGhdCZ8+exfvvvw8dHR3o6uoiKysL9vb2+Oqrr/Dxxx+XR0YiInoJiYmJWL16NSIiIrBz506kpaXJHYmo0tC4ENLX15cG0VlbW+PGjRsAAHNzc9y8ebNs0xERUakJIfDvv/9i5cqVuHv3LgAgIyODf6uJnqHxGKFWrVrh1KlTaNKkCby9vREYGIjExERs3LgRLVq0KI+MRESkofT0dOzatQsxMTFSm5WVFQICAmBjYyNjMqLKReNCaOHChUhNTQUALFiwAKNHj8bEiRPRpEkTrF69uswDEhGRZmJjY7Fjxw61Q2Bt2rRB7969oa+vL2MyospH40KoTZs20v9bW1tj//79ZRqIiIhKJzc3F2FhYTh58qTUZmxsjAEDBsDJyUnGZESVV5nNmHX69Gn069evrDZHREQaSk9Px9mzZ6XbjRs3xsSJE1kEERVDo0LowIEDmDFjBj7++GNcvXoVABAdHQ0/Pz+0bdtWugwHERFVPHNzc/Tt2xe6urrw9fXFiBEjYGJiIncsokqtxIfGVq9ejfHjx6NmzZpISkrCzz//jKVLl+Kdd97B0KFD8d9//6FZs2blmZWIiJ6RmpoKpVKpNgdQy5YtUb9+fZibm8uYjKjqKHGP0DfffIMvv/wSiYmJ2LJlCxITE/HDDz/g/PnzCAoKYhFERFSBoqOjERQUhH379hW4j0UQUcmVuEcoLi4OgwcPBgAMGjQIenp6WLx4Ma9LQ0RUgbKzs3Hw4EFERkYCAKKiotC0aVM0b95c5mREVVOJC6GMjAwYGxsDeHp9GgMDA85FQURUge7cuYOQkBA8fPhQanN2doaDg4N8oYiqOI1On//555+lgXe5ublYt24datWqpbYML7pKRFS2VCoVjh8/jiNHjkgnpejr68PX1xetWrWCQqGQOSFR1aUQQoiSLOjg4PDCD5tCoZDOJiupFStWYPHixbh37x7c3Nzw3XffwdPTs8jlHz9+jNmzZyMkJASPHj1CgwYNsHz5cvTp06dEj5eSkgJzc3MkJyfDzMxMo6xE2s7ODrh9G7C1BW7dkjuNdkhOTkZoaCiuX78utdnY2CAgIABWVlYyJiOqWOX1/V3iHqH4+Pgye9B8wcHBmD59OoKCgtCuXTssX74cPj4+iImJgbW1dYHls7Oz0atXL1hbW+P333+Hra0trl+/DgsLizLPRkQkt4cPH+Lnn39GZmam1NapUyd07doVurq6MiYjqj40nlm6LC1duhTjx4/H2LFjAQBBQUHYs2cP1qxZg5kzZxZYfs2aNXj06BGOHz8uTRPPY+NEVF3VrFkTtra2iIuLg5mZGfz9/fk3j6iMldnM0prKzs5GZGQkevbs+b8wOjro2bMnTpw4Ueg6O3fuRIcOHTB58mTUqVMHLVq0wMKFC5GXl1dRsYmIKoxCocDAgQPRunVrTJgwgUUQUTmQrUcoMTEReXl5qFOnjlp7nTp1EB0dXeg6V69exeHDhzFy5Ejs3bsXsbGxmDRpEnJycjB37txC18nKykJWVpZ0OyUlpeyeBBFRGVGpVAgPD0eDBg3QsGFDqd3U1BT9+/eXMRlR9SZbj1BpqFQqWFtb46effoKHhweGDh2K2bNnIygoqMh1Fi1aBHNzc+mfvb19BSYmInqxpKQkrF27Fn/++SdCQ0ORkZEhdyQirSFbIVSrVi3o6uoiISFBrT0hIQF169YtdB0bGxs0bdpUbZBgs2bNcO/ePWRnZxe6zqxZs5CcnCz9u3nzZtk9CSKilyCEQFRUFIKCgnDr/0/DS0tLw7Vr12RORqQ9SlUIxcXF4ZNPPsHw4cNx//59AMC+fftw4cKFEm9DqVTCw8MDhw4dktpUKhUOHTqEDh06FLpOx44dERsbq3Zx18uXL8PGxgZKpbLQdQwMDGBmZqb2j4hIbhkZGdi2bRu2b98u/ZCztLTEG2+8wVmiiSqQxoXQn3/+iZYtW+LkyZMICQlBWloagKfTvBc1Tqco06dPx6pVq7B+/XpcunQJEydORHp6unQW2ejRozFr1ixp+YkTJ+LRo0eYOnUqLl++jD179mDhwoWYPHmypk+DiEg28fHxCAoKUvvx6O7ujrfffpuXLSKqYBoPlp45cyY+//xzTJ8+HaamplJ79+7d8f3332u0raFDh+LBgwcIDAzEvXv34O7ujv3790sDqG/cuAEdnf/Vavb29jhw4ACmTZsGV1dX2NraYurUqfjoo480fRpE5WrrViAwEEhNlTtJ2bp7V+4EVVteXh6OHDmCiIgIqc3Q0BD9+vWDi4uLjMmItFeJZ5bOZ2JigvPnz6Nhw4YwNTVFVFQUGjVqhPj4eDg7O6tN/FUZcWZpqgjNmgFFnPxYLTg7A5cuyZ2i6klKSsKPP/6InJwcAE/nQfPz8+PV4olKQPaZpfNZWFjg7t27aqd3AsCZM2dga2tbZsGIqrL8niAdHaC6XZvY1BSYP1/uFFWTpaUlfH19sWfPHnTv3h1eXl68ThiRzDQuhIYNG4aPPvoIW7duhUKhgEqlQkREBGbMmIHRo0eXR0aiKsvGhtfk0mZPnjyBvr6+NBM+ALRq1QoODg6oWbOmjMmIKJ/Gg6UXLlwIZ2dn2NvbIy0tDc2bN0eXLl3g5eWFTz75pDwyEhFVObGxsfjxxx9x8OBBtXaFQsEiiKgS0XiMUL4bN27gv//+Q1paGlq1aoUmTZqUdbZywTFCVBF4lXbtlZubi7CwMJw8eVJqGz58OJo2bSpjKqKqr9KMETp27Bg6deqE+vXro379+mUWhIioqktISEBISIg0vxoANG7cGPXq1ZMxFREVR+NCqHv37rC1tcXw4cPx2muvceIvItJ6QgicPHkSYWFh0kWgdXV10atXL3h6enJANFElpvEYoTt37uD999/Hn3/+iRYtWsDd3R2LFy+WpocnItImqamp2LRpEw4cOCAVQdbW1njrrbfQrl07FkFElVypxwgBwLVr1/Drr7/it99+Q3R0NLp06YLDhw+XZb4yxzFCVBE4Rkg7JCYmYu3atXjy5InU1r59e/To0QN6ehp3uBNRMSrNGKFnNWzYEDNnzoSbmxvmzJmDP//8s6xyERFVejVr1kTt2rVx/fp1mJiYwM/PD46OjnLHIiINlPrq8xEREZg0aRJsbGwwYsQItGjRAnv27CnLbERElZqOjg78/f3h6uqKiRMnsggiqoI07hGaNWsWNm/ejDt37qBXr1745ptvMHDgQBgbG5dHPiKiSkGlUuH48eNo0KAB7O3tpXZzc3P4+/vLmIyIXobGhVB4eDg++OADDBkyBLVq1SqPTERElUpycjJCQ0Nx/fp1WFhYYMKECTAwMJA7FhGVAY0LoWevmkxEVN1duHABu3fvli4o/fjxY8TFxXHqEKJqokSF0M6dO/HKK69AX18fO3fuLHbZAQMGlEkwIiI5ZWVlYd++fYiKipLazMzM4O/vDwcHB/mCEVGZKlEh5Ofnh3v37sHa2hp+fn5FLqdQKKR5NIiIqqqbN28iNDQUSUlJUpuLiwv69u0LIyMjGZMRUVkrUSGkUqkK/X8ioupEpVIhPDwc4eHhyJ9iTalUok+fPnB1deXkiETVkManz2/YsAFZWVkF2rOzs7Fhw4YyCUVEJIdHjx7h2LFjUhFkb2+PCRMmwM3NjUUQUTWlcSE0duxYJCcnF2hPTU3F2LFjyyQUEZEcatWqhV69ekGhUKBr1654/fXXYWlpKXcsIipHGp81JoQo9JfRrVu3YG5uXiahiIgqQkZGBvT19dUuh+Hp6YmGDRvC2tpaxmREVFFKXAi1atUKCoUCCoWiwHV08vLycO3aNfj6+pZLSCKishYfH4/Q0FC4uLigd+/eUrtCoWARRKRFSlwI5Z8tdvbsWfj4+MDExES6T6lUwsHBAQEBAWUekIioLOXl5eHIkSPSnGgnTpxA48aN0ahRI5mTEZEcSlwIzZ07FwDg4OCAoUOHwtDQsNxCERGVh8TERISEhODu3btSm4ODA2fJJ9JiGo8RGjNmTHnkICIqN0IIREZG4sCBA8jNzQXw9IKp3bt3h5eXF88II9JiJSqEatasicuXL6NWrVqwtLQs9o/Go0ePyiwcEdHLSk9Px65duxATEyO1WVlZISAgADY2NjImI6LKoESF0LJly2Bqair9P389EVFVkJiYiPXr1yMtLU1qa9OmDXr37g19fX0ZkxFRZVGiQujZw2Gvv/56eWUhIipTlpaWMDMzQ1paGoyNjTFgwAA4OTnJHYuIKhGNJ1Q8ffo0zp8/L93esWMH/Pz88PHHHyM7O7tMwxERvQxdXV0MGjQIzZo1w8SJE1kEEVEBGhdCb7/9Ni5fvgwAuHr1KoYOHQpjY2Ns3boVH374YZkHJCIqCSEETp48qXZGGPB0PNCQIUPUpvwgIsqncSF0+fJluLu7AwC2bt0Kb29v/Prrr1i3bh22bdtW1vmIKp2tW4FmzQA7u6L/PfddTOUsNTUVmzZtwv79+xESEoKcnBy5IxFRFVGqS2zkX4E+LCwM/fr1A/D04oSJiYllm46oEgoMBKKjS7bs/59jQOUoOjoau3btwpMnTwA8HSB95coVNG/eXOZkRFQVaFwItWnTBp9//jl69uyJP//8Ez/++CMA4Nq1a6hTp06ZBySqbFJTn/5XRwco7uxrU1Ng/vyKyaSNsrOzcfDgQURGRkptJiYm8PPzg6Ojo4zJiKgq0bgQWr58OUaOHInt27dj9uzZaNy4MQDg999/h5eXV5kHJKqsbGyAW7fkTqGd7ty5g5CQEDx8+FBqc3Z2Rv/+/WFsbCxjMiKqahRCCFEWG8rMzISurm6ln5sjJSUF5ubmSE5OhpmZmdxxqAqyswNu3wZsbVkIVTSVSoXjx4/jyJEj0iF6fX19+Pj4oHXr1pzjjKgaK6/vb417hPJFRkbi0qVLAIDmzZujdevWZRaKiKgwiYmJakWQjY0NAgICYGVlJXMyIqqqNC6E7t+/j6FDh+LPP/+EhYUFAODx48fo1q0bNm/ejNq1a5d1RiIiAIC1tTW6deuGQ4cOoVOnTujatSt0dXXljkVEVZjGp8+/8847SEtLw4ULF/Do0SM8evQI//33H1JSUvDuu++WR0Yi0lJZWVlS708+Ly8vjB8/Hj169GARREQvTeMeof379yMsLAzNmjWT2po3b44VK1agd+/eZRqOiLTXzZs3ERoaCldXV3Tt2lVq19HRQb169eQLRkTVisaFkEqlKnRAtL6+foFfbkREmlKpVAgPD0d4eDiEEAgPD4ejoyPs7e3ljkZE1ZDGh8a6d++OqVOn4s6dO1Lb7du3MW3aNPTo0aNMwxGRdklKSsLatWvx559/Iv+EVjs7O14eg4jKjcY9Qt9//z0GDBgABwcH6RfazZs30aJFC/zyyy9lHpCIqj8hBM6dO4e9e/dKF29WKBTw9vZG586doaOj8W82IqIS0bgQsre3x+nTp3Ho0CHp9PlmzZqhZ8+eZR6OiKq/jIwM7NmzBxcuXJDaLC0tMWjQINjZ2cmYjIi0gUaFUHBwMHbu3Ins7Gz06NED77zzTnnlIiItkJiYiI0bNyIlJUVqc3d3h6+vLwwMDGRMRkTaosSF0I8//ojJkyejSZMmMDIyQkhICOLi4rB48eLyzEdE1ZiFhQUMDQ2RkpICQ0ND9OvXDy4uLnLHIiItUuID799//z3mzp2LmJgYnD17FuvXr8cPP/xQntmIqJrT09NDQEAAmjRpgokTJ7IIIqIKV+JrjRkZGeHSpUtwcHAA8PQUVyMjI8THx8OmuEtwVzK81hi9LF5rrHSEEDh9+jTq16/PGeiJSGOyX2ssKysLNWrUkG7r6OhAqVQiIyOjzMIQUfWUnp6OXbt2ISYmBnXq1MGbb74JPb1SX+qQiKjMaPSXaM6cOTA2NpZuZ2dnY8GCBTA3N5fali5dWnbpiKjKi42NxY4dO5CWlgYASEhIwOXLl9G8eXOZkxERaVAIdenSBTExMWptXl5euHr1qnRboVCUXTIiqtJyc3MRFhaGkydPSm3GxsYYMGAAnJycZExGRPQ/JS6Ejh49Wo4xiKg6SUhIQEhICO7fvy+1OTo6ws/Pj7NEE1GlwoP0RFRmhBA4efIkwsLCkJeXBwDQ1dVFr1694OnpyV5jIqp0WAgRUZlJSEjAwYMHpeuEWVtbIyAgANbW1jInIyIqHC/gQ0Rlpm7duujUqRMAoH379hg/fjyLICKq1NgjRESllpOTAz09PbVDXt7e3nB0dESDBg1kTEZEVDLsESKiUrlz5w5WrlyJ48ePq7Xr6uqyCCKiKqNUhdBff/2F1157DR06dMDt27cBABs3bsSxY8fKNBwRVT4qlQrHjh3D6tWr8fDhQxw+fBh3796VOxYRUaloXAht27YNPj4+MDIywpkzZ5CVlQUASE5OxsKFC8s8IBFVHsnJydiwYQMOHToElUoFAKhTpw6USqXMyYiISkfjQujzzz9HUFAQVq1aBX19fam9Y8eOOH36dJmGI6LK48KFCwgKCsL169eltk6dOmHcuHGwsrKSMRkRUelpPFg6JiYGXbp0KdBubm6Ox48fl0UmItls3QoEBgKpqUUvo21HgbKysrBv3z5ERUVJbWZmZvD395cuwkxEVFVpXAjVrVsXsbGxBf4AHjt2DI0aNSqrXESyCAwEoqNLtqypaflmqQwSExPx66+/IikpSWpzcXFBv379YGhoKGMyIqKyoXEhNH78eEydOhVr1qyBQqHAnTt3cOLECcyYMQNz5swpj4xEFSa/J0hHB7CxKXo5U1Ng/vyKySQnMzMz6Og8PYKuVCrRp08fuLq6coZoIqo2NC6EZs6cCZVKhR49euDJkyfo0qULDAwMMGPGDLzzzjulCrFixQosXrwY9+7dg5ubG7777jt4enq+cL3Nmzdj+PDhGDhwILZv316qxyYqjI0NcOuW3Cnkp1QqMWjQIPzxxx8YMGAALC0t5Y5ERFSmFCJ/LnwNZWdnIzY2FmlpaWjevHmpL6QYHByM0aNHIygoCO3atcPy5cuxdetWxMTEFDsjbXx8PDp16oRGjRqhZs2aJS6EUlJSYG5ujuTkZJiZmZUqM1VfdnbA7duAra32FUJCCJw7dw729vaoWbNmgfvYC0REciqv7+9ST6ioVCrRvHlzeHp6vtTVpJcuXYrx48dj7NixaN68OYKCgmBsbIw1a9YUuU5eXh5GjhyJefPmcVwSURnIyMjAtm3bsH37doSEhEgXTM3HIoiIqiuND41169at2D+Khw8fLvG2srOzERkZiVmzZkltOjo66NmzJ06cOFHkep999hmsra0xbtw4/PXXX8U+RlZWljTXEfC0oiSi/4mPj0doaKj02bh9+zYuX76MZs2ayZyMiKj8aVwIubu7q93OycnB2bNn8d9//2HMmDEabSsxMRF5eXmoU6eOWnudOnUQXcSpO/kz2p49e7ZEj7Fo0SLMmzdPo1xE2iAvLw9HjhxBRESE1GZoaIj+/fuzCCIiraFxIbRs2bJC2z/99FOkpaW9dKDipKamYtSoUVi1ahVq1apVonVmzZqF6dOnS7dTUlJgb29fXhGJqoTExESEhISoXRrDwcEB/v7+HDtHRFqlzK4+/9prr8HT0xNff/11idepVasWdHV1kZCQoNaekJCAunXrFlg+Li4O8fHx6N+/v9SWP82/np4eYmJi4OjoqLaOgYEBDAwMNHkqRNWWEAKRkZE4cOAAcnNzATw9HN29e3d4eXlxLBARaZ0yK4ROnDih8QRrSqUSHh4eOHToEPz8/AA8LWwOHTqEKVOmFFje2dkZ58+fV2v75JNPkJqaim+++YY9PUQvcO/ePezZs0e6bWVlhYCAANgUN2kSEVE1pnEhNGjQILXbQgjcvXsX//77b6kmVJw+fTrGjBmDNm3awNPTE8uXL0d6ejrGjh0LABg9ejRsbW2xaNEiGBoaokWLFmrrW1hYAECBdiIqyMbGBu3bt8fff/+NNm3aoHfv3mrXDCQi0jYaF0Lm5uZqt3V0dODk5ITPPvsMvXv31jjA0KFD8eDBAwQGBuLevXtwd3fH/v37pQHUN27ckGa2JSLN5ObmQldXV+2QV48ePdC4ceMCh5GJiLSRRhMq5uXlISIiAi1btqyyM8xyQkUqTnWaUDEhIQEhISFo06YN2rZtK3ccIqKXUikmVNTV1UXv3r15lXmiSkwIgb///hurVq3C/fv3cfDgQTx48EDuWERElZLGh8ZatGiBq1evomHDhuWRh4heQmpqKnbs2IG4uDip7fnLZRAR0f9oXAh9/vnnmDFjBubPnw8PDw/UqFFD7X4ebiKSR3R0NHbt2oUnT55Ibe3bt0ePHj2gp1dmJ4gSEVUrJf7r+Nlnn+H9999Hnz59AAADBgxQG4CZf1HG569RRETlKzs7GwcPHkRkZKTUZmJiAj8/Pw6IJiJ6gRIXQvPmzcOECRNw5MiR8sxDRBp4+PAhfvvtNzx8+FBqc3Z2Rv/+/WFsbCxjMiKiqqHEhVD+yWXe3t7lFoaINFOjRg2pF1ZfXx++vr5o1aoVZ4gmIiohjQYO8I8rUeViaGgIf39/HDx4EP7+/rCyspI7EhFRlaJRIdS0adMXFkOPHj16qUBEVLQLFy7Azs5ObWLT+vXrY9y4cfyhQkRUChoVQvPmzSswszQRlb+srCzs27cPUVFRcHBwwKhRo9RmXGcRRERUOhoVQsOGDYO1tXV5ZSGiQty8eROhoaFISkoCAMTHx+Py5ctwdnaWORkRUdVX4kKIvziJKpZKpUJ4eDjCw8OlkxWUSiX69OkDJycnmdMREVUPGp81RkTlLykpCSEhIbj1zAXP7O3t4e/vX2Wv80dEVBmVuBBSqVTlmYOI8PQHx7lz57B3715kZ2cDeNob6+3tjc6dO6uNCyIiopfHefeJKpE7d+5g+/bt0m1LS0sMGjQIdnZ28oUiIqrGWAgRVSK2trbw8PBAZGQk3N3d4evrCwMDA7ljERFVWyyEqoCtW4HAQCA1Ve4k1d/duxX7eHl5edDR0VE7GaF3795o0qQJB0QTEVUAFkJVQGAgEB0tdwrtYmpa/o+RmJiIkJAQeHp6wt3dXWpXKpUsgoiIKggLoSogvydIRwewsZE3izYwNQXmzy+/7QshEBkZiQMHDiA3Nxf79u1D/fr1UbNmzfJ7UCIiKhQLoSrExgZ45mxqqoLS09Oxa9cuxMTESG2mpqbIycmRMRURkfZiIURUQWJjY7Fjxw6kpaVJbR4eHvDx8YG+vr6MyYiItBcLIaJylpubi7CwMJw8eVJqMzY2xoABAzgWiIhIZiyEiMrRo0ePEBwcjPv370ttjRs3xsCBA2FiYiJjMiIiAlgIEZUrQ0NDZGRkAAB0dXXRq1cveHp68tp9RESVBAshonJkbGyMgQMH4o8//sCgQYNgbW0tdyQiInoGCyGiMhQTEwNbW1u1w16Ojo5o2LAhrxNGRFQJ8S8zURnIzs7G7t27sXnzZuzYsQNCCLX7WQQREVVO7BEiekl37txBSEgIHj58CODpafKXL1/mGWFERFUACyGiUlKpVDh+/DiOHDkClUoFANDX14evry+aNm0qczoiIioJFkJEpZCcnIzQ0FBcv35darOxsUFAQACsrKxkTEZERJpgIUSkof/++w979uxBZmam1NapUyd07doVurq6MiYjIiJNsRAi0sCtW7ewbds26baZmRn8/f3h4OAgXygiIio1FkJEGrCzs4OrqyvOnTsHFxcX9O3bF0ZGRnLHIiKiUmIhRFQMIUSBWaD79OmDJk2awMXFhTNEExFVcZzchKgISUlJWLNmDS5cuKDWbmBggBYtWrAIIiKqBtgjRPQcIQTOnTuHvXv3ShMl2tnZwdzcXO5oRERUxlgIET0jIyMDe/bsUesFMjIyQkZGBgshIqJqiIUQ0f+Lj49HaGgoUlJSpDZ3d3f4+vrCwMBAxmRERFReWAiR1svLy8ORI0cQEREhtRkaGqJfv35wcXGRMRkREZU3FkKk1ZKSkrB161bcvXtXanNwcICfnx8PhRERaQEWQqTV9PT0kJycDODpFeK7d+8OLy8vnhFGRKQlWAiRVjM1NcWAAQMQFhaGQYMGwcbGRu5IRERUgVgIkVa5evUq6tatC2NjY6nNyckJjRs35nXCiIi0ECdUJK2Qm5uL/fv3Y+PGjdi9ezeEEGr3swgiItJO7BGiai8hIQEhISG4f/8+AODSpUuIjY1FkyZNZE5GRERyYyFE1ZYQAidPnkRYWBjy8vIAPO356dWrFxo3bixzOiIiqgxYCJWjrVuBwEAgNfXltvPMmd1UQqmpqdixYwfi4uKkNmtrawQEBMDa2lrGZEREVJmwECpHgYFAdHTZbc/UtOy2VZ3FxMRg586dePLkidTWvn179OjRA3p6fMsTEdH/8FuhHOX3BOnoAC97VrapKTB//stnqu5u3LiBzZs3S7dNTEzg5+cHR0dHGVMREVFlxUKoAtjYALduyZ1CO9jb28PZ2RnR0dFwcnLCgAED1E6VJyIiehYLIarShBBqs0ArFAr0798fTk5OcHNz4wzRRERULM4jRFVWcnIyNmzYgMuXL6u1Gxsbw93dnUUQERG9EHuEqEq6cOECdu/ejczMTNy/fx8TJ06EiYmJ3LGIiKiKYSFEVUpWVhb27duHqKgoqU1PTw+pqakshIiISGMshKjKuHnzJkJCQvD48WOpzcXFBX379oWRkZF8wYiIqMpiIUSVnkqlQnh4OMLDw6VrhCmVSvTp0weurq4cC0RERKXGQogqtcePH2Pbtm249cz8A/b29vD394elpaWMyYiIqDpgIUSVmkKhwIMHD6T/9/b2RufOnaGjwxMeiYjo5bEQokrN3Nwc/fr1w+HDhzFo0CDY2dnJHYmIiKoRFkJUqVy/fh1169aFgYGB1NaiRQs4OzvzOmFERFTmKsXxhRUrVsDBwQGGhoZo164d/vnnnyKXXbVqFTp37gxLS0tYWlqiZ8+exS5PVUNeXh7CwsKwbt067Nu3r8D9LIKIiKg8yF4IBQcHY/r06Zg7dy5Onz4NNzc3+Pj44P79+4Uuf/ToUQwfPhxHjhzBiRMnYG9vj969e+P27dsVnJzKSmJiIlavXo2IiAgAQFRUFOLi4mRORURE2kAh8s9Hlkm7du3Qtm1bfP/99wCeniptb2+Pd955BzNnznzh+nl5ebC0tMT333+P0aNHv3D5lJQUmJubIzk5GWZmZi+dvzh2dsDt24CtLS+6WhghBCIjI3HgwAHk5uYCAHR0dNC9e3d4eXnxtHgiIpKU1/e3rMcbsrOzERkZiVmzZkltOjo66NmzJ06cOFGibTx58gQ5OTmoWbNmofdnZWUhKytLup2SkvJyoalMpKenY9euXYiJiZHarKysEBAQABsbGxmTERGRNpG1EEpMTEReXh7q1Kmj1l6nTh1ER0eXaBsfffQR6tWrh549exZ6/6JFizBv3ryXzkplJzY2Fjt27EBaWprU1qZNG/Tu3Rv6+voyJiMiIm0j+xihl/HFF19g8+bNCA0NhaGhYaHLzJo1C8nJydK/mzdvVnBKetb169exadMmqQgyNjbGsGHD0LdvXxZBRERU4WTtEapVqxZ0dXWRkJCg1p6QkIC6desWu+7XX3+NL774AmFhYXB1dS1yOQMDA7VTsUle9evXR+PGjREbG4vGjRtj4MCBvFgqERHJRtYeIaVSCQ8PDxw6dEhqU6lUOHToEDp06FDkel999RXmz5+P/fv3o02bNhURlcqIQqHAwIED0adPH4wYMYJFEBERyUr2Q2PTp0/HqlWrsH79ely6dAkTJ05Eeno6xo4dCwAYPXq02mDqL7/8EnPmzMGaNWvg4OCAe/fu4d69e2rjTahySEtLw6+//oqrV6+qtZuYmKBt27Y8K4yIiGQn+yx1Q4cOxYMHDxAYGIh79+7B3d0d+/fvlwZQ37hxQ+26Uj/++COys7Px6quvqm1n7ty5+PTTTysyOhUjJiYGO3fuxJMnT3Dv3j1MmDABxsbGcsciIiJSI/s8QhWN8wiVr+zsbBw8eBCRkZFSm4mJCYYPH4569erJmIyIiKqyajmPEFUvd+7cQUhICB4+fCi1OTs7o3///uwNIiKiSomFEL00lUqF48eP48iRI1CpVAAAfX19+Pr6olWrVhwLRERElRYLIXopKSkpCA0NRXx8vNRmY2ODgIAAWFlZyReMiIioBFgI0UvJyclRu+Btp06d0LVrV+jq6sqYioiIqGRYCNFLsbKywiuvvIKjR4/C398fDg4OckciIiIqMRZCpJHbt2/D2tpa7XIY7u7ucHFxgVKplDEZERGR5mSfUJGqBpVKhaNHj2L16tU4ePCg2n0KhYJFEBERVUnsEaIXSkpKQkhICG79/2RI//77L5o3b46GDRvKnIyIiOjlsBCiIgkhcO7cOezduxfZ2dkAnvb+eHt7o0GDBjKnIyIienkshKhQGRkZ2LNnDy5cuCC1WVpaYtCgQbCzs5MxGRERUdlhIUQFxMfHIzQ0FCkpKVKbu7s7fH19YWBgIGMyIiKissVCiNTEx8dj/fr10m1DQ0P069cPLi4uMqYiIiIqHyyESE39+vXRoEEDXL9+HQ4ODvD39y/3i9MSERHJhYUQqdHR0YG/vz8uXryI9u3b8zphRERUrXEeIS2Wnp6OLVu24MaNG2rt5ubm6NChA4sgIiKq9tgjpKViY2OxY8cOpKWl4e7du5gwYQIHQhMRkdZhIaRlcnNzERYWhpMnT0pt2dnZePjwIerVqydjMiIioorHQkiLJCQkICQkBPfv35faGjdujIEDB8LExETGZERERPJgIaQFhBA4efIkwsLCkJeXBwDQ1dVFr1694OnpybFARESktVgIVXOpqanYsWMH4uLipDZra2sEBATA2tpaxmRERETyYyFUzWVkZCA+Pl663b59e/To0QN6etz1RERE/Das5qytrdGrVy8cO3YMfn5+cHR0lDsSERFRpcFCqJq5d+8eatWqpdbj4+npCVdXVxgZGcmYjIiIqPLhhIrVhEqlwrFjx7Bq1SocPnxY7T6FQsEiiIiIqBDsEaoGkpOTERoaiuvXrwMATpw4AWdnZ9SvX1/mZERERJUbC6Eq7sKFC9i9ezcyMzOltk6dOsHW1lbGVERERFUDC6EqKisrC/v27UNUVJTUZmZmBn9/fzg4OMgXjIiIqAphIVQF3bx5E6GhoUhKSpLaXFxc0LdvX44FIiIi0gALoSomPj4eGzZsgBACAKBUKtGnTx+4urpyhmgiIiINsRCqYuzt7VGvXj3cvn0b9vb28Pf3h6WlpdyxiIiIqiQWQlWMrq4uBg0ahP/++w+dOnWCjg5nQCAiIiotFkKVWEZGBvbt24f27dujXr16UnvNmjXRpUsXGZMREVU8IQRyc3Oli0dT9aOvrw9dXd0KfUwWQpVUfHw8QkNDkZKSgjt37uDtt9+Gvr6+3LGIiGSRnZ2Nu3fv4smTJ3JHoXKkUChgZ2cHExOTCntMrS2EnJ2B8j6qdPeu5uvk5eXhyJEjiIiIkNrS09Nx//59zg1ERFpJpVLh2rVr0NXVRb169aBUKnlySDUkhMCDBw9w69YtNGnSpMJ6hrS2ECpNkVJapqYlWy4xMREhISG4+0w4BwcH+Pv7w8zMrJzSERFVbtnZ2VCpVLC3t4exsbHccagc1a5dG/Hx8cjJyWEhVN4UCuCZYTflxtQUmD+/+GWEEIiMjMSBAweQm5sLANDR0UH37t3h5eXFXz5ERABPDtECcnzfaW0hVLcucOuW3CmeHvbatWsXYmJipDYrKysEBATAxsZGxmRERETVn9YWQpVFSkoKrly5It1u06YNevfuzYHRREREFYD9jDKzsbFBt27dYGxsjGHDhqFv374sgoiIqoHXX38dCoUCCoUC+vr6aNiwIT788EO1i2Tn2717N7y9vWFqagpjY2O0bdsW69atK3S727ZtQ9euXWFubg4TExO4urris88+w6NHj8r5GVVPLIQqWGJiYoE5MLy8vDBp0iQ4OTnJlIqIiMqDr68v7t69i6tXr2LZsmVYuXIl5s6dq7bMd999h4EDB6Jjx444efIkzp07h2HDhmHChAmYMWOG2rKzZ8/G0KFD0bZtW+zbtw///fcflixZgqioKGzcuLHCnld2dnaFPVa5E1omOTlZABA2NskV+rgqlUqcOHFCzJ8/Xxw+fLhCH5uIqCrLyMgQFy9eFBkZGXJH0ciYMWPEwIED1doGDRokWrVqJd2+ceOG0NfXF9OnTy+w/rfffisAiL///lsIIcTJkycFALF8+fJCHy8pKanILDdv3hTDhg0TlpaWwtjYWHh4eEjbLSzn1KlThbe3t3Tb29tbTJ48WUydOlVYWVmJrl27iuHDh4shQ4aorZednS2srKzE+vXrhRBC5OXliYULFwoHBwdhaGgoXF1dxdatW4vMWdy+zv/+Tk4u2+9v9ghVgNTUVGzatAkHDhxAXl4e/vrrL9y+fVvuWEREVIH+++8/HD9+HEqlUmr7/fffkZOTU6DnBwDefvttmJiY4LfffgMAbNq0CSYmJpg0aVKh27ewsCi0PS0tDd7e3rh9+zZ27tyJqKgofPjhh1CpVBrlX79+PZRKJSIiIhAUFISRI0di165dSEtLk5Y5cOAAnjx5An9/fwDAokWLsGHDBgQFBeHChQuYNm0aXnvtNfz5558aPXZ54mDpchYdHY1du3apzYbq6emJOnXqyJiKiKhqa9MGuHev4h+3bl3g339Lvvzu3bthYmKC3NxcZGVlQUdHB99//710/+XLl2Fubl7oWcJKpRKNGjXC5cuXAQBXrlxBo0aNNB5H+uuvv+LBgwc4deoUatasCQBo3LixRtsAgCZNmuCrr76Sbjs6OqJGjRoIDQ3FqFGjpMcaMGAATE1NkZWVhYULFyIsLAwdOnQAADRq1AjHjh3DypUr4e3trXGG8sBCqJxkZ2fj4MGDiIyMlNpMTEzg5+cHR0dHGZMREVV99+4BVaFjvVu3bvjxxx+Rnp6OZcuWQU9PDwEBAaXalhCiVOudPXsWrVq1koqg0vLw8FC7raenhyFDhmDTpk0YNWoU0tPTsWPHDmzevBkAEBsbiydPnqBXr15q62VnZ6NVq1YvlaUssRAqB3fu3EFISAgePnwotTk5OWHAgAGcFZWIqAzUrVs1HrdGjRpS78uaNWvg5uaG1atXY9y4cQCApk2bIjk5GXfu3FG7uDbwtGCIi4tDt27dpGWPHTuGnJwcjXqFjIyMir1fR0enQJGVk5NT6HN53siRI+Ht7Y379+/jjz/+gJGREXx9fQFAOmS2Z8+eApeIMjAwKHH+8sZCqIxdu3YNv/zyi3TsVV9fHz4+PmjdujVniCYiKiOaHJ6qLHR0dPDxxx9j+vTpGDFiBIyMjBAQEICPPvoIS5YswZIlS9SWDwoKQnp6OoYPHw4AGDFiBL799lv88MMPmDp1aoHtP378uNBxQq6urvj555/x6NGjQnuFateujf/++0+t7ezZsyUqtry8vGBvb4/g4GDs27cPgwcPltZr3rw5DAwMcOPGjUpzGKwwHCxdxuzt7VG7dm0AT+cIevvtt+Hh4cEiiIiIMHjwYOjq6mLFihUAgPr16+Orr77C8uXLMXv2bERHRyMuLg5Lly7Fhx9+iPfffx/t2rUDALRr105q+/DDD3HixAlcv34dhw4dwuDBg7F+/fpCH3P48OGoW7cu/Pz8EBERgatXr2Lbtm04ceIEAKB79+74999/sWHDBly5cgVz584tUBgVZ8SIEQgKCsIff/yBkSNHSu2mpqaYMWMGpk2bhvXr1yMuLg6nT5/Gd999V2RWWZTpOWhVQEWcPp+QkCAOHTokcnNzy+0xiIi0RXU6fV4IIRYtWiRq164t0tLSpLYdO3aIzp07ixo1aghDQ0Ph4eEh1qxZU+h2g4ODRZcuXYSpqamoUaOGcHV1FZ999lmxp8/Hx8eLgIAAYWZmJoyNjUWbNm3EyZMnpfsDAwNFnTp1hLm5uZg2bZqYMmVKgdPnp06dWui2L168KACIBg0aCJVKpXafSqUSy5cvF05OTkJfX1/Url1b+Pj4iD///LPQbclx+rxCiFKOvqqiUlJS/n+EfjLu3Hm5K7pnZWXhwIEDaN++PaytrcsoIRERPSszMxPXrl1Dw4YNYWhoKHccKkfF7ev87+/k5GSYmb3c9/ezOEaolG7evInQ0FAkJSXhzp07ePPNN6Gnx5eTiIioKuE3t4ZUKhXCw8MRHh4ujbJPSkpCQkJCgVHxREREVLmxENJAUlISQkJCcOvWLanN3t4e/v7+sLS0lDEZERERlQYLoRIQQuDcuXPYu3evdKE5hUIBb29vdO7cGTo6PPmOiIioKmIh9AIZGRnYs2cPLly4ILVZWlpi0KBBsLOzkzEZERERvSwWQi+QmJiIixcvSrfd3d3h6+tbqWbFJCLSBlp2krNWkmMf85jOC9jb26Nz584wNDTEq6++ioEDB7IIIiKqQPkzFT978WqqnvKHn+jq6lbYY7JH6DlJSUkwNzdXG/fTpUsXeHh4lOm8BUREVDK6urqwsLDA/fv3AQDGxsacrb8aUqlUePDgAYyNjSt0OhoWQv9PCIHIyEgcOHAA3t7e6NSpk3Sfrq4uiyAiIhnV/f+rneYXQ1Q96ejooH79+hVa6LIQApCeno5du3YhJiYGAHDkyBE4OjrCxsZG5mRERAQ8PVPXxsYG1tbWhV4ZnaoHpVJZ4WdiV4pCaMWKFVi8eDHu3bsHNzc3fPfdd/D09Cxy+a1bt2LOnDmIj49HkyZN8OWXX6JPnz6leuzY2Fjs2LEDaWlpUlurVq1Qq1atUm2PiIjKj66uboWOH6HqT/bB0sHBwZg+fTrmzp2L06dPw83NDT4+PkV2fx4/fhzDhw/HuHHjcObMGfj5+cHPz0+jK+UCgK5uLvbv349NmzZJRZCxsTGGDRuGfv36SYPziIiIqPqS/aKr7dq1Q9u2bfH9998DeDpYyt7eHu+88w5mzpxZYPmhQ4ciPT0du3fvltrat28Pd3d3BAUFvfDx8i/a9vbbS2Bjkyq1N27cGAMHDoSJiUkZPCsiIiIqS+V10VVZe4Sys7MRGRmJnj17Sm06Ojro2bMnTpw4Ueg6J06cUFseAHx8fIpcviiWlg8APO1m9fX1xYgRI1gEERERaRlZxwglJiYiLy8PderUUWuvU6cOoqOjC13n3r17hS5/7969QpfPyspCVlaWdDs5OVlqr127NgYOHIjatWsjNTW10PWJiIhIfikpKQDKftLFSjFYujwtWrQI8+bNK9C+bNkyAMD7779f0ZGIiIiolB4+fAhzc/My256shVCtWrWgq6uLhIQEtfaEhARpzojn1a1bV6PlZ82ahenTp0u3Hz9+jAYNGuDGjRtl+kKS5lJSUmBvb4+bN29ynqZKgPuj8uC+qDy4LyqP5ORk1K9fHzVr1izT7cpaCCmVSnh4eODQoUPw8/MD8HSw9KFDhzBlypRC1+nQoQMOHTqE9957T2r7448/0KFDh0KXNzAwKPSSGObm5nxTVxJmZmbcF5UI90flwX1ReXBfVB5lPc+Q7IfGpk+fjjFjxqBNmzbw9PTE8uXLkZ6ejrFjxwIARo8eDVtbWyxatAgAMHXqVHh7e2PJkiXo27cvNm/ejH///Rc//fSTnE+DiIiIqiDZC6GhQ4fiwYMHCAwMxL179+Du7o79+/dLA6Jv3LihVv15eXnh119/xSeffIKPP/4YTZo0wfbt29GiRQu5ngIRERFVUbIXQgAwZcqUIg+FHT16tEDb4MGDMXjw4FI9loGBAebOncsryFcC3BeVC/dH5cF9UXlwX1Qe5bUvZJ9QkYiIiEgusl9ig4iIiEguLISIiIhIa7EQIiIiIq3FQoiIiIi0VrUshFasWAEHBwcYGhqiXbt2+Oeff4pdfuvWrXB2doahoSFatmyJvXv3VlDS6k+TfbFq1Sp07twZlpaWsLS0RM+ePV+470gzmn428m3evBkKhUKa+JRenqb74vHjx5g8eTJsbGxgYGCApk2b8m9VGdF0XyxfvhxOTk4wMjKCvb09pk2bhszMzApKW32Fh4ejf//+qFevHhQKBbZv3/7CdY4ePYrWrVvDwMAAjRs3xrp16zR/YFHNbN68WSiVSrFmzRpx4cIFMX78eGFhYSESEhIKXT4iIkLo6uqKr776Sly8eFF88sknQl9fX5w/f76Ck1c/mu6LESNGiBUrVogzZ86IS5cuiddff12Ym5uLW7duVXDy6knT/ZHv2rVrwtbWVnTu3FkMHDiwYsJWc5rui6ysLNGmTRvRp08fcezYMXHt2jVx9OhRcfbs2QpOXv1oui82bdokDAwMxKZNm8S1a9fEgQMHhI2NjZg2bVoFJ69+9u7dK2bPni1CQkIEABEaGlrs8levXhXGxsZi+vTp4uLFi+K7774Turq6Yv/+/Ro9brUrhDw9PcXkyZOl23l5eaJevXpi0aJFhS4/ZMgQ0bdvX7W2du3aibfffrtcc2oDTffF83Jzc4WpqalYv359eUXUKqXZH7m5ucLLy0v8/PPPYsyYMSyEyoim++LHH38UjRo1EtnZ2RUVUWtoui8mT54sunfvrtY2ffp00bFjx3LNqW1KUgh9+OGHwsXFRa1t6NChwsfHR6PHqlaHxrKzsxEZGYmePXtKbTo6OujZsydOnDhR6DonTpxQWx4AfHx8ilyeSqY0++J5T548QU5OTplfYE8blXZ/fPbZZ7C2tsa4ceMqIqZWKM2+2LlzJzp06IDJkyejTp06aNGiBRYuXIi8vLyKil0tlWZfeHl5ITIyUjp8dvXqVezduxd9+vSpkMz0P2X1/V0pZpYuK4mJicjLy5Muz5GvTp06iI6OLnSde/fuFbr8vXv3yi2nNijNvnjeRx99hHr16hV4o5PmSrM/jh07htWrV+Ps2bMVkFB7lGZfXL16FYcPH8bIkSOxd+9exMbGYtKkScjJycHcuXMrIna1VJp9MWLECCQmJqJTp04QQiA3NxcTJkzAxx9/XBGR6RlFfX+npKQgIyMDRkZGJdpOteoRourjiy++wObNmxEaGgpDQ0O542id1NRUjBo1CqtWrUKtWrXkjqP1VCoVrK2t8dNPP8HDwwNDhw7F7NmzERQUJHc0rXP06FEsXLgQP/zwA06fPo2QkBDs2bMH8+fPlzsalVK16hGqVasWdHV1kZCQoNaekJCAunXrFrpO3bp1NVqeSqY0+yLf119/jS+++AJhYWFwdXUtz5haQ9P9ERcXh/j4ePTv319qU6lUAAA9PT3ExMTA0dGxfENXU6X5bNjY2EBfXx+6urpSW7NmzXDv3j1kZ2dDqVSWa+bqqjT7Ys6cORg1ahTefPNNAEDLli2Rnp6Ot956C7Nnz1a7SDiVr6K+v83MzErcGwRUsx4hpVIJDw8PHDp0SGpTqVQ4dOgQOnToUOg6HTp0UFseAP74448il6eSKc2+AICvvvoK8+fPx/79+9GmTZuKiKoVNN0fzs7OOH/+PM6ePSv9GzBgALp164azZ8/C3t6+IuNXK6X5bHTs2BGxsbFSMQoAly9fho2NDYugl1CaffHkyZMCxU5+gSp46c4KVWbf35qN4678Nm/eLAwMDMS6devExYsXxVtvvSUsLCzEvXv3hBBCjBo1SsycOVNaPiIiQujp6Ymvv/5aXLp0ScydO5enz5cRTffFF198IZRKpfj999/F3bt3pX+pqalyPYVqRdP98TyeNVZ2NN0XN27cEKampmLKlCkiJiZG7N69W1hbW4vPP/9crqdQbWi6L+bOnStMTU3Fb7/9Jq5evSoOHjwoHB0dxZAhQ+R6CtVGamqqOHPmjDhz5owAIJYuXSrOnDkjrl+/LoQQYubMmWLUqFHS8vmnz3/wwQfi0qVLYsWKFTx9Pt93330n6tevL5RKpfD09BR///23dJ+3t7cYM2aM2vJbtmwRTZs2FUqlUri4uIg9e/ZUcOLqS5N90aBBAwGgwL+5c+dWfPBqStPPxrNYCJUtTffF8ePHRbt27YSBgYFo1KiRWLBggcjNza3g1NWTJvsiJydHfPrpp8LR0VEYGhoKe3t7MWnSJJGUlFTxwauZI0eOFPodkP/6jxkzRnh7exdYx93dXSiVStGoUSOxdu1ajR9XIQT78oiIiEg7VasxQkRERESaYCFEREREWouFEBEREWktFkJERESktVgIERERkdZiIURERERai4UQERERaS0WQkSkZt26dbCwsJA7RqkpFAps37692GVef/11+Pn5VUgeIqrcWAgRVUOvv/46FApFgX+xsbFyR8O6deukPDo6OrCzs8PYsWNx//79Mtn+3bt38corrwAA4uPjoVAocPbsWbVlvvnmG6xbt65MHq8on376qfQ8dXV1YW9vj7feeguPHj3SaDss2ojKV7W6+jwR/Y+vry/Wrl2r1la7dm2Z0qgzMzNDTEwMVCoVoqKiMHbsWNy5cwcHDhx46W0XddXwZ5mbm7/045SEi4sLwsLCkJeXh0uXLuGNN95AcnIygoODK+TxiejF2CNEVE0ZGBigbt26av90dXWxdOlStGzZEjVq1IC9vT0mTZqEtLS0IrcTFRWFbt26wdTUFGZmZvDw8MC///4r3X/s2DF07twZRkZGsLe3x7vvvov09PRisykUCtStWxf16tXDK6+8gnfffRdhYWHIyMiASqXCZ599Bjs7OxgYGMDd3R379++X1s3OzsaUKVNgY2MDQ0NDNGjQAIsWLVLbdv6hsYYNGwIAWrVqBYVCga5duwJQ72X56aefUK9ePbUruwPAwIED8cYbb0i3d+zYgdatW8PQ0BCNGjXCvHnzkJubW+zz1NPTQ926dWFra4uePXti8ODB+OOPP6T78/LyMG7cODRs2BBGRkZwcnLCN998I93/6aefYv369dixY4fUu3T06FEAwM2bNzFkyBBYWFigZs2aGDhwIOLj44vNQ0QFsRAi0jI6Ojr49ttvceHCBaxfvx6HDx/Ghx9+WOTyI0eOhJ2dHU6dOoXIyEjMnDkT+vr6AIC4uDj4+voiICAA586dQ3BwMI4dO4YpU6ZolMnIyAgqlQq5ubn45ptvsGTJEnz99dc4d+4cfHx8MGDAAFy5cgUA8O2332Lnzp3YsmULYmJisGnTJjg4OBS63X/++QcAEBYWhrt37yIkJKTAMoMHD8bDhw9x5MgRqe3Ro0fYv38/Ro4cCQD466+/MHr0aEydOhUXL17EypUrsW7dOixYsKDEzzE+Ph4HDhyAUqmU2lQqFezs7LB161ZcvHgRgYGB+Pjjj7FlyxYAwIwZMzBkyBD4+vri7t27uHv3Lry8vJCTkwMfHx+Ymprir7/+QkREBExMTODr64vs7OwSZyIioFpefZ5I240ZM0bo6uqKGjVqSP9effXVQpfdunWrsLKykm6vXbtWmJubS7dNTU3FunXrCl133Lhx4q233lJr++uvv4SOjo7IyMgodJ3nt3/58mXRtGlT0aZNGyGEEPXq1RMLFixQW6dt27Zi0qRJQggh3nnnHdG9e3ehUqkK3T4AERoaKoQQ4tq1awKAOHPmjNoyY8aMEQMHDpRuDxw4ULzxxhvS7ZUrV4p69eqJvLw8IYQQPXr0EAsXLlTbxsaNG4WNjU2hGYQQYu7cuUJHR0fUqFFDGBoaSlfSXrp0aZHrCCHE5MmTRUBAQJFZ8x/byclJ7TXIysoSRkZG4sCBA8Vun4jUcYwQUTXVrVs3/Pjjj9LtGjVqAHjaO7Jo0SJER0cjJSUFubm5yMzMxJMnT2BsbFxgO9OnT8ebb76JjRs3Sod3HB0dATw9bHbu3Dls2rRJWl4IAZVKhWvXrqFZs2aFZktOToaJiQlUKhUyMzPRqVMn/Pzzz0hJScGdO3fQsWNHteU7duyIqKgoAE8Pa/Xq1QtOTk7w9fVFv3790Lt375d6rUaOHInx48fjhx9+gIGBATZt2oRhw4ZBR0dHep4RERFqPUB5eXnFvm4A4OTkhJ07dyIzMxO//PILzp49i3feeUdtmRUrVmDNmjW4ceMGMjIykJ2dDXd392LzRkVFITY2FqampmrtmZmZiIuLK8UrQKS9WAgRVVM1atRA48aN1dri4+PRr18/TJw4EQsWLEDNmjVx7NgxjBs3DtnZ2YV+oX/66acYMWIE9uzZg3379mHu3LnYvHkz/P39kZaWhrfffhvvvvtugfXq169fZDZTU1OcPn0aOjo6sLGxgZGREQAgJSXlhc+rdevWuHbtGvbt24ewsDAMGTIEPXv2xO+///7CdYvSv39/CCGwZ88etG3bFn/99ReWLVsm3Z+WloZ58+Zh0KBBBdY1NDQscrtKpVLaB1988QX69u2LefPmYf78+QCAzZs3Y8aMGViyZAk6dOgAU1NTLF68GCdPniw2b1paGjw8PNQK0HyVZUA8UVXBQohIi0RGRkKlUmHJkiVSb0f+eJTiNG3aFE2bNsW0adMwfPhwrF27Fv7+/mjdujUuXrxYoOB6ER0dnULXMTMzQ7169RAREQFvb2+pPSIiAp6enmrLDR06FEOHDsWrr74KX19fPHr0CDVr1lTbXv54nLy8vGLzGBoaYtCgQdi0aRNiY2Ph5OSE1q1bS/e3bt0aMTExGj/P533yySfo3r07Jk6cKD1PLy8vTJo0SVrm+R4dpVJZIH/r1q0RHBwMa2trmJmZvVQmIm3HwdJEWqRx48bIycnBd999h6tXr2Ljxo0ICgoqcvmMjAxMmTIFR48exfXr1xEREYFTp05Jh7w++ugjHD9+HFOmTMHZs2dx5coV7NixQ+PB0s/64IMP8OWXXyI4OBgxMTGYOXMmzp49i6lTpwIAli5dit9++w3R0dG4fPkytm7dirp16xY6CaS1tTWMjIywf/9+JCQkIDk5ucjHHTlyJPbs2YM1a9ZIg6TzBQYGYsOGDZg3bx4uXLiAS5cuYfPmzfjkk080em4dOnSAq6srFi5cCABo0qQJ/v33Xxw4cACXL1/GnDlzcOrUKbV1HBwccO7cOcTExCAxMRE5OTkYOXIkatWqhYEDB+Kvv/7CtWvXcPToUbz77ru4deuWRpmItJ7cg5SIqOwVNsA239KlS4WNjY0wMjISPj4+YsOGDQKASEpKEkKoD2bOysoSw4YNE/b29kKpVIp69eqJKVOmqA2E/ueff0SvXr2EiYmJqFGjhnB1dS0w2PlZzw+Wfl5eXp749NNPha2trdDX1xdubm5i37590v0//fSTcHd3FzVq1BBmZmaiR48e4vTp09L9eGawtBBCrFq1Stjb2wsdHR3h7e1d5OuTl5cnbGxsBAARFxdXINf+/fuFl5eXMDIyEmZmZsLT01P89NNPRT6PuXPnCjc3twLtv/32mzAwMBA3btwQmZmZ4vXXXxfm5ubCwsJCTJw4UcycOVNtvfv370uvLwBx5MgRIYQQd+/eFaNHjxa1atUSBgYGolGjRmL8+PEiOTm5yExEVJBCCCHkLcWIiIiI5MFDY0RERKS1WAgRERGR1mIhRERERFqLhRARERFpLRZCREREpLVYCBEREZHWYiFEREREWouFEBEREWktFkJERESktVgIERERkdZiIURERERai4UQERERaa3/A4WHsw+ze/p2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(list(pred_msi['Pred_Prob']),list(pred_msi['Y_True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8621554-50ec-4655-a49c-3c280e3cdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT:\n",
    "pred_df = all_perd_df\n",
    "SELECTED_LABEL = ['MSI_POS']\n",
    "#Get True Postives\n",
    "true_postive_ids = {}\n",
    "for label in SELECTED_LABEL:\n",
    "    cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 1) & (pred_df['OUTCOME'] == label)\n",
    "    cur_pred_df = pred_df.loc[cond]\n",
    "    cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "    true_postive_ids[label] = cur_ids\n",
    "\n",
    "#Get true nagative\n",
    "true_negative_ids = {}\n",
    "for label in SELECTED_LABEL:\n",
    "    cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 0) & (pred_df['OUTCOME'] == label)\n",
    "    cur_pred_df = pred_df.loc[cond]\n",
    "    cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "    true_negative_ids[label] = cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326fde41-231c-4a9d-ba4e-b3dbd8d119ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Atention scores\n",
    "####################################################################################\n",
    "save_image_size = 250\n",
    "pixel_overlap = 0\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "mag_target_prob = 2.5\n",
    "smooth = True\n",
    "mag_target_tiss = 1.25\n",
    "\n",
    "def get_attention_and_tileinfo(pt_label_df, patient_att_score):    \n",
    "    #Get label\n",
    "    pt_label_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Get attention\n",
    "    cur_att  = pd.DataFrame({'ATT':list(minmax_normalize(patient_att_score))})\n",
    "    cur_att.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Comb\n",
    "    cur_att_df = pd.concat([pt_label_df,cur_att], axis = 1)\n",
    "    cur_att_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return cur_att_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d14342-5cd3-461c-9e30-fd6499892438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test data\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')\n",
    "opx_ids_ol0 = [x[-2] for x in opx_data_ol0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684e7e43-8f39-4748-9855-8c1434037b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPX_075\n",
      "OPX_075\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/MSI_POS/OPX_075/' created.\n",
      "post-processing\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/MSI_POS/OPX_075/top_tiles/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out032025_ACMIL2/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/MSI_POS/OPX_075/bot_tiles/' created.\n"
     ]
    }
   ],
   "source": [
    "selected_ids = true_postive_ids[SELECTED_LABEL[0]]\n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "#branches = 2\n",
    "\n",
    "for pt in selected_ids:\n",
    "    i =  opx_ids_ol0.index(pt)\n",
    "    print(pt)\n",
    "    print(opx_ids_ol0[i])\n",
    "\n",
    "    save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "    save_location =  save_location  + pt + \"/\"\n",
    "    create_dir_if_not_exists(save_location)\n",
    "    \n",
    "    _file = wsi_path + pt + \".tif\"\n",
    "    oslide = openslide.OpenSlide(_file)\n",
    "    save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "\n",
    "    first_batch = opx_data_ol0[i]\n",
    "    feat = first_batch[0].unsqueeze(0).to(device)\n",
    "    sub_preds, slide_preds, attn = model(feat)\n",
    "    label_index = ALL_LABEL.index(SELECTED_LABEL[0])\n",
    "\n",
    "    #Get attention\n",
    "    cur_att = attn[label_index] #att no softmax \n",
    "    #cur_att_softmax = torch.softmax(cur_att, dim=-1) #att softmax over tiles\n",
    "\n",
    "    #Mean\n",
    "    cur_pt_att = cur_att.mean(dim = 1).squeeze().cpu().detach().numpy() #Mean aross channels without softmax\n",
    "    #cur_pt_att = cur_att_softmax.mean(dim = 1).squeeze().cpu().detach().numpy()  #Mean aross channels with softmax\n",
    "    \n",
    "    #cur_pt_att = cur_att[0,branches,:].cpu().detach().numpy() #branch\n",
    "    \n",
    "    #Get all tile info include noncancer tile\n",
    "    alltileinfo_dir = proj_dir + 'intermediate_data/2_cancer_detection/OPX/' + \"IMSIZE250_OL0\" + \"/\"\n",
    "    tile_info_df = pd.read_csv(alltileinfo_dir + pt + \"/ft_model/\"  + save_name + \"_TILE_TUMOR_PERC.csv\")\n",
    "    #Combine current pt_info an all tile info\n",
    "    #cur_pt_info = tile_info_df.merge(cur_pt_info, on = list(tile_info_df.columns), how = \"left\")\n",
    "    cur_pt_info = first_batch[3]\n",
    "    cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "    #cur_att_df.loc[pd.isna(cur_att_df['ATT']),'ATT'] = 0.0001\n",
    "    \n",
    "    \n",
    "    #Generate tiles\n",
    "    tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "    #get level 0 size in px\n",
    "    l0_w = oslide.level_dimensions[0][0]\n",
    "    l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "    #1.25x tissue detection for mask\n",
    "    from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "    from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "    import cv2\n",
    "    if 'OPX' in pt:\n",
    "        rad_tissue = 5\n",
    "    elif '(2017-0133)' in pt:\n",
    "        rad_tissue = 2\n",
    "    lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "    lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "    tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "    #2.5x for probability maps\n",
    "    lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "    x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    \n",
    "    for index, row in cur_att_df.iterrows():\n",
    "        cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "        x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "        #Extract tile for prediction\n",
    "        lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "        tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "        map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    \n",
    "        #Store predicted probabily in map and count\n",
    "        try: \n",
    "            x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "            x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print('post-processing')\n",
    "    x_count = np.where(x_count < 1, 1, x_count)\n",
    "    x_map = x_map / x_count\n",
    "    x_map[x_map>1]=1\n",
    "    \n",
    "    #Get the following before smooth\n",
    "    he_mask = cv2.resize(np.uint8(he_mask),(x_map.shape[1],x_map.shape[0])) #resize to output image size\n",
    "    cond1 = he_mask < 1 #Background\n",
    "    cond2 = (he_mask == 1) & (x_map == 0) #is tissue, but not selected\n",
    "    smooth = True\n",
    "    \n",
    "    if smooth == True:\n",
    "        #x_sm = filters.gaussian(x_map, sigma=0)\n",
    "        x_sm = np.where(x_map != 0, filters.gaussian(x_map, sigma=10), x_map)\n",
    "    if smooth == False:\n",
    "        x_sm = x_map\n",
    "    \n",
    "    #TODO:\n",
    "    #get cancer_mask:\n",
    "    # cancer_mask == \n",
    "    # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "    x_sm[cond1] = 0 #Background\n",
    "    x_sm[cond2] = 0.1 #Is tissue, but not selected \n",
    "    \n",
    "    # Define the colors for the sequential colormap (black to fluorescent green)\n",
    "    colors = [\"#4B0082\", \"#39FF14\"]  # Black to Fluorescent Green\n",
    "    # Create the sequential colormap\n",
    "    cmap_name = \"black_to_fluorescent_green\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    sequential_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "    cmap =  plt.cm.Spectral_r #sequential_cmap # plt.cm.YlGn_r\n",
    "    cmap_colors = cmap(np.arange(cmap.N))\n",
    "    cmap_colors[0] = np.array([0.95, 0.95, 0.95, 1]) #np.array([1, 1, 1, 1])  # Set the first color (corresponding to 0) to white\n",
    "    cmap_colors[1] = np.array([0, 0, 0.545, 1])  # RGB for dark blue\n",
    "    custom_cmap = ListedColormap(cmap_colors)\n",
    "    \n",
    "    plt.imshow(x_sm, cmap=custom_cmap) #Spectral_r\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    #Top attented tiles\n",
    "    save_location2 = save_location + \"top_tiles/\"\n",
    "    create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "    #Get a Attention, and corresponding tiles\n",
    "    cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "    cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "            \n",
    "    for i in range(TOP_K):\n",
    "        cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "        cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "        cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "        coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "        tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "        cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "    \n",
    "    #Bot attented tiles\n",
    "    save_location2 = save_location + \"bot_tiles/\"\n",
    "    create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "    #Get a Attention, and corresponding tiles\n",
    "    cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "    cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "    \n",
    "    for i in range(TOP_K):\n",
    "        cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "        cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "        cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "        coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "        tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "        cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
