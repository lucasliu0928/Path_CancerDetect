{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo, get_performance\n",
    "from train_utils import pull_tiles, FocalLoss\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from Model import Mutation_MIL_MT_sepAtt #, Mutation_MIL_MT\n",
    "from ACMIL import ACMIL_GA_MultiTask, predict, train_one_epoch_multitask, evaluate_multitask\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe6b4f-a374-4a86-8276-e5a1bced8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABELS = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0.9 \n",
    "feature_extraction_method = 'uni2' #retccl, uni1\n",
    "learning_method = \"abmil\"\n",
    "focal_gamma = 20\n",
    "focal_alpha = 0.95\n",
    "loss_method = 'Focal' #ATTLOSS\n",
    "\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "arch = 'ga_mt' #ga_mt or ga\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_list = [0,1,2,3,4]\n",
    "for SELECTED_FOLD in fold_list:\n",
    "\n",
    "    if feature_extraction_method == 'retccl':\n",
    "        SELECTED_FEATURE = [str(i) for i in range(0,2048)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "        N_FEATURE = 2048\n",
    "    elif feature_extraction_method == 'uni1': \n",
    "        SELECTED_FEATURE = [str(i) for i in range(0,1024)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "        N_FEATURE = 1024\n",
    "    elif feature_extraction_method == 'uni2':\n",
    "        SELECTED_FEATURE = [str(i) for i in range(0,1536)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "        N_FEATURE = 1536\n",
    "        \n",
    "    ################################\n",
    "    # get config\n",
    "    config_dir = \"myconf.yml\"\n",
    "    with open(config_dir, \"r\") as ymlfile:\n",
    "        c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "        #c.update(vars(args))\n",
    "        conf = Struct(**c)\n",
    "    \n",
    "    conf.train_epoch = 200\n",
    "    conf.D_feat = N_FEATURE\n",
    "    conf.D_inner = DIM_OUT\n",
    "    \n",
    "    if learning_method == 'abmil':\n",
    "        conf.n_token = 1\n",
    "        conf.mask_drop = 0\n",
    "        conf.n_masked_patch = 0\n",
    "    conf.n_class = 1\n",
    "    conf.wandb_mode = 'disabled'\n",
    "    conf.mask_drop = 0\n",
    "    conf.n_task = 7\n",
    "    #conf.lr = 0.000001 #change this for HR only\n",
    "    \n",
    "    # Print all key-value pairs in the conf object\n",
    "    for key, value in conf.__dict__.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "        \n",
    "    ##################\n",
    "    ###### DIR  ######\n",
    "    ##################\n",
    "    proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "    folder_name_overlap = \"IMSIZE250_OL100\"\n",
    "    folder_name_nonoverlap = \"IMSIZE250_OL0\"\n",
    "    feature_path_opx_train =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_overlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "    feature_path_opx_test =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "    feature_path_tma = os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"TAN_TMA_Cores\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "    feature_path_tcga = os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"TCGA_PRAD\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "    \n",
    "    folder_name_ids = 'uni1/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "    train_val_test_id_path =  os.path.join(proj_dir + 'intermediate_data/6_Train_TEST_IDS', folder_name_ids)\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    #Create output-dir\n",
    "    ################################################\n",
    "    folder_name1 = feature_extraction_method + '/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "    outdir0 =  proj_dir + \"intermediate_data/pred_out02282025_ACMIL\" + \"/\" + folder_name1 + 'FOLD' + str(SELECTED_FOLD) + '/' + SELECTED_MUTATION + \"/\" \n",
    "    outdir1 =  outdir0  + \"/saved_model/\"\n",
    "    outdir2 =  outdir0  + \"/model_para/\"\n",
    "    outdir3 =  outdir0  + \"/logs/\"\n",
    "    outdir4 =  outdir0  + \"/predictions/\"\n",
    "    outdir5 =  outdir0  + \"/perf/\"\n",
    "    \n",
    "    \n",
    "    create_dir_if_not_exists(outdir0)\n",
    "    create_dir_if_not_exists(outdir1)\n",
    "    create_dir_if_not_exists(outdir2)\n",
    "    create_dir_if_not_exists(outdir3)\n",
    "    create_dir_if_not_exists(outdir4)\n",
    "    create_dir_if_not_exists(outdir5)\n",
    "    \n",
    "    ##################\n",
    "    #Select GPU\n",
    "    ##################\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    \n",
    "    ################################################\n",
    "    #     Model ready data \n",
    "    ################################################\n",
    "    opx_data_ol100 = torch.load(feature_path_opx_train + '/OPX_data.pth')\n",
    "    opx_ids_ol100 = torch.load(feature_path_opx_train + '/OPX_ids.pth')\n",
    "    opx_info_ol100  = torch.load(feature_path_opx_train + '/OPX_info.pth')\n",
    "    \n",
    "    opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')\n",
    "    opx_ids_ol0 = torch.load(feature_path_opx_test + '/OPX_ids.pth')\n",
    "    opx_info_ol0  = torch.load(feature_path_opx_test + '/OPX_info.pth')\n",
    "    \n",
    "    tma_data = torch.load(feature_path_tma + '/tma_data.pth')\n",
    "    tma_ids = torch.load(feature_path_tma + '/tma_ids.pth')\n",
    "    tma_info  = torch.load(feature_path_tma + '/tma_info.pth')\n",
    "    \n",
    "    \n",
    "    tcga_data = torch.load(feature_path_tcga + '/TCGA_data.pth')\n",
    "    tcga_ids = torch.load(feature_path_tcga + '/TCGA_ids.pth')\n",
    "    tcga_info  = torch.load(feature_path_tcga + '/TCGA_info.pth')\n",
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    #Update tma\n",
    "    ########################################################\n",
    "    haslabel_indexes = []\n",
    "    for i in range(len(tma_data)):\n",
    "        if torch.isnan(tma_data[i][1]).all() == False:\n",
    "            #print(f\"Item {i} has the second element all NaNs.\")\n",
    "            haslabel_indexes.append(i)\n",
    "    \n",
    "    \n",
    "    tma_data = Subset(tma_data, haslabel_indexes)\n",
    "    tma_ids = list(Subset(tma_ids, haslabel_indexes))\n",
    "    tma_info = list(Subset(tma_info, haslabel_indexes))\n",
    "    len(tma_info) #355 if TF0.9, a lot of cores does not have enough cancer tiles > 0.9\n",
    "    \n",
    "    \n",
    "    ################################################\n",
    "    #Get train, test IDs\n",
    "    #NOTE: this was in the old train: ['OPX_207','OPX_209','OPX_213','OPX_214','OPX_215']\n",
    "    ################################################\n",
    "    train_test_val_id_df = pd.read_csv(train_val_test_id_path + \"train_test_split.csv\")\n",
    "    train_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TRAIN', 'SAMPLE_ID'])\n",
    "    test_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TEST', 'SAMPLE_ID'])\n",
    "    val_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'VALID', 'SAMPLE_ID'])\n",
    "    \n",
    "    \n",
    "    ################################################\n",
    "    #Get Train, test, val data\n",
    "    ################################################\n",
    "    #Train:\n",
    "    inc_idx = [opx_ids_ol100.index(x) for x in train_ids_all]\n",
    "    train_data = Subset(opx_data_ol100, inc_idx)\n",
    "    train_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "    train_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "    \n",
    "    #Val:\n",
    "    inc_idx = [opx_ids_ol100.index(x) for x in val_ids_all]\n",
    "    val_data = Subset(opx_data_ol100, inc_idx)\n",
    "    val_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "    val_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "    \n",
    "    #Test:\n",
    "    inc_idx = [opx_ids_ol0.index(x) for x in test_ids_all]\n",
    "    test_data = Subset(opx_data_ol0, inc_idx)\n",
    "    test_ids =  list(Subset(opx_ids_ol0, inc_idx))\n",
    "    test_info = list(Subset(opx_info_ol0, inc_idx))\n",
    "    \n",
    "    \n",
    "    #count labels in train\n",
    "    train_label_counts = [dt[1] for dt in train_data]\n",
    "    train_label_counts = torch.concat(train_label_counts)\n",
    "    count_ones = (train_label_counts == 1).sum(dim=0)\n",
    "    print(count_ones)\n",
    "    perc_ones = count_ones/train_label_counts.shape[0] * 100\n",
    "    formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "    print(formatted_numbers)\n",
    "    \n",
    "    #count labels in test\n",
    "    test_label_counts = [dt[1] for dt in test_data]\n",
    "    test_label_counts = torch.concat(test_label_counts)\n",
    "    count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "    print(count_ones)\n",
    "    perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "    formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "    print(formatted_numbers)\n",
    "    \n",
    "    #count labels in tma\n",
    "    tma_label_counts = [dt[1] for dt in tma_data] \n",
    "    tma_label_counts = torch.concat(tma_label_counts)\n",
    "    count_ones = (tma_label_counts == 1).sum(dim=0)\n",
    "    print(count_ones)\n",
    "    perc_ones = count_ones/tma_label_counts.shape[0] * 100\n",
    "    formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "    print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\"\n",
    "    \n",
    "    \n",
    "    #count labels in tcga\n",
    "    tcga_label_counts = [dt[1] for dt in tcga_data] \n",
    "    tcga_label_counts = torch.concat(tcga_label_counts)\n",
    "    count_ones = (tcga_label_counts == 1).sum(dim=0)\n",
    "    print(count_ones)\n",
    "    perc_ones = count_ones/tcga_label_counts.shape[0] * 100\n",
    "    formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "    print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\"\n",
    "    \n",
    "    print(len(train_data))\n",
    "    print(len(val_data))\n",
    "    print(len(test_data))\n",
    "    print(len(tma_data))\n",
    "    print(len(tcga_data))\n",
    "    \n",
    "    ####################################################\n",
    "    #            Train \n",
    "    ####################################################\n",
    "    set_seed(0)\n",
    "    #Dataloader for training\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    tma_loader = DataLoader(dataset=tma_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    tcga_loader = DataLoader(dataset=tcga_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # define network\n",
    "    if arch == 'ga':\n",
    "        model = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop)\n",
    "    elif arch == 'ga_mt':\n",
    "        model = ACMIL_GA_MultiTask(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop= conf.mask_drop, n_task = conf.n_task)\n",
    "    else:\n",
    "        model = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "    model.to(device)\n",
    "    \n",
    "                \n",
    "    # Example usage:\n",
    "    criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "    \n",
    "    # define optimizer, lr not important at this point\n",
    "    optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "    \n",
    "    \n",
    "    ckpt_dir = outdir1 + SELECTED_MUTATION + \"/\"\n",
    "    create_dir_if_not_exists(ckpt_dir)\n",
    "    \n",
    "    \n",
    "    from architecture.network import Classifier_1fc, DimReduction, DimReduction1\n",
    "    from utils.utils import MetricLogger, SmoothedValue, adjust_learning_rate\n",
    "    from timm.utils import accuracy\n",
    "    import torchmetrics\n",
    "    import wandb\n",
    "    @torch.no_grad()\n",
    "    def evaluate_multitask(net, criterion, data_loader, device, conf, header):\n",
    "    \n",
    "        # Set the network to evaluation mode\n",
    "        net.eval()\n",
    "    \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "    \n",
    "        metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    \n",
    "        for data in metric_logger.log_every(data_loader, 100, header):\n",
    "            image_patches = data[0].to(device, dtype=torch.float32)\n",
    "            label_lists = data[1][0]\n",
    "            tf = data[2].to(device, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "            sub_preds_list, slide_preds_list, attn_list = net(image_patches) #lists len of n of tasks, each task = [5,2], [1,2], [1,5,3],\n",
    "            \n",
    "            #Compute loss for each task, then sum\n",
    "            loss = 0\n",
    "            div_loss = 0\n",
    "            pred_list = []\n",
    "            acc1_list = []\n",
    "            for k in range(conf.n_task):\n",
    "                sub_preds = sub_preds_list[k]\n",
    "                slide_preds = slide_preds_list[k]\n",
    "                attn = attn_list[k]\n",
    "                labels = label_lists[:,k].to(device, dtype = torch.float32).to(device)\n",
    "                \n",
    "                div_loss += torch.sum(F.softmax(attn, dim=-1) * F.log_softmax(attn, dim=-1)) / attn.shape[1]\n",
    "                loss += criterion(slide_preds, labels.unsqueeze(1))\n",
    "                pred = torch.sigmoid(slide_preds)\n",
    "                acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "    \n",
    "                pred_list.append(pred)\n",
    "                acc1_list.append(acc1)\n",
    "                \n",
    "            avg_acc = sum(acc1_list)/conf.n_task\n",
    "    \n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.update(div_loss=div_loss.item())\n",
    "            metric_logger.meters['acc1'].update(avg_acc.item(), n=labels.shape[0])\n",
    "    \n",
    "            y_pred.append(pred_list)\n",
    "            y_true.append(label_lists)\n",
    "    \n",
    "        #Get prediction for each task\n",
    "        y_pred_tasks = []\n",
    "        y_true_tasks = []\n",
    "        for k in range(conf.n_task):\n",
    "            y_pred_tasks.append([p[k] for p in y_pred])\n",
    "            y_true_tasks.append([t[:,k].to(device, dtype = torch.int64) for t in y_true])\n",
    "        \n",
    "        #get performance for each calss\n",
    "        auroc_each = 0\n",
    "        f1_score_each = 0\n",
    "        for k in range(conf.n_task):\n",
    "            y_pred_each = torch.cat(y_pred_tasks[k], dim=0)\n",
    "            y_true_each = torch.cat(y_true_tasks[k], dim=0)\n",
    "        \n",
    "            AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='binary').to(device)\n",
    "            AUROC_metric(y_pred_each, y_true_each)\n",
    "            auroc_each += AUROC_metric.compute().item()\n",
    "        \n",
    "            F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='binary').to(device)\n",
    "            F1_metric(y_pred_each, y_true_each.unsqueeze(1))\n",
    "            f1_score_each += F1_metric.compute().item()\n",
    "            print(\"AUROC\",str(k),\":\",AUROC_metric.compute().item())\n",
    "        auroc = auroc_each/conf.n_task\n",
    "        f1_score = f1_score_each/conf.n_task\n",
    "    \n",
    "        print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f} auroc {AUROC:.3f} f1_score {F1:.3f}'\n",
    "              .format(top1=metric_logger.acc1, losses=metric_logger.loss, AUROC=auroc, F1=f1_score))\n",
    "    \n",
    "        return auroc, metric_logger.acc1.global_avg, f1_score, metric_logger.loss.global_avg\n",
    "    \n",
    "    \n",
    "    # define optimizer, lr not important at this point\n",
    "    optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "    \n",
    "    \n",
    "    best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "    train_epoch = conf.train_epoch\n",
    "    for epoch in range(train_epoch):\n",
    "        train_one_epoch_multitask(model, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "    \n",
    "    \n",
    "        val_auc, val_acc, val_f1, val_loss = evaluate_multitask(model, criterion, val_loader, device, conf, 'Val')\n",
    "        test_auc, test_acc, test_f1, test_loss = evaluate_multitask(model, criterion, test_loader, device, conf, 'Test')\n",
    "        #tma_auc, tma_acc, tma_f1, tma_loss = evaluate_multitask(model, criterion, tma_loader, device, conf, 'TMA')\n",
    "    \n",
    "        # if conf.wandb_mode != 'disabled':\n",
    "        #     wandb.log({'perf/val_acc1': val_acc}, commit=False)\n",
    "        #     wandb.log({'perf/val_auc': val_auc}, commit=False)\n",
    "        #     wandb.log({'perf/val_f1': val_f1}, commit=False)\n",
    "        #     wandb.log({'perf/val_loss': val_loss}, commit=False)\n",
    "        #     wandb.log({'perf/test_acc1': test_acc}, commit=False)\n",
    "        #     wandb.log({'perf/test_auc': test_auc}, commit=False)\n",
    "        #     wandb.log({'perf/test_f1': test_f1}, commit=False)\n",
    "        #     wandb.log({'perf/test_loss': test_loss}, commit=False)\n",
    "    \n",
    "    \n",
    "        # if val_f1 + val_auc > best_state['val_f1'] + best_state['val_auc']:\n",
    "        #     best_state['epoch'] = epoch\n",
    "        #     best_state['val_auc'] = val_auc\n",
    "        #     best_state['val_acc'] = val_acc\n",
    "        #     best_state['val_f1'] = val_f1\n",
    "        #     best_state['test_auc'] = test_auc\n",
    "        #     best_state['test_acc'] = test_acc\n",
    "        #     best_state['test_f1'] = test_f1\n",
    "        #     # best_state['tma_auc'] = tma_auc\n",
    "        #     # best_state['tma_acc'] = tma_acc\n",
    "        #     # best_state['tma_f1'] = tma_f1\n",
    "        #     save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "        #         save_path=os.path.join(ckpt_dir, 'checkpoint-best.pth'))\n",
    "        # print('\\n')\n",
    "    \n",
    "    \n",
    "        save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "            save_path=os.path.join(ckpt_dir + 'checkpoint_' + 'epoch' + str(epoch) + '.pth'))\n",
    "    print(\"Results on best epoch:\")\n",
    "    print(best_state)\n",
    "    wandb.finish()\n",
    "    \n",
    "    \n",
    "    def predict(net, data_loader, device, conf, header):    \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        y_pred_prob = []\n",
    "        # Set the network to evaluation mode\n",
    "        net.eval()\n",
    "        for data in data_loader:\n",
    "            image_patches = data[0].to(device, dtype=torch.float32)\n",
    "            label_lists = data[1][0]\n",
    "            sub_preds_list, slide_preds_list, attn_list = net(image_patches) #lists len of n of tasks, each task = [5,2], [1,2], [1,5,3],\n",
    "            \n",
    "            #Compute loss for each task, then sum\n",
    "            pred_list = []\n",
    "            pred_prob_list = []\n",
    "            for k in range(conf.n_task):\n",
    "                sub_preds = sub_preds_list[k]\n",
    "                slide_preds = slide_preds_list[k]\n",
    "                attn = attn_list[k]\n",
    "                labels = label_lists[:,k].to(device, dtype = torch.float32).to(device)\n",
    "                pred_prob = torch.sigmoid(slide_preds)\n",
    "                pred = pred_prob[0][0].round()\n",
    "                pred_list.append(pred)\n",
    "                pred_prob_list.append(pred_prob)\n",
    "        \n",
    "            y_pred.append(pred_list)\n",
    "            y_true.append(label_lists)\n",
    "            y_pred_prob.append(pred_prob_list)\n",
    "    \n",
    "        #Get prediction for each task\n",
    "        y_predprob_task = []\n",
    "        y_pred_tasks = []\n",
    "        y_true_tasks = []\n",
    "        for k in range(conf.n_task):\n",
    "            y_pred_tasks.append([p[k] for p in y_pred])\n",
    "            y_predprob_task.append([p[k].item() for p in y_pred_prob])\n",
    "            y_true_tasks.append([t[:,k].to(device, dtype = torch.int64).item() for t in y_true])\n",
    "        \n",
    "        return y_pred_tasks, y_predprob_task, y_true_tasks\n",
    "    \n",
    "    \n",
    "    y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, test_loader, device, conf, 'Test')\n",
    "    pred_df_list = []\n",
    "    perf_df_list = []\n",
    "    for i in range(conf.n_task):\n",
    "        pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], test_ids, ALL_LABELS[i], THRES = 0.5)\n",
    "        pred_df_list.append(pred_df)\n",
    "        perf_df_list.append(perf_df)\n",
    "    \n",
    "    all_perd_df = pd.concat(pred_df_list)\n",
    "    all_perf_df = pd.concat(perf_df_list)\n",
    "    print(all_perf_df)\n",
    "    \n",
    "    all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "    all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)\n",
    "    print(round(all_perf_df['AUC'].mean(),2))\n",
    "    \n",
    "    \n",
    "    pred_msi = all_perd_df.loc[all_perd_df['OUTCOME'] == 'MSI_POS']\n",
    "    pred_msi\n",
    "    \n",
    "    import torch\n",
    "    from torchmetrics import ROC\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    def plot_roc_curve(y_pred, y_true):\n",
    "        # Initialize ROC metric for binary classification\n",
    "        roc = ROC(task='binary')\n",
    "        \n",
    "        # Compute FPR, TPR, and thresholds\n",
    "        fpr, tpr, thresholds = roc(torch.tensor(y_pred), torch.tensor(y_true))\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    plot_roc_curve(list(pred_msi['Pred_Prob']),list(pred_msi['Y_True']))\n",
    "    \n",
    "    ##############################################################################################################################\n",
    "    # TMA\n",
    "    ##############################################################################################################################\n",
    "    y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, tma_loader, device, conf, 'TMA')\n",
    "    pred_df_list = []\n",
    "    perf_df_list = []\n",
    "    for i in range(conf.n_task): \n",
    "        if i not in [1,5,6]:\n",
    "            pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tma_ids, ALL_LABELS[i],THRES = 0.5)\n",
    "            pred_df_list.append(pred_df)\n",
    "            perf_df_list.append(perf_df)\n",
    "    \n",
    "    all_perd_df = pd.concat(pred_df_list)\n",
    "    all_perf_df = pd.concat(perf_df_list)\n",
    "    print(all_perf_df)\n",
    "    all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TMA_pred_df.csv\",index = False)\n",
    "    all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TMA_perf.csv\",index = True)\n",
    "    print(round(all_perf_df['AUC'].mean(),2))\n",
    "    \n",
    "    ##############################################################################################################################\n",
    "    # TCGA\n",
    "    ##############################################################################################################################\n",
    "    y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, tcga_loader, device, conf, 'TCGA')\n",
    "    pred_df_list = []\n",
    "    perf_df_list = []\n",
    "    for i in range(conf.n_task):\n",
    "        if i != 5 :\n",
    "            pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tcga_ids, ALL_LABELS[i], THRES = 0.5)\n",
    "            pred_df_list.append(pred_df)\n",
    "            perf_df_list.append(perf_df)\n",
    "    all_perd_df = pd.concat(pred_df_list)\n",
    "    all_perf_df = pd.concat(perf_df_list)\n",
    "    print(all_perf_df)\n",
    "    all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TCGA_pred_df.csv\",index = False)\n",
    "    all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TCGA_perf.csv\",index = True)\n",
    "    print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96bd86-f7d2-4819-a55f-db153e741541",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "# TCGA\n",
    "##############################################################################################################################\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, tcga_loader, device, conf, 'TCGA')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    if i != 5 :\n",
    "        pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tcga_ids, ALL_LABELS[i], THRES = 0.5)\n",
    "        pred_df_list.append(pred_df)\n",
    "        perf_df_list.append(perf_df)\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TCGA_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TCGA_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
