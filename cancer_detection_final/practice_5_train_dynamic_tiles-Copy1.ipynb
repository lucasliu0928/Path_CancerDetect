{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use paimg9 env\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction, BCE_Weighted_Reg, compute_loss_for_all_labels\n",
    "from Model import Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "model_name = \"MIL\" #Chose from Linear, LinearMT\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "#SELECTED_FEATURE = [str(i) for i in range(0,2048)] + ['TUMOR_PIXEL_PERC']\n",
    "SELECTED_FEATURE = [str(i) for i in range(0,2048)]\n",
    "TUMOR_FRAC_THRES = 0\n",
    "TRAIN_SAMPLE_SIZE = \"ALL_TUMOR_TILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "label_path = proj_dir + 'data/MutationCalls/'\n",
    "model_path = proj_dir + 'models/feature_extraction_models/'\n",
    "ft_ids_path =  proj_dir + 'intermediate_data/cd_finetune/cancer_detection_training/' #the ID used for fine-tuning cancer detection model, needs to be excluded from mutation study\n",
    "train_tile_path = proj_dir + 'intermediate_data/cancer_prediction_results110224/IMSIZE250_OL' + str(TRAIN_OVERLAP) + '/'\n",
    "test_tile_path =  proj_dir + 'intermediate_data/cancer_prediction_results110224/IMSIZE250_OL' + str(TEST_OVERLAP) + '/'\n",
    "model_data_path =  proj_dir + 'intermediate_data/model_ready_data/' + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_NFEATURES' + str(len(SELECTED_FEATURE)) + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '/'\n",
    "feature_name = 'features_alltiles_retccl'\n",
    "\n",
    "################################################\n",
    "#Create output-dir\n",
    "################################################\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out/\" + 'MAX_SS'+ str(TRAIN_SAMPLE_SIZE) + '_NFEATURES' + str(len(SELECTED_FEATURE)) + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '/'\n",
    "outdir1 =  outdir0  + SELECTED_MUTATION + \"/saved_model/\" + model_name + \"/\"\n",
    "outdir2 =  outdir0 + SELECTED_MUTATION + \"/model_para/\"\n",
    "outdir3 =  outdir0 + SELECTED_MUTATION + \"/logs/\"\n",
    "outdir4 =  outdir0 + SELECTED_MUTATION + \"/predictions/\"\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data = torch.load(model_data_path + 'train_data.pth')\n",
    "test_data = torch.load(model_data_path + 'test_data.pth')\n",
    "val_data = torch.load(model_data_path + 'val_data.pth')\n",
    "\n",
    "test_ids = torch.load(model_data_path + 'test_ids.pth')\n",
    "test_info  = torch.load(model_data_path + 'test_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE  = 1\n",
    "ACCUM_SIZE = 16  # Number of steps to accumulate gradients\n",
    "EPOCHS = 1500\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "N_FEATURE = len(SELECTED_FEATURE)\n",
    "N_LABELS = len(SELECTED_LABEL)\n",
    "LOSS_FUNC_NAME = \"BCE_Weighted_Reg\"\n",
    "LOSS_WEIGHTS_LIST = [[1, 100], [1, 100], [1, 50], [1, 100], [1, 100], [1, 10], [1, 20]]  #NEG, POS\n",
    "REG_COEEF = 0.001\n",
    "REG_TYPE = 'L1'\n",
    "OPTMIZER = \"ADAM\"\n",
    "ATT_REG_FLAG = True\n",
    "\n",
    "train_data\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f1cc8-6b2a-45f4-96e7-09a5d9e604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct model\n",
    "model = Mutation_MIL_MT(in_features = N_FEATURE, \n",
    "                        act_func = 'tanh', \n",
    "                        drop_out = DROPOUT,\n",
    "                        n_outcomes = N_LABELS,\n",
    "                        dim_out = DIM_OUT)\n",
    "model.to(device)\n",
    "\n",
    "#Optimizer\n",
    "if OPTMIZER == \"ADAM\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTMIZER == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Loss\n",
    "if LOSS_FUNC_NAME == \"BCE_Weighted_Reg\":\n",
    "    loss_func = BCE_Weighted_Reg(REG_COEEF, REG_TYPE, model, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "elif LOSS_FUNC_NAME == \"BCELoss\":\n",
    "    loss_func = torch.nn.BCELoss()\n",
    "    \n",
    "\n",
    "#Model para\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "#print(model)\n",
    "\n",
    "\n",
    "#OUTPUT MODEL hyper-para\n",
    "hyper_df = pd.DataFrame({\"Target_Mutation\": SELECTED_MUTATION,\n",
    "                         \"TRAIN_OVERLAP\": TRAIN_OVERLAP,\n",
    "                         \"TEST_OVERLAP\": TEST_OVERLAP,\n",
    "                         \"TRAIN_SAMPLE_SIZE\": TRAIN_SAMPLE_SIZE,\n",
    "                         \"TUMOR_FRAC_THRES\": TUMOR_FRAC_THRES,\n",
    "                         \"N_FEATURE\": N_FEATURE,\n",
    "                         \"N_LABELS\": N_LABELS,\n",
    "                         \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                         \"ACCUM_SIZE\": ACCUM_SIZE,\n",
    "                         \"N_EPOCH\": EPOCHS,\n",
    "                         \"OPTMIZER\": OPTMIZER,\n",
    "                         \"LEARNING_RATE\": LEARNING_RATE,\n",
    "                         \"DROPOUT\": DROPOUT,\n",
    "                         \"DIM_OUT\": DIM_OUT,\n",
    "                         \"REG_TYPE\": REG_TYPE,\n",
    "                         \"REG_COEEF\": REG_COEEF,\n",
    "                         \"LOSS_FUNC_NAME\": LOSS_FUNC_NAME,\n",
    "                         \"LOSS_WEIGHTS_LIST\": str(LOSS_WEIGHTS_LIST),\n",
    "                         \"ATT_REG_FLAG\": ATT_REG_FLAG,\n",
    "                         \"NUM_MODEL_PARA\": total_params}, index = [0])\n",
    "hyper_df.to_csv(outdir2 + \"hyperpara_df.csv\")\n",
    "\n",
    "\n",
    "log_message(\"Start Training\", outdir3 + \"training_log.txt\")\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "#Training\n",
    "####################################################################################\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    ct = 0\n",
    "    optmizer_loss = 0\n",
    "    for x,y,tf in train_loader:\n",
    "        ct += 1\n",
    "        optimizer.zero_grad() #zero the grad\n",
    "        yhat_list, train_att_list = model(x.to(device)) #Forward\n",
    "\n",
    "        #compute loss\n",
    "        loss = compute_loss_for_all_labels(yhat_list, y, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf , train_att_list)\n",
    "\n",
    "        running_loss += loss.detach().item() #acuumalated batch loss\n",
    "        optmizer_loss += loss #accumalted loss for optimizer\n",
    "       \n",
    "        #Optimize\n",
    "        if ct % ACCUM_SIZE == 0:\n",
    "            optmizer_loss = optmizer_loss/ACCUM_SIZE\n",
    "            optmizer_loss.backward() \n",
    "            optimizer.step()  # Optimize\n",
    "            optmizer_loss = 0\n",
    "            #optimizer.zero_grad() #gradient reset\n",
    "\n",
    "    #Training loss \n",
    "    epoch_loss = running_loss/len(train_loader) #accumulated loss/total # batches (averaged loss over batches)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_running_loss = 0\n",
    "        for x_val,y_val,tf_val in val_loader:\n",
    "            val_yhat_list, val_att_list = model(x_val.to(device))\n",
    "            val_loss = compute_loss_for_all_labels(val_yhat_list, y_val, LOSS_WEIGHTS_LIST, LOSS_FUNC_NAME, loss_func, device, tf_val, val_att_list)\n",
    "            val_running_loss += val_loss.detach().item() \n",
    "        val_epoch_loss = val_running_loss/len(val_loader) \n",
    "        valid_loss.append(val_epoch_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch\"+ str(epoch) + \":\",\n",
    "              \"Train-LOSS:\" + \"{:.5f}\".format(train_loss[epoch]) + \", \" +\n",
    "              \"Valid-LOSS:\" +  \"{:.5f}\".format(valid_loss[epoch]))\n",
    "    \n",
    "    #Save model parameters\n",
    "    torch.save(model.state_dict(), outdir1 + \"model\" + str(epoch))\n",
    "\n",
    "\n",
    "#Plot LOSS\n",
    "plot_LOSS(train_loss,valid_loss, outdir1)\n",
    "log_message(\"End Training\", outdir3 + \"training_log.txt\")\n",
    "\n",
    "#SAVE VALIDATION LOSS\n",
    "valid_loss_df  = pd.DataFrame({\"VALID_LOSS\": valid_loss})\n",
    "valid_loss_df.to_csv(outdir1 + \"Valid_LOSS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bf67b-a36c-4336-89dd-bee6b77e66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Testing\n",
    "####################################################################################\n",
    "#Load model\n",
    "valid_loss_df = pd.read_csv(outdir1 + \"Valid_LOSS.csv\")\n",
    "min_index = valid_loss_df['VALID_LOSS'].idxmin()\n",
    "print(min_index)\n",
    "model2 = Mutation_MIL_MT(in_features = N_FEATURE, act_func = 'tanh', drop_out = DROPOUT)\n",
    "state_dict = torch.load(outdir1 + \"model\" + str(min_index))\n",
    "\n",
    "#model_dir = \"/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/z_old_mutation_prediction_results/mutation_pred_out_11272024/MAX_SS0_NFEATURES2048/MT/saved_model/MIL/\"\n",
    "#state_dict = torch.load(model_dir + \"model\" + str(min_index))\n",
    "model2.load_state_dict(state_dict)\n",
    "model2.to(device)\n",
    "\n",
    "\n",
    "#Loss function\n",
    "loss_func = torch.nn.BCELoss()\n",
    "THRES = 0.34\n",
    "\n",
    "#predicts\n",
    "test_pred_prob, test_true_label, test_att, test_loss = prediction(test_loader, model2, N_LABELS, loss_func, device, attention = True)\n",
    "print(\"Test-Loss TOTAL: \" + \"{:.5f}\".format(test_loss))\n",
    "\n",
    "\n",
    "#Prediction df\n",
    "pred_df_list = []\n",
    "for i in range(0,N_LABELS):\n",
    "   pred_df_list.append(pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                                          \"Y_True\": [l[i] for l in test_true_label], \n",
    "                                          \"Pred_Prob\" :  [l[i] for l in test_pred_prob],\n",
    "                                          \"OUTCOME\": SELECTED_LABEL[i]}))\n",
    "pred_df = pd.concat(pred_df_list)\n",
    "\n",
    "#Add Predict class\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(outdir0 + SELECTED_MUTATION + \"/pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "#Compute performance\n",
    "perf_df = compute_performance_each_label(SELECTED_LABEL, pred_df, \"SAMPLE_LEVEL\")\n",
    "perf_df.to_csv(outdir0 + SELECTED_MUTATION + \"/perf.csv\",index = True)\n",
    "\n",
    "print(perf_df.iloc[:,[0,5,6,7,8,9]])\n",
    "print(\"AVG AUC:\", round(perf_df['AUC'].mean(),2))\n",
    "print(\"AVG PRAUC:\", round(perf_df['PR_AUC'].mean(),2))\n",
    "#Use regularization no dropout now has the best performance at avg AUC = 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193df4f-1451-49c1-8e55-7b6cfe3406e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Mutation_MIL_MT(in_features = N_FEATURE, act_func = 'tanh', drop_out = DROPOUT)\n",
    "state_dict = torch.load(outdir1 + \"model\" + str(99))\n",
    "model2.load_state_dict(state_dict)\n",
    "model2.to(device)\n",
    "\n",
    "check, check2 = model2(x_val.to(device))\n",
    "print(check2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e775e0-d175-4e9a-bb11-49e38f56539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Atention scores\n",
    "####################################################################################\n",
    "save_image_size = 250\n",
    "pixel_overlap = 100\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "pretrain_model_name = \"retccl\"\n",
    "mag_target_prob = 2.5\n",
    "smooth = False\n",
    "mag_target_tiss = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0367-e302-4b0e-963a-f57fc4624eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "pt = test_ids[i]\n",
    "print(pt)\n",
    "\n",
    "save_location =  outdir4  + pt + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "_file = wsi_path + pt + \".tif\"\n",
    "oslide = openslide.OpenSlide(_file)\n",
    "save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_pt_att = test_att[i]\n",
    "cur_pt_info = test_info[i]\n",
    "cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8695db6-68cf-40ae-bff4-a8ca81a1942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate tiles\n",
    "tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "\n",
    "#get level 0 size in px\n",
    "l0_w = oslide.level_dimensions[0][0]\n",
    "l0_h = oslide.level_dimensions[0][1]\n",
    "\n",
    "#1.25x tissue detection for mask\n",
    "from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "import cv2\n",
    "if 'OPX' in pt:\n",
    "    rad_tissue = 5\n",
    "elif '(2017-0133)' in pt:\n",
    "    rad_tissue = 2\n",
    "lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c5920-1ce0-4e18-a44a-85f99aad234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5x for probability maps\n",
    "lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "\n",
    "cur_att_df['pred_map_location'] = pd.NA\n",
    "for index, row in cur_att_df.iterrows():\n",
    "    cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "    x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "    \n",
    "    #Extract tile for prediction\n",
    "    lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "    tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "    map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    cur_att_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "\n",
    "    #Store predicted probabily in map and count\n",
    "    try: \n",
    "        x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "        x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93070951-982d-40f6-81ca-82dc3a6ab437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('post-processing')\n",
    "x_count = np.where(x_count < 1, 1, x_count)\n",
    "x_map = x_map / x_count\n",
    "x_map[x_map>1]=1\n",
    "\n",
    "if smooth == True:\n",
    "    x_sm = filters.gaussian(x_map, sigma=2)\n",
    "if smooth == False:\n",
    "    x_sm = x_map\n",
    "\n",
    "he_mask = cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])) #resize to output image size\n",
    "#TODO:\n",
    "#get cancer_mask:\n",
    "# cancer_mask == \n",
    "# x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "x_sm[he_mask < 1] = 0.001 \n",
    "\n",
    "plt.imshow(x_sm, cmap='Spectral_r')\n",
    "plt.colorbar()\n",
    "#plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb313585-3a55-44d6-9345-3aa100563dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top attented tiles\n",
    "save_location2 = save_location + \"top_tiles/\"\n",
    "create_dir_if_not_exists(save_location2)\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "\n",
    "for i in range(TOP_K):\n",
    "    cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "    cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "    cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "    coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "    tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "    cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "\n",
    "#Bot attented tiles\n",
    "save_location2 = save_location + \"bot_tiles/\"\n",
    "create_dir_if_not_exists(save_location2)\n",
    "\n",
    "#Get a Attention, and corresponding tiles\n",
    "cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "\n",
    "for i in range(TOP_K):\n",
    "    cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "    cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "    cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "    coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "    tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "    cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
