{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from Model import Mutation_MIL_MT_sepAtt #, Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from architecture.transformer import ACMIL_GA\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.utils import MetricLogger, SmoothedValue, adjust_learning_rate\n",
    "from timm.utils import accuracy\n",
    "import torchmetrics\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch: 100\n",
      "warmup_epoch: 0\n",
      "wd: 1e-05\n",
      "lr: 0.0001\n",
      "min_lr: 0\n",
      "dataset: bracs\n",
      "B: 1\n",
      "n_class: 2\n",
      "n_worker: 8\n",
      "pin_memory: False\n",
      "n_shot: -1\n",
      "D_feat: 2048\n",
      "D_inner: 128\n",
      "n_token: 5\n",
      "wandb_mode: disabled\n",
      "mask_drop: 0.6\n",
      "n_masked_patch: 0\n",
      "n_task: 7\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//saved_model/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//model_para/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//logs/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//predictions/' created.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//perf/' created.\n",
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABELS = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "SELECTED_LABEL = [\"AR\"]\n",
    "selected_label_index = ALL_LABELS.index(SELECTED_LABEL[0])\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "TUMOR_FRAC_THRES = 0.9\n",
    "TUMOR_FRAC_THRES_TEST = 0.9\n",
    "TUMOR_FRAC_THRES_TMA = 0.0\n",
    "feature_extraction_method = 'retccl'\n",
    "learning_method = \"acmil\"\n",
    "INCLUDE_TF = False\n",
    "INCLUDE_CLUSTER = False\n",
    "N_CLUSTERS = 4\n",
    "focal_gamma = 2\n",
    "focal_alpha = 0.1\n",
    "SAVE_IMAGE_SIZE = 250\n",
    "TMA_OVERLAP = 0\n",
    "\n",
    "\n",
    "####\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = SELECTED_LABEL[0]\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2048\n",
    "    feature_type = \"emb_only\"\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2049\n",
    "    feature_type = \"emb_and_tf\"\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2049\n",
    "    feature_type = \"emb_and_cluster\" + str(N_CLUSTERS)\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2050\n",
    "    feature_type = \"emb_and_tf_and_cluster\" + str(N_CLUSTERS) \n",
    "\n",
    "################################\n",
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "\n",
    "conf.train_epoch = 100\n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "conf.n_token = 5\n",
    "conf.n_class = 2\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.mask_drop = 0.6\n",
    "conf.n_masked_patch = 0\n",
    "#conf.lr = 0.000001 #change this for HR only\n",
    "\n",
    "# Print all key-value pairs in the conf object\n",
    "for key, value in conf.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "folder_name = feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "folder_name_test = feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES_TEST) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "\n",
    "in_data_path = proj_dir + 'intermediate_data/model_ready_data/feature_' + folder_name + \"model_input/\"\n",
    "in_data_path_test = proj_dir + 'intermediate_data/model_ready_data/feature_' + folder_name_test + \"model_input/\"\n",
    "\n",
    "in_data_path_tma = os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \n",
    "                       \"TAN_TMA_Cores/\" + \"IMSIZE\" + str(SAVE_IMAGE_SIZE) + \"_OL\" + str(TMA_OVERLAP) + \"/\", \n",
    "                       'feature_' + feature_extraction_method, \n",
    "                       'TFT' + str(TUMOR_FRAC_THRES_TMA) + '/')\n",
    "\n",
    "model_data_path =  in_data_path + feature_type + \"/\"\n",
    "model_data_path_test =  in_data_path_test + feature_type + \"/\"\n",
    "   \n",
    "################################################\n",
    "#Create output-dir\n",
    "################################################\n",
    "folder_name1 = feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TRAINTEST_TFT' + str(TUMOR_FRAC_THRES) + '_TMA_TFT' + str(TUMOR_FRAC_THRES_TMA) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out02062025\" + \"/\" + folder_name1 + \"/DL_\" + feature_type + \"/\" + SELECTED_MUTATION + \"/\" \n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data_old = torch.load(model_data_path + 'train_data.pth')\n",
    "test_data_old = torch.load(model_data_path_test + 'test_data.pth')\n",
    "val_data = torch.load(model_data_path + 'val_data.pth')\n",
    "\n",
    "train_ids_old = torch.load(model_data_path + 'train_ids.pth')\n",
    "test_ids_old = torch.load(model_data_path_test + 'test_ids.pth')\n",
    "\n",
    "train_info_old  = torch.load(model_data_path + 'train_info.pth')\n",
    "test_info_old  = torch.load(model_data_path_test + 'test_info.pth')\n",
    "\n",
    "new_data = torch.load(model_data_path_test + 'newMSI_test_data.pth')\n",
    "new_ids = torch.load(model_data_path_test + 'newMSI_test_ids.pth')\n",
    "new_info  = torch.load(model_data_path_test + 'newMSI_test_info.pth')\n",
    "\n",
    "\n",
    "\n",
    "tma_data = torch.load(in_data_path_tma + 'tma_data.pth')\n",
    "tma_ids = torch.load(in_data_path_tma + 'tma_ids.pth')\n",
    "tma_info  = torch.load(in_data_path_tma + 'tma_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d122e8aa-f42b-47f4-acd7-f52e3ad456bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "# #Update tma test , exclude no label tmas\n",
    "################################################\n",
    "haslabel_indexes = []\n",
    "for i in range(len(tma_data)):\n",
    "    if torch.isnan(tma_data[i][1]).all() == False:\n",
    "        #print(f\"Item {i} has the second element all NaNs.\")\n",
    "        haslabel_indexes.append(i)\n",
    "\n",
    "\n",
    "tma_data = Subset(tma_data, haslabel_indexes)\n",
    "tma_ids = list(Subset(tma_ids, haslabel_indexes))\n",
    "tma_info = list(Subset(tma_info, haslabel_indexes))\n",
    "len(tma_info) #355 if TF0.9, a lot of cores does not have enough cancer tiles > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d0065b-0505-4012-b3a0-214afadf5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Exclude OPX_085, Prostate cancer find in colorectal site, patterns are for CRC, not for prostate\n",
    "################################################\n",
    "exc_idx = test_ids_old.index('OPX_085')\n",
    "inc_idx = [i for i in range(len(test_data_old)) if i not in [exc_idx]]\n",
    "\n",
    "#Update old testset\n",
    "test_data_old = Subset(test_data_old, inc_idx)\n",
    "removed_id =   test_ids_old.pop(exc_idx)  \n",
    "removed_info = test_info_old.pop(exc_idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b424cb-213b-46b0-8311-5254f432f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OPX_207', 'OPX_209', 'OPX_213', 'OPX_214', 'OPX_215']\n",
      "['OPX_208', 'OPX_210', 'OPX_211', 'OPX_212', 'OPX_216']\n"
     ]
    }
   ],
   "source": [
    "train_add_ids = ['OPX_207','OPX_209','OPX_213','OPX_214','OPX_215']\n",
    "test_add_ids =  [x for x in new_ids if x not in train_add_ids]\n",
    "print(train_add_ids)\n",
    "print(test_add_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf71500-b576-450d-911e-6a305ceb552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Add Ids in train \n",
    "################################################\n",
    "inc_idx = [new_ids.index(x) for x in train_add_ids]\n",
    "new_data_train = Subset(new_data, inc_idx)\n",
    "new_id_train =  list(Subset(new_ids, inc_idx))\n",
    "new_info_train = list(Subset(new_info, inc_idx))\n",
    "\n",
    "#Combine old and new train data\n",
    "train_data  = ConcatDataset([train_data_old, new_data_train])\n",
    "train_ids = train_ids_old +  new_id_train\n",
    "train_info = train_info_old +  new_info_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1cec3e-58ee-41a1-bcc2-cfb1cf17cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Add Ids in test \n",
    "################################################\n",
    "inc_idx = [new_ids.index(x) for x in test_add_ids]\n",
    "new_data_test = Subset(new_data, inc_idx)\n",
    "new_id_test =  list(Subset(new_ids, inc_idx))\n",
    "new_info_test = list(Subset(new_info, inc_idx))\n",
    "\n",
    "#Combine old and new train data\n",
    "test_data  = ConcatDataset([test_data_old, new_data_test])\n",
    "test_ids = test_ids_old +  new_id_test\n",
    "test_info = test_info_old +  new_info_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 25, 31, 18, 58, 10,  9])\n",
      "['9.9', '16.4', '20.4', '11.8', '38.2', '6.6', '5.9']\n"
     ]
    }
   ],
   "source": [
    "#count labels in train\n",
    "train_label_counts = [dt[1] for dt in train_data]\n",
    "train_label_counts = torch.concat(train_label_counts)\n",
    "count_ones = (train_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/train_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2607834-7757-448e-a5e8-24b208e7514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  6, 10,  4, 16,  7,  7])\n",
      "['11.4', '13.6', '22.7', '9.1', '36.4', '15.9', '15.9']\n"
     ]
    }
   ],
   "source": [
    "#count labels in test\n",
    "test_label_counts = [dt[1] for dt in test_data]\n",
    "test_label_counts = torch.concat(test_label_counts)\n",
    "count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144dc475-af49-4278-8171-d55e76df3785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([334,   0, 257, 180, 297,   0,   0])\n",
      "['56.0', '0.0', '43.1', '30.2', '49.8', '0.0', '0.0']\n"
     ]
    }
   ],
   "source": [
    "#count labels in tma\n",
    "tma_label_counts = [dt[1] for dt in tma_data] \n",
    "tma_label_counts = torch.concat(tma_label_counts)\n",
    "count_ones = (tma_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/tma_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "366126c0-daa8-4bbb-a487-b51a2e07d2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "len(test_data)\n",
    "len(tma_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "tma_loader = DataLoader(dataset=tma_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287cee9a-95b9-4a80-b9c4-1c02a3060f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ga'\n",
    "# define network\n",
    "if arch == 'ga':\n",
    "    model = ACMIL_GA(conf, n_token=conf.n_token, n_masked_patch=0, mask_drop=0.6)\n",
    "else:\n",
    "    model = ACMIL_MHA(conf, n_token=conf.n_token, n_masked_patch=conf.n_masked_patch, mask_drop=conf.mask_drop)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "class FocalLoss_withATT(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss_withATT, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.att_reg_flag = True\n",
    "        self.att_reg_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, inputs, targets, tumor_fractions, attention_scores):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            F_loss =  F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            F_loss =  F_loss.sum()\n",
    "\n",
    "        if self.att_reg_flag == True:\n",
    "            attention_scores_mean = torch.softmax(attention_scores, dim=-1).mean(dim = 1) #Take the mean across all braches\n",
    "            F_loss = F_loss + self.att_reg_loss(tumor_fractions, attention_scores)\n",
    "\n",
    "        return F_loss\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss\n",
    "            \n",
    "# Example usage:\n",
    "criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9842a5-e223-46e8-8ed9-4374598be1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, data_loader, optimizer0, device, epoch, conf, selected_label_index):\n",
    "    \"\"\"\n",
    "    Trains the given network for one epoch according to given criterions (loss functions)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the network to training mode\n",
    "    model.train()\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 100\n",
    "\n",
    "\n",
    "    for data_it, data in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "        # for data_it, data in enumerate(data_loader, start=epoch * len(data_loader)):\n",
    "        # Move input batch onto GPU if eager execution is enabled (default), else leave it on CPU\n",
    "        # Data is a dict with keys `input` (patches) and `{task_name}` (labels for given task)\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0,:,selected_label_index].to(device, dtype = torch.int64).to(device)\n",
    "        tf = data[2].to(device, dtype=torch.float32)\n",
    "        \n",
    "        # # Calculate and set new learning rate\n",
    "        adjust_learning_rate(optimizer0, epoch + data_it/len(data_loader), conf)\n",
    "\n",
    "        # Compute loss\n",
    "        sub_preds, slide_preds, attn = model(image_patches)\n",
    "        if conf.n_token > 1:\n",
    "            loss0 = criterion(sub_preds, labels.repeat_interleave(conf.n_token))\n",
    "        else:\n",
    "            loss0 = torch.tensor(0.)\n",
    "        loss1 = criterion(slide_preds, labels)\n",
    "\n",
    "\n",
    "        diff_loss = torch.tensor(0).to(device, dtype=torch.float)\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "        \n",
    "\n",
    "        for i in range(conf.n_token):\n",
    "            for j in range(i + 1, conf.n_token):\n",
    "                diff_loss += torch.cosine_similarity(attn[:, i], attn[:, j], dim=-1).mean() / (\n",
    "                            conf.n_token * (conf.n_token - 1) / 2)\n",
    "\n",
    "        #ATT loss\n",
    "        # avg_attn = attn.mean(dim = 1) #Across tokens\n",
    "        # loss2 = F.mse_loss(avg_attn, tf)\n",
    "        #for each token\n",
    "        # loss2 = 0\n",
    "        # for i in range(conf.n_token):\n",
    "        #     loss2 += F.mse_loss(attn[:,i,:], tf)\n",
    "            \n",
    "       \n",
    "        #loss = diff_loss + loss0 + loss1 + loss2\n",
    "        loss = diff_loss + loss0 + loss1 \n",
    "        \n",
    "\n",
    "        optimizer0.zero_grad()\n",
    "        # Backpropagate error and update parameters\n",
    "        loss.backward()\n",
    "        optimizer0.step()\n",
    "\n",
    "\n",
    "        metric_logger.update(lr=optimizer0.param_groups[0]['lr'])\n",
    "        metric_logger.update(sub_loss=loss0.item())\n",
    "        metric_logger.update(diff_loss=diff_loss.item())\n",
    "        metric_logger.update(slide_loss=loss1.item())\n",
    "\n",
    "        if conf.wandb_mode != 'disabled':\n",
    "            \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "            This calibrates different curves when batch size changes.\n",
    "            \"\"\"\n",
    "            wandb.log({'sub_loss': loss0}, commit=False)\n",
    "            wandb.log({'diff_loss': diff_loss}, commit=False)\n",
    "            wandb.log({'slide_loss': loss1})\n",
    "            #wandb.log({'att_loss': loss2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce197d41-618e-41ac-b812-df698b3a0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient calculation during evaluation\n",
    "@torch.no_grad()\n",
    "def evaluate(net, criterion, data_loader, device, conf, header, selected_label_index):\n",
    "\n",
    "    # Set the network to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "    for data in metric_logger.log_every(data_loader, 100, header):\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0,:,selected_label_index].to(device, dtype = torch.int64).to(device)\n",
    "        tf = data[2].to(device, dtype=torch.float32)\n",
    "\n",
    "        sub_preds, slide_preds, attn = net(image_patches)\n",
    "        div_loss = torch.sum(F.softmax(attn, dim=-1) * F.log_softmax(attn, dim=-1)) / attn.shape[1]\n",
    "        loss = criterion(slide_preds, labels)\n",
    "        pred = torch.softmax(slide_preds, dim=-1)\n",
    "\n",
    "\n",
    "        acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.update(div_loss=div_loss.item())\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=labels.shape[0])\n",
    "\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(labels)\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "\n",
    "    AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "    AUROC_metric(y_pred, y_true)\n",
    "    auroc = AUROC_metric.compute().item()\n",
    "    F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "    F1_metric(y_pred, y_true)\n",
    "    f1_score = F1_metric.compute().item()\n",
    "\n",
    "    print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f} auroc {AUROC:.3f} f1_score {F1:.3f}'\n",
    "          .format(top1=metric_logger.acc1, losses=metric_logger.loss, AUROC=auroc, F1=f1_score))\n",
    "\n",
    "    return auroc, metric_logger.acc1.global_avg, f1_score, metric_logger.loss.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//saved_model/AR/' created.\n",
      "Epoch: [0]  [  0/152]  eta: 0:01:16  lr: 0.000100  sub_loss: 0.0176 (0.0176)  diff_loss: 1.0000 (1.0000)  slide_loss: 0.0157 (0.0157)  time: 0.5002  data: 0.0063  max mem: 0\n",
      "Epoch: [0]  [100/152]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0089 (0.0137)  diff_loss: 0.9994 (0.9998)  slide_loss: 0.0049 (0.0108)  time: 0.0179  data: 0.0037  max mem: 0\n",
      "Epoch: [0]  [151/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0052 (0.0119)  diff_loss: 0.9831 (0.9969)  slide_loss: 0.0029 (0.0096)  time: 0.0128  data: 0.0023  max mem: 0\n",
      "Epoch: [0] Total time: 0:00:02 (0.0175 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -6.4954 (-6.4954)  acc1: 100.0000 (100.0000)  time: 0.0017  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0022)  div_loss: -6.4954 (-6.9241)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -8.9026 (-8.9026)  acc1: 100.0000 (100.0000)  time: 0.0080  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0029 (0.0091)  div_loss: -6.0247 (-6.0248)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.009 auroc 0.723 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [1]  [  0/152]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0064 (0.0064)  diff_loss: 0.9741 (0.9741)  slide_loss: 0.0047 (0.0047)  time: 0.0081  data: 0.0009  max mem: 0\n",
      "Epoch: [1]  [100/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0051 (0.0089)  diff_loss: 0.4632 (0.7202)  slide_loss: 0.0038 (0.0089)  time: 0.0180  data: 0.0046  max mem: 0\n",
      "Epoch: [1]  [151/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0052 (0.0087)  diff_loss: 0.4096 (0.6312)  slide_loss: 0.0056 (0.0086)  time: 0.0144  data: 0.0022  max mem: 0\n",
      "Epoch: [1] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -5.7381 (-5.7381)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0030 (0.0041)  div_loss: -5.7381 (-6.0526)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0020  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.004 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0043 (0.0043)  div_loss: -8.0582 (-8.0582)  acc1: 100.0000 (100.0000)  time: 0.0110  data: 0.0062  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0070 (0.0087)  div_loss: -5.2714 (-5.1655)  acc1: 100.0000 (86.3636)  time: 0.0037  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 86.364 loss 0.009 auroc 0.764 f1_score 0.864\n",
      "\n",
      "\n",
      "Epoch: [2]  [  0/152]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0096 (0.0096)  diff_loss: 0.4439 (0.4439)  slide_loss: 0.0190 (0.0190)  time: 0.0079  data: 0.0007  max mem: 0\n",
      "Epoch: [2]  [100/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0044 (0.0088)  diff_loss: 0.3995 (0.4277)  slide_loss: 0.0037 (0.0080)  time: 0.0175  data: 0.0039  max mem: 0\n",
      "Epoch: [2]  [151/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0038 (0.0084)  diff_loss: 0.3907 (0.4202)  slide_loss: 0.0041 (0.0079)  time: 0.0122  data: 0.0022  max mem: 0\n",
      "Epoch: [2] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -5.4695 (-5.4695)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0024 (0.0030)  div_loss: -5.4695 (-5.7760)  acc1: 100.0000 (100.0000)  time: 0.0050  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0051 s / it)\n",
      "* Acc@1 100.000 loss 0.003 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0031 (0.0031)  div_loss: -7.8065 (-7.8065)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0034  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0049 (0.0082)  div_loss: -4.9972 (-4.8376)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.800 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [3]  [  0/152]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0077 (0.0077)  diff_loss: 0.4146 (0.4146)  slide_loss: 0.0161 (0.0161)  time: 0.0073  data: 0.0007  max mem: 0\n",
      "Epoch: [3]  [100/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0031 (0.0088)  diff_loss: 0.3180 (0.3709)  slide_loss: 0.0021 (0.0079)  time: 0.0162  data: 0.0035  max mem: 0\n",
      "Epoch: [3]  [151/152]  eta: 0:00:00  lr: 0.000100  sub_loss: 0.0027 (0.0083)  diff_loss: 0.2436 (0.3390)  slide_loss: 0.0027 (0.0077)  time: 0.0127  data: 0.0025  max mem: 0\n",
      "Epoch: [3] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0017 (0.0017)  div_loss: -5.4005 (-5.4005)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0014 (0.0019)  div_loss: -5.3459 (-5.5764)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0018  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0019 (0.0019)  div_loss: -7.5820 (-7.5820)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0029 (0.0081)  div_loss: -4.9002 (-4.6656)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [4]  [  0/152]  eta: 0:00:01  lr: 0.000100  sub_loss: 0.0067 (0.0067)  diff_loss: 0.3170 (0.3170)  slide_loss: 0.0154 (0.0154)  time: 0.0086  data: 0.0008  max mem: 0\n",
      "Epoch: [4]  [100/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0033 (0.0091)  diff_loss: 0.1967 (0.2452)  slide_loss: 0.0021 (0.0081)  time: 0.0178  data: 0.0042  max mem: 0\n",
      "Epoch: [4]  [151/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0029 (0.0086)  diff_loss: 0.1844 (0.2322)  slide_loss: 0.0028 (0.0079)  time: 0.0145  data: 0.0025  max mem: 0\n",
      "Epoch: [4] Total time: 0:00:02 (0.0148 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0018 (0.0018)  div_loss: -5.0292 (-5.0292)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0019)  div_loss: -5.0292 (-5.3270)  acc1: 100.0000 (100.0000)  time: 0.0060  data: 0.0019  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0061 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0020 (0.0020)  div_loss: -7.2405 (-7.2405)  acc1: 100.0000 (100.0000)  time: 0.0150  data: 0.0066  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0029 (0.0079)  div_loss: -4.5202 (-4.3361)  acc1: 100.0000 (88.6364)  time: 0.0042  data: 0.0016  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [5]  [  0/152]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0060 (0.0060)  diff_loss: 0.2324 (0.2324)  slide_loss: 0.0123 (0.0123)  time: 0.0081  data: 0.0009  max mem: 0\n",
      "Epoch: [5]  [100/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0035 (0.0089)  diff_loss: 0.1470 (0.1949)  slide_loss: 0.0025 (0.0080)  time: 0.0178  data: 0.0038  max mem: 0\n",
      "Epoch: [5]  [151/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0030 (0.0084)  diff_loss: 0.1269 (0.1814)  slide_loss: 0.0030 (0.0078)  time: 0.0132  data: 0.0024  max mem: 0\n",
      "Epoch: [5] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0018 (0.0018)  div_loss: -4.9112 (-4.9112)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0019)  div_loss: -4.9112 (-5.2599)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0020 (0.0020)  div_loss: -7.1431 (-7.1431)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0030 (0.0079)  div_loss: -4.3700 (-4.2340)  acc1: 100.0000 (88.6364)  time: 0.0052  data: 0.0024  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0038 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [6]  [  0/152]  eta: 0:00:02  lr: 0.000099  sub_loss: 0.0057 (0.0057)  diff_loss: 0.1825 (0.1825)  slide_loss: 0.0107 (0.0107)  time: 0.0190  data: 0.0118  max mem: 0\n",
      "Epoch: [6]  [100/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0035 (0.0089)  diff_loss: 0.0809 (0.1403)  slide_loss: 0.0026 (0.0080)  time: 0.0178  data: 0.0035  max mem: 0\n",
      "Epoch: [6]  [151/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0031 (0.0084)  diff_loss: 0.0656 (0.1267)  slide_loss: 0.0030 (0.0077)  time: 0.0121  data: 0.0022  max mem: 0\n",
      "Epoch: [6] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0019 (0.0019)  div_loss: -4.7834 (-4.7834)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0020)  div_loss: -4.7834 (-5.1382)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -7.0452 (-7.0452)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0032 (0.0079)  div_loss: -4.2037 (-4.1167)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0029 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [7]  [  0/152]  eta: 0:00:01  lr: 0.000099  sub_loss: 0.0056 (0.0056)  diff_loss: 0.1308 (0.1308)  slide_loss: 0.0103 (0.0103)  time: 0.0079  data: 0.0008  max mem: 0\n",
      "Epoch: [7]  [100/152]  eta: 0:00:00  lr: 0.000099  sub_loss: 0.0035 (0.0089)  diff_loss: 0.0447 (0.0991)  slide_loss: 0.0028 (0.0080)  time: 0.0164  data: 0.0039  max mem: 0\n",
      "Epoch: [7]  [151/152]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0031 (0.0084)  diff_loss: 0.0387 (0.0882)  slide_loss: 0.0030 (0.0077)  time: 0.0125  data: 0.0022  max mem: 0\n",
      "Epoch: [7] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -4.6305 (-4.6305)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0021)  div_loss: -4.6305 (-5.0107)  acc1: 100.0000 (100.0000)  time: 0.0067  data: 0.0025  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -6.9595 (-6.9595)  acc1: 100.0000 (100.0000)  time: 0.0161  data: 0.0072  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0036 (0.0078)  div_loss: -4.0476 (-4.0079)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [8]  [  0/152]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0055 (0.0055)  diff_loss: 0.0999 (0.0999)  slide_loss: 0.0098 (0.0098)  time: 0.0076  data: 0.0007  max mem: 0\n",
      "Epoch: [8]  [100/152]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0035 (0.0090)  diff_loss: 0.0260 (0.0757)  slide_loss: 0.0030 (0.0080)  time: 0.0165  data: 0.0034  max mem: 0\n",
      "Epoch: [8]  [151/152]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0031 (0.0084)  diff_loss: 0.0239 (0.0666)  slide_loss: 0.0031 (0.0077)  time: 0.0139  data: 0.0028  max mem: 0\n",
      "Epoch: [8] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.4764 (-4.4764)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0046  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -4.4764 (-4.9125)  acc1: 100.0000 (100.0000)  time: 0.0068  data: 0.0031  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0071 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0026 (0.0026)  div_loss: -6.9053 (-6.9053)  acc1: 100.0000 (100.0000)  time: 0.0108  data: 0.0061  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.9241 (-3.9307)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [9]  [  0/152]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0053 (0.0053)  diff_loss: 0.0773 (0.0773)  slide_loss: 0.0091 (0.0091)  time: 0.0108  data: 0.0008  max mem: 0\n",
      "Epoch: [9]  [100/152]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0035 (0.0090)  diff_loss: 0.0169 (0.0615)  slide_loss: 0.0031 (0.0080)  time: 0.0162  data: 0.0032  max mem: 0\n",
      "Epoch: [9]  [151/152]  eta: 0:00:00  lr: 0.000098  sub_loss: 0.0031 (0.0084)  diff_loss: 0.0159 (0.0537)  slide_loss: 0.0031 (0.0077)  time: 0.0127  data: 0.0024  max mem: 0\n",
      "Epoch: [9] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.3242 (-4.3242)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -4.3242 (-4.8413)  acc1: 100.0000 (100.0000)  time: 0.0062  data: 0.0022  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0063 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0027 (0.0027)  div_loss: -6.8764 (-6.8764)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.8397 (-3.8791)  acc1: 100.0000 (88.6364)  time: 0.0042  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [10]  [  0/152]  eta: 0:00:01  lr: 0.000098  sub_loss: 0.0050 (0.0050)  diff_loss: 0.0541 (0.0541)  slide_loss: 0.0085 (0.0085)  time: 0.0110  data: 0.0011  max mem: 0\n",
      "Epoch: [10]  [100/152]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0036 (0.0089)  diff_loss: 0.0125 (0.0515)  slide_loss: 0.0031 (0.0080)  time: 0.0161  data: 0.0036  max mem: 0\n",
      "Epoch: [10]  [151/152]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0031 (0.0084)  diff_loss: 0.0114 (0.0450)  slide_loss: 0.0031 (0.0077)  time: 0.0133  data: 0.0027  max mem: 0\n",
      "Epoch: [10] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.1996 (-4.1996)  acc1: 100.0000 (100.0000)  time: 0.0018  data: 0.0007  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0022)  div_loss: -4.2550 (-4.7889)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -6.8535 (-6.8535)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.7845 (-3.8416)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0036 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [11]  [  0/152]  eta: 0:00:01  lr: 0.000097  sub_loss: 0.0049 (0.0049)  diff_loss: 0.0360 (0.0360)  slide_loss: 0.0081 (0.0081)  time: 0.0104  data: 0.0008  max mem: 0\n",
      "Epoch: [11]  [100/152]  eta: 0:00:00  lr: 0.000097  sub_loss: 0.0036 (0.0089)  diff_loss: 0.0097 (0.0442)  slide_loss: 0.0031 (0.0079)  time: 0.0178  data: 0.0036  max mem: 0\n",
      "Epoch: [11]  [151/152]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0031 (0.0083)  diff_loss: 0.0088 (0.0387)  slide_loss: 0.0031 (0.0076)  time: 0.0139  data: 0.0026  max mem: 0\n",
      "Epoch: [11] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -4.1125 (-4.1125)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0023)  div_loss: -4.2466 (-4.7531)  acc1: 100.0000 (100.0000)  time: 0.0073  data: 0.0030  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0074 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -6.8376 (-6.8376)  acc1: 100.0000 (100.0000)  time: 0.0138  data: 0.0076  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0079)  div_loss: -3.7309 (-3.8131)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [12]  [  0/152]  eta: 0:00:01  lr: 0.000096  sub_loss: 0.0048 (0.0048)  diff_loss: 0.0240 (0.0240)  slide_loss: 0.0077 (0.0077)  time: 0.0086  data: 0.0007  max mem: 0\n",
      "Epoch: [12]  [100/152]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0036 (0.0089)  diff_loss: 0.0077 (0.0385)  slide_loss: 0.0031 (0.0079)  time: 0.0171  data: 0.0039  max mem: 0\n",
      "Epoch: [12]  [151/152]  eta: 0:00:00  lr: 0.000096  sub_loss: 0.0030 (0.0083)  diff_loss: 0.0069 (0.0339)  slide_loss: 0.0031 (0.0076)  time: 0.0145  data: 0.0028  max mem: 0\n",
      "Epoch: [12] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -4.0580 (-4.0580)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.2428 (-4.7275)  acc1: 100.0000 (100.0000)  time: 0.0052  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0053 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -6.8257 (-6.8257)  acc1: 100.0000 (100.0000)  time: 0.0114  data: 0.0067  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0079)  div_loss: -3.6733 (-3.7916)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [13]  [  0/152]  eta: 0:00:01  lr: 0.000096  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0168 (0.0168)  slide_loss: 0.0075 (0.0075)  time: 0.0089  data: 0.0007  max mem: 0\n",
      "Epoch: [13]  [100/152]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0035 (0.0089)  diff_loss: 0.0062 (0.0345)  slide_loss: 0.0031 (0.0078)  time: 0.0184  data: 0.0043  max mem: 0\n",
      "Epoch: [13]  [151/152]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0030 (0.0083)  diff_loss: 0.0054 (0.0304)  slide_loss: 0.0032 (0.0075)  time: 0.0121  data: 0.0022  max mem: 0\n",
      "Epoch: [13] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -4.0227 (-4.0227)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.2411 (-4.7075)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -6.8131 (-6.8131)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0079)  div_loss: -3.6280 (-3.7739)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0066 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [14]  [  0/152]  eta: 0:00:01  lr: 0.000095  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0126 (0.0126)  slide_loss: 0.0074 (0.0074)  time: 0.0073  data: 0.0007  max mem: 0\n",
      "Epoch: [14]  [100/152]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0035 (0.0088)  diff_loss: 0.0052 (0.0315)  slide_loss: 0.0031 (0.0078)  time: 0.0188  data: 0.0041  max mem: 0\n",
      "Epoch: [14]  [151/152]  eta: 0:00:00  lr: 0.000095  sub_loss: 0.0029 (0.0083)  diff_loss: 0.0045 (0.0276)  slide_loss: 0.0031 (0.0075)  time: 0.0130  data: 0.0025  max mem: 0\n",
      "Epoch: [14] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -3.9973 (-3.9973)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.2401 (-4.6906)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -6.7967 (-6.7967)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0037  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0079)  div_loss: -3.5828 (-3.7578)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [15]  [  0/152]  eta: 0:00:01  lr: 0.000095  sub_loss: 0.0046 (0.0046)  diff_loss: 0.0101 (0.0101)  slide_loss: 0.0073 (0.0073)  time: 0.0078  data: 0.0007  max mem: 0\n",
      "Epoch: [15]  [100/152]  eta: 0:00:00  lr: 0.000094  sub_loss: 0.0034 (0.0088)  diff_loss: 0.0044 (0.0290)  slide_loss: 0.0031 (0.0078)  time: 0.0176  data: 0.0042  max mem: 0\n",
      "Epoch: [15]  [151/152]  eta: 0:00:00  lr: 0.000094  sub_loss: 0.0029 (0.0082)  diff_loss: 0.0038 (0.0253)  slide_loss: 0.0030 (0.0075)  time: 0.0134  data: 0.0023  max mem: 0\n",
      "Epoch: [15] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -3.9749 (-3.9749)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0023)  div_loss: -4.2369 (-4.6741)  acc1: 100.0000 (100.0000)  time: 0.0052  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0053 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0027 (0.0027)  div_loss: -6.7778 (-6.7778)  acc1: 100.0000 (100.0000)  time: 0.0097  data: 0.0034  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0079)  div_loss: -3.5452 (-3.7423)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [16]  [  0/152]  eta: 0:00:01  lr: 0.000094  sub_loss: 0.0046 (0.0046)  diff_loss: 0.0084 (0.0084)  slide_loss: 0.0072 (0.0072)  time: 0.0110  data: 0.0007  max mem: 0\n",
      "Epoch: [16]  [100/152]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0033 (0.0088)  diff_loss: 0.0038 (0.0271)  slide_loss: 0.0031 (0.0077)  time: 0.0178  data: 0.0040  max mem: 0\n",
      "Epoch: [16]  [151/152]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0029 (0.0082)  diff_loss: 0.0032 (0.0233)  slide_loss: 0.0030 (0.0075)  time: 0.0122  data: 0.0021  max mem: 0\n",
      "Epoch: [16] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -3.9479 (-3.9479)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0023)  div_loss: -4.2272 (-4.6542)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0027 (0.0027)  div_loss: -6.7533 (-6.7533)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0079)  div_loss: -3.5100 (-3.7250)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [17]  [  0/152]  eta: 0:00:01  lr: 0.000093  sub_loss: 0.0046 (0.0046)  diff_loss: 0.0071 (0.0071)  slide_loss: 0.0072 (0.0072)  time: 0.0080  data: 0.0008  max mem: 0\n",
      "Epoch: [17]  [100/152]  eta: 0:00:00  lr: 0.000093  sub_loss: 0.0033 (0.0087)  diff_loss: 0.0033 (0.0256)  slide_loss: 0.0030 (0.0077)  time: 0.0171  data: 0.0037  max mem: 0\n",
      "Epoch: [17]  [151/152]  eta: 0:00:00  lr: 0.000092  sub_loss: 0.0029 (0.0082)  diff_loss: 0.0027 (0.0216)  slide_loss: 0.0030 (0.0074)  time: 0.0124  data: 0.0021  max mem: 0\n",
      "Epoch: [17] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -3.9192 (-3.9192)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0023)  div_loss: -4.2150 (-4.6336)  acc1: 100.0000 (100.0000)  time: 0.0051  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0052 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0027 (0.0027)  div_loss: -6.7235 (-6.7235)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0078)  div_loss: -3.4743 (-3.7072)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0016  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [18]  [  0/152]  eta: 0:00:01  lr: 0.000092  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0062 (0.0062)  slide_loss: 0.0072 (0.0072)  time: 0.0098  data: 0.0008  max mem: 0\n",
      "Epoch: [18]  [100/152]  eta: 0:00:00  lr: 0.000092  sub_loss: 0.0032 (0.0087)  diff_loss: 0.0029 (0.0244)  slide_loss: 0.0030 (0.0077)  time: 0.0164  data: 0.0035  max mem: 0\n",
      "Epoch: [18]  [151/152]  eta: 0:00:00  lr: 0.000091  sub_loss: 0.0029 (0.0082)  diff_loss: 0.0024 (0.0202)  slide_loss: 0.0029 (0.0074)  time: 0.0124  data: 0.0021  max mem: 0\n",
      "Epoch: [18] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8990 (-3.8990)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0023)  div_loss: -4.2103 (-4.6200)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0026 (0.0026)  div_loss: -6.6996 (-6.6996)  acc1: 100.0000 (100.0000)  time: 0.0113  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.4570 (-3.6943)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [19]  [  0/152]  eta: 0:00:01  lr: 0.000091  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0054 (0.0054)  slide_loss: 0.0072 (0.0072)  time: 0.0081  data: 0.0010  max mem: 0\n",
      "Epoch: [19]  [100/152]  eta: 0:00:00  lr: 0.000091  sub_loss: 0.0032 (0.0087)  diff_loss: 0.0027 (0.0234)  slide_loss: 0.0030 (0.0077)  time: 0.0173  data: 0.0039  max mem: 0\n",
      "Epoch: [19]  [151/152]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0028 (0.0081)  diff_loss: 0.0020 (0.0189)  slide_loss: 0.0029 (0.0074)  time: 0.0136  data: 0.0025  max mem: 0\n",
      "Epoch: [19] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8940 (-3.8940)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.2168 (-4.6162)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0026 (0.0026)  div_loss: -6.6920 (-6.6920)  acc1: 100.0000 (100.0000)  time: 0.0087  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.4579 (-3.6884)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [20]  [  0/152]  eta: 0:00:01  lr: 0.000090  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0048 (0.0048)  slide_loss: 0.0071 (0.0071)  time: 0.0081  data: 0.0008  max mem: 0\n",
      "Epoch: [20]  [100/152]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0032 (0.0087)  diff_loss: 0.0024 (0.0221)  slide_loss: 0.0029 (0.0076)  time: 0.0173  data: 0.0036  max mem: 0\n",
      "Epoch: [20]  [151/152]  eta: 0:00:00  lr: 0.000090  sub_loss: 0.0028 (0.0081)  diff_loss: 0.0018 (0.0177)  slide_loss: 0.0029 (0.0074)  time: 0.0135  data: 0.0032  max mem: 0\n",
      "Epoch: [20] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8866 (-3.8866)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.2021 (-4.6094)  acc1: 100.0000 (100.0000)  time: 0.0072  data: 0.0032  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0073 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -6.6811 (-6.6811)  acc1: 100.0000 (100.0000)  time: 0.0152  data: 0.0104  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.4516 (-3.6797)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [21]  [  0/152]  eta: 0:00:01  lr: 0.000090  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0043 (0.0043)  slide_loss: 0.0071 (0.0071)  time: 0.0124  data: 0.0008  max mem: 0\n",
      "Epoch: [21]  [100/152]  eta: 0:00:00  lr: 0.000089  sub_loss: 0.0031 (0.0086)  diff_loss: 0.0022 (0.0208)  slide_loss: 0.0029 (0.0076)  time: 0.0163  data: 0.0031  max mem: 0\n",
      "Epoch: [21]  [151/152]  eta: 0:00:00  lr: 0.000089  sub_loss: 0.0028 (0.0081)  diff_loss: 0.0015 (0.0167)  slide_loss: 0.0028 (0.0074)  time: 0.0131  data: 0.0027  max mem: 0\n",
      "Epoch: [21] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8778 (-3.8778)  acc1: 100.0000 (100.0000)  time: 0.0020  data: 0.0009  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.1877 (-4.6017)  acc1: 100.0000 (100.0000)  time: 0.0052  data: 0.0017  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0053 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -6.6689 (-6.6689)  acc1: 100.0000 (100.0000)  time: 0.0082  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.4428 (-3.6706)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [22]  [  0/152]  eta: 0:00:01  lr: 0.000089  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0038 (0.0038)  slide_loss: 0.0071 (0.0071)  time: 0.0084  data: 0.0008  max mem: 0\n",
      "Epoch: [22]  [100/152]  eta: 0:00:00  lr: 0.000088  sub_loss: 0.0031 (0.0086)  diff_loss: 0.0019 (0.0196)  slide_loss: 0.0029 (0.0076)  time: 0.0167  data: 0.0037  max mem: 0\n",
      "Epoch: [22]  [151/152]  eta: 0:00:00  lr: 0.000088  sub_loss: 0.0028 (0.0081)  diff_loss: 0.0014 (0.0157)  slide_loss: 0.0028 (0.0073)  time: 0.0135  data: 0.0026  max mem: 0\n",
      "Epoch: [22] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8688 (-3.8688)  acc1: 100.0000 (100.0000)  time: 0.0028  data: 0.0017  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.1757 (-4.5941)  acc1: 100.0000 (100.0000)  time: 0.0064  data: 0.0023  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -6.6584 (-6.6584)  acc1: 100.0000 (100.0000)  time: 0.0099  data: 0.0052  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.4377 (-3.6622)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [23]  [  0/152]  eta: 0:00:01  lr: 0.000088  sub_loss: 0.0047 (0.0047)  diff_loss: 0.0035 (0.0035)  slide_loss: 0.0072 (0.0072)  time: 0.0093  data: 0.0008  max mem: 0\n",
      "Epoch: [23]  [100/152]  eta: 0:00:00  lr: 0.000087  sub_loss: 0.0031 (0.0086)  diff_loss: 0.0017 (0.0185)  slide_loss: 0.0029 (0.0076)  time: 0.0177  data: 0.0043  max mem: 0\n",
      "Epoch: [23]  [151/152]  eta: 0:00:00  lr: 0.000086  sub_loss: 0.0028 (0.0080)  diff_loss: 0.0012 (0.0148)  slide_loss: 0.0028 (0.0073)  time: 0.0126  data: 0.0025  max mem: 0\n",
      "Epoch: [23] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8586 (-3.8586)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0023)  div_loss: -4.1650 (-4.5858)  acc1: 100.0000 (100.0000)  time: 0.0066  data: 0.0026  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0067 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -6.6482 (-6.6482)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.4404 (-3.6535)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0030 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [24]  [  0/152]  eta: 0:00:01  lr: 0.000086  sub_loss: 0.0048 (0.0048)  diff_loss: 0.0032 (0.0032)  slide_loss: 0.0072 (0.0072)  time: 0.0082  data: 0.0008  max mem: 0\n",
      "Epoch: [24]  [100/152]  eta: 0:00:00  lr: 0.000086  sub_loss: 0.0030 (0.0085)  diff_loss: 0.0015 (0.0175)  slide_loss: 0.0028 (0.0075)  time: 0.0177  data: 0.0041  max mem: 0\n",
      "Epoch: [24]  [151/152]  eta: 0:00:00  lr: 0.000085  sub_loss: 0.0027 (0.0080)  diff_loss: 0.0011 (0.0140)  slide_loss: 0.0028 (0.0073)  time: 0.0134  data: 0.0027  max mem: 0\n",
      "Epoch: [24] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8466 (-3.8466)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0023)  div_loss: -4.1548 (-4.5765)  acc1: 100.0000 (100.0000)  time: 0.0064  data: 0.0025  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -6.6378 (-6.6378)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.4405 (-3.6442)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [25]  [  0/152]  eta: 0:00:01  lr: 0.000085  sub_loss: 0.0048 (0.0048)  diff_loss: 0.0029 (0.0029)  slide_loss: 0.0073 (0.0073)  time: 0.0087  data: 0.0008  max mem: 0\n",
      "Epoch: [25]  [100/152]  eta: 0:00:00  lr: 0.000085  sub_loss: 0.0030 (0.0085)  diff_loss: 0.0013 (0.0166)  slide_loss: 0.0028 (0.0075)  time: 0.0171  data: 0.0045  max mem: 0\n",
      "Epoch: [25]  [151/152]  eta: 0:00:00  lr: 0.000084  sub_loss: 0.0027 (0.0080)  diff_loss: 0.0010 (0.0132)  slide_loss: 0.0028 (0.0073)  time: 0.0140  data: 0.0019  max mem: 0\n",
      "Epoch: [25] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8333 (-3.8333)  acc1: 100.0000 (100.0000)  time: 0.0051  data: 0.0041  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0023)  div_loss: -4.1442 (-4.5663)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0059 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -6.6271 (-6.6271)  acc1: 100.0000 (100.0000)  time: 0.0096  data: 0.0041  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0078)  div_loss: -3.4383 (-3.6344)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [26]  [  0/152]  eta: 0:00:01  lr: 0.000084  sub_loss: 0.0049 (0.0049)  diff_loss: 0.0026 (0.0026)  slide_loss: 0.0073 (0.0073)  time: 0.0080  data: 0.0007  max mem: 0\n",
      "Epoch: [26]  [100/152]  eta: 0:00:00  lr: 0.000083  sub_loss: 0.0030 (0.0085)  diff_loss: 0.0012 (0.0158)  slide_loss: 0.0028 (0.0075)  time: 0.0173  data: 0.0034  max mem: 0\n",
      "Epoch: [26]  [151/152]  eta: 0:00:00  lr: 0.000083  sub_loss: 0.0027 (0.0079)  diff_loss: 0.0009 (0.0126)  slide_loss: 0.0027 (0.0072)  time: 0.0119  data: 0.0021  max mem: 0\n",
      "Epoch: [26] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8198 (-3.8198)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0023)  div_loss: -4.1318 (-4.5559)  acc1: 100.0000 (100.0000)  time: 0.0066  data: 0.0028  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0067 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -6.6163 (-6.6163)  acc1: 100.0000 (100.0000)  time: 0.0082  data: 0.0037  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0078)  div_loss: -3.4351 (-3.6248)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [27]  [  0/152]  eta: 0:00:01  lr: 0.000083  sub_loss: 0.0049 (0.0049)  diff_loss: 0.0024 (0.0024)  slide_loss: 0.0074 (0.0074)  time: 0.0084  data: 0.0008  max mem: 0\n",
      "Epoch: [27]  [100/152]  eta: 0:00:00  lr: 0.000082  sub_loss: 0.0030 (0.0084)  diff_loss: 0.0010 (0.0152)  slide_loss: 0.0028 (0.0074)  time: 0.0167  data: 0.0041  max mem: 0\n",
      "Epoch: [27]  [151/152]  eta: 0:00:00  lr: 0.000082  sub_loss: 0.0027 (0.0079)  diff_loss: 0.0008 (0.0121)  slide_loss: 0.0027 (0.0072)  time: 0.0131  data: 0.0029  max mem: 0\n",
      "Epoch: [27] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.8065 (-3.8065)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.1185 (-4.5456)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0021 (0.0021)  div_loss: -6.6059 (-6.6059)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0037  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.4311 (-3.6155)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [28]  [  0/152]  eta: 0:00:01  lr: 0.000082  sub_loss: 0.0049 (0.0049)  diff_loss: 0.0022 (0.0022)  slide_loss: 0.0074 (0.0074)  time: 0.0086  data: 0.0007  max mem: 0\n",
      "Epoch: [28]  [100/152]  eta: 0:00:00  lr: 0.000081  sub_loss: 0.0030 (0.0084)  diff_loss: 0.0009 (0.0147)  slide_loss: 0.0028 (0.0074)  time: 0.0182  data: 0.0048  max mem: 0\n",
      "Epoch: [28]  [151/152]  eta: 0:00:00  lr: 0.000081  sub_loss: 0.0027 (0.0079)  diff_loss: 0.0007 (0.0117)  slide_loss: 0.0028 (0.0071)  time: 0.0134  data: 0.0022  max mem: 0\n",
      "Epoch: [28] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.7939 (-3.7939)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.1045 (-4.5355)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0020 (0.0020)  div_loss: -6.5958 (-6.5958)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.4270 (-3.6067)  acc1: 100.0000 (88.6364)  time: 0.0035  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0030 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [29]  [  0/152]  eta: 0:00:01  lr: 0.000081  sub_loss: 0.0050 (0.0050)  diff_loss: 0.0020 (0.0020)  slide_loss: 0.0075 (0.0075)  time: 0.0087  data: 0.0007  max mem: 0\n",
      "Epoch: [29]  [100/152]  eta: 0:00:00  lr: 0.000080  sub_loss: 0.0030 (0.0083)  diff_loss: 0.0008 (0.0143)  slide_loss: 0.0027 (0.0073)  time: 0.0166  data: 0.0036  max mem: 0\n",
      "Epoch: [29]  [151/152]  eta: 0:00:00  lr: 0.000079  sub_loss: 0.0027 (0.0078)  diff_loss: 0.0006 (0.0114)  slide_loss: 0.0027 (0.0071)  time: 0.0137  data: 0.0022  max mem: 0\n",
      "Epoch: [29] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.7819 (-3.7819)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0023)  div_loss: -4.0903 (-4.5258)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0020 (0.0020)  div_loss: -6.5862 (-6.5862)  acc1: 100.0000 (100.0000)  time: 0.0100  data: 0.0052  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.4228 (-3.5983)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [30]  [  0/152]  eta: 0:00:01  lr: 0.000079  sub_loss: 0.0050 (0.0050)  diff_loss: 0.0018 (0.0018)  slide_loss: 0.0075 (0.0075)  time: 0.0079  data: 0.0007  max mem: 0\n",
      "Epoch: [30]  [100/152]  eta: 0:00:00  lr: 0.000079  sub_loss: 0.0030 (0.0083)  diff_loss: 0.0007 (0.0139)  slide_loss: 0.0027 (0.0073)  time: 0.0179  data: 0.0042  max mem: 0\n",
      "Epoch: [30]  [151/152]  eta: 0:00:00  lr: 0.000078  sub_loss: 0.0027 (0.0078)  diff_loss: 0.0006 (0.0111)  slide_loss: 0.0027 (0.0071)  time: 0.0136  data: 0.0025  max mem: 0\n",
      "Epoch: [30] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.7704 (-3.7704)  acc1: 100.0000 (100.0000)  time: 0.0031  data: 0.0020  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.0761 (-4.5163)  acc1: 100.0000 (100.0000)  time: 0.0064  data: 0.0027  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0019 (0.0019)  div_loss: -6.5769 (-6.5769)  acc1: 100.0000 (100.0000)  time: 0.0087  data: 0.0040  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.4184 (-3.5901)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0037 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.841 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [31]  [  0/152]  eta: 0:00:01  lr: 0.000078  sub_loss: 0.0051 (0.0051)  diff_loss: 0.0017 (0.0017)  slide_loss: 0.0076 (0.0076)  time: 0.0073  data: 0.0008  max mem: 0\n",
      "Epoch: [31]  [100/152]  eta: 0:00:00  lr: 0.000077  sub_loss: 0.0030 (0.0082)  diff_loss: 0.0007 (0.0136)  slide_loss: 0.0027 (0.0072)  time: 0.0184  data: 0.0036  max mem: 0\n",
      "Epoch: [31]  [151/152]  eta: 0:00:00  lr: 0.000077  sub_loss: 0.0027 (0.0077)  diff_loss: 0.0005 (0.0108)  slide_loss: 0.0027 (0.0070)  time: 0.0135  data: 0.0025  max mem: 0\n",
      "Epoch: [31] Total time: 0:00:02 (0.0146 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0023 (0.0023)  div_loss: -3.7596 (-3.7596)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.0622 (-4.5071)  acc1: 100.0000 (100.0000)  time: 0.0062  data: 0.0027  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0063 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0018 (0.0018)  div_loss: -6.5678 (-6.5678)  acc1: 100.0000 (100.0000)  time: 0.0113  data: 0.0066  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.4138 (-3.5822)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [32]  [  0/152]  eta: 0:00:01  lr: 0.000077  sub_loss: 0.0051 (0.0051)  diff_loss: 0.0016 (0.0016)  slide_loss: 0.0076 (0.0076)  time: 0.0079  data: 0.0007  max mem: 0\n",
      "Epoch: [32]  [100/152]  eta: 0:00:00  lr: 0.000076  sub_loss: 0.0030 (0.0082)  diff_loss: 0.0006 (0.0133)  slide_loss: 0.0027 (0.0072)  time: 0.0164  data: 0.0036  max mem: 0\n",
      "Epoch: [32]  [151/152]  eta: 0:00:00  lr: 0.000075  sub_loss: 0.0027 (0.0077)  diff_loss: 0.0005 (0.0106)  slide_loss: 0.0027 (0.0070)  time: 0.0133  data: 0.0023  max mem: 0\n",
      "Epoch: [32] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -3.7492 (-3.7492)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0023 (0.0022)  div_loss: -4.0487 (-4.4982)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0017 (0.0017)  div_loss: -6.5591 (-6.5591)  acc1: 100.0000 (100.0000)  time: 0.0089  data: 0.0040  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.4092 (-3.5746)  acc1: 100.0000 (88.6364)  time: 0.0047  data: 0.0019  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.841 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [33]  [  0/152]  eta: 0:00:01  lr: 0.000075  sub_loss: 0.0051 (0.0051)  diff_loss: 0.0015 (0.0015)  slide_loss: 0.0076 (0.0076)  time: 0.0075  data: 0.0009  max mem: 0\n",
      "Epoch: [33]  [100/152]  eta: 0:00:00  lr: 0.000075  sub_loss: 0.0030 (0.0081)  diff_loss: 0.0006 (0.0131)  slide_loss: 0.0027 (0.0071)  time: 0.0167  data: 0.0040  max mem: 0\n",
      "Epoch: [33]  [151/152]  eta: 0:00:00  lr: 0.000074  sub_loss: 0.0027 (0.0077)  diff_loss: 0.0004 (0.0104)  slide_loss: 0.0026 (0.0069)  time: 0.0134  data: 0.0023  max mem: 0\n",
      "Epoch: [33] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -3.7394 (-3.7394)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.0355 (-4.4896)  acc1: 100.0000 (100.0000)  time: 0.0050  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0051 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0017 (0.0017)  div_loss: -6.5506 (-6.5506)  acc1: 100.0000 (100.0000)  time: 0.0080  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.4045 (-3.5672)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [34]  [  0/152]  eta: 0:00:01  lr: 0.000074  sub_loss: 0.0052 (0.0052)  diff_loss: 0.0014 (0.0014)  slide_loss: 0.0077 (0.0077)  time: 0.0089  data: 0.0007  max mem: 0\n",
      "Epoch: [34]  [100/152]  eta: 0:00:00  lr: 0.000073  sub_loss: 0.0030 (0.0081)  diff_loss: 0.0005 (0.0129)  slide_loss: 0.0027 (0.0071)  time: 0.0173  data: 0.0040  max mem: 0\n",
      "Epoch: [34]  [151/152]  eta: 0:00:00  lr: 0.000073  sub_loss: 0.0027 (0.0076)  diff_loss: 0.0004 (0.0102)  slide_loss: 0.0026 (0.0069)  time: 0.0129  data: 0.0021  max mem: 0\n",
      "Epoch: [34] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -3.7301 (-3.7301)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.0232 (-4.4813)  acc1: 100.0000 (100.0000)  time: 0.0052  data: 0.0016  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0053 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0016 (0.0016)  div_loss: -6.5425 (-6.5425)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0036 (0.0078)  div_loss: -3.3997 (-3.5601)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [35]  [  0/152]  eta: 0:00:01  lr: 0.000073  sub_loss: 0.0052 (0.0052)  diff_loss: 0.0013 (0.0013)  slide_loss: 0.0077 (0.0077)  time: 0.0076  data: 0.0008  max mem: 0\n",
      "Epoch: [35]  [100/152]  eta: 0:00:00  lr: 0.000072  sub_loss: 0.0030 (0.0080)  diff_loss: 0.0005 (0.0127)  slide_loss: 0.0027 (0.0070)  time: 0.0177  data: 0.0031  max mem: 0\n",
      "Epoch: [35]  [151/152]  eta: 0:00:00  lr: 0.000071  sub_loss: 0.0028 (0.0076)  diff_loss: 0.0003 (0.0100)  slide_loss: 0.0026 (0.0068)  time: 0.0139  data: 0.0029  max mem: 0\n",
      "Epoch: [35] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -3.7213 (-3.7213)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.0115 (-4.4733)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0017  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0015 (0.0015)  div_loss: -6.5346 (-6.5346)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0036 (0.0078)  div_loss: -3.3949 (-3.5532)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [36]  [  0/152]  eta: 0:00:01  lr: 0.000071  sub_loss: 0.0052 (0.0052)  diff_loss: 0.0012 (0.0012)  slide_loss: 0.0077 (0.0077)  time: 0.0089  data: 0.0008  max mem: 0\n",
      "Epoch: [36]  [100/152]  eta: 0:00:00  lr: 0.000070  sub_loss: 0.0030 (0.0080)  diff_loss: 0.0004 (0.0125)  slide_loss: 0.0027 (0.0070)  time: 0.0196  data: 0.0036  max mem: 0\n",
      "Epoch: [36]  [151/152]  eta: 0:00:00  lr: 0.000070  sub_loss: 0.0028 (0.0075)  diff_loss: 0.0003 (0.0099)  slide_loss: 0.0025 (0.0068)  time: 0.0147  data: 0.0028  max mem: 0\n",
      "Epoch: [36] Total time: 0:00:02 (0.0146 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -3.7129 (-3.7129)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0022 (0.0022)  div_loss: -4.0005 (-4.4657)  acc1: 100.0000 (100.0000)  time: 0.0088  data: 0.0045  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0089 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0015 (0.0015)  div_loss: -6.5270 (-6.5270)  acc1: 100.0000 (100.0000)  time: 0.0089  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.3901 (-3.5466)  acc1: 100.0000 (88.6364)  time: 0.0046  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0036 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [37]  [  0/152]  eta: 0:00:01  lr: 0.000070  sub_loss: 0.0053 (0.0053)  diff_loss: 0.0011 (0.0011)  slide_loss: 0.0077 (0.0077)  time: 0.0112  data: 0.0008  max mem: 0\n",
      "Epoch: [37]  [100/152]  eta: 0:00:00  lr: 0.000069  sub_loss: 0.0030 (0.0079)  diff_loss: 0.0004 (0.0123)  slide_loss: 0.0027 (0.0069)  time: 0.0169  data: 0.0034  max mem: 0\n",
      "Epoch: [37]  [151/152]  eta: 0:00:00  lr: 0.000068  sub_loss: 0.0027 (0.0075)  diff_loss: 0.0003 (0.0098)  slide_loss: 0.0025 (0.0067)  time: 0.0128  data: 0.0026  max mem: 0\n",
      "Epoch: [37] Total time: 0:00:02 (0.0148 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0024 (0.0024)  div_loss: -3.7050 (-3.7050)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0022)  div_loss: -3.9903 (-4.4584)  acc1: 100.0000 (100.0000)  time: 0.0054  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0014 (0.0014)  div_loss: -6.5196 (-6.5196)  acc1: 100.0000 (100.0000)  time: 0.0119  data: 0.0067  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.3852 (-3.5402)  acc1: 100.0000 (88.6364)  time: 0.0042  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0038 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [38]  [  0/152]  eta: 0:00:01  lr: 0.000068  sub_loss: 0.0053 (0.0053)  diff_loss: 0.0010 (0.0010)  slide_loss: 0.0078 (0.0078)  time: 0.0110  data: 0.0040  max mem: 0\n",
      "Epoch: [38]  [100/152]  eta: 0:00:00  lr: 0.000067  sub_loss: 0.0030 (0.0079)  diff_loss: 0.0004 (0.0122)  slide_loss: 0.0027 (0.0069)  time: 0.0171  data: 0.0043  max mem: 0\n",
      "Epoch: [38]  [151/152]  eta: 0:00:00  lr: 0.000067  sub_loss: 0.0027 (0.0074)  diff_loss: 0.0003 (0.0096)  slide_loss: 0.0025 (0.0067)  time: 0.0127  data: 0.0019  max mem: 0\n",
      "Epoch: [38] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -3.6975 (-3.6975)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0022)  div_loss: -3.9807 (-4.4515)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0016  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0014 (0.0014)  div_loss: -6.5125 (-6.5125)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.3804 (-3.5342)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [39]  [  0/152]  eta: 0:00:01  lr: 0.000067  sub_loss: 0.0054 (0.0054)  diff_loss: 0.0009 (0.0009)  slide_loss: 0.0078 (0.0078)  time: 0.0076  data: 0.0008  max mem: 0\n",
      "Epoch: [39]  [100/152]  eta: 0:00:00  lr: 0.000066  sub_loss: 0.0030 (0.0078)  diff_loss: 0.0003 (0.0120)  slide_loss: 0.0026 (0.0068)  time: 0.0158  data: 0.0033  max mem: 0\n",
      "Epoch: [39]  [151/152]  eta: 0:00:00  lr: 0.000065  sub_loss: 0.0027 (0.0074)  diff_loss: 0.0002 (0.0095)  slide_loss: 0.0024 (0.0066)  time: 0.0141  data: 0.0024  max mem: 0\n",
      "Epoch: [39] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -3.6905 (-3.6905)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0022)  div_loss: -3.9717 (-4.4450)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0013 (0.0013)  div_loss: -6.5058 (-6.5058)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0037 (0.0078)  div_loss: -3.3756 (-3.5284)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [40]  [  0/152]  eta: 0:00:01  lr: 0.000065  sub_loss: 0.0054 (0.0054)  diff_loss: 0.0009 (0.0009)  slide_loss: 0.0078 (0.0078)  time: 0.0080  data: 0.0008  max mem: 0\n",
      "Epoch: [40]  [100/152]  eta: 0:00:00  lr: 0.000064  sub_loss: 0.0030 (0.0078)  diff_loss: 0.0003 (0.0119)  slide_loss: 0.0026 (0.0067)  time: 0.0173  data: 0.0046  max mem: 0\n",
      "Epoch: [40]  [151/152]  eta: 0:00:00  lr: 0.000064  sub_loss: 0.0027 (0.0073)  diff_loss: 0.0002 (0.0094)  slide_loss: 0.0024 (0.0066)  time: 0.0138  data: 0.0022  max mem: 0\n",
      "Epoch: [40] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0025 (0.0025)  div_loss: -3.6840 (-3.6840)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0021 (0.0022)  div_loss: -3.9634 (-4.4389)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0013 (0.0013)  div_loss: -6.4995 (-6.4995)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.3712 (-3.5230)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.831 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [41]  [  0/152]  eta: 0:00:01  lr: 0.000064  sub_loss: 0.0054 (0.0054)  diff_loss: 0.0008 (0.0008)  slide_loss: 0.0079 (0.0079)  time: 0.0076  data: 0.0008  max mem: 0\n",
      "Epoch: [41]  [100/152]  eta: 0:00:00  lr: 0.000063  sub_loss: 0.0030 (0.0077)  diff_loss: 0.0003 (0.0117)  slide_loss: 0.0025 (0.0067)  time: 0.0183  data: 0.0049  max mem: 0\n",
      "Epoch: [41]  [151/152]  eta: 0:00:00  lr: 0.000062  sub_loss: 0.0027 (0.0073)  diff_loss: 0.0002 (0.0093)  slide_loss: 0.0024 (0.0065)  time: 0.0130  data: 0.0020  max mem: 0\n",
      "Epoch: [41] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0026 (0.0026)  div_loss: -3.6782 (-3.6782)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0022)  div_loss: -3.9555 (-4.4331)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0012 (0.0012)  div_loss: -6.4936 (-6.4936)  acc1: 100.0000 (100.0000)  time: 0.0114  data: 0.0064  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.3672 (-3.5180)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.836 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [42]  [  0/152]  eta: 0:00:01  lr: 0.000062  sub_loss: 0.0055 (0.0055)  diff_loss: 0.0008 (0.0008)  slide_loss: 0.0079 (0.0079)  time: 0.0084  data: 0.0008  max mem: 0\n",
      "Epoch: [42]  [100/152]  eta: 0:00:00  lr: 0.000061  sub_loss: 0.0030 (0.0077)  diff_loss: 0.0003 (0.0115)  slide_loss: 0.0024 (0.0066)  time: 0.0166  data: 0.0035  max mem: 0\n",
      "Epoch: [42]  [151/152]  eta: 0:00:00  lr: 0.000061  sub_loss: 0.0027 (0.0072)  diff_loss: 0.0002 (0.0091)  slide_loss: 0.0024 (0.0065)  time: 0.0123  data: 0.0020  max mem: 0\n",
      "Epoch: [42] Total time: 0:00:02 (0.0138 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0026 (0.0026)  div_loss: -3.6729 (-3.6729)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0022)  div_loss: -3.9481 (-4.4275)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0016  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0012 (0.0012)  div_loss: -6.4882 (-6.4882)  acc1: 100.0000 (100.0000)  time: 0.0089  data: 0.0040  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0038 (0.0078)  div_loss: -3.3636 (-3.5133)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [43]  [  0/152]  eta: 0:00:01  lr: 0.000061  sub_loss: 0.0055 (0.0055)  diff_loss: 0.0007 (0.0007)  slide_loss: 0.0079 (0.0079)  time: 0.0076  data: 0.0007  max mem: 0\n",
      "Epoch: [43]  [100/152]  eta: 0:00:00  lr: 0.000060  sub_loss: 0.0030 (0.0076)  diff_loss: 0.0003 (0.0112)  slide_loss: 0.0024 (0.0066)  time: 0.0165  data: 0.0037  max mem: 0\n",
      "Epoch: [43]  [151/152]  eta: 0:00:00  lr: 0.000059  sub_loss: 0.0026 (0.0072)  diff_loss: 0.0002 (0.0089)  slide_loss: 0.0023 (0.0064)  time: 0.0130  data: 0.0020  max mem: 0\n",
      "Epoch: [43] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0026 (0.0026)  div_loss: -3.6681 (-3.6681)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0022)  div_loss: -3.9411 (-4.4220)  acc1: 100.0000 (100.0000)  time: 0.0065  data: 0.0022  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0066 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0011 (0.0011)  div_loss: -6.4830 (-6.4830)  acc1: 100.0000 (100.0000)  time: 0.0089  data: 0.0041  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.3600 (-3.5088)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [44]  [  0/152]  eta: 0:00:01  lr: 0.000059  sub_loss: 0.0055 (0.0055)  diff_loss: 0.0007 (0.0007)  slide_loss: 0.0079 (0.0079)  time: 0.0085  data: 0.0008  max mem: 0\n",
      "Epoch: [44]  [100/152]  eta: 0:00:00  lr: 0.000058  sub_loss: 0.0029 (0.0076)  diff_loss: 0.0003 (0.0109)  slide_loss: 0.0023 (0.0065)  time: 0.0170  data: 0.0037  max mem: 0\n",
      "Epoch: [44]  [151/152]  eta: 0:00:00  lr: 0.000058  sub_loss: 0.0026 (0.0072)  diff_loss: 0.0002 (0.0087)  slide_loss: 0.0023 (0.0064)  time: 0.0123  data: 0.0019  max mem: 0\n",
      "Epoch: [44] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0027 (0.0027)  div_loss: -3.6633 (-3.6633)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0020 (0.0022)  div_loss: -3.9347 (-4.4164)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0011 (0.0011)  div_loss: -6.4773 (-6.4773)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.3556 (-3.5043)  acc1: 100.0000 (88.6364)  time: 0.0042  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [45]  [  0/152]  eta: 0:00:01  lr: 0.000058  sub_loss: 0.0056 (0.0056)  diff_loss: 0.0006 (0.0006)  slide_loss: 0.0079 (0.0079)  time: 0.0078  data: 0.0007  max mem: 0\n",
      "Epoch: [45]  [100/152]  eta: 0:00:00  lr: 0.000057  sub_loss: 0.0029 (0.0075)  diff_loss: 0.0002 (0.0106)  slide_loss: 0.0023 (0.0065)  time: 0.0166  data: 0.0036  max mem: 0\n",
      "Epoch: [45]  [151/152]  eta: 0:00:00  lr: 0.000056  sub_loss: 0.0026 (0.0071)  diff_loss: 0.0002 (0.0085)  slide_loss: 0.0023 (0.0064)  time: 0.0136  data: 0.0023  max mem: 0\n",
      "Epoch: [45] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0027 (0.0027)  div_loss: -3.6583 (-3.6583)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -3.9294 (-4.4110)  acc1: 100.0000 (100.0000)  time: 0.0065  data: 0.0024  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0066 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0010 (0.0010)  div_loss: -6.4712 (-6.4712)  acc1: 100.0000 (100.0000)  time: 0.0118  data: 0.0069  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0039 (0.0078)  div_loss: -3.3501 (-3.4997)  acc1: 100.0000 (88.6364)  time: 0.0045  data: 0.0018  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0037 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.826 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [46]  [  0/152]  eta: 0:00:01  lr: 0.000056  sub_loss: 0.0056 (0.0056)  diff_loss: 0.0006 (0.0006)  slide_loss: 0.0079 (0.0079)  time: 0.0076  data: 0.0007  max mem: 0\n",
      "Epoch: [46]  [100/152]  eta: 0:00:00  lr: 0.000055  sub_loss: 0.0029 (0.0075)  diff_loss: 0.0002 (0.0104)  slide_loss: 0.0022 (0.0064)  time: 0.0162  data: 0.0033  max mem: 0\n",
      "Epoch: [46]  [151/152]  eta: 0:00:00  lr: 0.000055  sub_loss: 0.0026 (0.0071)  diff_loss: 0.0002 (0.0084)  slide_loss: 0.0022 (0.0063)  time: 0.0133  data: 0.0023  max mem: 0\n",
      "Epoch: [46] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -3.6534 (-3.6534)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -3.9247 (-4.4059)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0016  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0010 (0.0010)  div_loss: -6.4649 (-6.4649)  acc1: 100.0000 (100.0000)  time: 0.0152  data: 0.0077  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0078)  div_loss: -3.3442 (-3.4952)  acc1: 100.0000 (88.6364)  time: 0.0031  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [47]  [  0/152]  eta: 0:00:01  lr: 0.000055  sub_loss: 0.0057 (0.0057)  diff_loss: 0.0006 (0.0006)  slide_loss: 0.0080 (0.0080)  time: 0.0081  data: 0.0007  max mem: 0\n",
      "Epoch: [47]  [100/152]  eta: 0:00:00  lr: 0.000054  sub_loss: 0.0028 (0.0074)  diff_loss: 0.0002 (0.0102)  slide_loss: 0.0022 (0.0064)  time: 0.0173  data: 0.0038  max mem: 0\n",
      "Epoch: [47]  [151/152]  eta: 0:00:00  lr: 0.000053  sub_loss: 0.0026 (0.0070)  diff_loss: 0.0002 (0.0083)  slide_loss: 0.0022 (0.0063)  time: 0.0129  data: 0.0026  max mem: 0\n",
      "Epoch: [47] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0028 (0.0028)  div_loss: -3.6486 (-3.6486)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -3.9206 (-4.4011)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0020  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0010 (0.0010)  div_loss: -6.4589 (-6.4589)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0037  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0078)  div_loss: -3.3385 (-3.4909)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [48]  [  0/152]  eta: 0:00:01  lr: 0.000053  sub_loss: 0.0057 (0.0057)  diff_loss: 0.0005 (0.0005)  slide_loss: 0.0080 (0.0080)  time: 0.0082  data: 0.0008  max mem: 0\n",
      "Epoch: [48]  [100/152]  eta: 0:00:00  lr: 0.000052  sub_loss: 0.0028 (0.0074)  diff_loss: 0.0002 (0.0101)  slide_loss: 0.0022 (0.0063)  time: 0.0186  data: 0.0043  max mem: 0\n",
      "Epoch: [48]  [151/152]  eta: 0:00:00  lr: 0.000052  sub_loss: 0.0026 (0.0070)  diff_loss: 0.0001 (0.0082)  slide_loss: 0.0022 (0.0062)  time: 0.0137  data: 0.0029  max mem: 0\n",
      "Epoch: [48] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0029 (0.0029)  div_loss: -3.6440 (-3.6440)  acc1: 100.0000 (100.0000)  time: 0.0016  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -3.9168 (-4.3964)  acc1: 100.0000 (100.0000)  time: 0.0065  data: 0.0018  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0066 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0009 (0.0009)  div_loss: -6.4531 (-6.4531)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0040 (0.0078)  div_loss: -3.3331 (-3.4868)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0016  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [49]  [  0/152]  eta: 0:00:01  lr: 0.000052  sub_loss: 0.0057 (0.0057)  diff_loss: 0.0005 (0.0005)  slide_loss: 0.0080 (0.0080)  time: 0.0100  data: 0.0007  max mem: 0\n",
      "Epoch: [49]  [100/152]  eta: 0:00:00  lr: 0.000051  sub_loss: 0.0028 (0.0073)  diff_loss: 0.0002 (0.0100)  slide_loss: 0.0022 (0.0063)  time: 0.0180  data: 0.0043  max mem: 0\n",
      "Epoch: [49]  [151/152]  eta: 0:00:00  lr: 0.000050  sub_loss: 0.0026 (0.0069)  diff_loss: 0.0001 (0.0081)  slide_loss: 0.0022 (0.0062)  time: 0.0129  data: 0.0020  max mem: 0\n",
      "Epoch: [49] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0029 (0.0029)  div_loss: -3.6397 (-3.6397)  acc1: 100.0000 (100.0000)  time: 0.0042  data: 0.0029  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0019 (0.0022)  div_loss: -3.9134 (-4.3920)  acc1: 100.0000 (100.0000)  time: 0.0063  data: 0.0025  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0064 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0009 (0.0009)  div_loss: -6.4477 (-6.4477)  acc1: 100.0000 (100.0000)  time: 0.0082  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0078)  div_loss: -3.3279 (-3.4828)  acc1: 100.0000 (88.6364)  time: 0.0047  data: 0.0017  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0038 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [50]  [  0/152]  eta: 0:00:01  lr: 0.000050  sub_loss: 0.0058 (0.0058)  diff_loss: 0.0005 (0.0005)  slide_loss: 0.0081 (0.0081)  time: 0.0087  data: 0.0015  max mem: 0\n",
      "Epoch: [50]  [100/152]  eta: 0:00:00  lr: 0.000049  sub_loss: 0.0027 (0.0073)  diff_loss: 0.0002 (0.0099)  slide_loss: 0.0021 (0.0062)  time: 0.0172  data: 0.0044  max mem: 0\n",
      "Epoch: [50]  [151/152]  eta: 0:00:00  lr: 0.000048  sub_loss: 0.0026 (0.0069)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0021 (0.0061)  time: 0.0134  data: 0.0023  max mem: 0\n",
      "Epoch: [50] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0030 (0.0030)  div_loss: -3.6356 (-3.6356)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0022)  div_loss: -3.9103 (-4.3877)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0009 (0.0009)  div_loss: -6.4425 (-6.4425)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0078)  div_loss: -3.3230 (-3.4791)  acc1: 100.0000 (88.6364)  time: 0.0034  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0029 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [51]  [  0/152]  eta: 0:00:01  lr: 0.000048  sub_loss: 0.0058 (0.0058)  diff_loss: 0.0004 (0.0004)  slide_loss: 0.0081 (0.0081)  time: 0.0073  data: 0.0007  max mem: 0\n",
      "Epoch: [51]  [100/152]  eta: 0:00:00  lr: 0.000047  sub_loss: 0.0027 (0.0072)  diff_loss: 0.0002 (0.0097)  slide_loss: 0.0021 (0.0062)  time: 0.0173  data: 0.0042  max mem: 0\n",
      "Epoch: [51]  [151/152]  eta: 0:00:00  lr: 0.000047  sub_loss: 0.0026 (0.0069)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0021 (0.0061)  time: 0.0134  data: 0.0027  max mem: 0\n",
      "Epoch: [51] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0030 (0.0030)  div_loss: -3.6316 (-3.6316)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0022)  div_loss: -3.9072 (-4.3836)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0008 (0.0008)  div_loss: -6.4375 (-6.4375)  acc1: 100.0000 (100.0000)  time: 0.0088  data: 0.0040  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0078)  div_loss: -3.3185 (-3.4755)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [52]  [  0/152]  eta: 0:00:01  lr: 0.000047  sub_loss: 0.0059 (0.0059)  diff_loss: 0.0004 (0.0004)  slide_loss: 0.0081 (0.0081)  time: 0.0087  data: 0.0008  max mem: 0\n",
      "Epoch: [52]  [100/152]  eta: 0:00:00  lr: 0.000046  sub_loss: 0.0027 (0.0072)  diff_loss: 0.0002 (0.0096)  slide_loss: 0.0021 (0.0061)  time: 0.0180  data: 0.0038  max mem: 0\n",
      "Epoch: [52]  [151/152]  eta: 0:00:00  lr: 0.000045  sub_loss: 0.0025 (0.0068)  diff_loss: 0.0001 (0.0078)  slide_loss: 0.0021 (0.0061)  time: 0.0122  data: 0.0023  max mem: 0\n",
      "Epoch: [52] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0031 (0.0031)  div_loss: -3.6278 (-3.6278)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0022)  div_loss: -3.9045 (-4.3797)  acc1: 100.0000 (100.0000)  time: 0.0078  data: 0.0035  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0079 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0008 (0.0008)  div_loss: -6.4329 (-6.4329)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0041 (0.0078)  div_loss: -3.3141 (-3.4721)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [53]  [  0/152]  eta: 0:00:01  lr: 0.000045  sub_loss: 0.0059 (0.0059)  diff_loss: 0.0004 (0.0004)  slide_loss: 0.0082 (0.0082)  time: 0.0077  data: 0.0008  max mem: 0\n",
      "Epoch: [53]  [100/152]  eta: 0:00:00  lr: 0.000044  sub_loss: 0.0026 (0.0071)  diff_loss: 0.0001 (0.0095)  slide_loss: 0.0021 (0.0061)  time: 0.0172  data: 0.0046  max mem: 0\n",
      "Epoch: [53]  [151/152]  eta: 0:00:00  lr: 0.000044  sub_loss: 0.0025 (0.0068)  diff_loss: 0.0001 (0.0078)  slide_loss: 0.0021 (0.0060)  time: 0.0137  data: 0.0019  max mem: 0\n",
      "Epoch: [53] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0031 (0.0031)  div_loss: -3.6241 (-3.6241)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0022)  div_loss: -3.9017 (-4.3760)  acc1: 100.0000 (100.0000)  time: 0.0060  data: 0.0018  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0061 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0008 (0.0008)  div_loss: -6.4284 (-6.4284)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0042 (0.0078)  div_loss: -3.3100 (-3.4687)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [54]  [  0/152]  eta: 0:00:01  lr: 0.000044  sub_loss: 0.0059 (0.0059)  diff_loss: 0.0004 (0.0004)  slide_loss: 0.0082 (0.0082)  time: 0.0081  data: 0.0008  max mem: 0\n",
      "Epoch: [54]  [100/152]  eta: 0:00:00  lr: 0.000043  sub_loss: 0.0026 (0.0071)  diff_loss: 0.0001 (0.0094)  slide_loss: 0.0020 (0.0060)  time: 0.0173  data: 0.0042  max mem: 0\n",
      "Epoch: [54]  [151/152]  eta: 0:00:00  lr: 0.000042  sub_loss: 0.0025 (0.0068)  diff_loss: 0.0001 (0.0077)  slide_loss: 0.0021 (0.0060)  time: 0.0132  data: 0.0027  max mem: 0\n",
      "Epoch: [54] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0032 (0.0032)  div_loss: -3.6205 (-3.6205)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0022)  div_loss: -3.8992 (-4.3724)  acc1: 100.0000 (100.0000)  time: 0.0063  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0064 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0008 (0.0008)  div_loss: -6.4241 (-6.4241)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0042 (0.0078)  div_loss: -3.3061 (-3.4655)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [55]  [  0/152]  eta: 0:00:01  lr: 0.000042  sub_loss: 0.0060 (0.0060)  diff_loss: 0.0004 (0.0004)  slide_loss: 0.0082 (0.0082)  time: 0.0100  data: 0.0008  max mem: 0\n",
      "Epoch: [55]  [100/152]  eta: 0:00:00  lr: 0.000041  sub_loss: 0.0026 (0.0070)  diff_loss: 0.0001 (0.0093)  slide_loss: 0.0020 (0.0060)  time: 0.0182  data: 0.0039  max mem: 0\n",
      "Epoch: [55]  [151/152]  eta: 0:00:00  lr: 0.000041  sub_loss: 0.0025 (0.0067)  diff_loss: 0.0001 (0.0076)  slide_loss: 0.0020 (0.0059)  time: 0.0137  data: 0.0025  max mem: 0\n",
      "Epoch: [55] Total time: 0:00:02 (0.0151 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0032 (0.0032)  div_loss: -3.6170 (-3.6170)  acc1: 100.0000 (100.0000)  time: 0.0076  data: 0.0061  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0018 (0.0023)  div_loss: -3.8966 (-4.3689)  acc1: 100.0000 (100.0000)  time: 0.0061  data: 0.0024  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0063 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0008 (0.0008)  div_loss: -6.4199 (-6.4199)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0042 (0.0078)  div_loss: -3.3023 (-3.4624)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [56]  [  0/152]  eta: 0:00:01  lr: 0.000041  sub_loss: 0.0060 (0.0060)  diff_loss: 0.0004 (0.0004)  slide_loss: 0.0083 (0.0083)  time: 0.0081  data: 0.0010  max mem: 0\n",
      "Epoch: [56]  [100/152]  eta: 0:00:00  lr: 0.000040  sub_loss: 0.0025 (0.0070)  diff_loss: 0.0001 (0.0092)  slide_loss: 0.0020 (0.0060)  time: 0.0178  data: 0.0041  max mem: 0\n",
      "Epoch: [56]  [151/152]  eta: 0:00:00  lr: 0.000039  sub_loss: 0.0025 (0.0067)  diff_loss: 0.0001 (0.0076)  slide_loss: 0.0020 (0.0059)  time: 0.0128  data: 0.0022  max mem: 0\n",
      "Epoch: [56] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0033 (0.0033)  div_loss: -3.6135 (-3.6135)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8942 (-4.3655)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0007 (0.0007)  div_loss: -6.4160 (-6.4160)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0043 (0.0078)  div_loss: -3.2988 (-3.4593)  acc1: 100.0000 (88.6364)  time: 0.0043  data: 0.0017  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0036 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [57]  [  0/152]  eta: 0:00:01  lr: 0.000039  sub_loss: 0.0060 (0.0060)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0083 (0.0083)  time: 0.0078  data: 0.0007  max mem: 0\n",
      "Epoch: [57]  [100/152]  eta: 0:00:00  lr: 0.000038  sub_loss: 0.0025 (0.0070)  diff_loss: 0.0001 (0.0092)  slide_loss: 0.0020 (0.0059)  time: 0.0166  data: 0.0038  max mem: 0\n",
      "Epoch: [57]  [151/152]  eta: 0:00:00  lr: 0.000038  sub_loss: 0.0025 (0.0066)  diff_loss: 0.0001 (0.0075)  slide_loss: 0.0020 (0.0059)  time: 0.0134  data: 0.0029  max mem: 0\n",
      "Epoch: [57] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0033 (0.0033)  div_loss: -3.6102 (-3.6102)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8917 (-4.3621)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0007 (0.0007)  div_loss: -6.4120 (-6.4120)  acc1: 100.0000 (100.0000)  time: 0.0112  data: 0.0065  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0043 (0.0078)  div_loss: -3.2952 (-3.4562)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [58]  [  0/152]  eta: 0:00:01  lr: 0.000038  sub_loss: 0.0061 (0.0061)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0083 (0.0083)  time: 0.0079  data: 0.0008  max mem: 0\n",
      "Epoch: [58]  [100/152]  eta: 0:00:00  lr: 0.000037  sub_loss: 0.0025 (0.0069)  diff_loss: 0.0001 (0.0091)  slide_loss: 0.0019 (0.0059)  time: 0.0161  data: 0.0033  max mem: 0\n",
      "Epoch: [58]  [151/152]  eta: 0:00:00  lr: 0.000036  sub_loss: 0.0025 (0.0066)  diff_loss: 0.0001 (0.0074)  slide_loss: 0.0020 (0.0058)  time: 0.0125  data: 0.0025  max mem: 0\n",
      "Epoch: [58] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0034 (0.0034)  div_loss: -3.6069 (-3.6069)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8893 (-4.3589)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0007 (0.0007)  div_loss: -6.4083 (-6.4083)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0043 (0.0078)  div_loss: -3.2918 (-3.4533)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [59]  [  0/152]  eta: 0:00:01  lr: 0.000036  sub_loss: 0.0061 (0.0061)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0084 (0.0084)  time: 0.0080  data: 0.0008  max mem: 0\n",
      "Epoch: [59]  [100/152]  eta: 0:00:00  lr: 0.000035  sub_loss: 0.0024 (0.0069)  diff_loss: 0.0001 (0.0090)  slide_loss: 0.0019 (0.0058)  time: 0.0177  data: 0.0037  max mem: 0\n",
      "Epoch: [59]  [151/152]  eta: 0:00:00  lr: 0.000035  sub_loss: 0.0025 (0.0066)  diff_loss: 0.0001 (0.0074)  slide_loss: 0.0020 (0.0058)  time: 0.0133  data: 0.0023  max mem: 0\n",
      "Epoch: [59] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0034 (0.0034)  div_loss: -3.6038 (-3.6038)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8867 (-4.3557)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0007 (0.0007)  div_loss: -6.4045 (-6.4045)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0043 (0.0078)  div_loss: -3.2885 (-3.4503)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0030 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [60]  [  0/152]  eta: 0:00:01  lr: 0.000035  sub_loss: 0.0061 (0.0061)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0084 (0.0084)  time: 0.0078  data: 0.0007  max mem: 0\n",
      "Epoch: [60]  [100/152]  eta: 0:00:00  lr: 0.000034  sub_loss: 0.0024 (0.0069)  diff_loss: 0.0001 (0.0089)  slide_loss: 0.0019 (0.0058)  time: 0.0174  data: 0.0037  max mem: 0\n",
      "Epoch: [60]  [151/152]  eta: 0:00:00  lr: 0.000033  sub_loss: 0.0025 (0.0066)  diff_loss: 0.0001 (0.0073)  slide_loss: 0.0020 (0.0058)  time: 0.0140  data: 0.0030  max mem: 0\n",
      "Epoch: [60] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0035 (0.0035)  div_loss: -3.6007 (-3.6007)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8843 (-4.3526)  acc1: 100.0000 (100.0000)  time: 0.0053  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0055 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0007 (0.0007)  div_loss: -6.4009 (-6.4009)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0044 (0.0079)  div_loss: -3.2852 (-3.4475)  acc1: 100.0000 (88.6364)  time: 0.0042  data: 0.0017  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0036 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [61]  [  0/152]  eta: 0:00:01  lr: 0.000033  sub_loss: 0.0061 (0.0061)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0084 (0.0084)  time: 0.0079  data: 0.0007  max mem: 0\n",
      "Epoch: [61]  [100/152]  eta: 0:00:00  lr: 0.000032  sub_loss: 0.0024 (0.0068)  diff_loss: 0.0001 (0.0088)  slide_loss: 0.0018 (0.0058)  time: 0.0165  data: 0.0034  max mem: 0\n",
      "Epoch: [61]  [151/152]  eta: 0:00:00  lr: 0.000032  sub_loss: 0.0025 (0.0065)  diff_loss: 0.0001 (0.0073)  slide_loss: 0.0019 (0.0057)  time: 0.0132  data: 0.0027  max mem: 0\n",
      "Epoch: [61] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0035 (0.0035)  div_loss: -3.5977 (-3.5977)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8820 (-4.3496)  acc1: 100.0000 (100.0000)  time: 0.0051  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0052 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0007 (0.0007)  div_loss: -6.3974 (-6.3974)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0044 (0.0079)  div_loss: -3.2820 (-3.4447)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0036 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [62]  [  0/152]  eta: 0:00:01  lr: 0.000032  sub_loss: 0.0062 (0.0062)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0085 (0.0085)  time: 0.0081  data: 0.0008  max mem: 0\n",
      "Epoch: [62]  [100/152]  eta: 0:00:00  lr: 0.000031  sub_loss: 0.0023 (0.0068)  diff_loss: 0.0001 (0.0088)  slide_loss: 0.0018 (0.0057)  time: 0.0176  data: 0.0033  max mem: 0\n",
      "Epoch: [62]  [151/152]  eta: 0:00:00  lr: 0.000030  sub_loss: 0.0025 (0.0065)  diff_loss: 0.0001 (0.0072)  slide_loss: 0.0019 (0.0057)  time: 0.0131  data: 0.0025  max mem: 0\n",
      "Epoch: [62] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0035 (0.0035)  div_loss: -3.5949 (-3.5949)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8797 (-4.3467)  acc1: 100.0000 (100.0000)  time: 0.0069  data: 0.0023  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0070 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3940 (-6.3940)  acc1: 100.0000 (100.0000)  time: 0.0082  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0044 (0.0079)  div_loss: -3.2789 (-3.4420)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [63]  [  0/152]  eta: 0:00:01  lr: 0.000030  sub_loss: 0.0062 (0.0062)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0085 (0.0085)  time: 0.0085  data: 0.0007  max mem: 0\n",
      "Epoch: [63]  [100/152]  eta: 0:00:00  lr: 0.000029  sub_loss: 0.0023 (0.0068)  diff_loss: 0.0001 (0.0087)  slide_loss: 0.0018 (0.0057)  time: 0.0168  data: 0.0042  max mem: 0\n",
      "Epoch: [63]  [151/152]  eta: 0:00:00  lr: 0.000029  sub_loss: 0.0025 (0.0065)  diff_loss: 0.0001 (0.0072)  slide_loss: 0.0019 (0.0057)  time: 0.0126  data: 0.0021  max mem: 0\n",
      "Epoch: [63] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0036 (0.0036)  div_loss: -3.5921 (-3.5921)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0069  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0023)  div_loss: -3.8776 (-4.3439)  acc1: 100.0000 (100.0000)  time: 0.0062  data: 0.0024  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0063 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3908 (-6.3908)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0037  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0044 (0.0079)  div_loss: -3.2760 (-3.4393)  acc1: 100.0000 (88.6364)  time: 0.0035  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [64]  [  0/152]  eta: 0:00:01  lr: 0.000029  sub_loss: 0.0062 (0.0062)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0085 (0.0085)  time: 0.0078  data: 0.0008  max mem: 0\n",
      "Epoch: [64]  [100/152]  eta: 0:00:00  lr: 0.000028  sub_loss: 0.0023 (0.0067)  diff_loss: 0.0001 (0.0086)  slide_loss: 0.0018 (0.0057)  time: 0.0168  data: 0.0034  max mem: 0\n",
      "Epoch: [64]  [151/152]  eta: 0:00:00  lr: 0.000027  sub_loss: 0.0025 (0.0064)  diff_loss: 0.0001 (0.0071)  slide_loss: 0.0019 (0.0057)  time: 0.0144  data: 0.0025  max mem: 0\n",
      "Epoch: [64] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0036 (0.0036)  div_loss: -3.5895 (-3.5895)  acc1: 100.0000 (100.0000)  time: 0.0078  data: 0.0049  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0017 (0.0024)  div_loss: -3.8755 (-4.3413)  acc1: 100.0000 (100.0000)  time: 0.0074  data: 0.0033  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0076 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3877 (-6.3877)  acc1: 100.0000 (100.0000)  time: 0.0127  data: 0.0075  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0045 (0.0079)  div_loss: -3.2732 (-3.4368)  acc1: 100.0000 (88.6364)  time: 0.0036  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [65]  [  0/152]  eta: 0:00:01  lr: 0.000027  sub_loss: 0.0062 (0.0062)  diff_loss: 0.0003 (0.0003)  slide_loss: 0.0085 (0.0085)  time: 0.0087  data: 0.0008  max mem: 0\n",
      "Epoch: [65]  [100/152]  eta: 0:00:00  lr: 0.000026  sub_loss: 0.0023 (0.0067)  diff_loss: 0.0001 (0.0086)  slide_loss: 0.0018 (0.0056)  time: 0.0176  data: 0.0042  max mem: 0\n",
      "Epoch: [65]  [151/152]  eta: 0:00:00  lr: 0.000026  sub_loss: 0.0025 (0.0064)  diff_loss: 0.0001 (0.0071)  slide_loss: 0.0019 (0.0056)  time: 0.0124  data: 0.0021  max mem: 0\n",
      "Epoch: [65] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0037 (0.0037)  div_loss: -3.5869 (-3.5869)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8734 (-4.3387)  acc1: 100.0000 (100.0000)  time: 0.0061  data: 0.0016  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0062 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3847 (-6.3847)  acc1: 100.0000 (100.0000)  time: 0.0087  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0045 (0.0079)  div_loss: -3.2704 (-3.4344)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [66]  [  0/152]  eta: 0:00:01  lr: 0.000026  sub_loss: 0.0063 (0.0063)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0086 (0.0086)  time: 0.0077  data: 0.0008  max mem: 0\n",
      "Epoch: [66]  [100/152]  eta: 0:00:00  lr: 0.000025  sub_loss: 0.0022 (0.0067)  diff_loss: 0.0001 (0.0085)  slide_loss: 0.0017 (0.0056)  time: 0.0175  data: 0.0038  max mem: 0\n",
      "Epoch: [66]  [151/152]  eta: 0:00:00  lr: 0.000025  sub_loss: 0.0025 (0.0064)  diff_loss: 0.0001 (0.0071)  slide_loss: 0.0019 (0.0056)  time: 0.0135  data: 0.0021  max mem: 0\n",
      "Epoch: [66] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0037 (0.0037)  div_loss: -3.5845 (-3.5845)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8715 (-4.3362)  acc1: 100.0000 (100.0000)  time: 0.0064  data: 0.0023  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3819 (-6.3819)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0045 (0.0079)  div_loss: -3.2679 (-3.4321)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [67]  [  0/152]  eta: 0:00:01  lr: 0.000025  sub_loss: 0.0063 (0.0063)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0086 (0.0086)  time: 0.0125  data: 0.0008  max mem: 0\n",
      "Epoch: [67]  [100/152]  eta: 0:00:00  lr: 0.000024  sub_loss: 0.0022 (0.0066)  diff_loss: 0.0001 (0.0085)  slide_loss: 0.0017 (0.0056)  time: 0.0170  data: 0.0040  max mem: 0\n",
      "Epoch: [67]  [151/152]  eta: 0:00:00  lr: 0.000023  sub_loss: 0.0024 (0.0064)  diff_loss: 0.0001 (0.0070)  slide_loss: 0.0019 (0.0056)  time: 0.0140  data: 0.0033  max mem: 0\n",
      "Epoch: [67] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0037 (0.0037)  div_loss: -3.5822 (-3.5822)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8695 (-4.3338)  acc1: 100.0000 (100.0000)  time: 0.0052  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0053 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3791 (-6.3791)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0034  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0045 (0.0079)  div_loss: -3.2654 (-3.4298)  acc1: 100.0000 (88.6364)  time: 0.0035  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [68]  [  0/152]  eta: 0:00:01  lr: 0.000023  sub_loss: 0.0063 (0.0063)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0086 (0.0086)  time: 0.0087  data: 0.0008  max mem: 0\n",
      "Epoch: [68]  [100/152]  eta: 0:00:00  lr: 0.000022  sub_loss: 0.0022 (0.0066)  diff_loss: 0.0001 (0.0084)  slide_loss: 0.0017 (0.0056)  time: 0.0175  data: 0.0041  max mem: 0\n",
      "Epoch: [68]  [151/152]  eta: 0:00:00  lr: 0.000022  sub_loss: 0.0024 (0.0063)  diff_loss: 0.0001 (0.0070)  slide_loss: 0.0019 (0.0056)  time: 0.0132  data: 0.0022  max mem: 0\n",
      "Epoch: [68] Total time: 0:00:02 (0.0146 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0038 (0.0038)  div_loss: -3.5800 (-3.5800)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8676 (-4.3316)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3765 (-6.3765)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0046 (0.0079)  div_loss: -3.2631 (-3.4277)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0030 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [69]  [  0/152]  eta: 0:00:01  lr: 0.000022  sub_loss: 0.0063 (0.0063)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0086 (0.0086)  time: 0.0077  data: 0.0008  max mem: 0\n",
      "Epoch: [69]  [100/152]  eta: 0:00:00  lr: 0.000021  sub_loss: 0.0022 (0.0066)  diff_loss: 0.0001 (0.0084)  slide_loss: 0.0017 (0.0055)  time: 0.0178  data: 0.0039  max mem: 0\n",
      "Epoch: [69]  [151/152]  eta: 0:00:00  lr: 0.000021  sub_loss: 0.0024 (0.0063)  diff_loss: 0.0001 (0.0070)  slide_loss: 0.0018 (0.0055)  time: 0.0126  data: 0.0023  max mem: 0\n",
      "Epoch: [69] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0038 (0.0038)  div_loss: -3.5780 (-3.5780)  acc1: 100.0000 (100.0000)  time: 0.0040  data: 0.0029  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8658 (-4.3294)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0019  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0059 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3741 (-6.3741)  acc1: 100.0000 (100.0000)  time: 0.0088  data: 0.0040  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0046 (0.0079)  div_loss: -3.2608 (-3.4256)  acc1: 100.0000 (88.6364)  time: 0.0048  data: 0.0021  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0037 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [70]  [  0/152]  eta: 0:00:01  lr: 0.000021  sub_loss: 0.0063 (0.0063)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0086 (0.0086)  time: 0.0078  data: 0.0008  max mem: 0\n",
      "Epoch: [70]  [100/152]  eta: 0:00:00  lr: 0.000020  sub_loss: 0.0022 (0.0066)  diff_loss: 0.0001 (0.0083)  slide_loss: 0.0017 (0.0055)  time: 0.0170  data: 0.0040  max mem: 0\n",
      "Epoch: [70]  [151/152]  eta: 0:00:00  lr: 0.000019  sub_loss: 0.0024 (0.0063)  diff_loss: 0.0001 (0.0069)  slide_loss: 0.0018 (0.0055)  time: 0.0135  data: 0.0030  max mem: 0\n",
      "Epoch: [70] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0038 (0.0038)  div_loss: -3.5760 (-3.5760)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8640 (-4.3273)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3717 (-6.3717)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0046 (0.0079)  div_loss: -3.2596 (-3.4237)  acc1: 100.0000 (88.6364)  time: 0.0044  data: 0.0018  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0036 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [71]  [  0/152]  eta: 0:00:01  lr: 0.000019  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0073  data: 0.0008  max mem: 0\n",
      "Epoch: [71]  [100/152]  eta: 0:00:00  lr: 0.000019  sub_loss: 0.0021 (0.0065)  diff_loss: 0.0001 (0.0083)  slide_loss: 0.0016 (0.0055)  time: 0.0167  data: 0.0035  max mem: 0\n",
      "Epoch: [71]  [151/152]  eta: 0:00:00  lr: 0.000018  sub_loss: 0.0024 (0.0063)  diff_loss: 0.0001 (0.0069)  slide_loss: 0.0018 (0.0055)  time: 0.0135  data: 0.0023  max mem: 0\n",
      "Epoch: [71] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0039 (0.0039)  div_loss: -3.5742 (-3.5742)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8624 (-4.3254)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3696 (-6.3696)  acc1: 100.0000 (100.0000)  time: 0.0085  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0046 (0.0079)  div_loss: -3.2592 (-3.4219)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.821 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [72]  [  0/152]  eta: 0:00:01  lr: 0.000018  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0108  data: 0.0007  max mem: 0\n",
      "Epoch: [72]  [100/152]  eta: 0:00:00  lr: 0.000017  sub_loss: 0.0021 (0.0065)  diff_loss: 0.0001 (0.0083)  slide_loss: 0.0016 (0.0055)  time: 0.0184  data: 0.0044  max mem: 0\n",
      "Epoch: [72]  [151/152]  eta: 0:00:00  lr: 0.000017  sub_loss: 0.0024 (0.0063)  diff_loss: 0.0001 (0.0069)  slide_loss: 0.0018 (0.0055)  time: 0.0133  data: 0.0032  max mem: 0\n",
      "Epoch: [72] Total time: 0:00:02 (0.0147 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0039 (0.0039)  div_loss: -3.5725 (-3.5725)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8608 (-4.3236)  acc1: 100.0000 (100.0000)  time: 0.0079  data: 0.0035  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0080 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0006 (0.0006)  div_loss: -6.3675 (-6.3675)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0046 (0.0079)  div_loss: -3.2588 (-3.4202)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [73]  [  0/152]  eta: 0:00:01  lr: 0.000017  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0076  data: 0.0008  max mem: 0\n",
      "Epoch: [73]  [100/152]  eta: 0:00:00  lr: 0.000016  sub_loss: 0.0021 (0.0065)  diff_loss: 0.0001 (0.0082)  slide_loss: 0.0016 (0.0055)  time: 0.0168  data: 0.0033  max mem: 0\n",
      "Epoch: [73]  [151/152]  eta: 0:00:00  lr: 0.000016  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0001 (0.0068)  slide_loss: 0.0018 (0.0055)  time: 0.0125  data: 0.0023  max mem: 0\n",
      "Epoch: [73] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0039 (0.0039)  div_loss: -3.5709 (-3.5709)  acc1: 100.0000 (100.0000)  time: 0.0062  data: 0.0045  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8594 (-4.3219)  acc1: 100.0000 (100.0000)  time: 0.0062  data: 0.0024  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0064 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3655 (-6.3655)  acc1: 100.0000 (100.0000)  time: 0.0082  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0046 (0.0079)  div_loss: -3.2583 (-3.4186)  acc1: 100.0000 (88.6364)  time: 0.0047  data: 0.0019  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0037 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [74]  [  0/152]  eta: 0:00:01  lr: 0.000016  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0081  data: 0.0008  max mem: 0\n",
      "Epoch: [74]  [100/152]  eta: 0:00:00  lr: 0.000015  sub_loss: 0.0021 (0.0065)  diff_loss: 0.0001 (0.0082)  slide_loss: 0.0016 (0.0054)  time: 0.0164  data: 0.0038  max mem: 0\n",
      "Epoch: [74]  [151/152]  eta: 0:00:00  lr: 0.000015  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0001 (0.0068)  slide_loss: 0.0018 (0.0054)  time: 0.0135  data: 0.0024  max mem: 0\n",
      "Epoch: [74] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0040 (0.0040)  div_loss: -3.5694 (-3.5694)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8579 (-4.3203)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3637 (-6.3637)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2579 (-3.4171)  acc1: 100.0000 (88.6364)  time: 0.0043  data: 0.0016  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [75]  [  0/152]  eta: 0:00:01  lr: 0.000015  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0108  data: 0.0009  max mem: 0\n",
      "Epoch: [75]  [100/152]  eta: 0:00:00  lr: 0.000014  sub_loss: 0.0021 (0.0065)  diff_loss: 0.0001 (0.0082)  slide_loss: 0.0016 (0.0054)  time: 0.0173  data: 0.0038  max mem: 0\n",
      "Epoch: [75]  [151/152]  eta: 0:00:00  lr: 0.000014  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0001 (0.0068)  slide_loss: 0.0018 (0.0054)  time: 0.0134  data: 0.0028  max mem: 0\n",
      "Epoch: [75] Total time: 0:00:02 (0.0146 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0040 (0.0040)  div_loss: -3.5680 (-3.5680)  acc1: 100.0000 (100.0000)  time: 0.0046  data: 0.0035  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8567 (-4.3188)  acc1: 100.0000 (100.0000)  time: 0.0075  data: 0.0034  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0076 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3620 (-6.3620)  acc1: 100.0000 (100.0000)  time: 0.0080  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2575 (-3.4157)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [76]  [  0/152]  eta: 0:00:01  lr: 0.000014  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0079  data: 0.0007  max mem: 0\n",
      "Epoch: [76]  [100/152]  eta: 0:00:00  lr: 0.000013  sub_loss: 0.0021 (0.0064)  diff_loss: 0.0001 (0.0081)  slide_loss: 0.0016 (0.0054)  time: 0.0171  data: 0.0033  max mem: 0\n",
      "Epoch: [76]  [151/152]  eta: 0:00:00  lr: 0.000013  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0001 (0.0068)  slide_loss: 0.0018 (0.0054)  time: 0.0128  data: 0.0027  max mem: 0\n",
      "Epoch: [76] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0040 (0.0040)  div_loss: -3.5667 (-3.5667)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0024)  div_loss: -3.8554 (-4.3174)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3605 (-6.3605)  acc1: 100.0000 (100.0000)  time: 0.0106  data: 0.0059  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2572 (-3.4144)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [77]  [  0/152]  eta: 0:00:01  lr: 0.000012  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0087 (0.0087)  time: 0.0128  data: 0.0037  max mem: 0\n",
      "Epoch: [77]  [100/152]  eta: 0:00:00  lr: 0.000012  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0081)  slide_loss: 0.0015 (0.0054)  time: 0.0164  data: 0.0035  max mem: 0\n",
      "Epoch: [77]  [151/152]  eta: 0:00:00  lr: 0.000011  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0000 (0.0068)  slide_loss: 0.0018 (0.0054)  time: 0.0127  data: 0.0027  max mem: 0\n",
      "Epoch: [77] Total time: 0:00:02 (0.0137 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0040 (0.0040)  div_loss: -3.5655 (-3.5655)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8543 (-4.3161)  acc1: 100.0000 (100.0000)  time: 0.0053  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0054 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3590 (-6.3590)  acc1: 100.0000 (100.0000)  time: 0.0079  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2569 (-3.4132)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [78]  [  0/152]  eta: 0:00:01  lr: 0.000011  sub_loss: 0.0064 (0.0064)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0106  data: 0.0008  max mem: 0\n",
      "Epoch: [78]  [100/152]  eta: 0:00:00  lr: 0.000011  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0081)  slide_loss: 0.0015 (0.0054)  time: 0.0175  data: 0.0044  max mem: 0\n",
      "Epoch: [78]  [151/152]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0000 (0.0068)  slide_loss: 0.0018 (0.0054)  time: 0.0129  data: 0.0026  max mem: 0\n",
      "Epoch: [78] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0040 (0.0040)  div_loss: -3.5644 (-3.5644)  acc1: 100.0000 (100.0000)  time: 0.0016  data: 0.0005  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8532 (-4.3149)  acc1: 100.0000 (100.0000)  time: 0.0062  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0063 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3577 (-6.3577)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2565 (-3.4121)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [79]  [  0/152]  eta: 0:00:01  lr: 0.000010  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0082  data: 0.0007  max mem: 0\n",
      "Epoch: [79]  [100/152]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0081)  slide_loss: 0.0015 (0.0054)  time: 0.0166  data: 0.0035  max mem: 0\n",
      "Epoch: [79]  [151/152]  eta: 0:00:00  lr: 0.000010  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0018 (0.0054)  time: 0.0146  data: 0.0019  max mem: 0\n",
      "Epoch: [79] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5634 (-3.5634)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0005  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8523 (-4.3138)  acc1: 100.0000 (100.0000)  time: 0.0068  data: 0.0020  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0069 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3564 (-6.3564)  acc1: 100.0000 (100.0000)  time: 0.0092  data: 0.0044  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2563 (-3.4111)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [80]  [  0/152]  eta: 0:00:01  lr: 0.000010  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0086  data: 0.0008  max mem: 0\n",
      "Epoch: [80]  [100/152]  eta: 0:00:00  lr: 0.000009  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0181  data: 0.0040  max mem: 0\n",
      "Epoch: [80]  [151/152]  eta: 0:00:00  lr: 0.000009  sub_loss: 0.0024 (0.0062)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0018 (0.0054)  time: 0.0129  data: 0.0022  max mem: 0\n",
      "Epoch: [80] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5624 (-3.5624)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8514 (-4.3129)  acc1: 100.0000 (100.0000)  time: 0.0070  data: 0.0029  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0071 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3553 (-6.3553)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2560 (-3.4102)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [81]  [  0/152]  eta: 0:00:01  lr: 0.000009  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0077  data: 0.0008  max mem: 0\n",
      "Epoch: [81]  [100/152]  eta: 0:00:00  lr: 0.000008  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0179  data: 0.0041  max mem: 0\n",
      "Epoch: [81]  [151/152]  eta: 0:00:00  lr: 0.000008  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0018 (0.0053)  time: 0.0137  data: 0.0021  max mem: 0\n",
      "Epoch: [81] Total time: 0:00:02 (0.0145 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5616 (-3.5616)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0048  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8506 (-4.3119)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3543 (-6.3543)  acc1: 100.0000 (100.0000)  time: 0.0095  data: 0.0050  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2557 (-3.4093)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.815 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [82]  [  0/152]  eta: 0:00:01  lr: 0.000008  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0088  data: 0.0009  max mem: 0\n",
      "Epoch: [82]  [100/152]  eta: 0:00:00  lr: 0.000007  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0168  data: 0.0037  max mem: 0\n",
      "Epoch: [82]  [151/152]  eta: 0:00:00  lr: 0.000007  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0018 (0.0053)  time: 0.0151  data: 0.0022  max mem: 0\n",
      "Epoch: [82] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5608 (-3.5608)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8499 (-4.3111)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3534 (-6.3534)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2555 (-3.4086)  acc1: 100.0000 (88.6364)  time: 0.0034  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0030 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [83]  [  0/152]  eta: 0:00:01  lr: 0.000007  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0079  data: 0.0007  max mem: 0\n",
      "Epoch: [83]  [100/152]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0162  data: 0.0035  max mem: 0\n",
      "Epoch: [83]  [151/152]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0122  data: 0.0020  max mem: 0\n",
      "Epoch: [83] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5602 (-3.5602)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8493 (-4.3104)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0017  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0061 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3525 (-6.3525)  acc1: 100.0000 (100.0000)  time: 0.0088  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2553 (-3.4079)  acc1: 100.0000 (88.6364)  time: 0.0040  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [84]  [  0/152]  eta: 0:00:01  lr: 0.000006  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0107  data: 0.0008  max mem: 0\n",
      "Epoch: [84]  [100/152]  eta: 0:00:00  lr: 0.000006  sub_loss: 0.0020 (0.0064)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0179  data: 0.0040  max mem: 0\n",
      "Epoch: [84]  [151/152]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0134  data: 0.0026  max mem: 0\n",
      "Epoch: [84] Total time: 0:00:02 (0.0152 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5596 (-3.5596)  acc1: 100.0000 (100.0000)  time: 0.0016  data: 0.0005  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8487 (-4.3097)  acc1: 100.0000 (100.0000)  time: 0.0053  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0054 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3518 (-6.3518)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2551 (-3.4073)  acc1: 100.0000 (88.6364)  time: 0.0038  data: 0.0010  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [85]  [  0/152]  eta: 0:00:01  lr: 0.000005  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0081  data: 0.0008  max mem: 0\n",
      "Epoch: [85]  [100/152]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0020 (0.0063)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0173  data: 0.0038  max mem: 0\n",
      "Epoch: [85]  [151/152]  eta: 0:00:00  lr: 0.000005  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0140  data: 0.0027  max mem: 0\n",
      "Epoch: [85] Total time: 0:00:02 (0.0149 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5590 (-3.5590)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0016 (0.0025)  div_loss: -3.8483 (-4.3092)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0020  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3512 (-6.3512)  acc1: 100.0000 (100.0000)  time: 0.0089  data: 0.0040  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2550 (-3.4067)  acc1: 100.0000 (88.6364)  time: 0.0043  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.810 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [86]  [  0/152]  eta: 0:00:01  lr: 0.000005  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0078  data: 0.0009  max mem: 0\n",
      "Epoch: [86]  [100/152]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0173  data: 0.0041  max mem: 0\n",
      "Epoch: [86]  [151/152]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0128  data: 0.0026  max mem: 0\n",
      "Epoch: [86] Total time: 0:00:02 (0.0146 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5586 (-3.5586)  acc1: 100.0000 (100.0000)  time: 0.0050  data: 0.0039  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8479 (-4.3087)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0061 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3506 (-6.3506)  acc1: 100.0000 (100.0000)  time: 0.0090  data: 0.0041  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2548 (-3.4063)  acc1: 100.0000 (88.6364)  time: 0.0043  data: 0.0016  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [87]  [  0/152]  eta: 0:00:01  lr: 0.000004  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0082  data: 0.0009  max mem: 0\n",
      "Epoch: [87]  [100/152]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0015 (0.0053)  time: 0.0176  data: 0.0045  max mem: 0\n",
      "Epoch: [87]  [151/152]  eta: 0:00:00  lr: 0.000004  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0123  data: 0.0023  max mem: 0\n",
      "Epoch: [87] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0041 (0.0041)  div_loss: -3.5582 (-3.5582)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8475 (-4.3082)  acc1: 100.0000 (100.0000)  time: 0.0054  data: 0.0016  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0054 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3501 (-6.3501)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0038  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2547 (-3.4059)  acc1: 100.0000 (88.6364)  time: 0.0034  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0028 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [88]  [  0/152]  eta: 0:00:01  lr: 0.000004  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0069  data: 0.0007  max mem: 0\n",
      "Epoch: [88]  [100/152]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0080)  slide_loss: 0.0014 (0.0053)  time: 0.0172  data: 0.0035  max mem: 0\n",
      "Epoch: [88]  [151/152]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0136  data: 0.0026  max mem: 0\n",
      "Epoch: [88] Total time: 0:00:02 (0.0141 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5578 (-3.5578)  acc1: 100.0000 (100.0000)  time: 0.0054  data: 0.0043  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8472 (-4.3079)  acc1: 100.0000 (100.0000)  time: 0.0075  data: 0.0037  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0077 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3497 (-6.3497)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2545 (-3.4055)  acc1: 100.0000 (88.6364)  time: 0.0042  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0034 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [89]  [  0/152]  eta: 0:00:01  lr: 0.000003  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0077  data: 0.0008  max mem: 0\n",
      "Epoch: [89]  [100/152]  eta: 0:00:00  lr: 0.000003  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0053)  time: 0.0173  data: 0.0040  max mem: 0\n",
      "Epoch: [89]  [151/152]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0124  data: 0.0021  max mem: 0\n",
      "Epoch: [89] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5575 (-3.5575)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8470 (-4.3076)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3493 (-6.3493)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2545 (-3.4052)  acc1: 100.0000 (88.6364)  time: 0.0049  data: 0.0019  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0040 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [90]  [  0/152]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0126  data: 0.0056  max mem: 0\n",
      "Epoch: [90]  [100/152]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0053)  time: 0.0177  data: 0.0042  max mem: 0\n",
      "Epoch: [90]  [151/152]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0067)  slide_loss: 0.0017 (0.0053)  time: 0.0120  data: 0.0018  max mem: 0\n",
      "Epoch: [90] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5573 (-3.5573)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8468 (-4.3073)  acc1: 100.0000 (100.0000)  time: 0.0055  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0056 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3491 (-6.3491)  acc1: 100.0000 (100.0000)  time: 0.0110  data: 0.0062  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2544 (-3.4050)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [91]  [  0/152]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0082  data: 0.0007  max mem: 0\n",
      "Epoch: [91]  [100/152]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0053)  time: 0.0166  data: 0.0038  max mem: 0\n",
      "Epoch: [91]  [151/152]  eta: 0:00:00  lr: 0.000002  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0134  data: 0.0027  max mem: 0\n",
      "Epoch: [91] Total time: 0:00:02 (0.0139 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5571 (-3.5571)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8466 (-4.3071)  acc1: 100.0000 (100.0000)  time: 0.0056  data: 0.0017  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0057 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3488 (-6.3488)  acc1: 100.0000 (100.0000)  time: 0.0097  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2543 (-3.4048)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0014  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [92]  [  0/152]  eta: 0:00:01  lr: 0.000002  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0090  data: 0.0007  max mem: 0\n",
      "Epoch: [92]  [100/152]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0053)  time: 0.0175  data: 0.0040  max mem: 0\n",
      "Epoch: [92]  [151/152]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0132  data: 0.0028  max mem: 0\n",
      "Epoch: [92] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5569 (-3.5569)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8465 (-4.3070)  acc1: 100.0000 (100.0000)  time: 0.0059  data: 0.0021  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3486 (-6.3486)  acc1: 100.0000 (100.0000)  time: 0.0088  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2542 (-3.4046)  acc1: 100.0000 (88.6364)  time: 0.0037  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0032 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [93]  [  0/152]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0110  data: 0.0009  max mem: 0\n",
      "Epoch: [93]  [100/152]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0053)  time: 0.0175  data: 0.0039  max mem: 0\n",
      "Epoch: [93]  [151/152]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0130  data: 0.0024  max mem: 0\n",
      "Epoch: [93] Total time: 0:00:02 (0.0149 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5568 (-3.5568)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3068)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0017  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0060 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3485 (-6.3485)  acc1: 100.0000 (100.0000)  time: 0.0086  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2542 (-3.4045)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0012  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [94]  [  0/152]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0084  data: 0.0008  max mem: 0\n",
      "Epoch: [94]  [100/152]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0052)  time: 0.0167  data: 0.0037  max mem: 0\n",
      "Epoch: [94]  [151/152]  eta: 0:00:00  lr: 0.000001  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0141  data: 0.0027  max mem: 0\n",
      "Epoch: [94] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5567 (-3.5567)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3068)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0018  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0059 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3484 (-6.3484)  acc1: 100.0000 (100.0000)  time: 0.0081  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2542 (-3.4044)  acc1: 100.0000 (88.6364)  time: 0.0048  data: 0.0019  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0040 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [95]  [  0/152]  eta: 0:00:01  lr: 0.000001  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0119  data: 0.0008  max mem: 0\n",
      "Epoch: [95]  [100/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0052)  time: 0.0170  data: 0.0031  max mem: 0\n",
      "Epoch: [95]  [151/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0131  data: 0.0021  max mem: 0\n",
      "Epoch: [95] Total time: 0:00:02 (0.0142 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5567 (-3.5567)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3067)  acc1: 100.0000 (100.0000)  time: 0.0058  data: 0.0018  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0059 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3483 (-6.3483)  acc1: 100.0000 (100.0000)  time: 0.0080  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2541 (-3.4044)  acc1: 100.0000 (88.6364)  time: 0.0041  data: 0.0015  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0035 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [96]  [  0/152]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0079  data: 0.0008  max mem: 0\n",
      "Epoch: [96]  [100/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0052)  time: 0.0172  data: 0.0041  max mem: 0\n",
      "Epoch: [96]  [151/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0137  data: 0.0029  max mem: 0\n",
      "Epoch: [96] Total time: 0:00:02 (0.0144 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5566 (-3.5566)  acc1: 100.0000 (100.0000)  time: 0.0014  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3067)  acc1: 100.0000 (100.0000)  time: 0.0049  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0050 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3483 (-6.3483)  acc1: 100.0000 (100.0000)  time: 0.0083  data: 0.0035  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2541 (-3.4043)  acc1: 100.0000 (88.6364)  time: 0.0034  data: 0.0009  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0031 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [97]  [  0/152]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0082  data: 0.0007  max mem: 0\n",
      "Epoch: [97]  [100/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0052)  time: 0.0161  data: 0.0033  max mem: 0\n",
      "Epoch: [97]  [151/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0141  data: 0.0035  max mem: 0\n",
      "Epoch: [97] Total time: 0:00:02 (0.0140 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5566 (-3.5566)  acc1: 100.0000 (100.0000)  time: 0.0068  data: 0.0041  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3066)  acc1: 100.0000 (100.0000)  time: 0.0064  data: 0.0020  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0066 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3483 (-6.3483)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2541 (-3.4043)  acc1: 100.0000 (88.6364)  time: 0.0044  data: 0.0017  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0037 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [98]  [  0/152]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0082  data: 0.0008  max mem: 0\n",
      "Epoch: [98]  [100/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0052)  time: 0.0182  data: 0.0035  max mem: 0\n",
      "Epoch: [98]  [151/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0146  data: 0.0027  max mem: 0\n",
      "Epoch: [98] Total time: 0:00:02 (0.0153 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5566 (-3.5566)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3066)  acc1: 100.0000 (100.0000)  time: 0.0064  data: 0.0023  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3483 (-6.3483)  acc1: 100.0000 (100.0000)  time: 0.0087  data: 0.0039  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2541 (-3.4043)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0013  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Epoch: [99]  [  0/152]  eta: 0:00:01  lr: 0.000000  sub_loss: 0.0065 (0.0065)  diff_loss: 0.0002 (0.0002)  slide_loss: 0.0088 (0.0088)  time: 0.0112  data: 0.0008  max mem: 0\n",
      "Epoch: [99]  [100/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0019 (0.0063)  diff_loss: 0.0001 (0.0079)  slide_loss: 0.0014 (0.0052)  time: 0.0174  data: 0.0043  max mem: 0\n",
      "Epoch: [99]  [151/152]  eta: 0:00:00  lr: 0.000000  sub_loss: 0.0024 (0.0061)  diff_loss: 0.0000 (0.0066)  slide_loss: 0.0017 (0.0053)  time: 0.0136  data: 0.0027  max mem: 0\n",
      "Epoch: [99] Total time: 0:00:02 (0.0143 s / it)\n",
      "Val  [0/7]  eta: 0:00:00  loss: 0.0042 (0.0042)  div_loss: -3.5566 (-3.5566)  acc1: 100.0000 (100.0000)  time: 0.0015  data: 0.0004  max mem: 0\n",
      "Val  [6/7]  eta: 0:00:00  loss: 0.0015 (0.0025)  div_loss: -3.8464 (-4.3066)  acc1: 100.0000 (100.0000)  time: 0.0057  data: 0.0015  max mem: 0\n",
      "Val Total time: 0:00:00 (0.0058 s / it)\n",
      "* Acc@1 100.000 loss 0.002 auroc 0.000 f1_score 1.000\n",
      "Test  [ 0/44]  eta: 0:00:00  loss: 0.0005 (0.0005)  div_loss: -6.3483 (-6.3483)  acc1: 100.0000 (100.0000)  time: 0.0084  data: 0.0036  max mem: 0\n",
      "Test  [43/44]  eta: 0:00:00  loss: 0.0047 (0.0079)  div_loss: -3.2541 (-3.4043)  acc1: 100.0000 (88.6364)  time: 0.0039  data: 0.0011  max mem: 0\n",
      "Test Total time: 0:00:00 (0.0033 s / it)\n",
      "* Acc@1 88.636 loss 0.008 auroc 0.805 f1_score 0.886\n",
      "\n",
      "\n",
      "Results on best epoch:\n",
      "{'epoch': 0, 'val_acc': 100.0, 'val_auc': 0.0, 'val_f1': 1.0, 'test_acc': 88.63636363636364, 'test_auc': 0.7230769395828247, 'test_f1': 0.8863636255264282}\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = outdir1 + SELECTED_LABEL[0] + \"/\"\n",
    "create_dir_if_not_exists(ckpt_dir)\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "\n",
    "\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "train_epoch = conf.train_epoch\n",
    "for epoch in range(train_epoch):\n",
    "    train_one_epoch(model, criterion, train_loader, optimizer0, device, epoch, conf, selected_label_index)\n",
    "\n",
    "\n",
    "    val_auc, val_acc, val_f1, val_loss = evaluate(model, criterion, val_loader, device, conf, 'Val', selected_label_index)\n",
    "    test_auc, test_acc, test_f1, test_loss = evaluate(model, criterion, test_loader, device, conf, 'Test', selected_label_index)\n",
    "\n",
    "    if conf.wandb_mode != 'disabled':\n",
    "        wandb.log({'perf/val_acc1': val_acc}, commit=False)\n",
    "        wandb.log({'perf/val_auc': val_auc}, commit=False)\n",
    "        wandb.log({'perf/val_f1': val_f1}, commit=False)\n",
    "        wandb.log({'perf/val_loss': val_loss}, commit=False)\n",
    "        wandb.log({'perf/test_acc1': test_acc}, commit=False)\n",
    "        wandb.log({'perf/test_auc': test_auc}, commit=False)\n",
    "        wandb.log({'perf/test_f1': test_f1}, commit=False)\n",
    "        wandb.log({'perf/test_loss': test_loss}, commit=False)\n",
    "\n",
    "\n",
    "    if val_f1 + val_auc > best_state['val_f1'] + best_state['val_auc']:\n",
    "        best_state['epoch'] = epoch\n",
    "        best_state['val_auc'] = val_auc\n",
    "        best_state['val_acc'] = val_acc\n",
    "        best_state['val_f1'] = val_f1\n",
    "        best_state['test_auc'] = test_auc\n",
    "        best_state['test_acc'] = test_acc\n",
    "        best_state['test_f1'] = test_f1\n",
    "        save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "            save_path=os.path.join(ckpt_dir, 'checkpoint-best.pth'))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "    save_path=os.path.join(ckpt_dir, 'checkpoint-last.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d86b7f05-3c5c-4682-83f0-00c2a2df921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [ 0/44]  eta: 0:00:00    time: 0.0090  data: 0.0042  max mem: 0\n",
      "  [43/44]  eta: 0:00:00    time: 0.0041  data: 0.0017  max mem: 0\n",
      " Total time: 0:00:00 (0.0033 s / it)\n",
      "0.8051282167434692\n",
      "0.8863636255264282\n"
     ]
    }
   ],
   "source": [
    "# Set the network to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "y_predprob = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "for data in metric_logger.log_every(test_loader, 100, None):\n",
    "    image_patches = data[0].to(device, dtype=torch.float32)\n",
    "    labels = data[1][0,:,selected_label_index].to(device, dtype = torch.int64).to(device)\n",
    "\n",
    "    sub_preds, slide_preds, attn = model(image_patches)\n",
    "    pred = torch.softmax(slide_preds, dim=-1)\n",
    "    pred_prob = torch.softmax(slide_preds, dim=-1)[:,1]\n",
    "\n",
    "    y_predprob.append(pred_prob)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(labels)\n",
    "    \n",
    "y_predprob = torch.cat(y_predprob, dim=0)\n",
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "y_true = torch.cat(y_true, dim=0)\n",
    "\n",
    "AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "AUROC_metric(y_pred, y_true)\n",
    "auroc = AUROC_metric.compute().item()\n",
    "F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "F1_metric(y_pred, y_true)\n",
    "f1_score = F1_metric.compute().item()\n",
    "print(auroc)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd4a25a-9da6-4be5-b0ca-8c54a04c3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//predictions/AR/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//perf/AR/' already exists.\n",
      "               AUC   ACC    F1    F2    F3  Recall  Precision  Specificity  \\\n",
      "SAMPLE_LEVEL  0.81  0.77  0.29  0.34  0.37     0.4       0.22         0.82   \n",
      "\n",
      "               PR_AUC OUTCOME  \n",
      "SAMPLE_LEVEL  0.45881      AR  \n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#Predict\n",
    "####################################################################################\n",
    "\n",
    "#predicts\n",
    "test_pred_prob  = y_predprob\n",
    "test_true_label = y_true\n",
    "\n",
    "#Prediction df\n",
    "pred_df = pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                        \"Y_True\": y_true.cpu().detach().numpy(), \n",
    "                        \"Pred_Prob\" :  test_pred_prob.cpu().detach().numpy(),\n",
    "                        \"OUTCOME\": SELECTED_LABEL[0]})\n",
    "\n",
    "#Add Predict class\n",
    "save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "THRES = round(pred_df['Pred_Prob'].quantile(0.8),2)\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(save_location + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "# #Compute performance\n",
    "save_location = outdir5 + SELECTED_LABEL[0] + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "perf_df = compute_performance_each_label(SELECTED_LABEL, pred_df, \"SAMPLE_LEVEL\")\n",
    "print(perf_df)\n",
    "perf_df.to_csv(save_location + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7ae512d-7261-4625-89f8-af42b950c227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [  0/596]  eta: 0:00:01    time: 0.0032  data: 0.0016  max mem: 0\n",
      "  [100/596]  eta: 0:00:00    time: 0.0012  data: 0.0005  max mem: 0\n",
      "  [200/596]  eta: 0:00:00    time: 0.0008  data: 0.0002  max mem: 0\n",
      "  [300/596]  eta: 0:00:00    time: 0.0008  data: 0.0002  max mem: 0\n",
      "  [400/596]  eta: 0:00:00    time: 0.0008  data: 0.0002  max mem: 0\n",
      "  [500/596]  eta: 0:00:00    time: 0.0011  data: 0.0004  max mem: 0\n",
      "  [595/596]  eta: 0:00:00    time: 0.0012  data: 0.0005  max mem: 0\n",
      " Total time: 0:00:00 (0.0010 s / it)\n",
      "0.48109889030456543\n",
      "0.43288591504096985\n"
     ]
    }
   ],
   "source": [
    "#TMA\n",
    "# Set the network to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "y_predprob = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "for data in metric_logger.log_every(tma_loader, 100, None):\n",
    "    image_patches = data[0].to(device, dtype=torch.float32)\n",
    "    labels = data[1][0,:,selected_label_index].to(device, dtype = torch.int64).to(device)\n",
    "\n",
    "    sub_preds, slide_preds, attn = model(image_patches)\n",
    "    pred = torch.softmax(slide_preds, dim=-1)\n",
    "    pred_prob = torch.softmax(slide_preds, dim=-1)[:,1]\n",
    "\n",
    "    y_predprob.append(pred_prob)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(labels)\n",
    "    \n",
    "y_predprob = torch.cat(y_predprob, dim=0)\n",
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "y_true = torch.cat(y_true, dim=0)\n",
    "\n",
    "AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "AUROC_metric(y_pred, y_true)\n",
    "auroc = AUROC_metric.compute().item()\n",
    "F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "F1_metric(y_pred, y_true)\n",
    "f1_score = F1_metric.compute().item()\n",
    "print(auroc)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f15757a8-e9af-4bcb-9c21-a5cf56d94095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//predictions/AR/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02062025/retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TRAINTEST_TFT0.9_TMA_TFT0.0/split_fold0//DL_emb_only/ST//perf/AR/' already exists.\n",
      "               AUC   ACC    F1    F2    F3  Recall  Precision  Specificity  \\\n",
      "SAMPLE_LEVEL  0.48  0.41  0.23  0.18  0.17    0.16       0.43         0.74   \n",
      "\n",
      "                PR_AUC OUTCOME  \n",
      "SAMPLE_LEVEL  0.535545      AR  \n"
     ]
    }
   ],
   "source": [
    "#TMA predict\n",
    "test_pred_prob  = y_predprob\n",
    "test_true_label = y_true\n",
    "\n",
    "#Prediction df\n",
    "pred_df = pd.DataFrame({\"SAMPLE_IDs\":  tma_ids, \n",
    "                        \"Y_True\": test_true_label.cpu().detach().numpy(), \n",
    "                        \"Pred_Prob\" :  test_pred_prob.cpu().detach().numpy(),\n",
    "                        \"OUTCOME\": SELECTED_LABEL[0]})\n",
    "\n",
    "#Add Predict class\n",
    "save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "THRES = round(pred_df['Pred_Prob'].quantile(0.8),2)\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(save_location + \"/n_token\" + str(conf.n_token) + \"_TMA_pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "# #Compute performance\n",
    "save_location = outdir5 + SELECTED_LABEL[0] + \"/\"\n",
    "create_dir_if_not_exists(save_location)\n",
    "\n",
    "perf_df = compute_performance_each_label(SELECTED_LABEL, pred_df, \"SAMPLE_LEVEL\")\n",
    "print(perf_df)\n",
    "perf_df.to_csv(save_location + \"/n_token\" + str(conf.n_token) + \"_TMA_perf.csv\",index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
