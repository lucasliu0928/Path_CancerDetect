{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo, get_performance\n",
    "from train_utils import pull_tiles, FocalLoss\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from Model import Mutation_MIL_MT_sepAtt #, Mutation_MIL_MT\n",
    "from ACMIL import ACMIL_GA_MultiTask, predict, train_one_epoch_multitask, evaluate_multitask\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fe6b4f-a374-4a86-8276-e5a1bced8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch: 100\n",
      "warmup_epoch: 0\n",
      "wd: 1e-05\n",
      "lr: 0.0001\n",
      "min_lr: 0\n",
      "dataset: bracs\n",
      "B: 1\n",
      "n_class: 1\n",
      "n_worker: 8\n",
      "pin_memory: False\n",
      "n_shot: -1\n",
      "D_feat: 1536\n",
      "D_inner: 128\n",
      "n_token: 3\n",
      "wandb_mode: disabled\n",
      "n_task: 1\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "ALL_LABELS = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "TUMOR_FRAC_THRES = 0.9 \n",
    "feature_extraction_method = 'uni2' #retccl, uni1\n",
    "learning_method = \"transmil\"\n",
    "focal_gamma = 20\n",
    "focal_alpha = 0.95\n",
    "loss_method = 'Focal' #ATTLOSS\n",
    "\n",
    "################################\n",
    "#model Para\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "SELECTED_FOLD = 0\n",
    "\n",
    "if feature_extraction_method == 'retccl':\n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,2048)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 2048\n",
    "elif feature_extraction_method == 'uni1': \n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,1024)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 1024\n",
    "elif feature_extraction_method == 'uni2':\n",
    "    SELECTED_FEATURE = [str(i) for i in range(0,1536)] + ['TUMOR_PIXEL_PERC'] #If retccl 2048, if uni 1024\n",
    "    N_FEATURE = 1536\n",
    "    \n",
    "################################\n",
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "\n",
    "conf.train_epoch = 100\n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "conf.n_token = 3\n",
    "conf.n_class = 1\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.n_task = 1\n",
    "#conf.lr = 0.000001 #change this for HR only\n",
    "\n",
    "# Print all key-value pairs in the conf object\n",
    "for key, value in conf.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name_overlap = \"IMSIZE250_OL100\"\n",
    "folder_name_nonoverlap = \"IMSIZE250_OL0\"\n",
    "feature_path_opx_train =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_overlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_opx_test =  os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"OPX\", folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_tma = os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"TAN_TMA_Cores\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "feature_path_tcga = os.path.join(proj_dir + 'intermediate_data/5_model_ready_data', \"TCGA_PRAD\",folder_name_nonoverlap, 'feature_' + feature_extraction_method, 'TFT' + str(TUMOR_FRAC_THRES))\n",
    "\n",
    "folder_name_ids = 'uni1/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "train_val_test_id_path =  os.path.join(proj_dir + 'intermediate_data/6_Train_TEST_IDS', folder_name_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02282025_transmil/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02282025_transmil/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02282025_transmil/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02282025_transmil/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02282025_transmil/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out02282025_transmil/uni2/TrainOL100_TestOL0_TFT0.9/FOLD0/MT//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#Create output-dir\n",
    "################################################\n",
    "folder_name1 = feature_extraction_method + '/TrainOL100_TestOL0_TFT' + str(TUMOR_FRAC_THRES)  + \"/\"\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out02282025_transmil\" + \"/\" + folder_name1 + 'FOLD' + str(SELECTED_FOLD) + '/' + SELECTED_MUTATION + \"/\" \n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "opx_data_ol100 = torch.load(feature_path_opx_train + '/OPX_data.pth')\n",
    "opx_ids_ol100 = torch.load(feature_path_opx_train + '/OPX_ids.pth')\n",
    "opx_info_ol100  = torch.load(feature_path_opx_train + '/OPX_info.pth')\n",
    "\n",
    "opx_data_ol0 = torch.load(feature_path_opx_test + '/OPX_data.pth')\n",
    "opx_ids_ol0 = torch.load(feature_path_opx_test + '/OPX_ids.pth')\n",
    "opx_info_ol0  = torch.load(feature_path_opx_test + '/OPX_info.pth')\n",
    "\n",
    "tma_data = torch.load(feature_path_tma + '/tma_data.pth')\n",
    "tma_ids = torch.load(feature_path_tma + '/tma_ids.pth')\n",
    "tma_info  = torch.load(feature_path_tma + '/tma_info.pth')\n",
    "\n",
    "\n",
    "tcga_data = torch.load(feature_path_tcga + '/TCGA_data.pth')\n",
    "tcga_ids = torch.load(feature_path_tcga + '/TCGA_ids.pth')\n",
    "tcga_info  = torch.load(feature_path_tcga + '/TCGA_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba1f8a8-cf34-43b9-80f8-94339c4c5b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################\n",
    "#Update tma\n",
    "########################################################\n",
    "haslabel_indexes = []\n",
    "for i in range(len(tma_data)):\n",
    "    if torch.isnan(tma_data[i][1]).all() == False:\n",
    "        #print(f\"Item {i} has the second element all NaNs.\")\n",
    "        haslabel_indexes.append(i)\n",
    "\n",
    "\n",
    "tma_data = Subset(tma_data, haslabel_indexes)\n",
    "tma_ids = list(Subset(tma_ids, haslabel_indexes))\n",
    "tma_info = list(Subset(tma_info, haslabel_indexes))\n",
    "len(tma_info) #355 if TF0.9, a lot of cores does not have enough cancer tiles > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d4a40cb-f7ca-4128-9fee-7d8f045af85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get train, test IDs\n",
    "#NOTE: this was in the old train: ['OPX_207','OPX_209','OPX_213','OPX_214','OPX_215']\n",
    "################################################\n",
    "train_test_val_id_df = pd.read_csv(train_val_test_id_path + \"train_test_split.csv\")\n",
    "train_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TRAIN', 'SAMPLE_ID'])\n",
    "test_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'TEST', 'SAMPLE_ID'])\n",
    "val_ids_all = list(train_test_val_id_df.loc[train_test_val_id_df['FOLD' + str(SELECTED_FOLD)] == 'VALID', 'SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6998013-f398-4d47-a884-3751784365a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Get Train, test, val data\n",
    "################################################\n",
    "#Train:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in train_ids_all]\n",
    "train_data = Subset(opx_data_ol100, inc_idx)\n",
    "train_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "train_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "\n",
    "#Val:\n",
    "inc_idx = [opx_ids_ol100.index(x) for x in val_ids_all]\n",
    "val_data = Subset(opx_data_ol100, inc_idx)\n",
    "val_ids =  list(Subset(opx_ids_ol100, inc_idx))\n",
    "val_info = list(Subset(opx_info_ol100, inc_idx))\n",
    "\n",
    "#Test:\n",
    "inc_idx = [opx_ids_ol0.index(x) for x in test_ids_all]\n",
    "test_data = Subset(opx_data_ol0, inc_idx)\n",
    "test_ids =  list(Subset(opx_ids_ol0, inc_idx))\n",
    "test_info = list(Subset(opx_info_ol0, inc_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 25, 32, 18, 55, 10,  9])\n",
      "['10.0', '16.7', '21.3', '12.0', '36.7', '6.7', '6.0']\n",
      "tensor([ 5,  7,  8,  4, 18,  7,  7])\n",
      "['11.1', '15.6', '17.8', '8.9', '40.0', '15.6', '15.6']\n",
      "tensor([216,   0, 119, 107, 178,   0,   0])\n",
      "['60.8', '0.0', '33.5', '30.1', '50.1', '0.0', '0.0']\n",
      "tensor([ 2, 34, 13,  3, 53,  0,  4])\n",
      "['0.4', '7.6', '2.9', '0.7', '11.9', '0.0', '0.9']\n"
     ]
    }
   ],
   "source": [
    "#count labels in train\n",
    "train_label_counts = [dt[1] for dt in train_data]\n",
    "train_label_counts = torch.concat(train_label_counts)\n",
    "count_ones = (train_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/train_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)\n",
    "\n",
    "#count labels in test\n",
    "test_label_counts = [dt[1] for dt in test_data]\n",
    "test_label_counts = torch.concat(test_label_counts)\n",
    "count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)\n",
    "\n",
    "#count labels in tma\n",
    "tma_label_counts = [dt[1] for dt in tma_data] \n",
    "tma_label_counts = torch.concat(tma_label_counts)\n",
    "count_ones = (tma_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/tma_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\"\n",
    "\n",
    "\n",
    "#count labels in tcga\n",
    "tcga_label_counts = [dt[1] for dt in tcga_data] \n",
    "tcga_label_counts = torch.concat(tcga_label_counts)\n",
    "count_ones = (tcga_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/tcga_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers) #[\"AR\",\"PTEN\",\"RB1\",\"TP53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "366126c0-daa8-4bbb-a487-b51a2e07d2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "8\n",
      "45\n",
      "355\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "print(len(tma_data))\n",
    "print(len(tcga_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "tma_loader = DataLoader(dataset=tma_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "tcga_loader = DataLoader(dataset=tcga_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5feec6-e1a3-417c-943f-aa7e78e8bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, reduce\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def moore_penrose_iter_pinv(x, iters = 6):\n",
    "    device = x.device\n",
    "\n",
    "    abs_x = torch.abs(x)\n",
    "    col = abs_x.sum(dim = -1)\n",
    "    row = abs_x.sum(dim = -2)\n",
    "    z = rearrange(x, '... i j -> ... j i') / (torch.max(col) * torch.max(row))\n",
    "\n",
    "    I = torch.eye(x.shape[-1], device = device)\n",
    "    I = rearrange(I, 'i j -> () i j')\n",
    "\n",
    "    for _ in range(iters):\n",
    "        xz = x @ z\n",
    "        z = 0.25 * z @ (13 * I - (xz @ (15 * I - (xz @ (7 * I - xz)))))\n",
    "\n",
    "    return z\n",
    "    \n",
    "class NystromAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        num_landmarks = 256,\n",
    "        pinv_iterations = 6,\n",
    "        residual = True,\n",
    "        residual_conv_kernel = 33,\n",
    "        eps = 1e-8,\n",
    "        dropout = 0.,\n",
    "        n_token = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        inner_dim = heads * dim_head\n",
    "        self.n_token = n_token\n",
    "\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.pinv_iterations = pinv_iterations\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.residual = residual\n",
    "        if residual:\n",
    "            kernel_size = residual_conv_kernel\n",
    "            padding = residual_conv_kernel // 2\n",
    "            self.res_conv = nn.Conv2d(heads, heads, (kernel_size, 1), padding = (padding, 0), groups = heads, bias = False)\n",
    "\n",
    "    def forward(self, x, mask = None, return_attn = False):\n",
    "        b, n, _, h, m, iters, eps = *x.shape, self.heads, self.num_landmarks, self.pinv_iterations, self.eps\n",
    "\n",
    "        # pad so that sequence can be evenly divided into m landmarks\n",
    "\n",
    "        remainder = n % m\n",
    "        if remainder > 0:\n",
    "            padding = m - (n % m)\n",
    "            x = F.pad(x, (0, 0, padding, 0), value = 0)\n",
    "\n",
    "            if exists(mask):\n",
    "                mask = F.pad(mask, (padding, 0), value = False)\n",
    "\n",
    "        # derive query, keys, values\n",
    "\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        # set masked positions to 0 in queries, keys, values\n",
    "\n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, 'b n -> b () n')\n",
    "            q, k, v = map(lambda t: t * mask[..., None], (q, k, v))\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # generate landmarks by sum reduction, and then calculate mean using the mask\n",
    "\n",
    "        l = ceil(n / m)\n",
    "        landmark_einops_eq = '... (n l) d -> ... n d'\n",
    "        q_landmarks = reduce(q, landmark_einops_eq, 'sum', l = l)\n",
    "        k_landmarks = reduce(k, landmark_einops_eq, 'sum', l = l)\n",
    "\n",
    "        # calculate landmark mask, and also get sum of non-masked elements in preparation for masked mean\n",
    "\n",
    "        divisor = l\n",
    "        if exists(mask):\n",
    "            mask_landmarks_sum = reduce(mask, '... (n l) -> ... n', 'sum', l = l)\n",
    "            divisor = mask_landmarks_sum[..., None] + eps\n",
    "            mask_landmarks = mask_landmarks_sum > 0\n",
    "\n",
    "        # masked mean (if mask exists)\n",
    "\n",
    "        q_landmarks /= divisor\n",
    "        k_landmarks /= divisor\n",
    "\n",
    "        # similarities\n",
    "\n",
    "        einops_eq = '... i d, ... j d -> ... i j'\n",
    "        attn1 = einsum(einops_eq, q, k_landmarks)\n",
    "        attn2 = einsum(einops_eq, q_landmarks, k_landmarks)\n",
    "        attn3 = einsum(einops_eq, q_landmarks, k)\n",
    "\n",
    "        # masking\n",
    "\n",
    "        if exists(mask):\n",
    "            mask_value = -torch.finfo(q.dtype).max\n",
    "            sim1.masked_fill_(~(mask[..., None] * mask_landmarks[..., None, :]), mask_value)\n",
    "            sim2.masked_fill_(~(mask_landmarks[..., None] * mask_landmarks[..., None, :]), mask_value)\n",
    "            sim3.masked_fill_(~(mask_landmarks[..., None] * mask[..., None, :]), mask_value)\n",
    "\n",
    "        # eq (15) in the paper and aggregate values\n",
    "\n",
    "        attn1, attn2, attn3 = map(lambda t: t.softmax(dim = -1), (attn1, attn2, attn3))\n",
    "        attn2 = moore_penrose_iter_pinv(attn2, iters)\n",
    "        out = (attn1 @ attn2) @ (attn3 @ v)\n",
    "\n",
    "        # add depth-wise conv residual of values\n",
    "        if self.residual:\n",
    "            out += self.res_conv(v)\n",
    "\n",
    "        # merge and combine heads\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
    "        out = self.to_out(out)\n",
    "        out = out[:, -n:]\n",
    "        if return_attn:\n",
    "            attn1 = attn1[:,:,:self.n_token] @ attn2\n",
    "            attn1 = (attn1 @ attn3)\n",
    "        \n",
    "            return out, attn1.mean(1)\n",
    "\n",
    "        return out\n",
    "        \n",
    "class TransLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, norm_layer=nn.LayerNorm, dim=512):\n",
    "        super().__init__()\n",
    "        self.norm = norm_layer(dim)\n",
    "        self.attn = NystromAttention(\n",
    "            dim=dim,\n",
    "            dim_head=dim // 8,\n",
    "            heads=8,\n",
    "            num_landmarks=dim // 2,  # number of landmarks\n",
    "            pinv_iterations=6,\n",
    "            # number of moore-penrose iterations for approximating pinverse. 6 was recommended by the paper\n",
    "            residual=True,\n",
    "            # whether to do an extra residual with the value or not. supposedly faster convergence if turned on\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm(x))\n",
    "\n",
    "        return x\n",
    "        \n",
    "class PPEG(nn.Module):\n",
    "    def __init__(self, dim=512):\n",
    "        super(PPEG, self).__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim, 7, 1, 7 // 2, groups=dim)\n",
    "        self.proj1 = nn.Conv2d(dim, dim, 5, 1, 5 // 2, groups=dim)\n",
    "        self.proj2 = nn.Conv2d(dim, dim, 3, 1, 3 // 2, groups=dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, _, C = x.shape\n",
    "        cls_token, feat_token = x[:, 0], x[:, 1:]\n",
    "        cnn_feat = feat_token.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.proj(cnn_feat) + cnn_feat + self.proj1(cnn_feat) + self.proj2(cnn_feat)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = torch.cat((cls_token.unsqueeze(1), x), dim=1)\n",
    "        return x\n",
    "        \n",
    "class TransMIL(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(TransMIL, self).__init__()\n",
    "        self.pos_layer = PPEG(dim=conf.D_inner)\n",
    "        self._fc1 = nn.Sequential(nn.Linear(conf.D_feat, conf.D_inner), nn.ReLU())\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, conf.D_inner))\n",
    "        self.n_classes = conf.n_class\n",
    "        self.layer1 = TransLayer(dim=conf.D_inner)\n",
    "        self.layer2 = TransLayer(dim=conf.D_inner)\n",
    "        self.norm = nn.LayerNorm(conf.D_inner)\n",
    "        self._fc2 = nn.Linear(conf.D_inner, conf.n_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "        h = self._fc1(input)  # [B, n, 512]\n",
    "\n",
    "        # ---->pad\n",
    "        H = h.shape[1]\n",
    "        _H, _W = int(np.ceil(np.sqrt(H))), int(np.ceil(np.sqrt(H)))\n",
    "        add_length = _H * _W - H\n",
    "        h = torch.cat([h, h[:, :add_length, :]], dim=1)  # [B, N, 512]\n",
    "\n",
    "        # ---->cls_token\n",
    "        B = h.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1).cuda()\n",
    "        h = torch.cat((cls_tokens, h), dim=1)\n",
    "\n",
    "        # ---->Translayer x1\n",
    "        h = self.layer1(h)  # [B, N, 512]\n",
    "\n",
    "        # ---->PPEG\n",
    "        h = self.pos_layer(h, _H, _W)  # [B, N, 512]\n",
    "\n",
    "        # ---->Translayer x2\n",
    "        h = self.layer2(h)  # [B, N, 512]\n",
    "\n",
    "        # ---->cls_token\n",
    "        h = self.norm(h)[:, 0]\n",
    "\n",
    "        # ---->predict\n",
    "        logits = self._fc2(h)  # [B, n_classes]\n",
    "        # Y_hat = torch.argmax(logits, dim=1)\n",
    "        # Y_prob = F.softmax(logits, dim=1)\n",
    "        # results_dict = {'logits': logits, 'Y_prob': Y_prob, 'Y_hat': Y_hat}\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287cee9a-95b9-4a80-b9c4-1c02a3060f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.arch = 'transmil'\n",
    "conf.w_loss = 0.8\n",
    "model = TransMIL(conf)\n",
    "model.to(device)\n",
    "\n",
    "            \n",
    "# Example usage:\n",
    "criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905974d-e12d-4d4b-975d-d82626c663c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import MetricLogger, SmoothedValue, adjust_learning_rate\n",
    "def loss_forward_and_backward(net, image_patches, labels, criterion, conf,\n",
    "                              device, optimizer, metric_logger, log_writer=None):\n",
    "    # Compute loss\n",
    "    preds = net(image_patches)\n",
    "    ce_loss = criterion(preds, labels)\n",
    "\n",
    "    diff_loss = torch.tensor(0).to(device, dtype=torch.float)\n",
    "\n",
    "    loss = conf.w_loss * diff_loss + ce_loss\n",
    "    print(ce_loss)\n",
    "\n",
    "    # Backpropagate error and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    metric_logger.update(lr=optimizer.param_groups[0]['lr'])\n",
    "    metric_logger.update(ce_loss=ce_loss.item())\n",
    "    metric_logger.update(diff_loss=diff_loss.item())\n",
    "\n",
    "        \n",
    "def train_one_epoch(net, labelindex, criterion, data_loader, optimizer, device, epoch, conf, log_writer=None):\n",
    "    \"\"\"\n",
    "    Trains the given network for one epoch according to given criterions (loss functions)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the network to training mode\n",
    "    net.train()\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 100\n",
    "\n",
    "    for data_it, data in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "        # for data_it, data in enumerate(data_loader, start=epoch * len(data_loader)):\n",
    "        # Move input batch onto GPU if eager execution is enabled (default), else leave it on CPU\n",
    "        # Data is a dict with keys `input` (patches) and `{task_name}` (labels for given task)\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0][:,labelindex].unsqueeze(0).to(device)\n",
    "        # # Calculate and set new learning rate\n",
    "        adjust_learning_rate(optimizer, epoch + data_it / len(data_loader), conf)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if conf.arch == 'dsmil':\n",
    "            loss_forward_and_backward_dsmil(net, image_patches, labels, criterion, conf,\n",
    "                                            device, optimizer, metric_logger, log_writer)\n",
    "        elif conf.arch in ('clam_sb', 'clam_mb'):\n",
    "            loss_forward_and_backward_clam(net, image_patches, labels, criterion, conf,\n",
    "                                            device, optimizer, metric_logger, log_writer)\n",
    "        elif conf.arch == 'bmil_spvis':\n",
    "            loss_forward_and_backward_bmil(net, image_patches, coords, labels, criterion, conf,\n",
    "                                           device, optimizer, metric_logger, log_writer)\n",
    "        else:\n",
    "            loss_forward_and_backward(net, image_patches, labels, criterion, conf,\n",
    "                                      device, optimizer, metric_logger, log_writer)\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12329219-f221-4abd-9800-7c093ada02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = outdir1 + SELECTED_MUTATION + \"/\"\n",
    "create_dir_if_not_exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)\n",
    "\n",
    "\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "train_epoch = conf.train_epoch\n",
    "labelindex = 0\n",
    "for epoch in range(train_epoch):\n",
    "    train_one_epoch(model, labelindex, criterion, train_loader, optimizer0, device, epoch, conf, loss_method)\n",
    "\n",
    "\n",
    "    # val_auc, val_acc, val_f1, val_loss = evaluate_multitask(model, criterion, val_loader, device, conf, 'Val')\n",
    "    # test_auc, test_acc, test_f1, test_loss = evaluate_multitask(model, criterion, test_loader, device, conf, 'Test')\n",
    "    #tma_auc, tma_acc, tma_f1, tma_loss = evaluate_multitask(model, criterion, tma_loader, device, conf, 'TMA')\n",
    "\n",
    "    save_model(conf=conf, model=model, optimizer=optimizer0, epoch=epoch,\n",
    "        save_path=os.path.join(ckpt_dir + 'checkpoint_' + 'epoch' + str(epoch) + '.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a8447-78d1-40e8-a997-847b0ba91e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_multitask(net, criterion, data_loader, device, conf, header):        \n",
    "    # Set the network to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_pred_prob = []\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "    for data in metric_logger.log_every(data_loader, 100, header):\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0][:,labelindex].to(device, dtype = torch.int64).squeeze()\n",
    "        slide_preds = net(image_patches)\n",
    "        pred_prob = torch.sigmoid(slide_preds).squeeze()\n",
    "        pred = pred_prob.round().squeeze()\n",
    "        acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "        \n",
    "        y_pred.append(pred.detach().cpu())\n",
    "        y_true.append(labels.detach().cpu())\n",
    "        y_pred_prob.append(pred_prob.detach().cpu())\n",
    "        \n",
    "        #Compute loss for each task, then sum\n",
    "        loss = 0\n",
    "        div_loss = 0\n",
    "        pred_list = []\n",
    "        acc1_list = []\n",
    "        for k in range(conf.n_task):\n",
    "            sub_preds = sub_preds_list[k]\n",
    "            slide_preds = slide_preds_list[k]\n",
    "            attn = attn_list[k]\n",
    "            labels = label_lists[:,k].to(device, dtype = torch.float32).to(device)\n",
    "            \n",
    "            div_loss += torch.sum(F.softmax(attn, dim=-1) * F.log_softmax(attn, dim=-1)) / attn.shape[1]\n",
    "            loss += criterion(slide_preds, labels.unsqueeze(1))\n",
    "            pred = torch.sigmoid(slide_preds)\n",
    "            acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "\n",
    "            pred_list.append(pred)\n",
    "            acc1_list.append(acc1)\n",
    "            \n",
    "        avg_acc = sum(acc1_list)/conf.n_task\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.update(div_loss=div_loss.item())\n",
    "        metric_logger.meters['acc1'].update(avg_acc.item(), n=labels.shape[0])\n",
    "\n",
    "        y_pred.append(pred_list)\n",
    "        y_true.append(label_lists)\n",
    "\n",
    "    #Get prediction for each task\n",
    "    y_pred_tasks = []\n",
    "    y_true_tasks = []\n",
    "    for k in range(conf.n_task):\n",
    "        y_pred_tasks.append([p[k] for p in y_pred])\n",
    "        y_true_tasks.append([t[:,k].to(device, dtype = torch.int64) for t in y_true])\n",
    "    \n",
    "    #get performance for each calss\n",
    "    auroc_each = 0\n",
    "    f1_score_each = 0\n",
    "    for k in range(conf.n_task):\n",
    "        y_pred_each = torch.cat(y_pred_tasks[k], dim=0)\n",
    "        y_true_each = torch.cat(y_true_tasks[k], dim=0)\n",
    "    \n",
    "        AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='binary').to(device)\n",
    "        AUROC_metric(y_pred_each, y_true_each)\n",
    "        auroc_each += AUROC_metric.compute().item()\n",
    "    \n",
    "        F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='binary').to(device)\n",
    "        F1_metric(y_pred_each, y_true_each.unsqueeze(1))\n",
    "        f1_score_each += F1_metric.compute().item()\n",
    "        print(\"AUROC\",str(k),\":\",AUROC_metric.compute().item())\n",
    "    auroc = auroc_each/conf.n_task\n",
    "    f1_score = f1_score_each/conf.n_task\n",
    "\n",
    "    print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f} auroc {AUROC:.3f} f1_score {F1:.3f}'\n",
    "          .format(top1=metric_logger.acc1, losses=metric_logger.loss, AUROC=auroc, F1=f1_score))\n",
    "\n",
    "    return auroc, metric_logger.acc1.global_avg, f1_score, metric_logger.loss.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d528e-df0b-4a19-b3d5-daa96f0b508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_onelabel(net, labelindex, data_loader, device, conf, header):    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_pred_prob = []\n",
    "    net.eval()\n",
    "    for data in test_loader:\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0][:,labelindex].to(device, dtype = torch.int64).squeeze()\n",
    "        slide_preds = net(image_patches) \n",
    "        pred_prob = torch.sigmoid(slide_preds).squeeze()\n",
    "        pred = pred_prob.round().squeeze()\n",
    "        \n",
    "        y_pred.append(pred.detach().cpu())\n",
    "        y_true.append(labels.detach().cpu())\n",
    "        y_pred_prob.append(pred_prob.detach().cpu())\n",
    "    return y_pred, y_pred_prob, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0231244-dff1-4b96-afc8-7ed52ef18d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07377042-2f38-4f48-9c86-b37329f2e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the checkpoint\n",
    "# #checkpoint = torch.load(ckpt_dir + 'checkpoint-best.pth')\n",
    "# checkpoint = torch.load(ckpt_dir + 'checkpoint_epoch99.pth')\n",
    "\n",
    "# # Load the state_dict into the model\n",
    "# model2.load_state_dict(checkpoint['model'])\n",
    "\n",
    "labelindex = 0\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict_onelabel(model, labelindex, test_loader, device, conf, 'Test')\n",
    "# pred_df_list = []\n",
    "# perf_df_list = []\n",
    "# for i in range(conf.n_task):\n",
    "pred_df, perf_df = get_performance(y_pred_tasks_test, y_true_task_test, test_ids, ALL_LABELS[labelindex], THRES = 0.5)\n",
    "#     pred_df_list.append(pred_df)\n",
    "#     perf_df_list.append(perf_df)\n",
    "\n",
    "# all_perd_df = pd.concat(pred_df_list)\n",
    "# all_perf_df = pd.concat(perf_df_list)\n",
    "# print(all_perf_df)\n",
    "\n",
    "# all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TEST_pred_df.csv\",index = False)\n",
    "# all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TEST_perf.csv\",index = True)\n",
    "# print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d117f-1e63-4396-965f-9858cd4dc078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9237644-7892-4b00-82f2-0678121ac2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tasks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a236391-ba85-46bb-80c8-62fa3773f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_msi = all_perd_df.loc[all_perd_df['OUTCOME'] == 'MSI_POS']\n",
    "pred_msi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353cef6-bb76-4e88-bea9-c0adbd3d0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import ROC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(y_pred, y_true):\n",
    "    # Initialize ROC metric for binary classification\n",
    "    roc = ROC(task='binary')\n",
    "    \n",
    "    # Compute FPR, TPR, and thresholds\n",
    "    fpr, tpr, thresholds = roc(torch.tensor(y_pred), torch.tensor(y_true))\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e5db7-8c0e-43c3-af13-3c3e5285c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(list(pred_msi['Pred_Prob']),list(pred_msi['Y_True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8621554-50ec-4655-a49c-3c280e3cdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PLOT:\n",
    "# pred_df = all_perd_df\n",
    "# SELECTED_LABEL = ['MSI_POS']\n",
    "# #Get True Postives\n",
    "# true_postive_ids = {}\n",
    "# for label in SELECTED_LABEL:\n",
    "#     cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 1) & (pred_df['OUTCOME'] == label)\n",
    "#     cur_pred_df = pred_df.loc[cond]\n",
    "#     cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "#     true_postive_ids[label] = cur_ids\n",
    "\n",
    "# #Get true nagative\n",
    "# true_negative_ids = {}\n",
    "# for label in SELECTED_LABEL:\n",
    "#     cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 0) & (pred_df['OUTCOME'] == label)\n",
    "#     cur_pred_df = pred_df.loc[cond]\n",
    "#     cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "#     true_negative_ids[label] = cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fde41-231c-4a9d-ba4e-b3dbd8d119ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################################################\n",
    "# #Atention scores\n",
    "# ####################################################################################\n",
    "# save_image_size = 250\n",
    "# pixel_overlap = 0\n",
    "# mag_extract = 20\n",
    "# limit_bounds = True\n",
    "# TOP_K = 5\n",
    "# pretrain_model_name = \"retccl\"\n",
    "# mag_target_prob = 2.5\n",
    "# smooth = True\n",
    "# mag_target_tiss = 1.25\n",
    "\n",
    "# def get_attention_and_tileinfo(pt_label_df, patient_att_score):    \n",
    "#     #Get label\n",
    "#     pt_label_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     #Get attention\n",
    "#     cur_att  = pd.DataFrame({'ATT':list(minmax_normalize(patient_att_score))})\n",
    "#     cur_att.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     #Comb\n",
    "#     cur_att_df = pd.concat([pt_label_df,cur_att], axis = 1)\n",
    "#     cur_att_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#     return cur_att_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1e366-7bc8-4ab9-a6db-44b2647d8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn[label_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e7e43-8f39-4748-9855-8c1434037b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_ids = true_postive_ids[SELECTED_LABEL[0]]\n",
    "# wsi_path = proj_dir + '/data/OPX/'\n",
    "# branches = 1\n",
    "\n",
    "# for pt in selected_ids:\n",
    "#     i = test_ids.index(pt)\n",
    "#     pt = test_ids[i]\n",
    "#     print(pt)\n",
    "\n",
    "#     save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "#     save_location =  save_location  + pt + \"/\"\n",
    "#     create_dir_if_not_exists(save_location)\n",
    "    \n",
    "#     _file = wsi_path + pt + \".tif\"\n",
    "#     oslide = openslide.OpenSlide(_file)\n",
    "#     save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "    \n",
    "#     first_batch = list(test_loader)[i]\n",
    "#     feat = first_batch[0].to(device)\n",
    "#     sub_preds, slide_preds, attn = model(feat)\n",
    "#     #cur_pt_att =  attn[0,:,:].mean(0).cpu().detach().numpy() #Take the mean across branches without softmax\n",
    "#     label_index = ALL_LABELS.index(SELECTED_LABEL[0])\n",
    "#     cur_pt_att = attn[label_index][branches].mean(0).cpu().detach().numpy()\n",
    "#     #branches = 0\n",
    "#     #cur_pt_att = torch.softmax(attn, dim=-1)[0][branches].cpu().detach().numpy() \n",
    "    \n",
    "#     #Get all tile info include noncancer tile\n",
    "#     alltileinfo_dir = proj_dir + 'intermediate_data/TODELETE_cancer_prediction_results110224/' + \"IMSIZE250_OL0\" + \"/\"\n",
    "#     tile_info_df = pd.read_csv(alltileinfo_dir + pt + \"/\"  + save_name + \"_tiles.csv\")\n",
    "#     cur_pt_info = test_info[i]\n",
    "#     #Combine current pt_info an all tile info\n",
    "#     #cur_pt_info = tile_info_df.merge(cur_pt_info, on = list(tile_info_df.columns), how = \"left\")\n",
    "    \n",
    "#     cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "#     #cur_att_df.loc[pd.isna(cur_att_df['ATT']),'ATT'] = 0.0001\n",
    "    \n",
    "#     #Generate tiles\n",
    "#     tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "#     #get level 0 size in px\n",
    "#     l0_w = oslide.level_dimensions[0][0]\n",
    "#     l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "#     #1.25x tissue detection for mask\n",
    "#     from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "#     from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "#     import cv2\n",
    "#     if 'OPX' in pt:\n",
    "#         rad_tissue = 5\n",
    "#     elif '(2017-0133)' in pt:\n",
    "#         rad_tissue = 2\n",
    "#     lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "#     lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "#     tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "#     #2.5x for probability maps\n",
    "#     lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "#     x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "#     x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    \n",
    "#     for index, row in cur_att_df.iterrows():\n",
    "#         cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "#         x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "#         #Extract tile for prediction\n",
    "#         lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "#         tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "#         map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    \n",
    "#         #Store predicted probabily in map and count\n",
    "#         try: \n",
    "#             x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "#             x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#     print('post-processing')\n",
    "#     x_count = np.where(x_count < 1, 1, x_count)\n",
    "#     x_map = x_map / x_count\n",
    "#     x_map[x_map>1]=1\n",
    "    \n",
    "#     #Get the following before smooth\n",
    "#     he_mask = cv2.resize(np.uint8(he_mask),(x_map.shape[1],x_map.shape[0])) #resize to output image size\n",
    "#     cond1 = he_mask < 1 #Background\n",
    "#     cond2 = (he_mask == 1) & (x_map == 0) #is tissue, but not selected\n",
    "#     smooth = True\n",
    "    \n",
    "#     if smooth == True:\n",
    "#         #x_sm = filters.gaussian(x_map, sigma=0)\n",
    "#         x_sm = np.where(x_map != 0, filters.gaussian(x_map, sigma=10), x_map)\n",
    "#     if smooth == False:\n",
    "#         x_sm = x_map\n",
    "    \n",
    "#     #TODO:\n",
    "#     #get cancer_mask:\n",
    "#     # cancer_mask == \n",
    "#     # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "#     x_sm[cond1] = 0 #Background\n",
    "#     x_sm[cond2] = 0.1 #Is tissue, but not selected \n",
    "    \n",
    "#     # Define the colors for the sequential colormap (black to fluorescent green)\n",
    "#     colors = [\"#4B0082\", \"#39FF14\"]  # Black to Fluorescent Green\n",
    "#     # Create the sequential colormap\n",
    "#     cmap_name = \"black_to_fluorescent_green\"\n",
    "#     from matplotlib.colors import LinearSegmentedColormap\n",
    "#     from matplotlib.colors import ListedColormap\n",
    "#     sequential_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "#     cmap =  plt.cm.Spectral_r #sequential_cmap # plt.cm.YlGn_r\n",
    "#     cmap_colors = cmap(np.arange(cmap.N))\n",
    "#     cmap_colors[0] = np.array([0.95, 0.95, 0.95, 1]) #np.array([1, 1, 1, 1])  # Set the first color (corresponding to 0) to white\n",
    "#     cmap_colors[1] = np.array([0, 0, 0.545, 1])  # RGB for dark blue\n",
    "#     custom_cmap = ListedColormap(cmap_colors)\n",
    "    \n",
    "#     plt.imshow(x_sm, cmap=custom_cmap) #Spectral_r\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "#     #Top attented tiles\n",
    "#     save_location2 = save_location + \"top_tiles/\"\n",
    "#     create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "#     #Get a Attention, and corresponding tiles\n",
    "#     cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "#     cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "            \n",
    "#     for i in range(TOP_K):\n",
    "#         cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#         cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#         cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#         coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#         tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#         cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "    \n",
    "#     #Bot attented tiles\n",
    "#     save_location2 = save_location + \"bot_tiles/\"\n",
    "#     create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "#     #Get a Attention, and corresponding tiles\n",
    "#     cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "#     cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "    \n",
    "#     for i in range(TOP_K):\n",
    "#         cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#         cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#         cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#         coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#         tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#         cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e138338-01e8-4cb0-91a7-76a7b44cb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "# TMA\n",
    "##############################################################################################################################\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, tma_loader, device, conf, 'TMA')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    if i not in [1,5,6]:\n",
    "        pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tma_ids, ALL_LABELS[i],thres_quantile = 0.7)\n",
    "        pred_df_list.append(pred_df)\n",
    "        perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TMA_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TMA_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b54552-96ad-42ac-a8f6-abaa438a9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "# TCGA\n",
    "##############################################################################################################################\n",
    "y_pred_tasks_test, y_predprob_task_test, y_true_task_test = predict(model, tcga_loader, device, conf, 'TCGA')\n",
    "pred_df_list = []\n",
    "perf_df_list = []\n",
    "for i in range(conf.n_task):\n",
    "    if i != 5 :\n",
    "        pred_df, perf_df = get_performance(y_predprob_task_test[i], y_true_task_test[i], tcga_ids, ALL_LABELS[i], thres_quantile = 0.6)\n",
    "        pred_df_list.append(pred_df)\n",
    "        perf_df_list.append(perf_df)\n",
    "\n",
    "all_perd_df = pd.concat(pred_df_list)\n",
    "all_perf_df = pd.concat(perf_df_list)\n",
    "print(all_perf_df)\n",
    "all_perd_df.to_csv(outdir4 + \"/n_token\" + str(conf.n_token) + \"_TCGA_pred_df.csv\",index = False)\n",
    "all_perf_df.to_csv(outdir5 + \"/n_token\" + str(conf.n_token) + \"_TCGA_perf.csv\",index = True)\n",
    "print(round(all_perf_df['AUC'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94820a81-e39e-415e-a4d6-db77afb615b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT:\n",
    "pred_df = all_perd_df\n",
    "SELECTED_LABEL = ['MSI_POS']\n",
    "#Get True Postives\n",
    "true_postive_ids = {}\n",
    "for label in SELECTED_LABEL:\n",
    "    cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 1) & (pred_df['OUTCOME'] == label)\n",
    "    cur_pred_df = pred_df.loc[cond]\n",
    "    cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "    true_postive_ids[label] = cur_ids\n",
    "\n",
    "#Get true nagative\n",
    "true_negative_ids = {}\n",
    "for label in SELECTED_LABEL:\n",
    "    cond = (pred_df['Y_True'] == pred_df['Pred_Class']) & (pred_df['Y_True'] == 0) & (pred_df['OUTCOME'] == label)\n",
    "    cur_pred_df = pred_df.loc[cond]\n",
    "    cur_ids = list(cur_pred_df['SAMPLE_IDs'])\n",
    "    true_negative_ids[label] = cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbd1de-30b6-49c3-a773-63c100f236e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#Atention scores\n",
    "####################################################################################\n",
    "save_image_size = 250\n",
    "pixel_overlap = 0\n",
    "mag_extract = 20\n",
    "limit_bounds = True\n",
    "TOP_K = 5\n",
    "pretrain_model_name = \"retccl\"\n",
    "mag_target_prob = 2.5\n",
    "smooth = True\n",
    "mag_target_tiss = 1.25\n",
    "\n",
    "def get_attention_and_tileinfo(pt_label_df, patient_att_score):    \n",
    "    #Get label\n",
    "    pt_label_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Get attention\n",
    "    cur_att  = pd.DataFrame({'ATT':list(minmax_normalize(patient_att_score))})\n",
    "    cur_att.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Comb\n",
    "    cur_att_df = pd.concat([pt_label_df,cur_att], axis = 1)\n",
    "    cur_att_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return cur_att_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea6977-e834-4509-85ba-2df6e185f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(attn[label_index].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a3968-1897-4f3e-9fd6-f805a8c5395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = true_postive_ids[SELECTED_LABEL[0]]\n",
    "wsi_path = proj_dir + '/data/TCGA_PRAD/'\n",
    "branches = 0\n",
    "\n",
    "for pt in selected_ids:\n",
    "    i = tcga_ids.index(pt)\n",
    "    pt = tcga_ids[i]\n",
    "    print(pt)\n",
    "\n",
    "    save_location = outdir4 + SELECTED_LABEL[0] + \"/\"\n",
    "    save_location =  save_location  + pt + \"/\"\n",
    "    create_dir_if_not_exists(save_location)\n",
    "\n",
    "    slides_name = [f for f in os.listdir(wsi_path + pt + '/') if '.svs' in f][0].replace('.svs','')\n",
    "    _file = wsi_path + pt + '/' + slides_name + '.svs'\n",
    "    oslide = openslide.OpenSlide(_file)\n",
    "    save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "    \n",
    "    first_batch = list(tcga_loader)[i]\n",
    "    feat = first_batch[0].to(device)\n",
    "    sub_preds, slide_preds, attn = model(feat)\n",
    "    label_index = ALL_LABELS.index(SELECTED_LABEL[0])\n",
    "    #cur_pt_att = attn[label_index][:,:,:].mean(1).cpu().detach().numpy() #mean across all branchs\n",
    "    cur_pt_att = attn[label_index][:,branches,:].mean(0).cpu().detach().numpy()\n",
    "    #branches = 0\n",
    "    #cur_pt_att = torch.softmax(attn[label_index], dim=1).cpu().detach().numpy() \n",
    "    \n",
    "    #Get all tile info include noncancer tile    \n",
    "    alltileinfo_dir = proj_dir + 'intermediate_data/1_tile_pulling/TCGA_PRAD/' + \"IMSIZE250_OL0\" + \"/\"\n",
    "    tile_info_df = pd.read_csv(alltileinfo_dir + pt + \"/\"  + save_name + \"_tiles.csv\")\n",
    "    cur_pt_info = tcga_info[i]\n",
    "    #Combine current pt_info an all tile info\n",
    "    #cur_pt_info = tile_info_df.merge(cur_pt_info, on = list(tile_info_df.columns), how = \"left\")\n",
    "    \n",
    "    cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "    #cur_att_df.loc[pd.isna(cur_att_df['ATT']),'ATT'] = 0.0001\n",
    "    \n",
    "    #Generate tiles\n",
    "    tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "    #get level 0 size in px\n",
    "    l0_w = oslide.level_dimensions[0][0]\n",
    "    l0_h = oslide.level_dimensions[0][1]\n",
    "    \n",
    "    #1.25x tissue detection for mask\n",
    "    from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "    from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "    import cv2\n",
    "    if 'OPX' in pt:\n",
    "        rad_tissue = 5\n",
    "    elif '(2017-0133)' in pt:\n",
    "        rad_tissue = 2\n",
    "    else:\n",
    "        rad_tissue = 2\n",
    "    lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "    lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "    tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "    \n",
    "    #2.5x for probability maps\n",
    "    lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "    x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "    \n",
    "    \n",
    "    for index, row in cur_att_df.iterrows():\n",
    "        cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "        x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "        \n",
    "        #Extract tile for prediction\n",
    "        lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "        tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "        map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "    \n",
    "        #Store predicted probabily in map and count\n",
    "        try: \n",
    "            x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "            x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print('post-processing')\n",
    "    x_count = np.where(x_count < 1, 1, x_count)\n",
    "    x_map = x_map / x_count\n",
    "    x_map[x_map>1]=1\n",
    "    \n",
    "    #Get the following before smooth\n",
    "    he_mask = cv2.resize(np.uint8(he_mask),(x_map.shape[1],x_map.shape[0])) #resize to output image size\n",
    "    cond1 = he_mask < 1 #Background\n",
    "    cond2 = (he_mask == 1) & (x_map == 0) #is tissue, but not selected\n",
    "    smooth = True\n",
    "    \n",
    "    if smooth == True:\n",
    "        #x_sm = filters.gaussian(x_map, sigma=0)\n",
    "        x_sm = np.where(x_map != 0, filters.gaussian(x_map, sigma=10), x_map)\n",
    "    if smooth == False:\n",
    "        x_sm = x_map\n",
    "    \n",
    "    #TODO:\n",
    "    #get cancer_mask:\n",
    "    # cancer_mask == \n",
    "    # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "    x_sm[cond1] = 0 #Background\n",
    "    x_sm[cond2] = 0.1 #Is tissue, but not selected \n",
    "    \n",
    "    # Define the colors for the sequential colormap (black to fluorescent green)\n",
    "    colors = [\"#4B0082\", \"#39FF14\"]  # Black to Fluorescent Green\n",
    "    # Create the sequential colormap\n",
    "    cmap_name = \"black_to_fluorescent_green\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    sequential_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "    cmap =  plt.cm.Spectral_r #sequential_cmap # plt.cm.YlGn_r\n",
    "    cmap_colors = cmap(np.arange(cmap.N))\n",
    "    cmap_colors[0] = np.array([0.95, 0.95, 0.95, 1]) #np.array([1, 1, 1, 1])  # Set the first color (corresponding to 0) to white\n",
    "    cmap_colors[1] = np.array([0, 0, 0.545, 1])  # RGB for dark blue\n",
    "    custom_cmap = ListedColormap(cmap_colors)\n",
    "    \n",
    "    plt.imshow(x_sm, cmap=custom_cmap) #Spectral_r\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    #Top attented tiles\n",
    "    save_location2 = save_location + \"top_tiles/\"\n",
    "    create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "    #Get a Attention, and corresponding tiles\n",
    "    cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "    cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "            \n",
    "    for i in range(TOP_K):\n",
    "        cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "        cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "        cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "        coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "        tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "        cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "    \n",
    "    #Bot attented tiles\n",
    "    save_location2 = save_location + \"bot_tiles/\"\n",
    "    create_dir_if_not_exists(save_location2)\n",
    "    \n",
    "    #Get a Attention, and corresponding tiles\n",
    "    cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "    cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "    \n",
    "    for i in range(TOP_K):\n",
    "        cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "        cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "        cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "        coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "        tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "        cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
