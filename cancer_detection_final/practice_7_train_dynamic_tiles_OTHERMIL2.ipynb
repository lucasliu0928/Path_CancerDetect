{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47c950-7902-4158-b010-b1aedaab8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: use python env acmil in ACMIL folder\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from skimage import filters\n",
    "import random\n",
    "\n",
    "    \n",
    "sys.path.insert(0, '../Utils/')\n",
    "from Utils import create_dir_if_not_exists\n",
    "from Utils import generate_deepzoom_tiles, extract_tile_start_end_coords, get_map_startend\n",
    "from Utils import get_downsample_factor\n",
    "from Utils import minmax_normalize, set_seed\n",
    "from Utils import log_message\n",
    "from Eval import compute_performance, plot_LOSS, compute_performance_each_label, get_attention_and_tileinfo\n",
    "from train_utils import pull_tiles\n",
    "from train_utils import ModelReadyData_diffdim, convert_to_dict, prediction_sepatt, BCE_Weighted_Reg, BCE_Weighted_Reg_focal, compute_loss_for_all_labels_sepatt\n",
    "from Model import Mutation_MIL_MT_sepAtt #, Mutation_MIL_MT\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#FOR ACMIL\n",
    "current_dir = os.getcwd()\n",
    "grandparent_subfolder = os.path.join(current_dir, '..', '..', 'other_model_code','ACMIL-main')\n",
    "grandparent_subfolder = os.path.normpath(grandparent_subfolder)\n",
    "sys.path.insert(0, grandparent_subfolder)\n",
    "from architecture.transformer import ACMIL_GA\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import ACMIL_GA #ACMIL_GA\n",
    "from architecture.transformer import ACMIL_MHA\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.utils import MetricLogger, SmoothedValue, adjust_learning_rate\n",
    "from timm.utils import accuracy\n",
    "import torchmetrics\n",
    "import wandb\n",
    "\n",
    "#FOR OTHERs:\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import save_model, Struct, set_seed\n",
    "from datasets.datasets import build_HDF5_feat_dataset\n",
    "from architecture.transformer import MHA, ABMIL\n",
    "from architecture.transMIL import TransMIL\n",
    "from engine import train_one_epoch, evaluate\n",
    "from architecture.dsmil import MILNet, FCLayer, BClassifier\n",
    "from architecture.bmil import probabilistic_MIL_Bayes_spvis\n",
    "from architecture.clam import CLAM_SB, CLAM_MB\n",
    "from architecture.ilra import ILRA\n",
    "from modules import mean_max\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79365df-a851-470f-afd8-b586222f6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out01212025retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out01212025retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//saved_model/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out01212025retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//model_para/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out01212025retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//logs/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out01212025retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//predictions/' already exists.\n",
      "Directory '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/intermediate_data/pred_out01212025retccl/MAXSSALLTUMORTILES_TrainOL100_TestOL0_TFT0.9/split_fold0//DL_emb_only/MT//perf/' already exists.\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######      USERINPUT       ########\n",
    "####################################\n",
    "SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "#SELECTED_LABEL = \"MSI_POS\"\n",
    "TRAIN_SAMPLE_SIZE = \"ALLTUMORTILES\"\n",
    "TRAIN_OVERLAP = 100\n",
    "TEST_OVERLAP = 0\n",
    "SELECTED_FOLD = 0\n",
    "TUMOR_FRAC_THRES = 0.9\n",
    "feature_extraction_method = 'retccl'\n",
    "learning_method = \"acmil\"\n",
    "INCLUDE_TF = False\n",
    "INCLUDE_CLUSTER = False\n",
    "N_CLUSTERS = 4\n",
    "focal_gamma = 2\n",
    "\n",
    "\n",
    "####\n",
    "#model Para\n",
    "LEARNING_RATE = 0.00001 \n",
    "BATCH_SIZE  = 1\n",
    "ACCUM_SIZE = 16  # Number of steps to accumulate gradients\n",
    "EPOCHS = 100\n",
    "DROPOUT = 0\n",
    "DIM_OUT = 128\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2048\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    N_FEATURE = 2049\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2049\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    N_FEATURE = 2050\n",
    "            \n",
    "\n",
    "LOSS_FUNC_NAME = \"BCE_Weighted_Reg_focal\" #\"BCE_Weighted_Reg\", \"BCE_Weighted_Reg_focal\"\n",
    "REG_COEEF = 0.0000001\n",
    "REG_TYPE = 'L1'\n",
    "OPTMIZER = \"ADAM\"\n",
    "ATT_REG_FLAG = False\n",
    "SELECTED_MUTATION = \"MT\"\n",
    "\n",
    "if SELECTED_MUTATION == \"MT\":\n",
    "    N_LABELS = len(SELECTED_LABEL)\n",
    "    LOSS_WEIGHTS_LIST = [[1, 50], [1, 100], [1, 50], [1, 100], [1, 100], [1, 10], [1, 30]]  #NEG, POS #WSI 50\n",
    "else:\n",
    "    N_LABELS = 1\n",
    "    LOSS_WEIGHTS_LIST = [[1, 10], [1, 10], [1, 50], [1, 100], [1, 100], [1, 100], [1, 10]]  #NEG, POS\n",
    "\n",
    "##################\n",
    "###### DIR  ######\n",
    "##################\n",
    "proj_dir = '/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/'\n",
    "folder_name = feature_extraction_method + '/MAXSS'+ str(TRAIN_SAMPLE_SIZE)  + '_TrainOL' + str(TRAIN_OVERLAP) +  '_TestOL' + str(TEST_OVERLAP) + '_TFT' + str(TUMOR_FRAC_THRES) + \"/split_fold\" + str(SELECTED_FOLD) + \"/\" \n",
    "wsi_path = proj_dir + '/data/OPX/'\n",
    "in_data_path = proj_dir + 'intermediate_data/model_ready_data/feature_' + folder_name + \"model_input/\"\n",
    "\n",
    "if INCLUDE_TF == False and INCLUDE_CLUSTER == False:\n",
    "    feature_type = \"emb_only\"\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == False:\n",
    "    feature_type = \"emb_and_tf\"\n",
    "elif INCLUDE_TF == False and INCLUDE_CLUSTER == True:\n",
    "    feature_type = \"emb_and_cluster\" + str(N_CLUSTERS)\n",
    "elif INCLUDE_TF == True and INCLUDE_CLUSTER == True:\n",
    "    feature_type = \"emb_and_tf_and_cluster\" + str(N_CLUSTERS) \n",
    "\n",
    "model_data_path =  in_data_path + feature_type + \"/\"\n",
    "    \n",
    "################################################\n",
    "#Create output-dir\n",
    "################################################\n",
    "outdir0 =  proj_dir + \"intermediate_data/pred_out01212025\" + folder_name + \"/DL_\" + feature_type + \"/\" + SELECTED_MUTATION + \"/\"\n",
    "outdir1 =  outdir0  + \"/saved_model/\"\n",
    "outdir2 =  outdir0  + \"/model_para/\"\n",
    "outdir3 =  outdir0  + \"/logs/\"\n",
    "outdir4 =  outdir0  + \"/predictions/\"\n",
    "outdir5 =  outdir0  + \"/perf/\"\n",
    "ckpt_dir = outdir1\n",
    "\n",
    "create_dir_if_not_exists(outdir0)\n",
    "create_dir_if_not_exists(outdir1)\n",
    "create_dir_if_not_exists(outdir2)\n",
    "create_dir_if_not_exists(outdir3)\n",
    "create_dir_if_not_exists(outdir4)\n",
    "create_dir_if_not_exists(outdir5)\n",
    "\n",
    "##################\n",
    "#Select GPU\n",
    "##################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29af080-30a2-4b06-a3a6-b33991602065",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#     Model ready data \n",
    "################################################\n",
    "train_data_old = torch.load(model_data_path + 'train_data.pth')\n",
    "test_data_old = torch.load(model_data_path + 'test_data.pth')\n",
    "val_data = torch.load(model_data_path + 'val_data.pth')\n",
    "\n",
    "train_ids_old = torch.load(model_data_path + 'train_ids.pth')\n",
    "test_ids_old = torch.load(model_data_path + 'test_ids.pth')\n",
    "\n",
    "train_info_old  = torch.load(model_data_path + 'train_info.pth')\n",
    "test_info_old  = torch.load(model_data_path + 'test_info.pth')\n",
    "\n",
    "new_data = torch.load(model_data_path + 'newMSI_test_data.pth')\n",
    "new_ids = torch.load(model_data_path + 'newMSI_test_ids.pth')\n",
    "new_info  = torch.load(model_data_path + 'newMSI_test_info.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d122e8aa-f42b-47f4-acd7-f52e3ad456bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Exclude OPX_085, Prostate cancer find in colorectal site, patterns are for CRC, not for prostate\n",
    "################################################\n",
    "exc_idx = test_ids_old.index('OPX_085')\n",
    "inc_idx = [i for i in range(len(test_data_old)) if i not in [exc_idx]]\n",
    "\n",
    "#Update old testset\n",
    "test_data_old = Subset(test_data_old, inc_idx)\n",
    "removed_id =   test_ids_old.pop(exc_idx)  \n",
    "removed_info = test_info_old.pop(exc_idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d0065b-0505-4012-b3a0-214afadf5ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OPX_207', 'OPX_209', 'OPX_213', 'OPX_214', 'OPX_215']\n",
      "['OPX_208', 'OPX_210', 'OPX_211', 'OPX_212', 'OPX_216']\n"
     ]
    }
   ],
   "source": [
    "train_add_ids = ['OPX_207','OPX_209','OPX_213','OPX_214','OPX_215']\n",
    "test_add_ids =  [x for x in new_ids if x not in train_add_ids]\n",
    "print(train_add_ids)\n",
    "print(test_add_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf71500-b576-450d-911e-6a305ceb552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Add Ids in train \n",
    "################################################\n",
    "inc_idx = [new_ids.index(x) for x in train_add_ids]\n",
    "new_data_train = Subset(new_data, inc_idx)\n",
    "new_id_train =  list(Subset(new_ids, inc_idx))\n",
    "new_info_train = list(Subset(new_info, inc_idx))\n",
    "\n",
    "#Combine old and new train data\n",
    "train_data  = ConcatDataset([train_data_old, new_data_train])\n",
    "train_ids = train_ids_old +  new_id_train\n",
    "train_info = train_info_old +  new_info_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1cec3e-58ee-41a1-bcc2-cfb1cf17cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#Add Ids in test \n",
    "################################################\n",
    "inc_idx = [new_ids.index(x) for x in test_add_ids]\n",
    "new_data_test = Subset(new_data, inc_idx)\n",
    "new_id_test =  list(Subset(new_ids, inc_idx))\n",
    "new_info_test = list(Subset(new_info, inc_idx))\n",
    "\n",
    "#Combine old and new train data\n",
    "test_data  = ConcatDataset([test_data_old, new_data_test])\n",
    "test_ids = test_ids_old +  new_id_test\n",
    "test_info = test_info_old +  new_info_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67210258-529a-48e2-88b7-2bdec7cb9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 25, 31, 18, 58, 10,  9])\n",
      "['9.9', '16.4', '20.4', '11.8', '38.2', '6.6', '5.9']\n"
     ]
    }
   ],
   "source": [
    "#count labels in train\n",
    "train_label_counts = [dt[1] for dt in train_data]\n",
    "train_label_counts = torch.concat(train_label_counts)\n",
    "count_ones = (train_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/train_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2607834-7757-448e-a5e8-24b208e7514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  6, 10,  4, 16,  7,  7])\n",
      "['11.4', '13.6', '22.7', '9.1', '36.4', '15.9', '15.9']\n"
     ]
    }
   ],
   "source": [
    "#count labels in test\n",
    "test_label_counts = [dt[1] for dt in test_data]\n",
    "test_label_counts = torch.concat(test_label_counts)\n",
    "count_ones = (test_label_counts == 1).sum(dim=0)\n",
    "print(count_ones)\n",
    "perc_ones = count_ones/test_label_counts.shape[0] * 100\n",
    "formatted_numbers = [f\"{x.item():.1f}\" for x in perc_ones]\n",
    "print(formatted_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac20728-c805-47e7-a4a9-9bad6c775a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#            Train \n",
    "####################################################\n",
    "set_seed(0)\n",
    "\n",
    "#Dataloader for training\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "#Construct model\n",
    "# model = Mutation_MIL_MT_sepAtt(in_features = N_FEATURE, \n",
    "#                         act_func = 'tanh', \n",
    "#                         drop_out = DROPOUT,\n",
    "#                         n_outcomes = N_LABELS,\n",
    "#                         dim_out = DIM_OUT)\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# #Optimizer\n",
    "# if OPTMIZER == \"ADAM\":\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# elif OPTMIZER == \"SGD\":\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# #Loss\n",
    "# if LOSS_FUNC_NAME == \"BCE_Weighted_Reg\":\n",
    "#     loss_func = BCE_Weighted_Reg(REG_COEEF, REG_TYPE, model, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "# elif LOSS_FUNC_NAME == \"BCE_Weighted_Reg_focal\":\n",
    "#     loss_func = BCE_Weighted_Reg_focal(REG_COEEF, REG_TYPE, model, gamma = focal_gamma, reduction = 'mean', att_reg_flag = ATT_REG_FLAG)\n",
    "# elif LOSS_FUNC_NAME == \"BCELoss\":\n",
    "#     loss_func = torch.nn.BCELoss()\n",
    "    \n",
    "\n",
    "# #Model para\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f\"Number of parameters: {total_params}\")\n",
    "# #print(model)\n",
    "\n",
    "\n",
    "#OUTPUT MODEL hyper-para\n",
    "# hyper_df = pd.DataFrame({\"Target_Mutation\": SELECTED_MUTATION,\n",
    "#                          \"TRAIN_OVERLAP\": TRAIN_OVERLAP,\n",
    "#                          \"TEST_OVERLAP\": TEST_OVERLAP,\n",
    "#                          \"TRAIN_SAMPLE_SIZE\": TRAIN_SAMPLE_SIZE,\n",
    "#                          \"TUMOR_FRAC_THRES\": TUMOR_FRAC_THRES,\n",
    "#                          \"N_FEATURE\": N_FEATURE,\n",
    "#                          \"N_LABELS\": N_LABELS,\n",
    "#                          \"BATCH_SIZE\": BATCH_SIZE,\n",
    "#                          \"ACCUM_SIZE\": ACCUM_SIZE,\n",
    "#                          \"N_EPOCH\": EPOCHS,\n",
    "#                          \"OPTMIZER\": OPTMIZER,\n",
    "#                          \"LEARNING_RATE\": LEARNING_RATE,\n",
    "#                          \"DROPOUT\": DROPOUT,\n",
    "#                          \"DIM_OUT\": DIM_OUT,\n",
    "#                          \"REG_TYPE\": REG_TYPE,\n",
    "#                          \"REG_COEEF\": REG_COEEF,\n",
    "#                          \"LOSS_FUNC_NAME\": LOSS_FUNC_NAME,\n",
    "#                          \"LOSS_WEIGHTS_LIST\": str(LOSS_WEIGHTS_LIST),\n",
    "#                          \"ATT_REG_FLAG\": ATT_REG_FLAG,\n",
    "#                          \"NUM_MODEL_PARA\": total_params}, index = [0])\n",
    "# hyper_df.to_csv(outdir2 + \"hyperpara_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d35570ec-d05c-479c-8158-94845741d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch: 100\n",
      "warmup_epoch: 0\n",
      "wd: 1e-05\n",
      "lr: 0.0001\n",
      "min_lr: 0\n",
      "dataset: bracs\n",
      "B: 1\n",
      "n_class: 2\n",
      "data_dir: /mnt/Xsky/zyl/dataset/bracs/roi_feats_x100\n",
      "n_worker: 8\n",
      "pin_memory: False\n",
      "n_shot: -1\n",
      "backbone: ViT-S/16\n",
      "pretrain: medical_ssl\n",
      "D_feat: 2048\n",
      "D_inner: 128\n",
      "n_token: 1\n",
      "wandb_mode: disabled\n",
      "arch: clam_sb\n",
      "w_loss: 1\n"
     ]
    }
   ],
   "source": [
    "# get config\n",
    "config_dir = \"myconf.yml\"\n",
    "with open(config_dir, \"r\") as ymlfile:\n",
    "    c = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    #c.update(vars(args))\n",
    "    conf = Struct(**c)\n",
    "    \n",
    "conf.D_feat = N_FEATURE\n",
    "conf.D_inner = DIM_OUT\n",
    "conf.n_token = 1\n",
    "conf.n_class = 2\n",
    "conf.wandb_mode = 'disabled'\n",
    "conf.arch = 'clam_sb' #'dsmil' #'transmil'\n",
    "conf.w_loss = 1\n",
    "# Print all key-value pairs in the conf object\n",
    "for key, value in conf.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# define network\n",
    "if conf.arch == 'transmil':\n",
    "    model = TransMIL(conf)\n",
    "elif conf.arch == 'mha':\n",
    "    model = MHA(conf)\n",
    "elif conf.arch == 'clam_sb':\n",
    "    model = CLAM_SB(conf).to(device)\n",
    "elif conf.arch == 'clam_mb':\n",
    "    model = CLAM_MB(conf).to(device)\n",
    "elif conf.arch == 'dsmil':\n",
    "    i_classifier = FCLayer(conf.D_feat, conf.n_class)\n",
    "    b_classifier = BClassifier(conf, nonlinear=False)\n",
    "    model = MILNet(i_classifier, b_classifier)\n",
    "elif conf.arch == 'bmil_spvis':\n",
    "    model = probabilistic_MIL_Bayes_spvis(conf)\n",
    "    model.relocate()\n",
    "elif conf.arch == 'abmil':\n",
    "    model = ABMIL(conf)\n",
    "elif conf.arch == 'meanmil':\n",
    "    model = mean_max.MeanMIL(conf).to(device)\n",
    "elif conf.arch == 'maxmil':\n",
    "    model = mean_max.MaxMIL(conf).to(device)\n",
    "elif conf.arch == 'ilra':\n",
    "    model = ILRA(feat_dim=conf.D_feat, n_classes=conf.n_class, ln=True)\n",
    "else:\n",
    "    print(\"architecture %s is not exist.\"%conf.arch)\n",
    "    sys.exit(1)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "# Example usage:\n",
    "criterion = FocalLoss(alpha=0.1, gamma=2, reduction='mean')\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer, lr not important at this point\n",
    "optimizer0 = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=conf.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47b497a9-a195-4eaf-9518-e137a5f0813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_forward_and_backward_clam(net, image_patches, labels, criterion, conf,\n",
    "                                   device, optimizer, metric_logger, log_writer=None):\n",
    "    # Compute loss\n",
    "    logits, instance_loss = net(image_patches, labels, instance_eval=True)\n",
    "    loss = criterion(logits, labels)\n",
    "    total_loss = conf.w_loss * loss + (1 - conf.w_loss) * instance_loss\n",
    "\n",
    "\n",
    "    # Backpropagate error and update parameters\n",
    "    total_loss.backward()\n",
    "\n",
    "    metric_logger.update(lr=optimizer.param_groups[0]['lr'])\n",
    "    metric_logger.update(bag_loss=loss.item())\n",
    "    metric_logger.update(instance_loss=instance_loss.item())\n",
    "\n",
    "    if log_writer is not None:\n",
    "        \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "        This calibrates different curves when batch size changes.\n",
    "        \"\"\"\n",
    "        log_writer.log('bag_loss', loss, commit=False)\n",
    "        log_writer.log('instance_loss', instance_loss)\n",
    "        \n",
    "def loss_forward_and_backward_dsmil(net, image_patches, labels, criterion, conf,\n",
    "                                    device, optimizer, metric_logger, log_writer=None):\n",
    "    # Compute loss\n",
    "    ins_preds, bag_preds, attn = net(image_patches)\n",
    "    max_preds, _ = torch.max(ins_preds, 0, keepdim=True)\n",
    "    ce_loss = 0.5 * criterion(max_preds, labels) \\\n",
    "              + 0.5 * criterion(bag_preds, labels)\n",
    "\n",
    "    diff_loss = torch.tensor(0).to(device, dtype=torch.float)\n",
    "    attn = torch.softmax(attn, dim=-1)\n",
    "    for i in range(conf.n_token):\n",
    "        for j in range(i + 1, conf.n_token):\n",
    "            diff_loss += torch.cosine_similarity(attn[i], attn[j], dim=-1).mean() / (\n",
    "                        conf.n_token * (conf.n_token - 1) / 2)\n",
    "\n",
    "    loss = conf.w_loss * diff_loss + ce_loss\n",
    "\n",
    "    # Backpropagate error and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    metric_logger.update(lr=optimizer.param_groups[0]['lr'])\n",
    "    metric_logger.update(ce_loss=ce_loss.item())\n",
    "    metric_logger.update(diff_loss=diff_loss.item())\n",
    "\n",
    "    if log_writer is not None:\n",
    "        \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "        This calibrates different curves when batch size changes.\n",
    "        \"\"\"\n",
    "        log_writer.log('ce_loss', ce_loss, commit=False)\n",
    "        log_writer.log('diff_loss', diff_loss)\n",
    "        \n",
    "def loss_forward_and_backward(net, image_patches, labels, criterion, conf,\n",
    "                              device, optimizer, metric_logger, log_writer=None):\n",
    "    # Compute loss\n",
    "    preds = net(image_patches)\n",
    "    ce_loss = criterion(preds, labels)\n",
    "\n",
    "    diff_loss = torch.tensor(0).to(device, dtype=torch.float)\n",
    "\n",
    "    loss = conf.w_loss * diff_loss + ce_loss\n",
    "\n",
    "    # Backpropagate error and update parameters\n",
    "    loss.backward()\n",
    "\n",
    "    metric_logger.update(lr=optimizer.param_groups[0]['lr'])\n",
    "    metric_logger.update(ce_loss=ce_loss.item())\n",
    "    metric_logger.update(diff_loss=diff_loss.item())\n",
    "\n",
    "    if log_writer is not None:\n",
    "        \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "        This calibrates different curves when batch size changes.\n",
    "        \"\"\"\n",
    "        log_writer.log('ce_loss', ce_loss, commit=False)\n",
    "        log_writer.log('diff_loss', diff_loss)\n",
    "        \n",
    "def train_one_epoch(net, criterion, data_loader, optimizer, device, epoch, conf, log_writer=None):\n",
    "    \"\"\"\n",
    "    Trains the given network for one epoch according to given criterions (loss functions)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the network to training mode\n",
    "    net.train()\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 100\n",
    "\n",
    "    for data_it, data in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "        # for data_it, data in enumerate(data_loader, start=epoch * len(data_loader)):\n",
    "        # Move input batch onto GPU if eager execution is enabled (default), else leave it on CPU\n",
    "        # Data is a dict with keys `input` (patches) and `{task_name}` (labels for given task)\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0,:,6].to(device, dtype = torch.int64).to(device)\n",
    "        #coords = data['coords']\n",
    "        coords = None\n",
    "\n",
    "        # # Calculate and set new learning rate\n",
    "        adjust_learning_rate(optimizer, epoch + data_it / len(data_loader), conf)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if conf.arch == 'dsmil':\n",
    "            loss_forward_and_backward_dsmil(net, image_patches, labels, criterion, conf,\n",
    "                                            device, optimizer, metric_logger, log_writer)\n",
    "        elif conf.arch in ('clam_sb', 'clam_mb'):\n",
    "            loss_forward_and_backward_clam(net, image_patches, labels, criterion, conf,\n",
    "                                            device, optimizer, metric_logger, log_writer)\n",
    "        elif conf.arch == 'bmil_spvis':\n",
    "            loss_forward_and_backward_bmil(net, image_patches, coords, labels, criterion, conf,\n",
    "                                           device, optimizer, metric_logger, log_writer)\n",
    "        else:\n",
    "            loss_forward_and_backward(net, image_patches, labels, criterion, conf,\n",
    "                                      device, optimizer, metric_logger, log_writer)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# Disable gradient calculation during evaluation\n",
    "@torch.no_grad()\n",
    "def evaluate(net, criterion, data_loader, device, conf, header):\n",
    "    # Set the network to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "    for data in metric_logger.log_every(data_loader, 100, header):\n",
    "        image_patches = data[0].to(device, dtype=torch.float32)\n",
    "        labels = data[1][0,:,6].to(device, dtype = torch.int64).to(device)\n",
    "        #coords = data['coords']\n",
    "        coords = None\n",
    "\n",
    "        if conf.arch == 'dsmil':\n",
    "            # Compute loss\n",
    "            ins_preds, bag_preds, attn = net(image_patches)\n",
    "            max_preds, _ = torch.max(ins_preds, 0, keepdim=True)\n",
    "            loss = 0.5 * criterion(max_preds, labels) \\\n",
    "                   + 0.5 * criterion(bag_preds, labels)\n",
    "            pred = 0.5 * torch.softmax(max_preds, dim=-1) \\\n",
    "                   + 0.5 * torch.softmax(bag_preds, dim=-1)\n",
    "        elif conf.arch == 'bmil_spvis':\n",
    "            coords_array = coords.numpy()[0]\n",
    "            output, Y_prob, Y_hat, _, _ = net(image_patches, coords_array, coords_array[:, 1].max(),\n",
    "                                              coords_array[:, 0].max(), validation=True)\n",
    "            loss = criterion(output, labels)\n",
    "            pred = torch.softmax(output, dim=-1)\n",
    "        elif conf.arch in ('clam_sb', 'clam_mb'):\n",
    "            output = net(image_patches)\n",
    "            loss = criterion(output, labels)\n",
    "            pred = torch.softmax(output, dim=-1)\n",
    "        else:\n",
    "            # Compute loss\n",
    "            output = net(image_patches)\n",
    "            loss = criterion(output, labels)\n",
    "            pred = torch.softmax(output, dim=-1)\n",
    "\n",
    "        acc1 = accuracy(pred, labels, topk=(1,))[0]\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=labels.shape[0])\n",
    "\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(labels)\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "\n",
    "    AUROC_metric = torchmetrics.AUROC(num_classes=conf.n_class, average='macro',task='multiclass').to(device)\n",
    "    AUROC_metric(y_pred, y_true)\n",
    "    auroc = AUROC_metric.compute().item()\n",
    "    F1_metric = torchmetrics.F1Score(num_classes=conf.n_class, average='macro',task='multiclass').to(device)\n",
    "    F1_metric(y_pred, y_true)\n",
    "    f1_score = F1_metric.compute().item()\n",
    "\n",
    "    print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f} auroc {AUROC:.3f} f1_score {F1:.3f}'\n",
    "          .format(top1=metric_logger.acc1, losses=metric_logger.loss, AUROC=auroc, F1=f1_score))\n",
    "\n",
    "    return auroc, metric_logger.acc1.global_avg, f1_score, metric_logger.loss.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "864798bc-9ac0-405f-9ca8-24530fb43863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/152]  eta: 0:00:08  lr: 0.000100  bag_loss: 0.0149 (0.0149)  instance_loss: 0.6849 (0.6849)  time: 0.0557  data: 0.0020  max mem: 3601\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m best_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_auc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_f1\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(conf\u001b[38;5;241m.\u001b[39mtrain_epoch):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     val_auc, val_acc, val_f1, val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, criterion, val_loader, device, conf, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     test_auc, test_acc, test_f1, test_loss \u001b[38;5;241m=\u001b[39m evaluate(model, criterion, test_loader, device, conf, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[69], line 107\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(net, criterion, data_loader, optimizer, device, epoch, conf, log_writer)\u001b[0m\n\u001b[1;32m    104\u001b[0m     loss_forward_and_backward_dsmil(net, image_patches, labels, criterion, conf,\n\u001b[1;32m    105\u001b[0m                                     device, optimizer, metric_logger, log_writer)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m conf\u001b[38;5;241m.\u001b[39march \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclam_sb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclam_mb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 107\u001b[0m     \u001b[43mloss_forward_and_backward_clam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_writer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m conf\u001b[38;5;241m.\u001b[39march \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmil_spvis\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    110\u001b[0m     loss_forward_and_backward_bmil(net, image_patches, coords, labels, criterion, conf,\n\u001b[1;32m    111\u001b[0m                                    device, optimizer, metric_logger, log_writer)\n",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m, in \u001b[0;36mloss_forward_and_backward_clam\u001b[0;34m(net, image_patches, labels, criterion, conf, device, optimizer, metric_logger, log_writer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloss_forward_and_backward_clam\u001b[39m(net, image_patches, labels, criterion, conf,\n\u001b[1;32m      2\u001b[0m                                    device, optimizer, metric_logger, log_writer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     logits, instance_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[1;32m      6\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mw_loss \u001b[38;5;241m*\u001b[39m loss \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m conf\u001b[38;5;241m.\u001b[39mw_loss) \u001b[38;5;241m*\u001b[39m instance_loss\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/acmil/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/architecture/clam.py:178\u001b[0m, in \u001b[0;36mCLAM_SB.forward\u001b[0;34m(self, h, label, instance_eval, return_features, attention_only)\u001b[0m\n\u001b[1;32m    176\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_classifiers[i]\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inst_label \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# in-the-class:\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     instance_loss, preds, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     all_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    180\u001b[0m     all_targets\u001b[38;5;241m.\u001b[39mextend(targets\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/fh/fast/etzioni_r/Lucas/mh_proj/mutation_pred/other_model_code/ACMIL-main/architecture/clam.py:132\u001b[0m, in \u001b[0;36mCLAM_SB.inst_eval\u001b[0;34m(self, A, h, classifier)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    131\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m top_p_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_sample\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    133\u001b[0m top_p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mindex_select(h, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, index\u001b[38;5;241m=\u001b[39mtop_p_ids)\n\u001b[1;32m    134\u001b[0m top_n_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m-\u001b[39mA, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_sample, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "# define optimizer, lr not important at this point\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=conf.lr, weight_decay=conf.wd)\n",
    "\n",
    "best_state = {'epoch':-1, 'val_acc':0, 'val_auc':0, 'val_f1':0, 'test_acc':0, 'test_auc':0, 'test_f1':0}\n",
    "for epoch in range(conf.train_epoch):\n",
    "\n",
    "    train_one_epoch(model, criterion, train_loader, optimizer, device, epoch, conf)\n",
    "\n",
    "\n",
    "    val_auc, val_acc, val_f1, val_loss = evaluate(model, criterion, val_loader, device, conf, 'Val')\n",
    "    test_auc, test_acc, test_f1, test_loss = evaluate(model, criterion, test_loader, device, conf, 'Test')\n",
    "\n",
    "    if conf.wandb_mode != 'disabled':\n",
    "        wandb.log({'test/test_acc1': test_acc}, commit=False)\n",
    "        wandb.log({'test/test_auc': test_auc}, commit=False)\n",
    "        wandb.log({'test/test_f1': test_f1}, commit=False)\n",
    "        wandb.log({'test/test_loss': test_loss}, commit=False)\n",
    "        wandb.log({'val/val_acc1': val_acc}, commit=False)\n",
    "        wandb.log({'val/val_auc': val_auc}, commit=False)\n",
    "        wandb.log({'val/val_f1': val_f1}, commit=False)\n",
    "        wandb.log({'val/val_loss': val_loss}, commit=False)\n",
    "\n",
    "    if val_f1 + val_auc > best_state['val_f1'] + best_state['val_auc']:\n",
    "        best_state['epoch'] = epoch\n",
    "        best_state['val_auc'] = val_auc\n",
    "        best_state['val_acc'] = val_acc\n",
    "        best_state['val_f1'] = val_f1\n",
    "        best_state['test_auc'] = test_auc\n",
    "        best_state['test_acc'] = test_acc\n",
    "        best_state['test_f1'] = test_f1\n",
    "        # log_writer.summary('best_acc', val_acc)\n",
    "        save_model(conf=conf, model=model, optimizer=optimizer, epoch=epoch,\n",
    "                   save_path=os.path.join(ckpt_dir, 'checkpoint-best.pth'))\n",
    "    print('\\n')\n",
    "\n",
    "save_model(conf=conf, model=model, optimizer=optimizer, epoch=epoch,\n",
    "           save_path=os.path.join(ckpt_dir, 'checkpoint-last.pth'))\n",
    "print(\"Results on best epoch:\")\n",
    "print(best_state)\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9b5ff-be93-4f8d-b306-84aa105f19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(test_loader))\n",
    "feat = first_batch[0].to(device)\n",
    "sub_preds, slide_preds, attn = model(feat)\n",
    "slide_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d86b7f05-3c5c-4682-83f0-00c2a2df921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [ 0/44]  eta: 0:00:00    time: 0.0103  data: 0.0051  max mem: 3436\n",
      "  [43/44]  eta: 0:00:00    time: 0.0034  data: 0.0008  max mem: 3558\n",
      " Total time: 0:00:00 (0.0031 s / it)\n",
      "0.7451738119125366\n",
      "0.8409090638160706\n"
     ]
    }
   ],
   "source": [
    "# Set the network to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "y_predprob = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "metric_logger = MetricLogger(delimiter=\"  \")\n",
    "\n",
    "for data in metric_logger.log_every(test_loader, 100, None):\n",
    "    image_patches = data[0].to(device, dtype=torch.float32)\n",
    "    labels = data[1][0,:,6].to(device, dtype = torch.int64).to(device)\n",
    "\n",
    "\n",
    "    if conf.arch == 'dsmil':\n",
    "        # Compute loss\n",
    "        ins_preds, bag_preds, attn = model(image_patches)\n",
    "        max_preds, _ = torch.max(ins_preds, 0, keepdim=True)\n",
    "        loss = 0.5 * criterion(max_preds, labels) \\\n",
    "               + 0.5 * criterion(bag_preds, labels)\n",
    "        pred = 0.5 * torch.softmax(max_preds, dim=-1) \\\n",
    "               + 0.5 * torch.softmax(bag_preds, dim=-1)\n",
    "        pred_prob = torch.softmax(pred, dim=-1)[:,1]\n",
    "    elif conf.arch == 'bmil_spvis':\n",
    "        coords_array = coords.numpy()[0]\n",
    "        output, Y_prob, Y_hat, _, _ = net(image_patches, coords_array, coords_array[:, 1].max(),\n",
    "                                          coords_array[:, 0].max(), validation=True)\n",
    "        loss = criterion(output, labels)\n",
    "        pred = torch.softmax(output, dim=-1)\n",
    "    elif conf.arch in ('clam_sb', 'clam_mb'):\n",
    "        output = net(image_patches)\n",
    "        loss = criterion(output, labels)\n",
    "        pred = torch.softmax(output, dim=-1)\n",
    "    else:\n",
    "        # Compute loss   \n",
    "        output = model(image_patches)\n",
    "        loss = criterion(output, labels)\n",
    "        pred = torch.softmax(output, dim=-1)\n",
    "        pred_prob = torch.softmax(pred, dim=-1)[:,1]\n",
    "\n",
    "    y_predprob.append(pred_prob)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(labels)\n",
    "    \n",
    "y_predprob = torch.cat(y_predprob, dim=0)\n",
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "y_true = torch.cat(y_true, dim=0)\n",
    "\n",
    "AUROC_metric = torchmetrics.AUROC(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "AUROC_metric(y_pred, y_true)\n",
    "auroc = AUROC_metric.compute().item()\n",
    "F1_metric = torchmetrics.F1Score(num_classes = conf.n_class, task='multiclass').to(device)\n",
    "F1_metric(y_pred, y_true)\n",
    "f1_score = F1_metric.compute().item()\n",
    "print(auroc)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "685bd61d-89dd-4384-8915-a352011c04c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0444, -2.1475]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cd4a25a-9da6-4be5-b0ca-8c54a04c3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               AUC   ACC    F1    F2    F3  Recall  Precision  Specificity  \\\n",
      "SAMPLE_LEVEL  0.72  0.77  0.29  0.29  0.29    0.29       0.29         0.86   \n",
      "\n",
      "                PR_AUC  OUTCOME  \n",
      "SAMPLE_LEVEL  0.437791  MSI_POS  \n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#Predict\n",
    "####################################################################################\n",
    "\n",
    "#predicts\n",
    "test_pred_prob  = y_predprob\n",
    "test_true_label = y_true\n",
    "\n",
    "#Prediction df\n",
    "pred_df = pd.DataFrame({\"SAMPLE_IDs\":  test_ids, \n",
    "                            \"Y_True\": y_true.cpu().detach().numpy(), \n",
    "                            \"Pred_Prob\" :  test_pred_prob.cpu().detach().numpy(),\n",
    "                            \"OUTCOME\": 'MSI_POS'})\n",
    "\n",
    "#Add Predict class\n",
    "THRES = 0.28 #0.2\n",
    "pred_df['Pred_Class'] = 0\n",
    "pred_df.loc[pred_df['Pred_Prob'] > THRES,'Pred_Class'] = 1\n",
    "pred_df.to_csv(outdir4 + \"/pred_df.csv\",index = False)\n",
    "\n",
    "\n",
    "# #Compute performance\n",
    "perf_df = compute_performance_each_label(['MSI_POS'], pred_df, \"SAMPLE_LEVEL\")\n",
    "print(perf_df)\n",
    "# perf_df.to_csv(outdir5 + \"/perf.csv\",index = True)\n",
    "\n",
    "# print(perf_df.iloc[:,[0,5,6,7,8,9]])\n",
    "# print(\"AVG AUC:\", round(perf_df['AUC'].mean(),2))\n",
    "# print(\"AVG PRAUC:\", round(perf_df['PR_AUC'].mean(),2))\n",
    "# #Use regularization no dropout now has the best performance at avg AUC = 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a496a708-d63b-4daf-a3f7-90eafa2a5496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2711, 0.2809, 0.2698, 0.2712, 0.2706, 0.2798, 0.2755, 0.2707, 0.2727,\n",
       "        0.2744, 0.2699, 0.2743, 0.2709, 0.2695, 0.2744, 0.2711, 0.2701, 0.2703,\n",
       "        0.2821, 0.2701, 0.2699, 0.2717, 0.2711, 0.2856, 0.2702, 0.2834, 0.2713,\n",
       "        0.2708, 0.2971, 0.2720, 0.2699, 0.2716, 0.2696, 0.2699, 0.2729, 0.2706,\n",
       "        0.2704, 0.2746, 0.2708, 0.2707, 0.2704, 0.3191, 0.2899, 0.2730],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcf073-9bdf-4194-828c-c80d03e995d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################################################\n",
    "# #Atention scores\n",
    "# ####################################################################################\n",
    "# save_image_size = 250\n",
    "# pixel_overlap = 0\n",
    "# mag_extract = 20\n",
    "# limit_bounds = True\n",
    "# TOP_K = 5\n",
    "# pretrain_model_name = \"retccl\"\n",
    "# mag_target_prob = 2.5\n",
    "# smooth = False\n",
    "# mag_target_tiss = 1.25\n",
    "# #SELECTED_LABEL = [\"AR\",\"MMR (MSH2, MSH6, PMS2, MLH1, MSH3, MLH3, EPCAM)2\",\"PTEN\",\"RB1\",\"TP53\",\"TMB_HIGHorINTERMEDITATE\",\"MSI_POS\"]\n",
    "# #selected_outcome = 'RB1'\n",
    "# #selected_att_index = SELECTED_LABEL.index(selected_outcome)\n",
    "# selected_type = \"true_pos\"\n",
    "\n",
    "# # for selected_outcome in SELECTED_LABEL:\n",
    "# for selected_outcome in SELECTED_LABEL:\n",
    "#     selected_att_index = SELECTED_LABEL.index(selected_outcome)\n",
    "\n",
    "#     selected_ids = true_postive_ids['MSI_POS']\n",
    "#     for tp_pt in selected_ids:\n",
    "#         i = test_ids.index(tp_pt)\n",
    "#         pt = test_ids[i]\n",
    "#         print(pt)\n",
    "    \n",
    "#         save_location = outdir4 + selected_outcome + \"/\" + selected_type + \"/\"\n",
    "#         save_location =  save_location  + pt + \"/\"\n",
    "#         create_dir_if_not_exists(save_location)\n",
    "        \n",
    "#         _file = wsi_path + pt + \".tif\"\n",
    "#         oslide = openslide.OpenSlide(_file)\n",
    "#         save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "        \n",
    "        \n",
    "#         #Get a Attention, and corresponding tiles\n",
    "#         cur_pt_att = test_att[i][selected_att_index]\n",
    "#         cur_pt_info = test_info[i]\n",
    "#         cur_att_df = get_attention_and_tileinfo(cur_pt_info, cur_pt_att)\n",
    "        \n",
    "        \n",
    "#         #Generate tiles\n",
    "#         tiles, tile_lvls, physSize, base_mag = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "        \n",
    "#         #get level 0 size in px\n",
    "#         l0_w = oslide.level_dimensions[0][0]\n",
    "#         l0_h = oslide.level_dimensions[0][1]\n",
    "        \n",
    "#         #1.25x tissue detection for mask\n",
    "#         from Utils import get_downsample_factor, get_image_at_target_mag\n",
    "#         from Utils import do_mask_original,check_tissue,whitespace_check\n",
    "#         import cv2\n",
    "#         if 'OPX' in pt:\n",
    "#             rad_tissue = 5\n",
    "#         elif '(2017-0133)' in pt:\n",
    "#             rad_tissue = 2\n",
    "#         lvl_resize_tissue = get_downsample_factor(base_mag,target_magnification = mag_target_tiss) #downsample factor\n",
    "#         lvl_img = get_image_at_target_mag(oslide,l0_w, l0_h,lvl_resize_tissue)\n",
    "#         tissue, he_mask = do_mask_original(lvl_img, lvl_resize_tissue, rad = rad_tissue)\n",
    "        \n",
    "#         #2.5x for probability maps\n",
    "#         lvl_resize = get_downsample_factor(base_mag,target_magnification = mag_target_prob) #downsample factor\n",
    "#         x_map = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "#         x_count = np.zeros((int(np.ceil(l0_h/lvl_resize)),int(np.ceil(l0_w/lvl_resize))), float)\n",
    "        \n",
    "#         cur_att_df['pred_map_location'] = pd.NA\n",
    "#         for index, row in cur_att_df.iterrows():\n",
    "#             cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "#             x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "            \n",
    "#             #Extract tile for prediction\n",
    "#             lvl_in_deepzoom = tile_lvls.index(mag_extract)\n",
    "#             tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #get tile coords\n",
    "#             map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "#             cur_att_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "        \n",
    "#             #Store predicted probabily in map and count\n",
    "#             try: \n",
    "#                 x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "#                 x_map[map_xstart:map_xend,map_ystart:map_yend] += row['ATT']\n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "#         print('post-processing')\n",
    "#         x_count = np.where(x_count < 1, 1, x_count)\n",
    "#         x_map = x_map / x_count\n",
    "#         x_map[x_map>1]=1\n",
    "        \n",
    "#         if smooth == True:\n",
    "#             x_sm = filters.gaussian(x_map, sigma=2)\n",
    "#         if smooth == False:\n",
    "#             x_sm = x_map\n",
    "        \n",
    "#         he_mask = cv2.resize(np.uint8(he_mask),(x_sm.shape[1],x_sm.shape[0])) #resize to output image size\n",
    "#         #TODO:\n",
    "#         #get cancer_mask:\n",
    "#         # cancer_mask == \n",
    "#         # x_sm[(he_mask == 1) & (x_sm == 0)] = 0.1 #If tissue map value > 1, then x_sm = 1\n",
    "#         x_sm[he_mask < 1] = 0.001 \n",
    "        \n",
    "#         plt.imshow(x_sm, cmap='Spectral_r')\n",
    "#         plt.colorbar()\n",
    "#         plt.savefig(os.path.join(save_location, save_name + '_attention.png'), dpi=500,bbox_inches='tight')\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "        \n",
    "        \n",
    "#         #Top attented tiles\n",
    "#         save_location2 = save_location + \"top_tiles/\"\n",
    "#         create_dir_if_not_exists(save_location2)\n",
    "        \n",
    "#         #Get a Attention, and corresponding tiles\n",
    "#         cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = False) \n",
    "#         cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "        \n",
    "#         for i in range(TOP_K):\n",
    "#             cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#             cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#             cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#             coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#             tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#             cur_pulled_img.save(os.path.join(save_location2, tile_save_name))\n",
    "        \n",
    "#         #Bot attented tiles\n",
    "#         save_location2 = save_location + \"bot_tiles/\"\n",
    "#         create_dir_if_not_exists(save_location2)\n",
    "        \n",
    "#         #Get a Attention, and corresponding tiles\n",
    "#         cur_att_df= cur_att_df.sort_values(by = ['ATT'], ascending = True) \n",
    "#         cur_pulled_img_obj = pull_tiles(cur_att_df.iloc[0:TOP_K], tiles, tile_lvls)\n",
    "        \n",
    "#         for i in range(TOP_K):\n",
    "#             cur_pulled_img = cur_pulled_img_obj[i][0] #image\n",
    "#             cur_pulled_att = cur_pulled_img_obj[i][1] #attentiom\n",
    "#             cur_pulled_coord = cur_pulled_img_obj[i][2].strip(\"()\").split(\", \")  #att tile map coordiates\n",
    "#             coord_save_name = '[xs' + cur_pulled_coord[0] + '_xe' + cur_pulled_coord[1] + '_ys' + cur_pulled_coord[2] + '_ye' + cur_pulled_coord[3] + \"]\"\n",
    "#             tile_save_name = \"ATT\" + str(round(cur_pulled_att,2)) + \"_MAPCOORD\" +  coord_save_name +  \".png\"\n",
    "#             cur_pulled_img.save(os.path.join(save_location2, tile_save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
