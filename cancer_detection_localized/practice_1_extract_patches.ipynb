{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32745ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jliu6/anaconda3/envs/paimg1/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/jliu6/anaconda3/envs/paimg1/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import openslide\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import geojson\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import PIL\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from skimage import draw, measure, morphology, filters\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon, shape\n",
    "from shapely.ops import cascaded_union, unary_union\n",
    "import json\n",
    "import shapely\n",
    "import warnings\n",
    "from scipy import ndimage\n",
    "import h5py\n",
    "from Utils import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086cc468-27b6-4118-8547-32e3e2e087cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.0\n",
      "fastai: 2.7.12\n",
      "torch: 2.0.1\n",
      "torchvision: 0.15.2\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from platform import python_version\n",
    "print(\"Python: \" + python_version())\n",
    "print(\"fastai: \" + fastai.__version__)\n",
    "print(\"torch: \" + torch.__version__)\n",
    "print(\"torchvision: \" + torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd3609d-390c-4f56-9e5d-8a49fecd96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_if_not_exists(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Directory '{dir_path}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{dir_path}' already exists.\")\n",
    "\n",
    "\n",
    "def generate_deepzoom_tiles(slide, save_image_size, pixel_overlap, limit_bounds):\n",
    "    # this is physical microns per pixel\n",
    "    acq_mag = 10.0/float(slide.properties[openslide.PROPERTY_NAME_MPP_X])\n",
    "\n",
    "    # this is nearest multiple of 20 for base layer\n",
    "    base_mag = int(20 * round(float(acq_mag) / 20))\n",
    "\n",
    "    # this is how much we need to resample our physical patches for uniformity across studies\n",
    "    physSize = round(save_image_size*acq_mag/base_mag)\n",
    "\n",
    "    # grab tiles accounting for the physical size we need to pull for standardized tile size across studies\n",
    "    tiles = DeepZoomGenerator(slide, tile_size=physSize-round(pixel_overlap*acq_mag/base_mag), overlap=round(pixel_overlap*acq_mag/base_mag/2), \n",
    "                              limit_bounds=limit_bounds)\n",
    "\n",
    "    # calculate the effective magnification at each level of tiles, determined from base magnification\n",
    "    tile_lvls = tuple(base_mag/(tiles._l_z_downsamples[i]*tiles._l0_l_downsamples[tiles._slide_from_dz_level[i]]) for i in range(0,tiles.level_count))\n",
    "\n",
    "    return tiles, tile_lvls, physSize\n",
    "\n",
    "\n",
    "def extract_tile_start_end_coords(all_tile, deepzoom_lvl, x_loc, y_loc):\n",
    "    r'''\n",
    "    #This func returns the coordiates in the reference level 0 pixels\n",
    "    '''\n",
    "    #Get coords\n",
    "    tile_coords = all_tile.get_tile_coordinates(deepzoom_lvl, (x_loc, y_loc))\n",
    "\n",
    "    #Get top left pixel coordinates\n",
    "    topleft_x = tile_coords[0][0]\n",
    "    topleft_y = tile_coords[0][1]\n",
    "\n",
    "    #Get level (original)\n",
    "    o_lvl = tile_coords[1]\n",
    "\n",
    "    #Get downsample factor\n",
    "    ds_factor = all_tile._l0_l_downsamples[o_lvl] #downsample factor\n",
    "\n",
    "    #Get region size in current level \n",
    "    rsize_x = tile_coords[2][0] \n",
    "    rsize_y = tile_coords[2][1] \n",
    "\n",
    "    #Get tile starts and end   \n",
    "    start_loc = tile_coords[0] #start\n",
    "    end_loc = (int(topleft_x + ds_factor * rsize_x), int(topleft_y + ds_factor* rsize_y)) #end\n",
    "\n",
    "    #Get save coord name (first two is the starting loc, and the last two are the x and y size considering dsfactor)\n",
    "    coord_name = str(topleft_x) + \"-\" + str(topleft_y) + \"_\" + '%.0f' % (ds_factor * rsize_x) + \"-\" + '%.0f' % (ds_factor * rsize_y)\n",
    "    \n",
    "    return start_loc, end_loc, coord_name, tile_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ed8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_wd = '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/'\n",
    "save_location = cur_wd + 'intermediate_data/cancer_prediction_results102824/'  \n",
    "save_location2 = cur_wd + 'intermediate_data/cancer_prediction_results102824/tiles/'  \n",
    "save_location3 = cur_wd + 'intermediate_data/cancer_prediction_results102824/cancer_pred_out/'  \n",
    "mag_extract = 20 # do not change this, model trained at 250x250 at 20x\n",
    "save_image_size = 250  # do not change this, model trained at 250x250 at 20x\n",
    "pixel_overlap = 100  # specify the level of pixel overlap in your saved images\n",
    "limit_bounds = True  # this is weird, dont change it\n",
    "tiff_lvl =2 # low res pyramid level to grab\n",
    "save_location4 = save_location3 + str(pixel_overlap) + 'and' + str(tiff_lvl)  # args.save_location\n",
    "save_location6 = save_location2 + str(pixel_overlap) + 'and' + str(tiff_lvl)  # args.save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4f1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/tiles/' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/tiles/100and2' created.\n"
     ]
    }
   ],
   "source": [
    "create_dir_if_not_exists(save_location)\n",
    "create_dir_if_not_exists(save_location2)\n",
    "create_dir_if_not_exists(save_location3)\n",
    "create_dir_if_not_exists(save_location4)\n",
    "create_dir_if_not_exists(save_location6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ad4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_id = 'OPX_020'\n",
    "# _file = cur_wd + \"data/OPX/\" + cur_id + \".tif\"\n",
    "\n",
    "# cur_id = '(2017-0133) 15-B_A1-2' \n",
    "# _file = '/fh/scratch/delete90/haffner_m/user/scan_archives/Prostate/MDAnderson/CCola/all_slides/' + cur_id + '.svs'\n",
    "\n",
    "selected_ids = ['OPX_007','OPX_010','OPX_033','OPX_049','OPX_077','OPX_090','OPX_182','OPX_185','OPX_186','OPX_194']\n",
    "\n",
    "for cur_id in selected_ids:\n",
    "    _file = cur_wd + \"data/OPX/\" + cur_id + \".tif\"\n",
    "    #Load slides\n",
    "    oslide = openslide.OpenSlide(_file)\n",
    "    save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "    \n",
    "    save_location5 = save_location4 + \"/\" + cur_id + \"/\" \n",
    "    create_dir_if_not_exists(save_location5)\n",
    "    \n",
    "    #Generate tiles\n",
    "    tiles, tile_lvls, physSize = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "    \n",
    "    \n",
    "    #Get low res image,  intermeadiate level for probability map\n",
    "    slide_dim = oslide.level_dimensions[tiff_lvl] #slide dim at tiff_lvl\n",
    "    lvl_resize = oslide.level_downsamples[tiff_lvl] #downsample factor\n",
    "    lvl_img = oslide.read_region((0, 0), tiff_lvl, slide_dim)\n",
    "    lvl_img.save(os.path.join(save_location5 + save_name + '_low-res.png'))\n",
    "    \n",
    "    \n",
    "    # send to get tissue polygons\n",
    "    print('detecting tissue')\n",
    "    tissue, he_mask = do_mask_original(lvl_img,lvl_resize)\n",
    "    \n",
    "    #init x_map and x_count at intermeadiate level size\n",
    "    x_map   = np.zeros((lvl_img.size[1], lvl_img.size[0]), float)\n",
    "    x_count = np.zeros((lvl_img.size[1], lvl_img.size[0]), float)\n",
    "    \n",
    "    \n",
    "    lvl =  mag_extract\n",
    "    if lvl in tile_lvls:\n",
    "        lvl_in_deepzoom = tile_lvls.index(lvl)\n",
    "        # pull tile info for level\n",
    "        x_tiles, y_tiles = tiles.level_tiles[lvl_in_deepzoom] #this extract tiles at mag_extract\n",
    "        print(x_tiles, y_tiles)\n",
    "        tile_info = []\n",
    "        for y in range(0, y_tiles):\n",
    "            if y % 50 == 0: print(y)\n",
    "            for x in range(0, x_tiles):\n",
    "                #Grab tile coordinates\n",
    "                tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, lvl_in_deepzoom, x, y) #this returns the coors at level 0 reference original slides\n",
    "                \n",
    "                #Check tissue membership\n",
    "                tile_tiss = check_tissue(tile_starts= tile_starts, tile_ends=tile_ends,roi=tissue)\n",
    "                if tile_tiss > 0.9: #If the tile has more than 90% tissue coverage\n",
    "                    #Extract tile\n",
    "                    tile_pull = tiles.get_tile(lvl_in_deepzoom, (x, y))\n",
    "                \n",
    "                    #Check white space\n",
    "                    ws = whitespace_check(im=tile_pull)\n",
    "                    \n",
    "                    if ws < 0.95: #. If the white space is less than 95%\n",
    "                        tile_info.append(pd.DataFrame({'SAMPLE_ID' : save_name, \n",
    "                                                       'MAG_EXTRACT' : lvl,\n",
    "                                                       'SAVE_IMAGE_SIZE': save_image_size,\n",
    "                                                       'PIXEL_OVERLAP': pixel_overlap,\n",
    "                                                       'TIFF_LVL': tiff_lvl,\n",
    "                                                       'LIMIT_BOUNDS': limit_bounds,\n",
    "                                                       'TILE_XY_INDEXES' : str((x ,y)),\n",
    "                                                       'TILE_COOR_ATLV0' : save_coords,\n",
    "                                                       'WHITE_SPACE' : ws,\n",
    "                                                       'TISSUE_COVERAGE': tile_tiss}, index = [0]))\n",
    "    \n",
    "    tile_info_df = pd.concat(tile_info)\n",
    "    tile_info_df.to_csv(save_location6 + save_name + \".csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
