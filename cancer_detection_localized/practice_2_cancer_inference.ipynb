{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32745ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jliu6/anaconda3/envs/paimg1/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/jliu6/anaconda3/envs/paimg1/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import openslide\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import geojson\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import PIL\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from skimage import draw, measure, morphology, filters\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon, shape\n",
    "from shapely.ops import cascaded_union, unary_union\n",
    "import json\n",
    "import shapely\n",
    "import warnings\n",
    "from scipy import ndimage\n",
    "import h5py\n",
    "from Utils import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086cc468-27b6-4118-8547-32e3e2e087cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.0\n",
      "fastai: 2.7.12\n",
      "torch: 2.0.1\n",
      "torchvision: 0.15.2\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from platform import python_version\n",
    "print(\"Python: \" + python_version())\n",
    "print(\"fastai: \" + fastai.__version__)\n",
    "print(\"torch: \" + torch.__version__)\n",
    "print(\"torchvision: \" + torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd3609d-390c-4f56-9e5d-8a49fecd96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_if_not_exists(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Directory '{dir_path}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{dir_path}' already exists.\")\n",
    "\n",
    "\n",
    "def generate_deepzoom_tiles(slide, save_image_size, pixel_overlap, limit_bounds):\n",
    "    # this is physical microns per pixel\n",
    "    acq_mag = 10.0/float(slide.properties[openslide.PROPERTY_NAME_MPP_X])\n",
    "\n",
    "    # this is nearest multiple of 20 for base layer\n",
    "    base_mag = int(20 * round(float(acq_mag) / 20))\n",
    "\n",
    "    # this is how much we need to resample our physical patches for uniformity across studies\n",
    "    physSize = round(save_image_size*acq_mag/base_mag)\n",
    "\n",
    "    # grab tiles accounting for the physical size we need to pull for standardized tile size across studies\n",
    "    tiles = DeepZoomGenerator(slide, tile_size=physSize-round(pixel_overlap*acq_mag/base_mag), overlap=round(pixel_overlap*acq_mag/base_mag/2), \n",
    "                              limit_bounds=limit_bounds)\n",
    "\n",
    "    # calculate the effective magnification at each level of tiles, determined from base magnification\n",
    "    tile_lvls = tuple(base_mag/(tiles._l_z_downsamples[i]*tiles._l0_l_downsamples[tiles._slide_from_dz_level[i]]) for i in range(0,tiles.level_count))\n",
    "\n",
    "    return tiles, tile_lvls, physSize\n",
    "\n",
    "\n",
    "def extract_tile_start_end_coords(all_tile, deepzoom_lvl, x_loc, y_loc):\n",
    "    r'''\n",
    "    #This func returns the coordiates in the reference level 0 pixels\n",
    "    '''\n",
    "    #Get coords\n",
    "    tile_coords = all_tile.get_tile_coordinates(deepzoom_lvl, (x_loc, y_loc))\n",
    "\n",
    "    #Get top left pixel coordinates\n",
    "    topleft_x = tile_coords[0][0]\n",
    "    topleft_y = tile_coords[0][1]\n",
    "\n",
    "    #Get level (original)\n",
    "    o_lvl = tile_coords[1]\n",
    "\n",
    "    #Get downsample factor\n",
    "    ds_factor = all_tile._l0_l_downsamples[o_lvl] #downsample factor\n",
    "\n",
    "    #Get region size in current level \n",
    "    rsize_x = tile_coords[2][0] \n",
    "    rsize_y = tile_coords[2][1] \n",
    "\n",
    "    #Get tile starts and end   \n",
    "    start_loc = tile_coords[0] #start\n",
    "    end_loc = (int(topleft_x + ds_factor * rsize_x), int(topleft_y + ds_factor* rsize_y)) #end\n",
    "\n",
    "    #Get save coord name (first two is the starting loc, and the last two are the x and y size considering dsfactor)\n",
    "    coord_name = str(topleft_x) + \"-\" + str(topleft_y) + \"_\" + '%.0f' % (ds_factor * rsize_x) + \"-\" + '%.0f' % (ds_factor * rsize_y)\n",
    "    \n",
    "    return start_loc, end_loc, coord_name, tile_coords\n",
    "\n",
    "def get_map_startend(tile_start_cord, tile_end_cord, level_resize):\n",
    "    m_xstart = int(np.floor(tile_start_cord[1] / level_resize))\n",
    "    m_xend = int(np.floor(tile_end_cord[1] / level_resize))\n",
    "    m_ystart = int(np.floor(tile_start_cord[0] / level_resize))\n",
    "    m_yend = int(np.floor(tile_end_cord[0] / level_resize))\n",
    "\n",
    "    return m_xstart, m_xend, m_ystart, m_yend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ed8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_wd = '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/'\n",
    "save_location = cur_wd + 'intermediate_data/cancer_prediction_results102824/'  \n",
    "save_location2 = cur_wd + 'intermediate_data/cancer_prediction_results102824/tiles/'  \n",
    "save_location3 = cur_wd + 'intermediate_data/cancer_prediction_results102824/cancer_pred_out/'  \n",
    "mag_extract = 20 # do not change this, model trained at 250x250 at 20x\n",
    "save_image_size = 250  # do not change this, model trained at 250x250 at 20x\n",
    "pixel_overlap = 100  # specify the level of pixel overlap in your saved images\n",
    "limit_bounds = True  # this is weird, dont change it\n",
    "tiff_lvl =2 # low res pyramid level to grab\n",
    "binary_pred_thres = 0.8 #binary prediction thres\n",
    "ft_model = True\n",
    "model_path_m = cur_wd + 'models/cancer_detection_models/mets/ft_models/dlv3_2ep_2e4_update-07182023_RT_fine_tuned..pkl'\n",
    "model_path_m_prior = cur_wd + 'models/cancer_detection_models/mets/dlv3_2ep_2e4_update-07182023_RT.pkl'\n",
    "    \n",
    "#model_path_l = cur_wd + 'models/cancer_detection_models/local/binary_mblntv3_25ep_lr1e5_wAug_MixUpLS_sz500_bs12_10x.pkl'\n",
    "data_mut_path = cur_wd + 'data/MutationCalls/'\n",
    "save_location4 = save_location3 + str(pixel_overlap) + 'and' + str(tiff_lvl)  # args.save_location\n",
    "save_location6 = save_location2 + str(pixel_overlap) + 'and' + str(tiff_lvl)  # args.save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4f1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/tiles/' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/' already exists.\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2' already exists.\n"
     ]
    }
   ],
   "source": [
    "create_dir_if_not_exists(save_location)\n",
    "create_dir_if_not_exists(save_location2)\n",
    "create_dir_if_not_exists(save_location3)\n",
    "create_dir_if_not_exists(save_location4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37626018-bd73-4c5b-b9eb-c5db08b46611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #load mutation site\n",
    "# mut_site_df = pd.read_excel(data_mut_path + 'OPX_anatomic sites.xlsx')\n",
    "# mut_site_df\n",
    "# mets_ids = list(mut_site_df.loc[mut_site_df['Anatomic site']!= 'Prostate', 'OPX_Number'])\n",
    "# local_ids = list(mut_site_df.loc[mut_site_df['Anatomic site']== 'Prostate', 'OPX_Number'])\n",
    "# len(mets_ids)\n",
    "# len(local_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b7945a-f833-4225-8f2c-bb277989dbdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#All files list\n",
    "#flist=sorted(glob.glob(cur_wd + '/data/OPX/*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ea6def-8ca6-4d6d-8ec9-2b19d2162725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select IDs\n",
    "# selected_ids = mets_ids #mets_ids, local_ids\n",
    "# print(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea77f11d-6fb0-463a-a9a4-484623d957d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPX_049\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_049/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "post-processing\n",
      "detecting tissue\n",
      "OPX_077\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_077/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "post-processing\n",
      "detecting tissue\n",
      "OPX_090\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_090/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "post-processing\n",
      "detecting tissue\n",
      "OPX_182\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_182/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "post-processing\n",
      "detecting tissue\n",
      "OPX_185\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_185/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "post-processing\n",
      "detecting tissue\n",
      "OPX_186\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_186/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n",
      "50000\n",
      "50500\n",
      "51000\n",
      "51500\n",
      "52000\n",
      "52500\n",
      "53000\n",
      "53500\n",
      "54000\n",
      "54500\n",
      "55000\n",
      "55500\n",
      "56000\n",
      "56500\n",
      "57000\n",
      "57500\n",
      "58000\n",
      "58500\n",
      "59000\n",
      "59500\n",
      "60000\n",
      "60500\n",
      "61000\n",
      "post-processing\n",
      "detecting tissue\n",
      "OPX_194\n",
      "Directory '/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/cancer_prediction_results102824/cancer_pred_out/100and2/OPX_194/' already exists.\n",
      "True\n",
      "starting inference\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "post-processing\n",
      "detecting tissue\n"
     ]
    }
   ],
   "source": [
    "selected_ids = ['OPX_049','OPX_077','OPX_090','OPX_182','OPX_185','OPX_186','OPX_194']\n",
    "for cur_id in selected_ids:\n",
    "    print(cur_id)\n",
    "    _file = cur_wd + \"data/OPX/\" + cur_id + \".tif\"\n",
    "    # cur_id = '(2017-0133) 15-B_A1-2'\n",
    "    # _file = '/fh/scratch/delete90/haffner_m/user/scan_archives/Prostate/MDAnderson/CCola/all_slides/' + cur_id + '.svs'\n",
    "    oslide = openslide.OpenSlide(_file)\n",
    "    save_name = str(Path(os.path.basename(_file)).with_suffix(''))\n",
    "    \n",
    "    save_location5 = save_location4 + \"/\" + cur_id + \"/\" \n",
    "    create_dir_if_not_exists(save_location5)\n",
    "    \n",
    "    if ft_model == False:\n",
    "        save_location5 = save_location5 + \"/\" + \"prior_model\" + \"/\"\n",
    "        create_dir_if_not_exists(save_location5)\n",
    "    \n",
    "    \n",
    "    #get local or mets\n",
    "    # site = mut_site_df.loc[mut_site_df['OPX_Number'] == cur_id,'Anatomic site'].item()\n",
    "    # print(site)\n",
    "    #load pytorch model\n",
    "    learn = load_learner(model_path_m,cpu=False) #all use mets model\n",
    "    \n",
    "    if ft_model == True:\n",
    "        learn = load_learner(model_path_m,cpu=False) #all use mets model\n",
    "    else: \n",
    "        learn = load_learner(model_path_m_prior,cpu=False) #all use prior mets model\n",
    "    \n",
    "    # if site == \"Prostate\":\n",
    "    #     learn = load_learner(model_path_l,cpu=False)\n",
    "    # else:\n",
    "    #     learn = load_learner(model_path_m,cpu=False)\n",
    "    \n",
    "    \n",
    "    #Load tile info \n",
    "    tile_info_df = pd.read_csv(save_location6 + \"/\" + save_name + \".csv\")\n",
    "    tile_mag_extract = list(set(tile_info_df['MAG_EXTRACT']))[0]\n",
    "    tile_save_image_size = list(set(tile_info_df['SAVE_IMAGE_SIZE']))[0]\n",
    "    tile_pixel_overlap = list(set(tile_info_df['PIXEL_OVERLAP']))[0]\n",
    "    tile_limit_bounds =   list(set(tile_info_df['LIMIT_BOUNDS']))[0]\n",
    "    tile_tiff_lvl =  list(set(tile_info_df['TIFF_LVL']))[0]\n",
    "    \n",
    "    cond1 = (tile_mag_extract == mag_extract)\n",
    "    cond2 = (tile_save_image_size == save_image_size)\n",
    "    cond3 = (tile_pixel_overlap == pixel_overlap)\n",
    "    cond4 = (tile_limit_bounds == limit_bounds)\n",
    "    cond5 = (tile_tiff_lvl == tiff_lvl)\n",
    "    \n",
    "    if cond1 & cond2 & cond3 & cond4 & cond5 :\n",
    "        can_proceed = True\n",
    "        print(can_proceed)\n",
    "\n",
    "    print(tile_info_df.shape)\n",
    "    if can_proceed == True:\n",
    "        #Generate tiles\n",
    "        tiles, tile_lvls, physSize = generate_deepzoom_tiles(oslide,save_image_size, pixel_overlap, limit_bounds)\n",
    "        \n",
    "        #Get low res image,  intermeadiate level for probability map\n",
    "        slide_dim = oslide.level_dimensions[tiff_lvl] #slide dim at tiff_lvl\n",
    "        lvl_resize = oslide.level_downsamples[tiff_lvl] #downsample factor\n",
    "        \n",
    "        print('starting inference')\n",
    "        #init x_map and x_count at intermeadiate level size\n",
    "        x_map   = np.zeros((slide_dim[1], slide_dim[0]), float)\n",
    "        x_count = np.zeros((slide_dim[1], slide_dim[0]), float)\n",
    "        \n",
    "        tile_info_df['pred_map_location'] = pd.NA\n",
    "        for index, row in tile_info_df.iterrows():\n",
    "            if (index % 500 == 0): print(index)\n",
    "            cur_xy = row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "            x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "            \n",
    "            #Extract tile for prediction\n",
    "            tile_pull = tiles.get_tile(tile_lvls.index(mag_extract), (x, y))\n",
    "            tile_pull = tile_pull.resize(size=(save_image_size, save_image_size),resample=PIL.Image.LANCZOS) #resize\n",
    "            tile_starts, tile_ends, save_coords, tile_coords = extract_tile_start_end_coords(tiles, tile_lvls.index(mag_extract), x, y)\n",
    "            map_xstart, map_xend, map_ystart, map_yend = get_map_startend(tile_starts,tile_ends,lvl_resize) #Get current tile position in map\n",
    "            tile_info_df.loc[index,'pred_map_location'] = str(tuple([map_xstart, map_xend, map_ystart, map_yend]))\n",
    "            #Cancer segmentation\n",
    "            tile_pull = np.array(tile_pull)\n",
    "            \n",
    "            with learn.no_bar():\n",
    "                inp, pred_class, pred_idx, outputs = learn.predict(tile_pull[:, :, 0:3], with_input=True)\n",
    "            \n",
    "            #Get predicted output\n",
    "            outputs_np = outputs.numpy() #[N_CLASS, IMAGE_SIZE, IMAGE_SIZE]\n",
    "            output_c1 = PIL.Image.fromarray(outputs_np[1]) #Convert predicted class 1 probabliy to image\n",
    "            output_c1 = output_c1.resize(size=(map_xend - map_xstart, map_yend - map_ystart),resample=PIL.Image.LANCZOS) #resize for low-res\n",
    "            output_c1_np = np.array(output_c1)\n",
    "            \n",
    "            #Store predicted probabily in map and count\n",
    "            try: \n",
    "                x_count[map_xstart:map_xend,map_ystart:map_yend] += 1\n",
    "                x_map[map_xstart:map_xend,map_ystart:map_yend] += output_c1_np[1]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print('post-processing')\n",
    "        x_count = np.where(x_count < 1, 1, x_count)\n",
    "        x_map = x_map / x_count\n",
    "        slideimg = PIL.Image.fromarray(np.uint8(x_map * 255))\n",
    "        slideimg = slideimg.convert('L')\n",
    "        \n",
    "        cmap = plt.get_cmap('jet')\n",
    "        rgba_img = cmap(x_map)\n",
    "        rgb_img = np.delete(rgba_img, 3, 2)\n",
    "        colimg = PIL.Image.fromarray(np.uint8(rgb_img * 255))\n",
    "        colimg.save(os.path.join(save_location5, save_name + '_cancer_prob.jpeg'))\n",
    "        \n",
    "        # send to get tissue polygons\n",
    "        print('detecting tissue')\n",
    "        lvl_img = oslide.read_region((0, 0), tiff_lvl, slide_dim)\n",
    "        tissue, he_mask = do_mask_original(lvl_img,lvl_resize)\n",
    "        \n",
    "        #Binary classification\n",
    "        binary_preds = cancer_mask2(slideimg,he_mask, binary_pred_thres) \n",
    "        \n",
    "        #Output annotation\n",
    "        polygons = tile_ROIS(mask_arr=binary_preds, lvl_resize=lvl_resize)\n",
    "        slide_ROIS(polygons=polygons, mpp=float(oslide.properties[openslide.PROPERTY_NAME_MPP_X]),\n",
    "                        savename=os.path.join(save_location5,save_name+'_cancer.json'), labels='AI_tumor', ref=[0,0], roi_color=-16711936)\n",
    "        slide_ROIS(polygons=tissue, mpp=float(oslide.properties[openslide.PROPERTY_NAME_MPP_X]),\n",
    "                        savename=os.path.join(save_location5,save_name+'_tissue.json'), labels='tissue', ref=[0,0], roi_color=-16770432)\n",
    "        \n",
    "        \n",
    "        #Get binary prediction for each tile\n",
    "        #NOTE: prevoiuse do x_map when predition, is not accuate, because the x_map may change as process to the next tile, so need to to this in post processing\n",
    "        tile_info_df['TUMOR_PIXEL_PERC'] = pd.NA\n",
    "        for index, row in tile_info_df.iterrows():\n",
    "            cur_map_loc = row['pred_map_location'].strip(\"()\").split(\", \")\n",
    "            map_xstart, map_xend, map_ystart, map_yend = int(cur_map_loc[0]),int(cur_map_loc[1]), int(cur_map_loc[2]), int(cur_map_loc[3])\n",
    "        \n",
    "            #Get current prediction\n",
    "            cur_pred = binary_preds[map_xstart:map_xend,map_ystart:map_yend]\n",
    "            cur_count1 = np.sum(cur_pred == 1)\n",
    "            cur_perc1  = (cur_count1 / cur_pred.size)\n",
    "            tile_info_df.loc[index,'TUMOR_PIXEL_PERC'] = cur_perc1\n",
    "        \n",
    "        tile_info_df.to_csv(save_location5 + save_name + \"_TILE_TUMOR_PERC.csv\", index = False)\n",
    "        \n",
    "        \n",
    "        #Grab tiles and plot\n",
    "        tile_info_df_gt05 = tile_info_df.sort_values(by = ['TUMOR_PIXEL_PERC'], ascending = False) \n",
    "        for i in range(0,5): #top5\n",
    "            cur_row = tile_info_df_gt05.iloc[i]\n",
    "            cur_xy = cur_row['TILE_XY_INDEXES'].strip(\"()\").split(\", \")\n",
    "            x ,y = int(cur_xy[0]) , int(cur_xy[1])\n",
    "            tile_pull_ex = tiles.get_tile(tile_lvls.index(mag_extract), (x, y))\n",
    "            tile_pull_ex = tile_pull_ex.resize(size=(save_image_size, save_image_size),resample=PIL.Image.LANCZOS) #resize\n",
    "            tile_pull_ex.save(os.path.join(save_location5, \"EX_TILE\"  + str(i) + \".png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
