{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b6ccf7-72e8-4407-89f8-873cb49b97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import openslide\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from skimage import draw, measure, morphology, filters\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon, shape\n",
    "from shapely.ops import cascaded_union, unary_union\n",
    "import numpy as np\n",
    "from cucim import CuImage\n",
    "from cucim.clara.cache import preferred_memory_capacity\n",
    "from openslide import OpenSlide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d9a583-da28-4dfb-9e2b-e1d4d2e5db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepZoomGeneratorCucim(DeepZoomGenerator):\n",
    "    \"\"\"Create a DeepZoomGenerator, but instead of utilizing OpenSlide,\n",
    "    use cucim to read regions.\n",
    "\n",
    "    Args:\n",
    "        osr (OpenSlide): OpenSlide Image. Needed for OS compatibility and for retrieving metadata.\n",
    "        cucim_slide (CuImage): CuImage slide. Used for retrieving image data.\n",
    "        tile_size (int, optional): the width and height of a single tile.  For best viewer\n",
    "                      performance, tile_size + 2 * overlap should be a power\n",
    "                      of two.. Defaults to 254.\n",
    "        overlap (int, optional): the number of extra pixels to add to each interior edge\n",
    "                      of a tile. Defaults to 1.\n",
    "        limit_bounds (bool, optional): True to render only the non-empty slide region. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        osr: OpenSlide,\n",
    "        cucim_slide: CuImage,\n",
    "        tile_size: int = 254,\n",
    "        overlap: int = 1,\n",
    "        limit_bounds=False,\n",
    "    ):\n",
    "        super().__init__(osr, tile_size, overlap, limit_bounds)\n",
    "\n",
    "        self._cucim_slide = cucim_slide\n",
    "        self.memory_capacity = preferred_memory_capacity(\n",
    "            self._cucim_slide, patch_size=(tile_size, tile_size)\n",
    "        )\n",
    "        self.cache = CuImage.cache(\n",
    "            \"per_process\", memory_capacity=self.memory_capacity, record_stat=True\n",
    "        )\n",
    "\n",
    "    def get_tile(self, level: int, address: tuple[int]) -> Image:\n",
    "        \"\"\"Return an RGB PIL.Image for a tile\n",
    "\n",
    "        Args:\n",
    "            level (int): the Deep Zoom level\n",
    "            address (tuple(int)): the address of the tile within the level as a (col, row)\n",
    "                   tuple\n",
    "\n",
    "        Returns:\n",
    "            Image: PIL Image\n",
    "        \"\"\"\n",
    "        args, z_size = self._get_tile_info(level, address)\n",
    "\n",
    "        tile = self._cucim_slide.read_region(\n",
    "            location=args[0],\n",
    "            level=args[1],\n",
    "            size=args[2],\n",
    "        )\n",
    "        tile = Image.fromarray(np.array(tile), mode=\"RGB\")  # CuImage is RGB\n",
    "\n",
    "        # Scale to the correct size\n",
    "        if tile.size != z_size:\n",
    "            # Image.Resampling added in Pillow 9.1.0\n",
    "            # Image.LANCZOS removed in Pillow 10\n",
    "            tile.thumbnail(z_size, getattr(Image, \"Resampling\", Image).LANCZOS)\n",
    "\n",
    "        return tile\n",
    "\n",
    "class WSI_Analyzer:\n",
    "    def __init__(self, input_location, save_location, patch_size, mag_extract):\n",
    "        self.save_location = save_location\n",
    "        self.mag_extract = mag_extract  # specify which magnification you wish to pull images from - ONLY SUPPORTS SINGLE MAG\n",
    "        self.patch_size = patch_size  # specify image size to be saved at specified magnification\n",
    "        self.pixel_overlap = 0  # specify the level of pixel overlap in your saved images\n",
    "        self.runlist = input_location\n",
    "        self.limit_bounds = True\n",
    "        self.tiff_lvl = 2\n",
    "\n",
    "    @staticmethod\n",
    "    def whitespace_check(im):\n",
    "        '''\n",
    "        checks amount of whitespace in image\n",
    "        :param im:\n",
    "        :return: float: proportion of image covered in whitespace\n",
    "        '''\n",
    "        bw = im.convert('L')\n",
    "        bw = np.array(bw)\n",
    "        bw = bw.astype('float')\n",
    "        bw = bw / 255\n",
    "        prop_ws = (bw > 0.8).sum() / (bw > 0).sum()\n",
    "        return prop_ws\n",
    "\n",
    "    @staticmethod\n",
    "    def mask2polygons(mask, scale):\n",
    "        '''\n",
    "        converts binary tissue segmentation mask to ROI\n",
    "        :param mask: binary mask image\n",
    "        :param scale: factor by which to scale coordinates (to match base magnification level)\n",
    "        :return: Polygon representing masked region of interest\n",
    "        '''\n",
    "        # find contours from binary mask\n",
    "        contours, _ = cv2.findContours(mask.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # create polygons from cotours\n",
    "        polygons = []\n",
    "        for contour in tqdm(contours):\n",
    "            cvals = contour.transpose(0, 2, 1)\n",
    "            cvals = np.reshape(cvals, (cvals.shape[0], 2))\n",
    "            cvals = cvals.astype('float64')\n",
    "            for i in range(len(cvals)):\n",
    "                cvals[i][0] = np.round(cvals[i][0] * scale[0], 2)\n",
    "                cvals[i][1] = np.round(cvals[i][1] * scale[1], 2)\n",
    "            try:\n",
    "                if cvals.shape[0] > 2:\n",
    "                    poly = Polygon(cvals).buffer(0)\n",
    "                    if poly.area > 100000:\n",
    "                        polygons.append(poly)\n",
    "            except Exception as error:\n",
    "                print(\"error occured: \", error)\n",
    "        print(\"generated polygons...\")\n",
    "\n",
    "        return polygons\n",
    "\n",
    "    def segmentTissue(self, img):\n",
    "        ''' create tissue mask '''\n",
    "\n",
    "        # get he image and find tissue mask\n",
    "        he = img.read_region((0, 0),  len(img.level_dimensions) - 1, img.level_dimensions[-1]).convert('RGB')\n",
    "        # he = he[:, :, 0:3]\n",
    "        heHSV = cv2.cvtColor(np.array(he), cv2.COLOR_RGB2HSV)\n",
    "        he_blur = cv2.medianBlur(heHSV[:, :, 1], 7)  # Apply median blurring\n",
    "\n",
    "        _, he_otsu = cv2.threshold(he_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        # imagem = cv2.bitwise_not(he_otsu)\n",
    "        # Morphological closing\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        he_otsu = cv2.morphologyEx(he_otsu, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        scale = (img.level_downsamples[-1], img.level_downsamples[-1])\n",
    "\n",
    "        return self.mask2polygons(he_otsu, scale)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def measure_overlap(tile_starts, tile_ends, roi):\n",
    "        ''' calculates overlap of tile with ROI regions '''\n",
    "        tile_box = [tile_starts[0], tile_starts[1]], [tile_starts[0], tile_ends[1]], [tile_ends[0], tile_starts[1]], [\n",
    "            tile_ends[0], tile_ends[1]]\n",
    "        tile_box = list(tile_box)\n",
    "        tile_box = MultiPoint(tile_box).convex_hull\n",
    "        ov = 0  # initialize\n",
    "        if tile_box.intersects(roi):\n",
    "            # box_label = True\n",
    "            ov_reg = tile_box.intersection(roi)\n",
    "            ov += ov_reg.area / tile_box.area\n",
    "        return ov\n",
    "\n",
    "    @staticmethod\n",
    "    def save_hdf5(output_path, asset_dict, attr_dict=None, mode='w'):\n",
    "        '''\n",
    "        saves data to h5py format\n",
    "        :param output_path: path to output h5py file\n",
    "        :param asset_dict: dictionary containing the data\n",
    "        :param attr_dict:\n",
    "        :param mode:\n",
    "        :return:\n",
    "        '''\n",
    "        file = h5py.File(output_path, mode)\n",
    "        for key, val in asset_dict.items():\n",
    "            #print(key)\n",
    "            data_shape = val.shape\n",
    "            if key not in file:\n",
    "                data_type = val.dtype\n",
    "                chunk_shape = (1,) + data_shape[1:]\n",
    "                maxshape = (None,) + data_shape[1:]\n",
    "                try:\n",
    "                    dset = file.create_dataset(key, shape=data_shape, maxshape=maxshape, chunks=chunk_shape,dtype=data_type)\n",
    "                except:\n",
    "                    import pdb; pdb.set_trace()\n",
    "                dset[:] = val\n",
    "                if attr_dict is not None:\n",
    "                    if key in attr_dict.keys():\n",
    "                        print(key)\n",
    "                        for attr_key, attr_val in attr_dict[key].items():\n",
    "                            dset.attrs[attr_key] = attr_val\n",
    "        file.close()\n",
    "        print(\"finished writing to hdf5 file...\")\n",
    "        return output_path\n",
    "\n",
    "    def create_patches_openslide(self, save_data = True):\n",
    "        \"\"\"\n",
    "        Tesselate whole slide image into tiles and extract features for weakly supervised learning. Uses Bioformats in backend\n",
    "        Uses bioformats image reader as backend for reading large WSIs\n",
    "        :param use_annotations: if true, selects tiles from user-defined ROIs. Else selects tiles from entire tissue\n",
    "        :param save_data: if true, saves extracted features to h5 format\n",
    "        :return: {coords: [Nx2], features: [NxD]}. N: number of tiles analyzed. D: feature embedding dimension\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.save_location):\n",
    "            os.mkdir(self.save_location)\n",
    "\n",
    "        flist = sorted(glob.glob(self.runlist + '/*.*'))\n",
    "\n",
    "        ############ PARSE METADATA ############\n",
    "        for _file in flist:\n",
    "            print(_file)\n",
    "            oslide = OpenSlide(_file)\n",
    "            savnm = os.path.basename(_file)\n",
    "            save_name = str(Path(savnm).with_suffix(''))\n",
    "            if not os.path.isfile(os.path.join(self.save_location, save_name + \".hdf5\")):\n",
    "                try:\n",
    "                    # this is physical microns per pixel\n",
    "                    acq_mag = 10.0 / float(oslide.properties[openslide.PROPERTY_NAME_MPP_X])\n",
    "                except:\n",
    "                    try:\n",
    "                        acq_mag = 10.0 / (10000 / float(oslide.properties['tiff.XResolution']))\n",
    "                    except:\n",
    "                        print('MPP metadata missing. aborting')\n",
    "                        return\n",
    "\n",
    "                # this is nearest multiple of 20 for base layer\n",
    "                base_mag = int(20 * round(float(acq_mag) / 20))\n",
    "\n",
    "                # this is how much we need to resample our physical patches for uniformity across studies\n",
    "                physSize = round(self.patch_size * acq_mag / base_mag)\n",
    "\n",
    "                # grab tiles accounting for the physical size we need to pull for standardized tile size across studies\n",
    "                try:\n",
    "                    oslide_cu = CuImage(_file)\n",
    "                    tiles = DeepZoomGeneratorCucim(osr=oslide, cucim_slide=oslide_cu,\n",
    "                                                   tile_size=physSize - round(self.pixel_overlap * acq_mag / base_mag),\n",
    "                                                   overlap=round(self.pixel_overlap * acq_mag / base_mag / 2),\n",
    "                                                   limit_bounds=self.limit_bounds)\n",
    "                    print(\"try using cucim first...\")\n",
    "                except RuntimeError:\n",
    "                    tiles = DeepZoomGenerator(osr=oslide,\n",
    "                                              tile_size=physSize - round(self.pixel_overlap * acq_mag / base_mag),\n",
    "                                              overlap=round(self.pixel_overlap * acq_mag / base_mag / 2),\n",
    "                                              limit_bounds=self.limit_bounds)\n",
    "                    print(\"cucim not compatible, using openslide...\")\n",
    "\n",
    "\n",
    "                # calculate the effective magnification at each level of tiles, determined from base magnification\n",
    "                tile_lvls = tuple(base_mag / (tiles._l_z_downsamples[i] * tiles._l0_l_downsamples[tiles._slide_from_dz_level[i]]) for i in range(0, tiles.level_count))\n",
    "\n",
    "                ########### SELECT & PROCESS TILES ##############\n",
    "                wsi_coords = []\n",
    "                lvl = self.mag_extract\n",
    "                if lvl in tile_lvls:\n",
    "                    # send to get tissue polygons\n",
    "                    try:\n",
    "                        print('detecting tissue...')\n",
    "                        tissue = unary_union(self.segmentTissue(oslide))\n",
    "                    except:\n",
    "                        print('tissue not found or too much ink on slide')\n",
    "                        return\n",
    "                    x_tiles, y_tiles = tiles.level_tiles[tile_lvls.index(lvl)]\n",
    "                    print('creating tiles...')\n",
    "                    for y in tqdm(range(0, y_tiles)):\n",
    "                        for x in range(0, x_tiles):\n",
    "                            tile_coords = tiles.get_tile_coordinates(tile_lvls.index(lvl), (x, y))\n",
    "                            tile_ends = (\n",
    "                                int(tile_coords[0][0] + tiles._l0_l_downsamples[tile_coords[1]] * tile_coords[2][0]),\n",
    "                                int(tile_coords[0][1] + tiles._l0_l_downsamples[tile_coords[1]] * tile_coords[2][1]))\n",
    "                            # measure overlap between tile and annotation\n",
    "                            ov = self.measure_overlap(tile_starts=tile_coords[0], tile_ends=tile_ends, roi=tissue)\n",
    "                            # normally we only pull boxes that have a > 25% overlap\n",
    "                            if ov > 0.9:\n",
    "                                tile_pull = tiles.get_tile(tile_lvls.index(lvl), (x, y))\n",
    "                                # resample =PIL.Image.Resampling.LANCZOS for PIL v2.xx +, ANTIALIAS for v1.xx\n",
    "                                # 20x here is 256x256 patch size resize output after extract at 128x128, 40x is just original patch size\n",
    "                                tile_pull = tile_pull.resize(size=(self.patch_size, self.patch_size),\n",
    "                                                             resample=Image.Resampling.LANCZOS)\n",
    "                                ws = self.whitespace_check(im=tile_pull)\n",
    "                                if ws < 0.95:\n",
    "                                    try:\n",
    "                                        wsi_coords.append(tile_coords[0])\n",
    "                                    except Exception as error:\n",
    "                                        print(\"error normalizing H&E stains... going to next image\")\n",
    "                                        print(\"error msg: \", error)\n",
    "                                        continue\n",
    "                if len(wsi_coords) >0:\n",
    "                    asset_dict = {'coords': np.vstack(wsi_coords)}\n",
    "                    attr = {'patch_size': 256,  # To be considered...\n",
    "                            'patch_level': lvl,\n",
    "                            'downsample': round(acq_mag / self.mag_extract),\n",
    "                            'level_dim': (x_tiles, y_tiles),\n",
    "                            'name': save_name,\n",
    "                            'save_path': self.save_location}\n",
    "\n",
    "                    attr_dict = {'coords': attr}\n",
    "\n",
    "                    if save_data:\n",
    "                        self.save_hdf5(os.path.join(self.save_location, save_name + '.hdf5'),\n",
    "                                       asset_dict=asset_dict, attr_dict=attr_dict)\n",
    "                else:\n",
    "                    print(\"WARNING: YOU ENTERED AN INCORRECT MAGNIFICATION LEVEL\")\n",
    "\n",
    "            else:\n",
    "                print(\"file already preprocessed... moving to next one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d9fece8-6b74-4fba-a513-424c99479247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/test_input/OPX_001.tif\n",
      "cucim not compatible, using openslide...\n",
      "detecting tissue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 5/5 [00:00<00:00, 104.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated polygons...\n",
      "creating tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 39/39 [00:02<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords\n",
      "finished writing to hdf5 file...\n",
      "/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/test_input/OPX_002.tif\n",
      "cucim not compatible, using openslide...\n",
      "detecting tissue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 4/4 [00:00<00:00, 869.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated polygons...\n",
      "creating tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 82/82 [00:03<00:00, 26.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords\n",
      "finished writing to hdf5 file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     # change to BCMC or UW folder\n",
    "#     parser.add_argument('--by_folder', default=\"/raid/hzhang/Bladder_data/FHCRC/june-2024/slides\", type=str)\n",
    "#     parser.add_argument('--mag', type=int, default=20, help='WSI magnification level')\n",
    "#     parser.add_argument('--patch_size', type=int, default=256, help='size of WSI image patches')\n",
    "#     parser.add_argument('--save_location', type = str, default = \"/raid/hzhang/Bladder_data/FHCRC/patch_20_256/patches\", help='directory to save each patch')\n",
    "#     # add model path for cancer detection\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "input_loc = \"/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/test_input/\"\n",
    "output_loc = \"/fh/scratch/delete90/etzioni_r/lucas_l/michael_project/mutation_pred/intermediate_data/harry_code_output/extracted_patches/\"\n",
    "mag_level = 20\n",
    "p_size = 250\n",
    "\n",
    "########### INITIALIZE WSI ANALYZER ###############\n",
    "wsi_analyzer = WSI_Analyzer(input_location = input_loc, save_location=output_loc, mag_extract=mag_level, patch_size=p_size)\n",
    "\n",
    "############ RUN FEATURE EXTRACTION ################\n",
    "wsi_analyzer.create_patches_openslide()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
